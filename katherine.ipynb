{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(112358)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from random import randint \n",
    "\n",
    "from sklearn import tree\n",
    "%matplotlib inline\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "pd.set_option('display.width', 1500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Track ID</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Duration_ms</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Key</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time Signature</th>\n",
       "      <th>Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Lennon</td>\n",
       "      <td>Happy Xmas (War Is Over) - Remastered</td>\n",
       "      <td>3zJw3rugfpVrmBeDDnUYzy</td>\n",
       "      <td>85</td>\n",
       "      <td>0.31900</td>\n",
       "      <td>0.328</td>\n",
       "      <td>213880.0</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>-11.076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>146.539</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bruno Mars</td>\n",
       "      <td>Just the Way You Are</td>\n",
       "      <td>7BqBn9nzAq8spo5e7cZ0dJ</td>\n",
       "      <td>81</td>\n",
       "      <td>0.01510</td>\n",
       "      <td>0.637</td>\n",
       "      <td>220733.0</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0876</td>\n",
       "      <td>-5.413</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>109.012</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train</td>\n",
       "      <td>Hey, Soul Sister</td>\n",
       "      <td>4HlFJV71xXKIGcU3kRyttv</td>\n",
       "      <td>83</td>\n",
       "      <td>0.18500</td>\n",
       "      <td>0.673</td>\n",
       "      <td>216773.0</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0826</td>\n",
       "      <td>-4.440</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0431</td>\n",
       "      <td>97.012</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waka Flocka Flame</td>\n",
       "      <td>No Hands (feat. Roscoe Dash &amp; Wale)</td>\n",
       "      <td>03tqyYWC9Um2ZqU0ZN849H</td>\n",
       "      <td>75</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.760</td>\n",
       "      <td>263773.0</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>-6.366</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>131.497</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>POWER</td>\n",
       "      <td>2gZUPNdnz5Y45eiGxpHGSc</td>\n",
       "      <td>79</td>\n",
       "      <td>0.01620</td>\n",
       "      <td>0.543</td>\n",
       "      <td>292093.0</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7440</td>\n",
       "      <td>-4.746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>153.998</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Artist                             Track Name                Track ID  Popularity  Acousticness  Danceability  Duration_ms  Energy  Instrumentalness  Key  Liveness  Loudness  Mode  Speechiness    Tempo  Time Signature  Valence\n",
       "0        John Lennon  Happy Xmas (War Is Over) - Remastered  3zJw3rugfpVrmBeDDnUYzy          85       0.31900         0.328     213880.0   0.607               0.0  2.0    0.7650   -11.076   1.0       0.0315  146.539             3.0    0.395\n",
       "1         Bruno Mars                   Just the Way You Are  7BqBn9nzAq8spo5e7cZ0dJ          81       0.01510         0.637     220733.0   0.843               0.0  5.0    0.0876    -5.413   1.0       0.0432  109.012             4.0    0.434\n",
       "2              Train                       Hey, Soul Sister  4HlFJV71xXKIGcU3kRyttv          83       0.18500         0.673     216773.0   0.886               0.0  1.0    0.0826    -4.440   0.0       0.0431   97.012             4.0    0.795\n",
       "3  Waka Flocka Flame    No Hands (feat. Roscoe Dash & Wale)  03tqyYWC9Um2ZqU0ZN849H          75       0.00544         0.760     263773.0   0.595               0.0  1.0    0.2410    -6.366   1.0       0.0391  131.497             4.0    0.361\n",
       "4         Kanye West                                  POWER  2gZUPNdnz5Y45eiGxpHGSc          79       0.01620         0.543     292093.0   0.915               0.0  0.0    0.7440    -4.746   0.0       0.1130  153.998             4.0    0.577"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all songs\n",
    "songs_df = pd.read_csv('data/songs_all_decade_clean.csv')\n",
    "songs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Duration_ms</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Key</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time Signature</th>\n",
       "      <th>Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>88554.000000</td>\n",
       "      <td>88554.000000</td>\n",
       "      <td>88554.000000</td>\n",
       "      <td>88554.000000</td>\n",
       "      <td>88554.000000</td>\n",
       "      <td>88554.000000</td>\n",
       "      <td>88554.000000</td>\n",
       "      <td>88554.000000</td>\n",
       "      <td>88554.000000</td>\n",
       "      <td>88554.000000</td>\n",
       "      <td>88554.000000</td>\n",
       "      <td>88554.000000</td>\n",
       "      <td>88554.000000</td>\n",
       "      <td>88554.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49.006708</td>\n",
       "      <td>0.311873</td>\n",
       "      <td>0.577886</td>\n",
       "      <td>220548.322538</td>\n",
       "      <td>0.600973</td>\n",
       "      <td>0.135175</td>\n",
       "      <td>5.203255</td>\n",
       "      <td>0.189423</td>\n",
       "      <td>-8.324528</td>\n",
       "      <td>0.652991</td>\n",
       "      <td>0.095061</td>\n",
       "      <td>120.630076</td>\n",
       "      <td>3.896662</td>\n",
       "      <td>0.449532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.237356</td>\n",
       "      <td>0.330381</td>\n",
       "      <td>0.176493</td>\n",
       "      <td>68945.507097</td>\n",
       "      <td>0.249771</td>\n",
       "      <td>0.297049</td>\n",
       "      <td>3.589677</td>\n",
       "      <td>0.156954</td>\n",
       "      <td>5.528754</td>\n",
       "      <td>0.476021</td>\n",
       "      <td>0.098324</td>\n",
       "      <td>30.252905</td>\n",
       "      <td>0.431127</td>\n",
       "      <td>0.249264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053200</td>\n",
       "      <td>20139.000000</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009360</td>\n",
       "      <td>-54.837000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>33.506000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>182866.250000</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.097600</td>\n",
       "      <td>-9.510000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>96.032000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.247000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>214293.000000</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.124000</td>\n",
       "      <td>-6.737000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>120.014000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.429000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.557000</td>\n",
       "      <td>0.709000</td>\n",
       "      <td>249997.750000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.231000</td>\n",
       "      <td>-4.987000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>140.052000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.637000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.987000</td>\n",
       "      <td>599746.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.998000</td>\n",
       "      <td>1.593000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659000</td>\n",
       "      <td>220.169000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Popularity  Acousticness  Danceability    Duration_ms        Energy  Instrumentalness           Key      Liveness      Loudness          Mode   Speechiness         Tempo  Time Signature       Valence\n",
       "count  88554.000000  88554.000000  88554.000000   88554.000000  88554.000000      88554.000000  88554.000000  88554.000000  88554.000000  88554.000000  88554.000000  88554.000000    88554.000000  88554.000000\n",
       "mean      49.006708      0.311873      0.577886  220548.322538      0.600973          0.135175      5.203255      0.189423     -8.324528      0.652991      0.095061    120.630076        3.896662      0.449532\n",
       "std       13.237356      0.330381      0.176493   68945.507097      0.249771          0.297049      3.589677      0.156954      5.528754      0.476021      0.098324     30.252905        0.431127      0.249264\n",
       "min        0.000000      0.000000      0.053200   20139.000000      0.000020          0.000000      0.000000      0.009360    -54.837000      0.000000      0.022400     33.506000        0.000000      0.000000\n",
       "25%       41.000000      0.026600      0.465000  182866.250000      0.444000          0.000000      2.000000      0.097600     -9.510000      0.000000      0.036400     96.032000        4.000000      0.247000\n",
       "50%       49.000000      0.170000      0.590000  214293.000000      0.638000          0.000010      5.000000      0.124000     -6.737000      1.000000      0.051300    120.014000        4.000000      0.429000\n",
       "75%       57.000000      0.557000      0.709000  249997.750000      0.800000          0.011300      8.000000      0.231000     -4.987000      1.000000      0.105000    140.052000        4.000000      0.637000\n",
       "max      100.000000      0.996000      0.987000  599746.000000      1.000000          1.000000     11.000000      0.998000      1.593000      1.000000      0.659000    220.169000        5.000000      1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist               object\n",
      "Track Name           object\n",
      "Track ID             object\n",
      "Popularity            int64\n",
      "Acousticness        float64\n",
      "Danceability        float64\n",
      "Duration_ms         float64\n",
      "Energy              float64\n",
      "Instrumentalness    float64\n",
      "Key                 float64\n",
      "Liveness            float64\n",
      "Loudness            float64\n",
      "Mode                float64\n",
      "Speechiness         float64\n",
      "Tempo               float64\n",
      "Time Signature      float64\n",
      "Valence             float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# calculate summary statistics\n",
    "display(songs_df.describe())\n",
    "\n",
    "# print out variable types\n",
    "print(songs_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix of pairwise scatterplots\n",
    "scatter_matrix(songs_df, alpha = 0.8, figsize = (30, 20), diagonal = 'kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new binary response variable 'tophit'\n",
    "# classify as top hit if popularity > 60 (about halfway split)\n",
    "songs_df['tophit'] = np.where(songs_df['Popularity'] > 60, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for modeling\n",
    "songs_df_clean = songs_df.drop(columns = ['Artist', 'Track Name', 'Track ID', 'Popularity'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(songs_df_clean.loc[:, songs_df_clean.columns != 'tophit'], \n",
    "                                                    songs_df_clean.tophit, test_size = 0.2, \n",
    "                                                    random_state = 100, stratify = songs_df_clean.tophit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit cross-validated single decision tree\n",
    "depths = list(range(1, 21))\n",
    "\n",
    "def calc_meanstd(X_train, y_train, depths):\n",
    "    cvmeans = {}\n",
    "    cvstds = {}\n",
    "    train_scores = {}\n",
    "    for i in depths:\n",
    "        model = DecisionTreeClassifier(max_depth = i)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_train)\n",
    "        # get training set scores\n",
    "        train_scores[i] = accuracy_score(y_train, y_pred)\n",
    "        # get cross-validation scores\n",
    "        score = cross_val_score(estimator = model, X = X_train, y = y_train, cv = 5, n_jobs = -1)\n",
    "        cvmeans[i] = score.mean()\n",
    "        cvstds[i] = score.std()\n",
    "    return cvmeans, cvstds, train_scores\n",
    "\n",
    "cvmeans, cvstds, train_scores = calc_meanstd(X_train, y_train, depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best depth: 3\n",
      "Classification accuracy on training set: 0.645\n",
      "Classification accuracy on test set: 0.6395\n"
     ]
    }
   ],
   "source": [
    "# report best tree depth from cross-validation\n",
    "best_depth = sorted(cvmeans, key = cvmeans.get, reverse = True)[0]\n",
    "print('Best depth:', best_depth)\n",
    "\n",
    "# refit on best tree depth, then report classification accuracies\n",
    "best_model = DecisionTreeClassifier(max_depth = best_depth)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "best_cv_tree_train_score = accuracy_score(y_train, y_train_pred)\n",
    "print('Classification accuracy on training set:', best_cv_tree_train_score)\n",
    "\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "best_cv_tree_test_score = accuracy_score(y_test, y_test_pred)\n",
    "print('Classification accuracy on test set:', best_cv_tree_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Key', 'Time Signature', 'Mode']\n",
    "X_train_num = X_train.drop(cat_cols, axis = 1)\n",
    "X_test_num = X_test.drop(cat_cols, axis = 1)\n",
    "num_features = X_train_num.columns.tolist()\n",
    "num_index_train = X_train.index.tolist()\n",
    "num_index_test = X_test.index.tolist()\n",
    "\n",
    "# X_train_dum = pd.get_dummies(X_train[cat_cols], columns = cat_cols)\n",
    "# X_test_dum = pd.get_dummies(X_test[cat_cols], columns = cat_cols)\n",
    "X_train_dum = X_train[cat_cols]\n",
    "X_test_dum = X_test[cat_cols]\n",
    "\n",
    "scaler = StandardScaler().fit(X_train_num)\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(X_train_num), index = num_index_train, columns = num_features)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test_num), index = num_index_test, columns = num_features)\n",
    "\n",
    "X_train = pd.concat([X_train_dum, X_train_scaled], axis = 1)\n",
    "X_test = pd.concat([X_test_dum, X_test_scaled], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Time Signature</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Duration_ms</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42751</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.943781</td>\n",
       "      <td>-0.726754</td>\n",
       "      <td>0.477700</td>\n",
       "      <td>1.501201</td>\n",
       "      <td>-0.453331</td>\n",
       "      <td>-0.268879</td>\n",
       "      <td>0.665365</td>\n",
       "      <td>1.218310</td>\n",
       "      <td>0.636980</td>\n",
       "      <td>-0.728170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34498</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.898434</td>\n",
       "      <td>-2.211738</td>\n",
       "      <td>0.149377</td>\n",
       "      <td>-1.905981</td>\n",
       "      <td>-0.435899</td>\n",
       "      <td>-0.428016</td>\n",
       "      <td>-0.875771</td>\n",
       "      <td>-0.523018</td>\n",
       "      <td>1.962243</td>\n",
       "      <td>-1.337873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23353</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.802075</td>\n",
       "      <td>-1.049823</td>\n",
       "      <td>-0.699669</td>\n",
       "      <td>0.855841</td>\n",
       "      <td>-0.452488</td>\n",
       "      <td>-0.237052</td>\n",
       "      <td>0.549816</td>\n",
       "      <td>2.427988</td>\n",
       "      <td>2.026887</td>\n",
       "      <td>-0.952797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34136</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.865138</td>\n",
       "      <td>0.684547</td>\n",
       "      <td>-0.011866</td>\n",
       "      <td>-1.376866</td>\n",
       "      <td>-0.453668</td>\n",
       "      <td>-0.603703</td>\n",
       "      <td>-0.354985</td>\n",
       "      <td>-0.558597</td>\n",
       "      <td>-0.291994</td>\n",
       "      <td>-0.278914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79175</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.443941</td>\n",
       "      <td>0.412489</td>\n",
       "      <td>0.235791</td>\n",
       "      <td>0.366810</td>\n",
       "      <td>-0.453668</td>\n",
       "      <td>0.927829</td>\n",
       "      <td>0.650854</td>\n",
       "      <td>-0.586043</td>\n",
       "      <td>-0.057313</td>\n",
       "      <td>-0.230780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  Time Signature  Mode  Acousticness  Danceability  Duration_ms    Energy  Instrumentalness  Liveness  Loudness  Speechiness     Tempo   Valence\n",
       "42751  1.0             4.0   1.0     -0.943781     -0.726754     0.477700  1.501201         -0.453331 -0.268879  0.665365     1.218310  0.636980 -0.728170\n",
       "34498  1.0             3.0   1.0      1.898434     -2.211738     0.149377 -1.905981         -0.435899 -0.428016 -0.875771    -0.523018  1.962243 -1.337873\n",
       "23353  2.0             3.0   1.0     -0.802075     -1.049823    -0.699669  0.855841         -0.452488 -0.237052  0.549816     2.427988  2.026887 -0.952797\n",
       "34136  8.0             3.0   1.0      0.865138      0.684547    -0.011866 -1.376866         -0.453668 -0.603703 -0.354985    -0.558597 -0.291994 -0.278914\n",
       "79175  4.0             4.0   1.0      0.443941      0.412489     0.235791  0.366810         -0.453668  0.927829  0.650854    -0.586043 -0.057313 -0.230780"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 49590 samples, validate on 21253 samples\n",
      "Epoch 1/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.4481 - accuracy: 0.8224 - val_loss: 0.4404 - val_accuracy: 0.8233\n",
      "Epoch 2/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 0.4314 - accuracy: 0.8267 - val_loss: 0.4388 - val_accuracy: 0.8233\n",
      "Epoch 3/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.4274 - accuracy: 0.8268 - val_loss: 0.4365 - val_accuracy: 0.8233\n",
      "Epoch 4/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.4254 - accuracy: 0.8266 - val_loss: 0.4382 - val_accuracy: 0.8234\n",
      "Epoch 5/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.4238 - accuracy: 0.8266 - val_loss: 0.4379 - val_accuracy: 0.8228\n",
      "Epoch 6/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4223 - accuracy: 0.8267 - val_loss: 0.4344 - val_accuracy: 0.8236\n",
      "Epoch 7/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4216 - accuracy: 0.8265 - val_loss: 0.4359 - val_accuracy: 0.8234\n",
      "Epoch 8/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.4197 - accuracy: 0.8265 - val_loss: 0.4364 - val_accuracy: 0.8229\n",
      "Epoch 9/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.4191 - accuracy: 0.8268 - val_loss: 0.4340 - val_accuracy: 0.8231\n",
      "Epoch 10/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.4170 - accuracy: 0.8271 - val_loss: 0.4370 - val_accuracy: 0.8229\n",
      "Epoch 11/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4166 - accuracy: 0.8272 - val_loss: 0.4364 - val_accuracy: 0.8239\n",
      "Epoch 12/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4147 - accuracy: 0.8271 - val_loss: 0.4363 - val_accuracy: 0.8221\n",
      "Epoch 13/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.4142 - accuracy: 0.8278 - val_loss: 0.4412 - val_accuracy: 0.8227\n",
      "Epoch 14/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4125 - accuracy: 0.8279 - val_loss: 0.4361 - val_accuracy: 0.8230\n",
      "Epoch 15/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.4097 - accuracy: 0.8285 - val_loss: 0.4382 - val_accuracy: 0.8222\n",
      "Epoch 16/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.4088 - accuracy: 0.8294 - val_loss: 0.4380 - val_accuracy: 0.8232\n",
      "Epoch 17/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.4065 - accuracy: 0.8299 - val_loss: 0.4453 - val_accuracy: 0.8218\n",
      "Epoch 18/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.4053 - accuracy: 0.8298 - val_loss: 0.4454 - val_accuracy: 0.8206\n",
      "Epoch 19/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.4029 - accuracy: 0.8306 - val_loss: 0.4459 - val_accuracy: 0.8202\n",
      "Epoch 20/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4011 - accuracy: 0.8316 - val_loss: 0.4409 - val_accuracy: 0.8200\n",
      "Epoch 21/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.3990 - accuracy: 0.8313 - val_loss: 0.4486 - val_accuracy: 0.8169\n",
      "Epoch 22/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.3967 - accuracy: 0.8328 - val_loss: 0.4458 - val_accuracy: 0.8220\n",
      "Epoch 23/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.3952 - accuracy: 0.8326 - val_loss: 0.4558 - val_accuracy: 0.8153\n",
      "Epoch 24/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.3916 - accuracy: 0.8341 - val_loss: 0.4599 - val_accuracy: 0.8206\n",
      "Epoch 25/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.3896 - accuracy: 0.8347 - val_loss: 0.4625 - val_accuracy: 0.8127\n",
      "Epoch 26/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.3872 - accuracy: 0.8351 - val_loss: 0.4568 - val_accuracy: 0.8190\n",
      "Epoch 27/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.3851 - accuracy: 0.8353 - val_loss: 0.4585 - val_accuracy: 0.8173\n",
      "Epoch 28/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.3822 - accuracy: 0.8371 - val_loss: 0.4715 - val_accuracy: 0.8148\n",
      "Epoch 29/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.3793 - accuracy: 0.8385 - val_loss: 0.4720 - val_accuracy: 0.8077\n",
      "Epoch 30/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.3770 - accuracy: 0.8381 - val_loss: 0.4806 - val_accuracy: 0.8106\n",
      "Epoch 31/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.3733 - accuracy: 0.8410 - val_loss: 0.4824 - val_accuracy: 0.8123\n",
      "Epoch 32/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.3705 - accuracy: 0.8417 - val_loss: 0.4833 - val_accuracy: 0.8147\n",
      "Epoch 33/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.3679 - accuracy: 0.8423 - val_loss: 0.4875 - val_accuracy: 0.8131\n",
      "Epoch 34/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.3636 - accuracy: 0.8448 - val_loss: 0.4967 - val_accuracy: 0.8102\n",
      "Epoch 35/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.3615 - accuracy: 0.8447 - val_loss: 0.4969 - val_accuracy: 0.8084\n",
      "Epoch 36/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.3577 - accuracy: 0.8464 - val_loss: 0.5053 - val_accuracy: 0.8031\n",
      "Epoch 37/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.3543 - accuracy: 0.8470 - val_loss: 0.5126 - val_accuracy: 0.8084\n",
      "Epoch 38/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.3526 - accuracy: 0.8483 - val_loss: 0.5147 - val_accuracy: 0.7989\n",
      "Epoch 39/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.3487 - accuracy: 0.8496 - val_loss: 0.5107 - val_accuracy: 0.8015\n",
      "Epoch 40/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.3450 - accuracy: 0.8510 - val_loss: 0.5262 - val_accuracy: 0.8064\n",
      "Epoch 41/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.3433 - accuracy: 0.8524 - val_loss: 0.5300 - val_accuracy: 0.7960\n",
      "Epoch 42/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.3380 - accuracy: 0.8543 - val_loss: 0.5343 - val_accuracy: 0.7914\n",
      "Epoch 43/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.3350 - accuracy: 0.8558 - val_loss: 0.5458 - val_accuracy: 0.7894\n",
      "Epoch 44/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.3328 - accuracy: 0.8574 - val_loss: 0.5527 - val_accuracy: 0.8061\n",
      "Epoch 45/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.3292 - accuracy: 0.8586 - val_loss: 0.5586 - val_accuracy: 0.7961\n",
      "Epoch 46/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.3261 - accuracy: 0.8592 - val_loss: 0.5631 - val_accuracy: 0.7959\n",
      "Epoch 47/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.3248 - accuracy: 0.8588 - val_loss: 0.5616 - val_accuracy: 0.7984\n",
      "Epoch 48/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.3178 - accuracy: 0.8635 - val_loss: 0.5703 - val_accuracy: 0.7979\n",
      "Epoch 49/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.3163 - accuracy: 0.8636 - val_loss: 0.5728 - val_accuracy: 0.8004\n",
      "Epoch 50/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.3118 - accuracy: 0.8660 - val_loss: 0.5862 - val_accuracy: 0.7923\n",
      "Epoch 51/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.3097 - accuracy: 0.8673 - val_loss: 0.5947 - val_accuracy: 0.7902\n",
      "Epoch 52/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.3079 - accuracy: 0.8672 - val_loss: 0.6047 - val_accuracy: 0.7932\n",
      "Epoch 53/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.3032 - accuracy: 0.8696 - val_loss: 0.6029 - val_accuracy: 0.7935\n",
      "Epoch 54/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.3010 - accuracy: 0.8705 - val_loss: 0.6112 - val_accuracy: 0.7915\n",
      "Epoch 55/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.2971 - accuracy: 0.8720 - val_loss: 0.6229 - val_accuracy: 0.7968\n",
      "Epoch 56/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.2956 - accuracy: 0.8732 - val_loss: 0.6259 - val_accuracy: 0.7895\n",
      "Epoch 57/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.2912 - accuracy: 0.8756 - val_loss: 0.6327 - val_accuracy: 0.7906\n",
      "Epoch 58/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.2888 - accuracy: 0.8756 - val_loss: 0.6484 - val_accuracy: 0.7852\n",
      "Epoch 59/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.2852 - accuracy: 0.8771 - val_loss: 0.6503 - val_accuracy: 0.7815\n",
      "Epoch 60/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.2844 - accuracy: 0.8770 - val_loss: 0.6456 - val_accuracy: 0.7913\n",
      "Epoch 61/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.2779 - accuracy: 0.8800 - val_loss: 0.6593 - val_accuracy: 0.7789\n",
      "Epoch 62/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.2774 - accuracy: 0.8804 - val_loss: 0.6751 - val_accuracy: 0.7710\n",
      "Epoch 63/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.2720 - accuracy: 0.8834 - val_loss: 0.6636 - val_accuracy: 0.7744\n",
      "Epoch 64/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.2711 - accuracy: 0.8834 - val_loss: 0.6778 - val_accuracy: 0.7791\n",
      "Epoch 65/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.2696 - accuracy: 0.8854 - val_loss: 0.6870 - val_accuracy: 0.7771\n",
      "Epoch 66/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.2676 - accuracy: 0.8849 - val_loss: 0.6988 - val_accuracy: 0.7780\n",
      "Epoch 67/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.2624 - accuracy: 0.8875 - val_loss: 0.7030 - val_accuracy: 0.7812\n",
      "Epoch 68/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.2584 - accuracy: 0.8897 - val_loss: 0.7342 - val_accuracy: 0.7813\n",
      "Epoch 69/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.2571 - accuracy: 0.8883 - val_loss: 0.7336 - val_accuracy: 0.7732\n",
      "Epoch 70/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.2544 - accuracy: 0.8898 - val_loss: 0.7270 - val_accuracy: 0.7757\n",
      "Epoch 71/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.2537 - accuracy: 0.8920 - val_loss: 0.7659 - val_accuracy: 0.7789\n",
      "Epoch 72/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.2509 - accuracy: 0.8920 - val_loss: 0.7450 - val_accuracy: 0.7797\n",
      "Epoch 73/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.2490 - accuracy: 0.8932 - val_loss: 0.7730 - val_accuracy: 0.7801\n",
      "Epoch 74/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.2449 - accuracy: 0.8943 - val_loss: 0.7717 - val_accuracy: 0.7750\n",
      "Epoch 75/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.2414 - accuracy: 0.8969 - val_loss: 0.7834 - val_accuracy: 0.7822\n",
      "Epoch 76/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.2363 - accuracy: 0.8998 - val_loss: 0.8153 - val_accuracy: 0.7615\n",
      "Epoch 77/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.2373 - accuracy: 0.8987 - val_loss: 0.7802 - val_accuracy: 0.7721\n",
      "Epoch 78/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.2356 - accuracy: 0.8991 - val_loss: 0.7934 - val_accuracy: 0.7783\n",
      "Epoch 79/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.2292 - accuracy: 0.9022 - val_loss: 0.8232 - val_accuracy: 0.7743\n",
      "Epoch 80/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.2289 - accuracy: 0.9019 - val_loss: 0.8126 - val_accuracy: 0.7777\n",
      "Epoch 81/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.2269 - accuracy: 0.9027 - val_loss: 0.8481 - val_accuracy: 0.7732\n",
      "Epoch 82/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.2303 - accuracy: 0.9033 - val_loss: 0.8264 - val_accuracy: 0.7787\n",
      "Epoch 83/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.2238 - accuracy: 0.9050 - val_loss: 0.8532 - val_accuracy: 0.7660\n",
      "Epoch 84/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.2233 - accuracy: 0.9059 - val_loss: 0.8372 - val_accuracy: 0.7654\n",
      "Epoch 85/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.2184 - accuracy: 0.9065 - val_loss: 0.8755 - val_accuracy: 0.7722\n",
      "Epoch 86/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.2193 - accuracy: 0.9068 - val_loss: 0.8600 - val_accuracy: 0.7556\n",
      "Epoch 87/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.2141 - accuracy: 0.9090 - val_loss: 0.8844 - val_accuracy: 0.7640\n",
      "Epoch 88/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.2147 - accuracy: 0.9097 - val_loss: 0.8941 - val_accuracy: 0.7593\n",
      "Epoch 89/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.2153 - accuracy: 0.9086 - val_loss: 0.8772 - val_accuracy: 0.7702\n",
      "Epoch 90/1000\n",
      "49590/49590 [==============================] - 2s 43us/sample - loss: 0.2111 - accuracy: 0.9101 - val_loss: 0.8982 - val_accuracy: 0.7687\n",
      "Epoch 91/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.2061 - accuracy: 0.9124 - val_loss: 0.9105 - val_accuracy: 0.7663\n",
      "Epoch 92/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.2079 - accuracy: 0.9126 - val_loss: 0.8960 - val_accuracy: 0.7593\n",
      "Epoch 93/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.2037 - accuracy: 0.9144 - val_loss: 0.9298 - val_accuracy: 0.7678\n",
      "Epoch 94/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.2040 - accuracy: 0.9139 - val_loss: 0.9251 - val_accuracy: 0.7702\n",
      "Epoch 95/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.2006 - accuracy: 0.9162 - val_loss: 0.9347 - val_accuracy: 0.7623\n",
      "Epoch 96/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.1984 - accuracy: 0.9158 - val_loss: 0.9472 - val_accuracy: 0.7530\n",
      "Epoch 97/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.2017 - accuracy: 0.9154 - val_loss: 0.9279 - val_accuracy: 0.7521\n",
      "Epoch 98/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1924 - accuracy: 0.9209 - val_loss: 0.9768 - val_accuracy: 0.7610\n",
      "Epoch 99/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1907 - accuracy: 0.9191 - val_loss: 0.9628 - val_accuracy: 0.7593\n",
      "Epoch 100/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1945 - accuracy: 0.9183 - val_loss: 0.9663 - val_accuracy: 0.7573\n",
      "Epoch 101/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1911 - accuracy: 0.9197 - val_loss: 1.0035 - val_accuracy: 0.7532\n",
      "Epoch 102/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1883 - accuracy: 0.9217 - val_loss: 0.9873 - val_accuracy: 0.7744\n",
      "Epoch 103/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1847 - accuracy: 0.9216 - val_loss: 0.9970 - val_accuracy: 0.7648\n",
      "Epoch 104/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1844 - accuracy: 0.9227 - val_loss: 0.9895 - val_accuracy: 0.7635\n",
      "Epoch 105/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1888 - accuracy: 0.9214 - val_loss: 1.0106 - val_accuracy: 0.7568\n",
      "Epoch 106/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1885 - accuracy: 0.9214 - val_loss: 0.9996 - val_accuracy: 0.7610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1788 - accuracy: 0.9250 - val_loss: 1.0403 - val_accuracy: 0.7648\n",
      "Epoch 108/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.1817 - accuracy: 0.9240 - val_loss: 1.0278 - val_accuracy: 0.7570\n",
      "Epoch 109/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1774 - accuracy: 0.9251 - val_loss: 1.0285 - val_accuracy: 0.7554\n",
      "Epoch 110/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1778 - accuracy: 0.9262 - val_loss: 1.0431 - val_accuracy: 0.7619\n",
      "Epoch 111/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.1761 - accuracy: 0.9263 - val_loss: 1.0296 - val_accuracy: 0.7545\n",
      "Epoch 112/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.1776 - accuracy: 0.9253 - val_loss: 1.0679 - val_accuracy: 0.7423\n",
      "Epoch 113/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1713 - accuracy: 0.9279 - val_loss: 1.0810 - val_accuracy: 0.7579\n",
      "Epoch 114/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1726 - accuracy: 0.9292 - val_loss: 1.0954 - val_accuracy: 0.7443\n",
      "Epoch 115/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.1737 - accuracy: 0.9269 - val_loss: 1.0904 - val_accuracy: 0.7496\n",
      "Epoch 116/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.1692 - accuracy: 0.9293 - val_loss: 1.0818 - val_accuracy: 0.7580\n",
      "Epoch 117/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.1674 - accuracy: 0.9300 - val_loss: 1.1118 - val_accuracy: 0.7467\n",
      "Epoch 118/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.1704 - accuracy: 0.9291 - val_loss: 1.1258 - val_accuracy: 0.7622\n",
      "Epoch 119/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.1684 - accuracy: 0.9297 - val_loss: 1.1070 - val_accuracy: 0.7567\n",
      "Epoch 120/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1601 - accuracy: 0.9330 - val_loss: 1.1370 - val_accuracy: 0.7481\n",
      "Epoch 121/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.1657 - accuracy: 0.9311 - val_loss: 1.1190 - val_accuracy: 0.7511\n",
      "Epoch 122/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1620 - accuracy: 0.9317 - val_loss: 1.1515 - val_accuracy: 0.7568\n",
      "Epoch 123/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1641 - accuracy: 0.9317 - val_loss: 1.1524 - val_accuracy: 0.7574\n",
      "Epoch 124/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1597 - accuracy: 0.9342 - val_loss: 1.1635 - val_accuracy: 0.7435\n",
      "Epoch 125/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1607 - accuracy: 0.9330 - val_loss: 1.1526 - val_accuracy: 0.7593\n",
      "Epoch 126/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1599 - accuracy: 0.9340 - val_loss: 1.1343 - val_accuracy: 0.7563\n",
      "Epoch 127/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1617 - accuracy: 0.9337 - val_loss: 1.1648 - val_accuracy: 0.7456\n",
      "Epoch 128/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 0.1502 - accuracy: 0.9381 - val_loss: 1.1696 - val_accuracy: 0.7553\n",
      "Epoch 129/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 0.1529 - accuracy: 0.9361 - val_loss: 1.1734 - val_accuracy: 0.7484\n",
      "Epoch 130/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.1567 - accuracy: 0.9344 - val_loss: 1.2007 - val_accuracy: 0.7361\n",
      "Epoch 131/1000\n",
      "49590/49590 [==============================] - 2s 49us/sample - loss: 0.1591 - accuracy: 0.9342 - val_loss: 1.1805 - val_accuracy: 0.7577\n",
      "Epoch 132/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.1512 - accuracy: 0.9378 - val_loss: 1.1810 - val_accuracy: 0.7616\n",
      "Epoch 133/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.1450 - accuracy: 0.9397 - val_loss: 1.1889 - val_accuracy: 0.7510\n",
      "Epoch 134/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.1483 - accuracy: 0.9390 - val_loss: 1.2027 - val_accuracy: 0.7580\n",
      "Epoch 135/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.1491 - accuracy: 0.9385 - val_loss: 1.2097 - val_accuracy: 0.7536\n",
      "Epoch 136/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.1499 - accuracy: 0.9374 - val_loss: 1.2090 - val_accuracy: 0.7514\n",
      "Epoch 137/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.1441 - accuracy: 0.9402 - val_loss: 1.2198 - val_accuracy: 0.7502\n",
      "Epoch 138/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.1473 - accuracy: 0.9397 - val_loss: 1.2384 - val_accuracy: 0.7469\n",
      "Epoch 139/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.1470 - accuracy: 0.9379 - val_loss: 1.2418 - val_accuracy: 0.7569\n",
      "Epoch 140/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.1474 - accuracy: 0.9378 - val_loss: 1.2424 - val_accuracy: 0.7570\n",
      "Epoch 141/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.1495 - accuracy: 0.9377 - val_loss: 1.2661 - val_accuracy: 0.7611\n",
      "Epoch 142/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.1515 - accuracy: 0.9380 - val_loss: 1.2416 - val_accuracy: 0.7473\n",
      "Epoch 143/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.1368 - accuracy: 0.9443 - val_loss: 1.2518 - val_accuracy: 0.7504\n",
      "Epoch 144/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.1438 - accuracy: 0.9414 - val_loss: 1.2836 - val_accuracy: 0.7431\n",
      "Epoch 145/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.1380 - accuracy: 0.9428 - val_loss: 1.2831 - val_accuracy: 0.7487\n",
      "Epoch 146/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.1393 - accuracy: 0.9433 - val_loss: 1.2921 - val_accuracy: 0.7422\n",
      "Epoch 147/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.1371 - accuracy: 0.9433 - val_loss: 1.2744 - val_accuracy: 0.7441\n",
      "Epoch 148/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.1325 - accuracy: 0.9465 - val_loss: 1.3239 - val_accuracy: 0.7521\n",
      "Epoch 149/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.1441 - accuracy: 0.9410 - val_loss: 1.2980 - val_accuracy: 0.7640\n",
      "Epoch 150/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 0.1442 - accuracy: 0.9421 - val_loss: 1.2942 - val_accuracy: 0.7496\n",
      "Epoch 151/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.1407 - accuracy: 0.9410 - val_loss: 1.2950 - val_accuracy: 0.7380\n",
      "Epoch 152/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.1315 - accuracy: 0.9454 - val_loss: 1.2974 - val_accuracy: 0.7519\n",
      "Epoch 153/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.1335 - accuracy: 0.9456 - val_loss: 1.3402 - val_accuracy: 0.7452\n",
      "Epoch 154/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 0.1394 - accuracy: 0.9431 - val_loss: 1.3253 - val_accuracy: 0.7525\n",
      "Epoch 155/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.1266 - accuracy: 0.9491 - val_loss: 1.3444 - val_accuracy: 0.7503\n",
      "Epoch 156/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.1360 - accuracy: 0.9448 - val_loss: 1.3232 - val_accuracy: 0.7412\n",
      "Epoch 157/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.1270 - accuracy: 0.9484 - val_loss: 1.3701 - val_accuracy: 0.7437\n",
      "Epoch 158/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.1411 - accuracy: 0.9428 - val_loss: 1.3265 - val_accuracy: 0.7530\n",
      "Epoch 159/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.1298 - accuracy: 0.9482 - val_loss: 1.3535 - val_accuracy: 0.7437\n",
      "Epoch 160/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1263 - accuracy: 0.9491 - val_loss: 1.3369 - val_accuracy: 0.7526\n",
      "Epoch 161/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.1308 - accuracy: 0.9459 - val_loss: 1.3421 - val_accuracy: 0.7478\n",
      "Epoch 162/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.1285 - accuracy: 0.9469 - val_loss: 1.3726 - val_accuracy: 0.7478\n",
      "Epoch 163/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1331 - accuracy: 0.9462 - val_loss: 1.3468 - val_accuracy: 0.7545\n",
      "Epoch 164/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1208 - accuracy: 0.9494 - val_loss: 1.4008 - val_accuracy: 0.7501\n",
      "Epoch 165/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1234 - accuracy: 0.9492 - val_loss: 1.3751 - val_accuracy: 0.7607\n",
      "Epoch 166/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1309 - accuracy: 0.9469 - val_loss: 1.4027 - val_accuracy: 0.7513\n",
      "Epoch 167/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1459 - accuracy: 0.9422 - val_loss: 1.3907 - val_accuracy: 0.7438\n",
      "Epoch 168/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1227 - accuracy: 0.9494 - val_loss: 1.3972 - val_accuracy: 0.7471\n",
      "Epoch 169/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1206 - accuracy: 0.9519 - val_loss: 1.4060 - val_accuracy: 0.7525\n",
      "Epoch 170/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1225 - accuracy: 0.9510 - val_loss: 1.3946 - val_accuracy: 0.7508\n",
      "Epoch 171/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.1203 - accuracy: 0.9521 - val_loss: 1.4023 - val_accuracy: 0.7398\n",
      "Epoch 172/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.1298 - accuracy: 0.9478 - val_loss: 1.4030 - val_accuracy: 0.7511\n",
      "Epoch 173/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.1264 - accuracy: 0.9486 - val_loss: 1.4285 - val_accuracy: 0.7582\n",
      "Epoch 174/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.1252 - accuracy: 0.9494 - val_loss: 1.4130 - val_accuracy: 0.7532\n",
      "Epoch 175/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.1260 - accuracy: 0.9496 - val_loss: 1.4122 - val_accuracy: 0.7571\n",
      "Epoch 176/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1166 - accuracy: 0.9527 - val_loss: 1.4338 - val_accuracy: 0.7505\n",
      "Epoch 177/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.1108 - accuracy: 0.9557 - val_loss: 1.4709 - val_accuracy: 0.7539\n",
      "Epoch 178/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.1177 - accuracy: 0.9533 - val_loss: 1.4241 - val_accuracy: 0.7489\n",
      "Epoch 179/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1270 - accuracy: 0.9498 - val_loss: 1.4580 - val_accuracy: 0.7451\n",
      "Epoch 180/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1259 - accuracy: 0.9494 - val_loss: 1.4441 - val_accuracy: 0.7504\n",
      "Epoch 181/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1198 - accuracy: 0.9510 - val_loss: 1.4507 - val_accuracy: 0.7510\n",
      "Epoch 182/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.1115 - accuracy: 0.9546 - val_loss: 1.4677 - val_accuracy: 0.7522\n",
      "Epoch 183/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1129 - accuracy: 0.9549 - val_loss: 1.4884 - val_accuracy: 0.7513\n",
      "Epoch 184/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1252 - accuracy: 0.9507 - val_loss: 1.4986 - val_accuracy: 0.7334\n",
      "Epoch 185/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1192 - accuracy: 0.9518 - val_loss: 1.4633 - val_accuracy: 0.7606\n",
      "Epoch 186/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.1097 - accuracy: 0.9556 - val_loss: 1.4854 - val_accuracy: 0.7428\n",
      "Epoch 187/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.1159 - accuracy: 0.9541 - val_loss: 1.4865 - val_accuracy: 0.7478\n",
      "Epoch 188/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.1202 - accuracy: 0.9524 - val_loss: 1.4982 - val_accuracy: 0.7453\n",
      "Epoch 189/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1138 - accuracy: 0.9537 - val_loss: 1.4830 - val_accuracy: 0.7478\n",
      "Epoch 190/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1077 - accuracy: 0.9561 - val_loss: 1.4844 - val_accuracy: 0.7458\n",
      "Epoch 191/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1053 - accuracy: 0.9579 - val_loss: 1.5019 - val_accuracy: 0.7427\n",
      "Epoch 192/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.1113 - accuracy: 0.9554 - val_loss: 1.5201 - val_accuracy: 0.7560\n",
      "Epoch 193/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.1112 - accuracy: 0.9559 - val_loss: 1.4986 - val_accuracy: 0.7502\n",
      "Epoch 194/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1208 - accuracy: 0.9519 - val_loss: 1.5084 - val_accuracy: 0.7474\n",
      "Epoch 195/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.1153 - accuracy: 0.9546 - val_loss: 1.5216 - val_accuracy: 0.7404\n",
      "Epoch 196/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1111 - accuracy: 0.9569 - val_loss: 1.5288 - val_accuracy: 0.7494\n",
      "Epoch 197/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1114 - accuracy: 0.9558 - val_loss: 1.5282 - val_accuracy: 0.7473\n",
      "Epoch 198/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1145 - accuracy: 0.9542 - val_loss: 1.5207 - val_accuracy: 0.7460\n",
      "Epoch 199/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.1071 - accuracy: 0.9576 - val_loss: 1.5556 - val_accuracy: 0.7299\n",
      "Epoch 200/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.1051 - accuracy: 0.9580 - val_loss: 1.5182 - val_accuracy: 0.7480\n",
      "Epoch 201/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1155 - accuracy: 0.9546 - val_loss: 1.5085 - val_accuracy: 0.7499\n",
      "Epoch 202/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.1102 - accuracy: 0.9568 - val_loss: 1.5327 - val_accuracy: 0.7430\n",
      "Epoch 203/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 0.1143 - accuracy: 0.9542 - val_loss: 1.5267 - val_accuracy: 0.7394\n",
      "Epoch 204/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1109 - accuracy: 0.9558 - val_loss: 1.5564 - val_accuracy: 0.7497\n",
      "Epoch 205/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1006 - accuracy: 0.9609 - val_loss: 1.5620 - val_accuracy: 0.7522\n",
      "Epoch 206/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.1138 - accuracy: 0.9548 - val_loss: 1.5566 - val_accuracy: 0.7488\n",
      "Epoch 207/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.1112 - accuracy: 0.9572 - val_loss: 1.5854 - val_accuracy: 0.7386\n",
      "Epoch 208/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.1111 - accuracy: 0.9569 - val_loss: 1.5750 - val_accuracy: 0.7508\n",
      "Epoch 209/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.1038 - accuracy: 0.9580 - val_loss: 1.5635 - val_accuracy: 0.7457\n",
      "Epoch 210/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0976 - accuracy: 0.9613 - val_loss: 1.6075 - val_accuracy: 0.7465\n",
      "Epoch 211/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.0994 - accuracy: 0.9603 - val_loss: 1.6004 - val_accuracy: 0.7401\n",
      "Epoch 212/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.1239 - accuracy: 0.9527 - val_loss: 1.5715 - val_accuracy: 0.7351\n",
      "Epoch 213/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1011 - accuracy: 0.9596 - val_loss: 1.5859 - val_accuracy: 0.7487\n",
      "Epoch 214/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0956 - accuracy: 0.9633 - val_loss: 1.5978 - val_accuracy: 0.7369\n",
      "Epoch 215/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1020 - accuracy: 0.9615 - val_loss: 1.6081 - val_accuracy: 0.7463\n",
      "Epoch 216/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1113 - accuracy: 0.9568 - val_loss: 1.6040 - val_accuracy: 0.7462\n",
      "Epoch 217/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.1033 - accuracy: 0.9597 - val_loss: 1.6015 - val_accuracy: 0.7373\n",
      "Epoch 218/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.1038 - accuracy: 0.9589 - val_loss: 1.6217 - val_accuracy: 0.7391\n",
      "Epoch 219/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0998 - accuracy: 0.9606 - val_loss: 1.6299 - val_accuracy: 0.7435\n",
      "Epoch 220/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0932 - accuracy: 0.9642 - val_loss: 1.6356 - val_accuracy: 0.7539\n",
      "Epoch 221/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.1090 - accuracy: 0.9591 - val_loss: 1.6213 - val_accuracy: 0.7548\n",
      "Epoch 222/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1003 - accuracy: 0.9598 - val_loss: 1.6266 - val_accuracy: 0.7365\n",
      "Epoch 223/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0975 - accuracy: 0.9608 - val_loss: 1.6181 - val_accuracy: 0.7395\n",
      "Epoch 224/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0993 - accuracy: 0.9609 - val_loss: 1.6583 - val_accuracy: 0.7347\n",
      "Epoch 225/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.0986 - accuracy: 0.9612 - val_loss: 1.6282 - val_accuracy: 0.7401\n",
      "Epoch 226/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0979 - accuracy: 0.9609 - val_loss: 1.6385 - val_accuracy: 0.7407\n",
      "Epoch 227/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.1005 - accuracy: 0.9608 - val_loss: 1.6565 - val_accuracy: 0.7334\n",
      "Epoch 228/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1003 - accuracy: 0.9611 - val_loss: 1.6104 - val_accuracy: 0.7484\n",
      "Epoch 229/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1139 - accuracy: 0.9566 - val_loss: 1.6465 - val_accuracy: 0.7411\n",
      "Epoch 230/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0940 - accuracy: 0.9626 - val_loss: 1.6457 - val_accuracy: 0.7493\n",
      "Epoch 231/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0957 - accuracy: 0.9634 - val_loss: 1.6369 - val_accuracy: 0.7395\n",
      "Epoch 232/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.1012 - accuracy: 0.9603 - val_loss: 1.6853 - val_accuracy: 0.7285\n",
      "Epoch 233/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0964 - accuracy: 0.9614 - val_loss: 1.6562 - val_accuracy: 0.7478\n",
      "Epoch 234/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0946 - accuracy: 0.9635 - val_loss: 1.6450 - val_accuracy: 0.7541\n",
      "Epoch 235/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0971 - accuracy: 0.9622 - val_loss: 1.6394 - val_accuracy: 0.7517\n",
      "Epoch 236/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1052 - accuracy: 0.9587 - val_loss: 1.6425 - val_accuracy: 0.7433\n",
      "Epoch 237/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0944 - accuracy: 0.9632 - val_loss: 1.6342 - val_accuracy: 0.7577\n",
      "Epoch 238/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.0925 - accuracy: 0.9642 - val_loss: 1.6746 - val_accuracy: 0.7396\n",
      "Epoch 239/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0917 - accuracy: 0.9650 - val_loss: 1.6840 - val_accuracy: 0.7401\n",
      "Epoch 240/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.1008 - accuracy: 0.9611 - val_loss: 1.6684 - val_accuracy: 0.7420\n",
      "Epoch 241/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.1129 - accuracy: 0.9577 - val_loss: 1.6687 - val_accuracy: 0.7338\n",
      "Epoch 242/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.1025 - accuracy: 0.9612 - val_loss: 1.6685 - val_accuracy: 0.7476\n",
      "Epoch 243/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0913 - accuracy: 0.9645 - val_loss: 1.6967 - val_accuracy: 0.7361\n",
      "Epoch 244/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0961 - accuracy: 0.9629 - val_loss: 1.6806 - val_accuracy: 0.7429\n",
      "Epoch 245/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0899 - accuracy: 0.9648 - val_loss: 1.7063 - val_accuracy: 0.7434\n",
      "Epoch 246/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0842 - accuracy: 0.9672 - val_loss: 1.7093 - val_accuracy: 0.7383\n",
      "Epoch 247/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0938 - accuracy: 0.9637 - val_loss: 1.6634 - val_accuracy: 0.7455\n",
      "Epoch 248/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0992 - accuracy: 0.9610 - val_loss: 1.7053 - val_accuracy: 0.7386\n",
      "Epoch 249/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0902 - accuracy: 0.9649 - val_loss: 1.7308 - val_accuracy: 0.7406\n",
      "Epoch 250/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0892 - accuracy: 0.9657 - val_loss: 1.6846 - val_accuracy: 0.7551\n",
      "Epoch 251/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0901 - accuracy: 0.9654 - val_loss: 1.7244 - val_accuracy: 0.7486\n",
      "Epoch 252/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0980 - accuracy: 0.9624 - val_loss: 1.7331 - val_accuracy: 0.7341\n",
      "Epoch 253/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.1012 - accuracy: 0.9604 - val_loss: 1.7186 - val_accuracy: 0.7443\n",
      "Epoch 254/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.0853 - accuracy: 0.9674 - val_loss: 1.7359 - val_accuracy: 0.7406\n",
      "Epoch 255/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0814 - accuracy: 0.9685 - val_loss: 1.7377 - val_accuracy: 0.7451\n",
      "Epoch 256/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.1018 - accuracy: 0.9617 - val_loss: 1.7302 - val_accuracy: 0.7465\n",
      "Epoch 257/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0999 - accuracy: 0.9620 - val_loss: 1.7441 - val_accuracy: 0.7435\n",
      "Epoch 258/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0960 - accuracy: 0.9627 - val_loss: 1.7242 - val_accuracy: 0.7527\n",
      "Epoch 259/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0998 - accuracy: 0.9622 - val_loss: 1.7435 - val_accuracy: 0.7384\n",
      "Epoch 260/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0826 - accuracy: 0.9684 - val_loss: 1.7400 - val_accuracy: 0.7411\n",
      "Epoch 261/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0802 - accuracy: 0.9689 - val_loss: 1.7553 - val_accuracy: 0.7442\n",
      "Epoch 262/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0944 - accuracy: 0.9639 - val_loss: 1.7160 - val_accuracy: 0.7558\n",
      "Epoch 263/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0906 - accuracy: 0.9659 - val_loss: 1.7439 - val_accuracy: 0.7423\n",
      "Epoch 264/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0901 - accuracy: 0.9651 - val_loss: 1.7566 - val_accuracy: 0.7376\n",
      "Epoch 265/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0856 - accuracy: 0.9670 - val_loss: 1.7337 - val_accuracy: 0.7510\n",
      "Epoch 266/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0855 - accuracy: 0.9667 - val_loss: 1.7427 - val_accuracy: 0.7493\n",
      "Epoch 267/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0939 - accuracy: 0.9640 - val_loss: 1.7834 - val_accuracy: 0.7368\n",
      "Epoch 268/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0867 - accuracy: 0.9660 - val_loss: 1.7815 - val_accuracy: 0.7420\n",
      "Epoch 269/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0856 - accuracy: 0.9668 - val_loss: 1.7356 - val_accuracy: 0.7498\n",
      "Epoch 270/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0928 - accuracy: 0.9651 - val_loss: 1.7560 - val_accuracy: 0.7479\n",
      "Epoch 271/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0947 - accuracy: 0.9652 - val_loss: 1.7584 - val_accuracy: 0.7407\n",
      "Epoch 272/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0886 - accuracy: 0.9667 - val_loss: 1.7590 - val_accuracy: 0.7304\n",
      "Epoch 273/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0888 - accuracy: 0.9660 - val_loss: 1.7633 - val_accuracy: 0.7453\n",
      "Epoch 274/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0864 - accuracy: 0.9675 - val_loss: 1.7733 - val_accuracy: 0.7388\n",
      "Epoch 275/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0912 - accuracy: 0.9651 - val_loss: 1.8036 - val_accuracy: 0.7387\n",
      "Epoch 276/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0868 - accuracy: 0.9673 - val_loss: 1.8171 - val_accuracy: 0.7344\n",
      "Epoch 277/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0840 - accuracy: 0.9684 - val_loss: 1.7728 - val_accuracy: 0.7446\n",
      "Epoch 278/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0868 - accuracy: 0.9678 - val_loss: 1.7913 - val_accuracy: 0.7404\n",
      "Epoch 279/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0854 - accuracy: 0.9667 - val_loss: 1.8212 - val_accuracy: 0.7346\n",
      "Epoch 280/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0930 - accuracy: 0.9657 - val_loss: 1.7960 - val_accuracy: 0.7397\n",
      "Epoch 281/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0858 - accuracy: 0.9671 - val_loss: 1.8192 - val_accuracy: 0.7369\n",
      "Epoch 282/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0836 - accuracy: 0.9680 - val_loss: 1.8212 - val_accuracy: 0.7525\n",
      "Epoch 283/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0763 - accuracy: 0.9708 - val_loss: 1.8143 - val_accuracy: 0.7344\n",
      "Epoch 284/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0894 - accuracy: 0.9662 - val_loss: 1.8235 - val_accuracy: 0.7310\n",
      "Epoch 285/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0976 - accuracy: 0.9642 - val_loss: 1.8000 - val_accuracy: 0.7576\n",
      "Epoch 286/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0993 - accuracy: 0.9630 - val_loss: 1.7576 - val_accuracy: 0.7477\n",
      "Epoch 287/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0857 - accuracy: 0.9677 - val_loss: 1.7747 - val_accuracy: 0.7538\n",
      "Epoch 288/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0846 - accuracy: 0.9687 - val_loss: 1.7903 - val_accuracy: 0.7430\n",
      "Epoch 289/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0825 - accuracy: 0.9692 - val_loss: 1.8103 - val_accuracy: 0.7435\n",
      "Epoch 290/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0846 - accuracy: 0.9687 - val_loss: 1.8021 - val_accuracy: 0.7463\n",
      "Epoch 291/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.0749 - accuracy: 0.9718 - val_loss: 1.8209 - val_accuracy: 0.7471\n",
      "Epoch 292/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0810 - accuracy: 0.9693 - val_loss: 1.8124 - val_accuracy: 0.7438\n",
      "Epoch 293/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.0819 - accuracy: 0.9683 - val_loss: 1.8280 - val_accuracy: 0.7377\n",
      "Epoch 294/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.0870 - accuracy: 0.9670 - val_loss: 1.8142 - val_accuracy: 0.7354\n",
      "Epoch 295/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0864 - accuracy: 0.9679 - val_loss: 1.8336 - val_accuracy: 0.7435\n",
      "Epoch 296/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.0775 - accuracy: 0.9709 - val_loss: 1.8200 - val_accuracy: 0.7355\n",
      "Epoch 297/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.0932 - accuracy: 0.9656 - val_loss: 1.8557 - val_accuracy: 0.7373\n",
      "Epoch 298/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0927 - accuracy: 0.9654 - val_loss: 1.8303 - val_accuracy: 0.7397\n",
      "Epoch 299/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0905 - accuracy: 0.9665 - val_loss: 1.8220 - val_accuracy: 0.7408\n",
      "Epoch 300/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0747 - accuracy: 0.9718 - val_loss: 1.8467 - val_accuracy: 0.7368\n",
      "Epoch 301/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.0757 - accuracy: 0.9715 - val_loss: 1.8340 - val_accuracy: 0.7447\n",
      "Epoch 302/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.0782 - accuracy: 0.9705 - val_loss: 1.8036 - val_accuracy: 0.7492\n",
      "Epoch 303/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.0794 - accuracy: 0.9712 - val_loss: 1.7926 - val_accuracy: 0.7572\n",
      "Epoch 304/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0794 - accuracy: 0.9701 - val_loss: 1.8164 - val_accuracy: 0.7391\n",
      "Epoch 305/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0962 - accuracy: 0.9647 - val_loss: 1.8383 - val_accuracy: 0.7316\n",
      "Epoch 306/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0810 - accuracy: 0.9713 - val_loss: 1.8432 - val_accuracy: 0.7411\n",
      "Epoch 307/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0858 - accuracy: 0.9672 - val_loss: 1.8398 - val_accuracy: 0.7421\n",
      "Epoch 308/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.0749 - accuracy: 0.9725 - val_loss: 1.8595 - val_accuracy: 0.7443\n",
      "Epoch 309/1000\n",
      "49590/49590 [==============================] - 2s 49us/sample - loss: 0.0862 - accuracy: 0.9677 - val_loss: 1.8393 - val_accuracy: 0.7448\n",
      "Epoch 310/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0896 - accuracy: 0.9669 - val_loss: 1.8245 - val_accuracy: 0.7467\n",
      "Epoch 311/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0825 - accuracy: 0.9691 - val_loss: 1.8601 - val_accuracy: 0.7441\n",
      "Epoch 312/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0841 - accuracy: 0.9690 - val_loss: 1.8240 - val_accuracy: 0.7444\n",
      "Epoch 313/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0862 - accuracy: 0.9673 - val_loss: 1.8449 - val_accuracy: 0.7412\n",
      "Epoch 314/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0770 - accuracy: 0.9707 - val_loss: 1.8319 - val_accuracy: 0.7464\n",
      "Epoch 315/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0793 - accuracy: 0.9713 - val_loss: 1.8301 - val_accuracy: 0.7400\n",
      "Epoch 316/1000\n",
      "49590/49590 [==============================] - 2s 50us/sample - loss: 0.0721 - accuracy: 0.9730 - val_loss: 1.8388 - val_accuracy: 0.7521\n",
      "Epoch 317/1000\n",
      "49590/49590 [==============================] - 2s 49us/sample - loss: 0.0771 - accuracy: 0.9711 - val_loss: 1.8332 - val_accuracy: 0.7527\n",
      "Epoch 318/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.0820 - accuracy: 0.9705 - val_loss: 1.8434 - val_accuracy: 0.7478\n",
      "Epoch 319/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 2s 42us/sample - loss: 0.0802 - accuracy: 0.9699 - val_loss: 1.8893 - val_accuracy: 0.7384\n",
      "Epoch 320/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0903 - accuracy: 0.9669 - val_loss: 1.8698 - val_accuracy: 0.7409\n",
      "Epoch 321/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 0.0735 - accuracy: 0.9721 - val_loss: 1.9102 - val_accuracy: 0.7291\n",
      "Epoch 322/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0795 - accuracy: 0.9704 - val_loss: 1.8591 - val_accuracy: 0.7506\n",
      "Epoch 323/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0784 - accuracy: 0.9719 - val_loss: 1.8734 - val_accuracy: 0.7433\n",
      "Epoch 324/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0905 - accuracy: 0.9667 - val_loss: 1.8806 - val_accuracy: 0.7490\n",
      "Epoch 325/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0940 - accuracy: 0.9650 - val_loss: 1.8443 - val_accuracy: 0.7466\n",
      "Epoch 326/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0692 - accuracy: 0.9744 - val_loss: 1.9002 - val_accuracy: 0.7398\n",
      "Epoch 327/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0749 - accuracy: 0.9716 - val_loss: 1.8919 - val_accuracy: 0.7505\n",
      "Epoch 328/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0698 - accuracy: 0.9741 - val_loss: 1.8762 - val_accuracy: 0.7475\n",
      "Epoch 329/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0797 - accuracy: 0.9703 - val_loss: 1.8991 - val_accuracy: 0.7449\n",
      "Epoch 330/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0749 - accuracy: 0.9719 - val_loss: 1.8887 - val_accuracy: 0.7462\n",
      "Epoch 331/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0850 - accuracy: 0.9685 - val_loss: 1.8830 - val_accuracy: 0.7400\n",
      "Epoch 332/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0764 - accuracy: 0.9718 - val_loss: 1.8913 - val_accuracy: 0.7421\n",
      "Epoch 333/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0649 - accuracy: 0.9755 - val_loss: 1.8956 - val_accuracy: 0.7488\n",
      "Epoch 334/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0782 - accuracy: 0.9710 - val_loss: 1.8974 - val_accuracy: 0.7433\n",
      "Epoch 335/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0728 - accuracy: 0.9728 - val_loss: 1.9095 - val_accuracy: 0.7415\n",
      "Epoch 336/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0892 - accuracy: 0.9677 - val_loss: 1.8689 - val_accuracy: 0.7505\n",
      "Epoch 337/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0955 - accuracy: 0.9660 - val_loss: 1.8670 - val_accuracy: 0.7597\n",
      "Epoch 338/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0710 - accuracy: 0.9738 - val_loss: 1.9305 - val_accuracy: 0.7434\n",
      "Epoch 339/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0759 - accuracy: 0.9719 - val_loss: 1.8901 - val_accuracy: 0.7415\n",
      "Epoch 340/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0711 - accuracy: 0.9734 - val_loss: 1.9065 - val_accuracy: 0.7460\n",
      "Epoch 341/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0715 - accuracy: 0.9736 - val_loss: 1.9290 - val_accuracy: 0.7338\n",
      "Epoch 342/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0872 - accuracy: 0.9686 - val_loss: 1.9219 - val_accuracy: 0.7351\n",
      "Epoch 343/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0788 - accuracy: 0.9702 - val_loss: 1.8804 - val_accuracy: 0.7414\n",
      "Epoch 344/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0686 - accuracy: 0.9752 - val_loss: 1.9317 - val_accuracy: 0.7466\n",
      "Epoch 345/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0768 - accuracy: 0.9718 - val_loss: 1.9347 - val_accuracy: 0.7383\n",
      "Epoch 346/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.0757 - accuracy: 0.9721 - val_loss: 1.8949 - val_accuracy: 0.7451\n",
      "Epoch 347/1000\n",
      "49590/49590 [==============================] - 4s 77us/sample - loss: 0.0744 - accuracy: 0.9725 - val_loss: 1.9071 - val_accuracy: 0.7332\n",
      "Epoch 348/1000\n",
      "49590/49590 [==============================] - 2s 50us/sample - loss: 0.0822 - accuracy: 0.9700 - val_loss: 1.9068 - val_accuracy: 0.7479\n",
      "Epoch 349/1000\n",
      "49590/49590 [==============================] - 2s 45us/sample - loss: 0.0779 - accuracy: 0.9720 - val_loss: 1.9490 - val_accuracy: 0.7296\n",
      "Epoch 350/1000\n",
      "49590/49590 [==============================] - 2s 43us/sample - loss: 0.0684 - accuracy: 0.9750 - val_loss: 1.9121 - val_accuracy: 0.7379\n",
      "Epoch 351/1000\n",
      "49590/49590 [==============================] - 2s 49us/sample - loss: 0.0753 - accuracy: 0.9721 - val_loss: 1.9308 - val_accuracy: 0.7419\n",
      "Epoch 352/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0713 - accuracy: 0.9735 - val_loss: 1.9113 - val_accuracy: 0.7505\n",
      "Epoch 353/1000\n",
      "49590/49590 [==============================] - 2s 45us/sample - loss: 0.0708 - accuracy: 0.9749 - val_loss: 1.9284 - val_accuracy: 0.7399\n",
      "Epoch 354/1000\n",
      "49590/49590 [==============================] - 3s 70us/sample - loss: 0.0694 - accuracy: 0.9742 - val_loss: 1.9255 - val_accuracy: 0.7350\n",
      "Epoch 355/1000\n",
      "49590/49590 [==============================] - 3s 56us/sample - loss: 0.0702 - accuracy: 0.9750 - val_loss: 1.9944 - val_accuracy: 0.7287\n",
      "Epoch 356/1000\n",
      "49590/49590 [==============================] - 2s 47us/sample - loss: 0.0907 - accuracy: 0.9672 - val_loss: 1.8969 - val_accuracy: 0.7503\n",
      "Epoch 357/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 0.0751 - accuracy: 0.9725 - val_loss: 1.9305 - val_accuracy: 0.7404\n",
      "Epoch 358/1000\n",
      "49590/49590 [==============================] - 2s 45us/sample - loss: 0.0690 - accuracy: 0.9743 - val_loss: 1.9391 - val_accuracy: 0.7473\n",
      "Epoch 359/1000\n",
      "49590/49590 [==============================] - 2s 45us/sample - loss: 0.0679 - accuracy: 0.9755 - val_loss: 1.9208 - val_accuracy: 0.7500\n",
      "Epoch 360/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 0.0693 - accuracy: 0.9753 - val_loss: 1.9414 - val_accuracy: 0.7482\n",
      "Epoch 361/1000\n",
      "49590/49590 [==============================] - 2s 49us/sample - loss: 0.0767 - accuracy: 0.9718 - val_loss: 1.9476 - val_accuracy: 0.7438\n",
      "Epoch 362/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 0.0715 - accuracy: 0.9736 - val_loss: 1.9571 - val_accuracy: 0.7365\n",
      "Epoch 363/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.0786 - accuracy: 0.9719 - val_loss: 1.9264 - val_accuracy: 0.7540\n",
      "Epoch 364/1000\n",
      "49590/49590 [==============================] - 2s 44us/sample - loss: 0.0900 - accuracy: 0.9680 - val_loss: 1.9531 - val_accuracy: 0.7456\n",
      "Epoch 365/1000\n",
      "49590/49590 [==============================] - 2s 45us/sample - loss: 0.0727 - accuracy: 0.9739 - val_loss: 1.9598 - val_accuracy: 0.7406\n",
      "Epoch 366/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 0.0676 - accuracy: 0.9747 - val_loss: 1.9331 - val_accuracy: 0.7455\n",
      "Epoch 367/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0787 - accuracy: 0.9721 - val_loss: 1.9206 - val_accuracy: 0.7456\n",
      "Epoch 368/1000\n",
      "49590/49590 [==============================] - 2s 49us/sample - loss: 0.0694 - accuracy: 0.9752 - val_loss: 1.9493 - val_accuracy: 0.7422\n",
      "Epoch 369/1000\n",
      "49590/49590 [==============================] - 2s 48us/sample - loss: 0.0695 - accuracy: 0.9748 - val_loss: 1.9456 - val_accuracy: 0.7438\n",
      "Epoch 370/1000\n",
      "49590/49590 [==============================] - 2s 48us/sample - loss: 0.0617 - accuracy: 0.9767 - val_loss: 1.9481 - val_accuracy: 0.7401\n",
      "Epoch 371/1000\n",
      "49590/49590 [==============================] - 2s 44us/sample - loss: 0.0817 - accuracy: 0.9707 - val_loss: 1.9658 - val_accuracy: 0.7429\n",
      "Epoch 372/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 0.0779 - accuracy: 0.9714 - val_loss: 1.9722 - val_accuracy: 0.7420\n",
      "Epoch 373/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 0.0797 - accuracy: 0.9706 - val_loss: 1.9423 - val_accuracy: 0.7478\n",
      "Epoch 374/1000\n",
      "49590/49590 [==============================] - 2s 43us/sample - loss: 0.0722 - accuracy: 0.9742 - val_loss: 1.9491 - val_accuracy: 0.7508\n",
      "Epoch 375/1000\n",
      "49590/49590 [==============================] - 2s 43us/sample - loss: 0.0761 - accuracy: 0.9721 - val_loss: 1.9688 - val_accuracy: 0.7459\n",
      "Epoch 376/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.0683 - accuracy: 0.9757 - val_loss: 1.9906 - val_accuracy: 0.7395\n",
      "Epoch 377/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 0.0715 - accuracy: 0.9736 - val_loss: 1.9480 - val_accuracy: 0.7465\n",
      "Epoch 378/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 0.0790 - accuracy: 0.9715 - val_loss: 1.9699 - val_accuracy: 0.7436\n",
      "Epoch 379/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0656 - accuracy: 0.9762 - val_loss: 1.9598 - val_accuracy: 0.7495\n",
      "Epoch 380/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.0678 - accuracy: 0.9747 - val_loss: 1.9613 - val_accuracy: 0.7445\n",
      "Epoch 381/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0694 - accuracy: 0.9748 - val_loss: 1.9911 - val_accuracy: 0.7506\n",
      "Epoch 382/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.0711 - accuracy: 0.9743 - val_loss: 1.9457 - val_accuracy: 0.7417\n",
      "Epoch 383/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0702 - accuracy: 0.9746 - val_loss: 1.9625 - val_accuracy: 0.7487\n",
      "Epoch 384/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0731 - accuracy: 0.9730 - val_loss: 2.0541 - val_accuracy: 0.7314\n",
      "Epoch 385/1000\n",
      "49590/49590 [==============================] - 2s 44us/sample - loss: 0.0765 - accuracy: 0.9723 - val_loss: 1.9601 - val_accuracy: 0.7378\n",
      "Epoch 386/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0688 - accuracy: 0.9747 - val_loss: 1.9730 - val_accuracy: 0.7439\n",
      "Epoch 387/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.0645 - accuracy: 0.9766 - val_loss: 1.9846 - val_accuracy: 0.7482\n",
      "Epoch 388/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0622 - accuracy: 0.9779 - val_loss: 2.0219 - val_accuracy: 0.7334\n",
      "Epoch 389/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.0742 - accuracy: 0.9736 - val_loss: 1.9986 - val_accuracy: 0.7451\n",
      "Epoch 390/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.0747 - accuracy: 0.9726 - val_loss: 1.9827 - val_accuracy: 0.7439\n",
      "Epoch 391/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0667 - accuracy: 0.9750 - val_loss: 1.9745 - val_accuracy: 0.7455\n",
      "Epoch 392/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0661 - accuracy: 0.9753 - val_loss: 1.9598 - val_accuracy: 0.7555\n",
      "Epoch 393/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0661 - accuracy: 0.9758 - val_loss: 2.0216 - val_accuracy: 0.7314\n",
      "Epoch 394/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.0784 - accuracy: 0.9719 - val_loss: 1.9429 - val_accuracy: 0.7494\n",
      "Epoch 395/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 0.0840 - accuracy: 0.9698 - val_loss: 2.0307 - val_accuracy: 0.7388\n",
      "Epoch 396/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0651 - accuracy: 0.9766 - val_loss: 1.9934 - val_accuracy: 0.7363\n",
      "Epoch 397/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.0600 - accuracy: 0.9792 - val_loss: 1.9817 - val_accuracy: 0.7405\n",
      "Epoch 398/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 0.0693 - accuracy: 0.9750 - val_loss: 1.9326 - val_accuracy: 0.7469\n",
      "Epoch 399/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.0779 - accuracy: 0.9712 - val_loss: 1.9542 - val_accuracy: 0.7465\n",
      "Epoch 400/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0721 - accuracy: 0.9737 - val_loss: 1.9621 - val_accuracy: 0.7518\n",
      "Epoch 401/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 0.0620 - accuracy: 0.9779 - val_loss: 1.9924 - val_accuracy: 0.7414\n",
      "Epoch 402/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.0715 - accuracy: 0.9736 - val_loss: 2.0282 - val_accuracy: 0.7343\n",
      "Epoch 403/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0674 - accuracy: 0.9754 - val_loss: 1.9606 - val_accuracy: 0.7487\n",
      "Epoch 404/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.0652 - accuracy: 0.9759 - val_loss: 1.9748 - val_accuracy: 0.7482\n",
      "Epoch 405/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.0614 - accuracy: 0.9776 - val_loss: 1.9722 - val_accuracy: 0.7462\n",
      "Epoch 406/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.0751 - accuracy: 0.9732 - val_loss: 1.9791 - val_accuracy: 0.7526\n",
      "Epoch 407/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 0.0686 - accuracy: 0.9747 - val_loss: 2.0040 - val_accuracy: 0.7394\n",
      "Epoch 408/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.0714 - accuracy: 0.9737 - val_loss: 2.0167 - val_accuracy: 0.7393\n",
      "Epoch 409/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.0700 - accuracy: 0.9753 - val_loss: 1.9696 - val_accuracy: 0.7455\n",
      "Epoch 410/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0789 - accuracy: 0.9724 - val_loss: 1.9718 - val_accuracy: 0.7481\n",
      "Epoch 411/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 0.0783 - accuracy: 0.9716 - val_loss: 1.9783 - val_accuracy: 0.7445\n",
      "Epoch 412/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0692 - accuracy: 0.9756 - val_loss: 2.0103 - val_accuracy: 0.7398\n",
      "Epoch 413/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0579 - accuracy: 0.9785 - val_loss: 1.9866 - val_accuracy: 0.7537\n",
      "Epoch 414/1000\n",
      "49590/49590 [==============================] - 2s 44us/sample - loss: 0.0654 - accuracy: 0.9776 - val_loss: 2.0276 - val_accuracy: 0.7335\n",
      "Epoch 415/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0705 - accuracy: 0.9746 - val_loss: 1.9924 - val_accuracy: 0.7478\n",
      "Epoch 416/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0639 - accuracy: 0.9771 - val_loss: 2.0080 - val_accuracy: 0.7462\n",
      "Epoch 417/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 0.0570 - accuracy: 0.9788 - val_loss: 2.0443 - val_accuracy: 0.7398\n",
      "Epoch 418/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0675 - accuracy: 0.9751 - val_loss: 2.0305 - val_accuracy: 0.7308\n",
      "Epoch 419/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0680 - accuracy: 0.9754 - val_loss: 2.0218 - val_accuracy: 0.7430\n",
      "Epoch 420/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0703 - accuracy: 0.9755 - val_loss: 2.0007 - val_accuracy: 0.7504\n",
      "Epoch 421/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0620 - accuracy: 0.9770 - val_loss: 2.0036 - val_accuracy: 0.7411\n",
      "Epoch 422/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0674 - accuracy: 0.9760 - val_loss: 2.0057 - val_accuracy: 0.7407\n",
      "Epoch 423/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.0696 - accuracy: 0.9741 - val_loss: 2.0050 - val_accuracy: 0.7530\n",
      "Epoch 424/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0681 - accuracy: 0.9756 - val_loss: 1.9822 - val_accuracy: 0.7507\n",
      "Epoch 425/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0643 - accuracy: 0.9776 - val_loss: 2.0234 - val_accuracy: 0.7457\n",
      "Epoch 426/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0800 - accuracy: 0.9711 - val_loss: 2.0249 - val_accuracy: 0.7390\n",
      "Epoch 427/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0610 - accuracy: 0.9782 - val_loss: 2.0425 - val_accuracy: 0.7405\n",
      "Epoch 428/1000\n",
      "49590/49590 [==============================] - 2s 44us/sample - loss: 0.0527 - accuracy: 0.9813 - val_loss: 2.0324 - val_accuracy: 0.7401\n",
      "Epoch 429/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 0.0725 - accuracy: 0.9741 - val_loss: 2.0338 - val_accuracy: 0.7391\n",
      "Epoch 430/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0674 - accuracy: 0.9765 - val_loss: 2.0090 - val_accuracy: 0.7438\n",
      "Epoch 431/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 0.0661 - accuracy: 0.9759 - val_loss: 2.0001 - val_accuracy: 0.7523\n",
      "Epoch 432/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0651 - accuracy: 0.9765 - val_loss: 2.0235 - val_accuracy: 0.7424\n",
      "Epoch 433/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.0664 - accuracy: 0.9763 - val_loss: 2.0400 - val_accuracy: 0.7396\n",
      "Epoch 434/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0680 - accuracy: 0.9764 - val_loss: 2.0417 - val_accuracy: 0.7479\n",
      "Epoch 435/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0686 - accuracy: 0.9758 - val_loss: 2.0166 - val_accuracy: 0.7453\n",
      "Epoch 436/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.0647 - accuracy: 0.9772 - val_loss: 2.0673 - val_accuracy: 0.7364\n",
      "Epoch 437/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0703 - accuracy: 0.9754 - val_loss: 2.0105 - val_accuracy: 0.7455\n",
      "Epoch 438/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0695 - accuracy: 0.9751 - val_loss: 2.0279 - val_accuracy: 0.7411\n",
      "Epoch 439/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 0.0670 - accuracy: 0.9756 - val_loss: 2.0294 - val_accuracy: 0.7420\n",
      "Epoch 440/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0646 - accuracy: 0.9769 - val_loss: 1.9939 - val_accuracy: 0.7574\n",
      "Epoch 441/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0696 - accuracy: 0.9756 - val_loss: 2.0657 - val_accuracy: 0.7342\n",
      "Epoch 442/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.0664 - accuracy: 0.9766 - val_loss: 2.0203 - val_accuracy: 0.7427\n",
      "Epoch 443/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.0638 - accuracy: 0.9771 - val_loss: 2.0119 - val_accuracy: 0.7541\n",
      "Epoch 444/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 0.0517 - accuracy: 0.9813 - val_loss: 2.0563 - val_accuracy: 0.7363\n",
      "Epoch 445/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0634 - accuracy: 0.9778 - val_loss: 2.0452 - val_accuracy: 0.7430\n",
      "Epoch 446/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 0.0660 - accuracy: 0.9764 - val_loss: 2.0144 - val_accuracy: 0.7431\n",
      "Epoch 447/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0765 - accuracy: 0.9733 - val_loss: 2.0219 - val_accuracy: 0.7509\n",
      "Epoch 448/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.0726 - accuracy: 0.9738 - val_loss: 2.0273 - val_accuracy: 0.7538\n",
      "Epoch 449/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0583 - accuracy: 0.9792 - val_loss: 2.0180 - val_accuracy: 0.7517\n",
      "Epoch 450/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0611 - accuracy: 0.9789 - val_loss: 2.0853 - val_accuracy: 0.7416\n",
      "Epoch 451/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 0.0762 - accuracy: 0.9733 - val_loss: 2.0674 - val_accuracy: 0.7394\n",
      "Epoch 452/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 0.0733 - accuracy: 0.9737 - val_loss: 2.0112 - val_accuracy: 0.7567\n",
      "Epoch 453/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0561 - accuracy: 0.9797 - val_loss: 2.0778 - val_accuracy: 0.7386\n",
      "Epoch 454/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 0.0494 - accuracy: 0.9826 - val_loss: 2.0275 - val_accuracy: 0.7455\n",
      "Epoch 455/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0596 - accuracy: 0.9791 - val_loss: 2.0499 - val_accuracy: 0.7414\n",
      "Epoch 456/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.0622 - accuracy: 0.9766 - val_loss: 1.9977 - val_accuracy: 0.7567\n",
      "Epoch 457/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.0715 - accuracy: 0.9747 - val_loss: 2.0293 - val_accuracy: 0.7442\n",
      "Epoch 458/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0726 - accuracy: 0.9746 - val_loss: 2.0424 - val_accuracy: 0.7460\n",
      "Epoch 459/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 0.0646 - accuracy: 0.9769 - val_loss: 2.0420 - val_accuracy: 0.7425\n",
      "Epoch 460/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0623 - accuracy: 0.9783 - val_loss: 2.0798 - val_accuracy: 0.7335\n",
      "Epoch 461/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0564 - accuracy: 0.9795 - val_loss: 2.0686 - val_accuracy: 0.7480\n",
      "Epoch 462/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0650 - accuracy: 0.9777 - val_loss: 2.0620 - val_accuracy: 0.7412\n",
      "Epoch 463/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 0.0655 - accuracy: 0.9762 - val_loss: 2.0254 - val_accuracy: 0.7553\n",
      "Epoch 464/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.0580 - accuracy: 0.9792 - val_loss: 2.0736 - val_accuracy: 0.7390\n",
      "Epoch 465/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0670 - accuracy: 0.9769 - val_loss: 2.0681 - val_accuracy: 0.7437\n",
      "Epoch 466/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0651 - accuracy: 0.9762 - val_loss: 2.0384 - val_accuracy: 0.7403\n",
      "Epoch 467/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0682 - accuracy: 0.9760 - val_loss: 2.0444 - val_accuracy: 0.7469\n",
      "Epoch 468/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0588 - accuracy: 0.9788 - val_loss: 2.0282 - val_accuracy: 0.7406\n",
      "Epoch 469/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0644 - accuracy: 0.9776 - val_loss: 2.0681 - val_accuracy: 0.7389\n",
      "Epoch 470/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0656 - accuracy: 0.9769 - val_loss: 2.0765 - val_accuracy: 0.7430\n",
      "Epoch 471/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0583 - accuracy: 0.9789 - val_loss: 2.0586 - val_accuracy: 0.7434\n",
      "Epoch 472/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0583 - accuracy: 0.9790 - val_loss: 2.0655 - val_accuracy: 0.7430\n",
      "Epoch 473/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0580 - accuracy: 0.9789 - val_loss: 2.0499 - val_accuracy: 0.7448\n",
      "Epoch 474/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0618 - accuracy: 0.9778 - val_loss: 2.0653 - val_accuracy: 0.7443\n",
      "Epoch 475/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.0660 - accuracy: 0.9757 - val_loss: 2.0518 - val_accuracy: 0.7472\n",
      "Epoch 476/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0683 - accuracy: 0.9762 - val_loss: 2.0522 - val_accuracy: 0.7489\n",
      "Epoch 477/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0588 - accuracy: 0.9787 - val_loss: 2.0539 - val_accuracy: 0.7553\n",
      "Epoch 478/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0505 - accuracy: 0.9821 - val_loss: 2.1136 - val_accuracy: 0.7372\n",
      "Epoch 479/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.0648 - accuracy: 0.9772 - val_loss: 2.0853 - val_accuracy: 0.7403\n",
      "Epoch 480/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0711 - accuracy: 0.9752 - val_loss: 2.0596 - val_accuracy: 0.7383\n",
      "Epoch 481/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0656 - accuracy: 0.9770 - val_loss: 2.0543 - val_accuracy: 0.7440\n",
      "Epoch 482/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.0588 - accuracy: 0.9787 - val_loss: 2.0427 - val_accuracy: 0.7478\n",
      "Epoch 483/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0528 - accuracy: 0.9816 - val_loss: 2.0499 - val_accuracy: 0.7365\n",
      "Epoch 484/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.0728 - accuracy: 0.9751 - val_loss: 2.0782 - val_accuracy: 0.7460\n",
      "Epoch 485/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.0685 - accuracy: 0.9757 - val_loss: 2.0491 - val_accuracy: 0.7504\n",
      "Epoch 486/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0525 - accuracy: 0.9814 - val_loss: 2.0645 - val_accuracy: 0.7427\n",
      "Epoch 487/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0540 - accuracy: 0.9811 - val_loss: 2.0568 - val_accuracy: 0.7438\n",
      "Epoch 488/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0606 - accuracy: 0.9788 - val_loss: 2.0892 - val_accuracy: 0.7326\n",
      "Epoch 489/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.0607 - accuracy: 0.9788 - val_loss: 2.1170 - val_accuracy: 0.7326\n",
      "Epoch 490/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.0727 - accuracy: 0.9756 - val_loss: 2.0800 - val_accuracy: 0.7428\n",
      "Epoch 491/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.0622 - accuracy: 0.9774 - val_loss: 2.0983 - val_accuracy: 0.7335\n",
      "Epoch 492/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0519 - accuracy: 0.9818 - val_loss: 2.0896 - val_accuracy: 0.7450\n",
      "Epoch 493/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0703 - accuracy: 0.9757 - val_loss: 2.0516 - val_accuracy: 0.7541\n",
      "Epoch 494/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0672 - accuracy: 0.9764 - val_loss: 2.0745 - val_accuracy: 0.7486\n",
      "Epoch 495/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.0584 - accuracy: 0.9798 - val_loss: 2.0727 - val_accuracy: 0.7473\n",
      "Epoch 496/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0574 - accuracy: 0.9798 - val_loss: 2.0570 - val_accuracy: 0.7506\n",
      "Epoch 497/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0599 - accuracy: 0.9783 - val_loss: 2.0820 - val_accuracy: 0.7365\n",
      "Epoch 498/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.0546 - accuracy: 0.9804 - val_loss: 2.0571 - val_accuracy: 0.7533\n",
      "Epoch 499/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.0600 - accuracy: 0.9789 - val_loss: 2.0899 - val_accuracy: 0.7342\n",
      "Epoch 500/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.0599 - accuracy: 0.9781 - val_loss: 2.1141 - val_accuracy: 0.7417\n",
      "Epoch 501/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0730 - accuracy: 0.9747 - val_loss: 2.0626 - val_accuracy: 0.7442\n",
      "Epoch 502/1000\n",
      "49590/49590 [==============================] - 2s 45us/sample - loss: 0.0643 - accuracy: 0.9772 - val_loss: 2.1233 - val_accuracy: 0.7357\n",
      "Epoch 503/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 0.0680 - accuracy: 0.9765 - val_loss: 2.0862 - val_accuracy: 0.7349\n",
      "Epoch 504/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0633 - accuracy: 0.9783 - val_loss: 2.0564 - val_accuracy: 0.7530\n",
      "Epoch 505/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0491 - accuracy: 0.9823 - val_loss: 2.0583 - val_accuracy: 0.7407\n",
      "Epoch 506/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0508 - accuracy: 0.9825 - val_loss: 2.0924 - val_accuracy: 0.7398\n",
      "Epoch 507/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0519 - accuracy: 0.9817 - val_loss: 2.0875 - val_accuracy: 0.7483\n",
      "Epoch 508/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0630 - accuracy: 0.9778 - val_loss: 2.0389 - val_accuracy: 0.7442\n",
      "Epoch 509/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0574 - accuracy: 0.9799 - val_loss: 2.1288 - val_accuracy: 0.7368\n",
      "Epoch 510/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0686 - accuracy: 0.9760 - val_loss: 2.0679 - val_accuracy: 0.7426\n",
      "Epoch 511/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.0631 - accuracy: 0.9775 - val_loss: 2.0932 - val_accuracy: 0.7374\n",
      "Epoch 512/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0640 - accuracy: 0.9776 - val_loss: 2.0919 - val_accuracy: 0.7349\n",
      "Epoch 513/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0557 - accuracy: 0.9803 - val_loss: 2.1020 - val_accuracy: 0.7372\n",
      "Epoch 514/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0505 - accuracy: 0.9819 - val_loss: 2.0814 - val_accuracy: 0.7455\n",
      "Epoch 515/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.0591 - accuracy: 0.9788 - val_loss: 2.0789 - val_accuracy: 0.7478\n",
      "Epoch 516/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0591 - accuracy: 0.9786 - val_loss: 2.0846 - val_accuracy: 0.7441\n",
      "Epoch 517/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0690 - accuracy: 0.9769 - val_loss: 2.0551 - val_accuracy: 0.7550\n",
      "Epoch 518/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0640 - accuracy: 0.9775 - val_loss: 2.0930 - val_accuracy: 0.7387\n",
      "Epoch 519/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0546 - accuracy: 0.9806 - val_loss: 2.0708 - val_accuracy: 0.7429\n",
      "Epoch 520/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0658 - accuracy: 0.9768 - val_loss: 2.0521 - val_accuracy: 0.7470\n",
      "Epoch 521/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0517 - accuracy: 0.9816 - val_loss: 2.0478 - val_accuracy: 0.7493\n",
      "Epoch 522/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0530 - accuracy: 0.9810 - val_loss: 2.0430 - val_accuracy: 0.7532\n",
      "Epoch 523/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0583 - accuracy: 0.9794 - val_loss: 2.0741 - val_accuracy: 0.7454\n",
      "Epoch 524/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.0567 - accuracy: 0.9799 - val_loss: 2.0971 - val_accuracy: 0.7391\n",
      "Epoch 525/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0600 - accuracy: 0.9790 - val_loss: 2.0798 - val_accuracy: 0.7474\n",
      "Epoch 526/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0640 - accuracy: 0.9775 - val_loss: 2.1003 - val_accuracy: 0.7329\n",
      "Epoch 527/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0652 - accuracy: 0.9773 - val_loss: 2.0765 - val_accuracy: 0.7473\n",
      "Epoch 528/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0712 - accuracy: 0.9755 - val_loss: 2.0707 - val_accuracy: 0.7441\n",
      "Epoch 529/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.0497 - accuracy: 0.9828 - val_loss: 2.0814 - val_accuracy: 0.7536\n",
      "Epoch 530/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0530 - accuracy: 0.9809 - val_loss: 2.0671 - val_accuracy: 0.7395\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0637 - accuracy: 0.9770 - val_loss: 2.0842 - val_accuracy: 0.7480\n",
      "Epoch 532/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0578 - accuracy: 0.9804 - val_loss: 2.0828 - val_accuracy: 0.7412\n",
      "Epoch 533/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0492 - accuracy: 0.9836 - val_loss: 2.1125 - val_accuracy: 0.7390\n",
      "Epoch 534/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0596 - accuracy: 0.9797 - val_loss: 2.1154 - val_accuracy: 0.7422\n",
      "Epoch 535/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0713 - accuracy: 0.9750 - val_loss: 2.0710 - val_accuracy: 0.7506\n",
      "Epoch 536/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0626 - accuracy: 0.9785 - val_loss: 2.1122 - val_accuracy: 0.7331\n",
      "Epoch 537/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.0533 - accuracy: 0.9815 - val_loss: 2.0826 - val_accuracy: 0.7363\n",
      "Epoch 538/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 0.0511 - accuracy: 0.9820 - val_loss: 2.0917 - val_accuracy: 0.7366\n",
      "Epoch 539/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0566 - accuracy: 0.9806 - val_loss: 2.1262 - val_accuracy: 0.7392\n",
      "Epoch 540/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0593 - accuracy: 0.9783 - val_loss: 2.0975 - val_accuracy: 0.7513\n",
      "Epoch 541/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 0.0544 - accuracy: 0.9803 - val_loss: 2.0948 - val_accuracy: 0.7393\n",
      "Epoch 542/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0583 - accuracy: 0.9791 - val_loss: 2.1090 - val_accuracy: 0.7391\n",
      "Epoch 543/1000\n",
      "49590/49590 [==============================] - 2s 47us/sample - loss: 0.0483 - accuracy: 0.9834 - val_loss: 2.1011 - val_accuracy: 0.7449\n",
      "Epoch 544/1000\n",
      "49590/49590 [==============================] - 2s 44us/sample - loss: 0.0498 - accuracy: 0.9824 - val_loss: 2.1114 - val_accuracy: 0.7408\n",
      "Epoch 545/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 0.0585 - accuracy: 0.9792 - val_loss: 2.1054 - val_accuracy: 0.7509\n",
      "Epoch 546/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0743 - accuracy: 0.9736 - val_loss: 2.1331 - val_accuracy: 0.7353\n",
      "Epoch 547/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0565 - accuracy: 0.9798 - val_loss: 2.1187 - val_accuracy: 0.7439\n",
      "Epoch 548/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0590 - accuracy: 0.9795 - val_loss: 2.0756 - val_accuracy: 0.7461\n",
      "Epoch 549/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0513 - accuracy: 0.9828 - val_loss: 2.1233 - val_accuracy: 0.7398\n",
      "Epoch 550/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0601 - accuracy: 0.9793 - val_loss: 2.1127 - val_accuracy: 0.7441\n",
      "Epoch 551/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0473 - accuracy: 0.9838 - val_loss: 2.1297 - val_accuracy: 0.7330\n",
      "Epoch 552/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0488 - accuracy: 0.9830 - val_loss: 2.0989 - val_accuracy: 0.7457\n",
      "Epoch 553/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0671 - accuracy: 0.9769 - val_loss: 2.1303 - val_accuracy: 0.7423\n",
      "Epoch 554/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.0635 - accuracy: 0.9779 - val_loss: 2.0850 - val_accuracy: 0.7462\n",
      "Epoch 555/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.0581 - accuracy: 0.9799 - val_loss: 2.1088 - val_accuracy: 0.7361\n",
      "Epoch 556/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0522 - accuracy: 0.9817 - val_loss: 2.0872 - val_accuracy: 0.7494\n",
      "Epoch 557/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.0532 - accuracy: 0.9818 - val_loss: 2.1296 - val_accuracy: 0.7434\n",
      "Epoch 558/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0531 - accuracy: 0.9816 - val_loss: 2.0983 - val_accuracy: 0.7428\n",
      "Epoch 559/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 0.0629 - accuracy: 0.9777 - val_loss: 2.0989 - val_accuracy: 0.7455\n",
      "Epoch 560/1000\n",
      "49590/49590 [==============================] - 2s 50us/sample - loss: 0.0567 - accuracy: 0.9798 - val_loss: 2.1263 - val_accuracy: 0.7464\n",
      "Epoch 561/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.0564 - accuracy: 0.9805 - val_loss: 2.1047 - val_accuracy: 0.7477\n",
      "Epoch 562/1000\n",
      "49590/49590 [==============================] - 2s 44us/sample - loss: 0.0526 - accuracy: 0.9815 - val_loss: 2.1255 - val_accuracy: 0.7417\n",
      "Epoch 563/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0605 - accuracy: 0.9785 - val_loss: 2.1422 - val_accuracy: 0.7354\n",
      "Epoch 564/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0567 - accuracy: 0.9798 - val_loss: 2.1024 - val_accuracy: 0.7560\n",
      "Epoch 565/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0590 - accuracy: 0.9799 - val_loss: 2.0941 - val_accuracy: 0.7534\n",
      "Epoch 566/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0521 - accuracy: 0.9820 - val_loss: 2.1259 - val_accuracy: 0.7395\n",
      "Epoch 567/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0554 - accuracy: 0.9814 - val_loss: 2.1300 - val_accuracy: 0.7395\n",
      "Epoch 568/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0468 - accuracy: 0.9837 - val_loss: 2.1465 - val_accuracy: 0.7335\n",
      "Epoch 569/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0510 - accuracy: 0.9823 - val_loss: 2.1347 - val_accuracy: 0.7435\n",
      "Epoch 570/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0609 - accuracy: 0.9792 - val_loss: 2.1384 - val_accuracy: 0.7430\n",
      "Epoch 571/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0565 - accuracy: 0.9799 - val_loss: 2.1386 - val_accuracy: 0.7384\n",
      "Epoch 572/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0620 - accuracy: 0.9787 - val_loss: 2.1023 - val_accuracy: 0.7453\n",
      "Epoch 573/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0575 - accuracy: 0.9801 - val_loss: 2.1243 - val_accuracy: 0.7473\n",
      "Epoch 574/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0537 - accuracy: 0.9809 - val_loss: 2.1250 - val_accuracy: 0.7452\n",
      "Epoch 575/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0491 - accuracy: 0.9835 - val_loss: 2.0765 - val_accuracy: 0.7584\n",
      "Epoch 576/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0690 - accuracy: 0.9755 - val_loss: 2.1052 - val_accuracy: 0.7340\n",
      "Epoch 577/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0608 - accuracy: 0.9786 - val_loss: 2.1144 - val_accuracy: 0.7460\n",
      "Epoch 578/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0480 - accuracy: 0.9829 - val_loss: 2.1297 - val_accuracy: 0.7427\n",
      "Epoch 579/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0501 - accuracy: 0.9817 - val_loss: 2.1274 - val_accuracy: 0.7459\n",
      "Epoch 580/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0520 - accuracy: 0.9822 - val_loss: 2.1445 - val_accuracy: 0.7351\n",
      "Epoch 581/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0555 - accuracy: 0.9809 - val_loss: 2.1643 - val_accuracy: 0.7377\n",
      "Epoch 582/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0583 - accuracy: 0.9797 - val_loss: 2.1042 - val_accuracy: 0.7456\n",
      "Epoch 583/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0557 - accuracy: 0.9804 - val_loss: 2.1141 - val_accuracy: 0.7424\n",
      "Epoch 584/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0659 - accuracy: 0.9780 - val_loss: 2.1177 - val_accuracy: 0.7468\n",
      "Epoch 585/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0514 - accuracy: 0.9827 - val_loss: 2.1441 - val_accuracy: 0.7329\n",
      "Epoch 586/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0474 - accuracy: 0.9832 - val_loss: 2.1105 - val_accuracy: 0.7435\n",
      "Epoch 587/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0468 - accuracy: 0.9834 - val_loss: 2.1400 - val_accuracy: 0.7419\n",
      "Epoch 588/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0569 - accuracy: 0.9798 - val_loss: 2.1149 - val_accuracy: 0.7412\n",
      "Epoch 589/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0477 - accuracy: 0.9834 - val_loss: 2.1338 - val_accuracy: 0.7459\n",
      "Epoch 590/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0554 - accuracy: 0.9816 - val_loss: 2.1156 - val_accuracy: 0.7340\n",
      "Epoch 591/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0750 - accuracy: 0.9744 - val_loss: 2.1177 - val_accuracy: 0.7406\n",
      "Epoch 592/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0585 - accuracy: 0.9794 - val_loss: 2.1572 - val_accuracy: 0.7438\n",
      "Epoch 593/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0558 - accuracy: 0.9813 - val_loss: 2.1349 - val_accuracy: 0.7453\n",
      "Epoch 594/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0512 - accuracy: 0.9824 - val_loss: 2.1232 - val_accuracy: 0.7428\n",
      "Epoch 595/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0454 - accuracy: 0.9838 - val_loss: 2.1425 - val_accuracy: 0.7438\n",
      "Epoch 596/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0477 - accuracy: 0.9840 - val_loss: 2.1258 - val_accuracy: 0.7446\n",
      "Epoch 597/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0544 - accuracy: 0.9815 - val_loss: 2.1437 - val_accuracy: 0.7489\n",
      "Epoch 598/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0584 - accuracy: 0.9802 - val_loss: 2.1369 - val_accuracy: 0.7436\n",
      "Epoch 599/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0511 - accuracy: 0.9816 - val_loss: 2.1609 - val_accuracy: 0.7385\n",
      "Epoch 600/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0578 - accuracy: 0.9798 - val_loss: 2.1460 - val_accuracy: 0.7423\n",
      "Epoch 601/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0536 - accuracy: 0.9813 - val_loss: 2.1324 - val_accuracy: 0.7432\n",
      "Epoch 602/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0541 - accuracy: 0.9806 - val_loss: 2.1641 - val_accuracy: 0.7390\n",
      "Epoch 603/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0506 - accuracy: 0.9821 - val_loss: 2.1200 - val_accuracy: 0.7467\n",
      "Epoch 604/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0510 - accuracy: 0.9823 - val_loss: 2.1454 - val_accuracy: 0.7487\n",
      "Epoch 605/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0619 - accuracy: 0.9787 - val_loss: 2.1662 - val_accuracy: 0.7382\n",
      "Epoch 606/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0661 - accuracy: 0.9780 - val_loss: 2.1448 - val_accuracy: 0.7382\n",
      "Epoch 607/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0528 - accuracy: 0.9818 - val_loss: 2.1580 - val_accuracy: 0.7405\n",
      "Epoch 608/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0436 - accuracy: 0.9853 - val_loss: 2.1380 - val_accuracy: 0.7446\n",
      "Epoch 609/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0484 - accuracy: 0.9834 - val_loss: 2.1198 - val_accuracy: 0.7503\n",
      "Epoch 610/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0611 - accuracy: 0.9790 - val_loss: 2.1788 - val_accuracy: 0.7382\n",
      "Epoch 611/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0601 - accuracy: 0.9792 - val_loss: 2.1644 - val_accuracy: 0.7308\n",
      "Epoch 612/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0542 - accuracy: 0.9813 - val_loss: 2.1389 - val_accuracy: 0.7399\n",
      "Epoch 613/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0577 - accuracy: 0.9805 - val_loss: 2.1170 - val_accuracy: 0.7488\n",
      "Epoch 614/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0531 - accuracy: 0.9817 - val_loss: 2.1112 - val_accuracy: 0.7492\n",
      "Epoch 615/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 0.0469 - accuracy: 0.9836 - val_loss: 2.1360 - val_accuracy: 0.7459\n",
      "Epoch 616/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0492 - accuracy: 0.9829 - val_loss: 2.1506 - val_accuracy: 0.7439\n",
      "Epoch 617/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0582 - accuracy: 0.9795 - val_loss: 2.1404 - val_accuracy: 0.7438\n",
      "Epoch 618/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0561 - accuracy: 0.9806 - val_loss: 2.1320 - val_accuracy: 0.7470\n",
      "Epoch 619/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0529 - accuracy: 0.9815 - val_loss: 2.1228 - val_accuracy: 0.7454\n",
      "Epoch 620/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0460 - accuracy: 0.9840 - val_loss: 2.1548 - val_accuracy: 0.7371\n",
      "Epoch 621/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0502 - accuracy: 0.9829 - val_loss: 2.1629 - val_accuracy: 0.7439\n",
      "Epoch 622/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0535 - accuracy: 0.9818 - val_loss: 2.1364 - val_accuracy: 0.7440\n",
      "Epoch 623/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0488 - accuracy: 0.9825 - val_loss: 2.1730 - val_accuracy: 0.7406\n",
      "Epoch 624/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0596 - accuracy: 0.9794 - val_loss: 2.2182 - val_accuracy: 0.7371\n",
      "Epoch 625/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0604 - accuracy: 0.9796 - val_loss: 2.1602 - val_accuracy: 0.7436\n",
      "Epoch 626/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0487 - accuracy: 0.9830 - val_loss: 2.1899 - val_accuracy: 0.7339\n",
      "Epoch 627/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0507 - accuracy: 0.9825 - val_loss: 2.1630 - val_accuracy: 0.7377\n",
      "Epoch 628/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0489 - accuracy: 0.9830 - val_loss: 2.1385 - val_accuracy: 0.7555\n",
      "Epoch 629/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0488 - accuracy: 0.9831 - val_loss: 2.1490 - val_accuracy: 0.7450\n",
      "Epoch 630/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0486 - accuracy: 0.9830 - val_loss: 2.1574 - val_accuracy: 0.7375\n",
      "Epoch 631/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0558 - accuracy: 0.9810 - val_loss: 2.1493 - val_accuracy: 0.7332\n",
      "Epoch 632/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0551 - accuracy: 0.9806 - val_loss: 2.1543 - val_accuracy: 0.7454\n",
      "Epoch 633/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0525 - accuracy: 0.9821 - val_loss: 2.1220 - val_accuracy: 0.7491\n",
      "Epoch 634/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0529 - accuracy: 0.9822 - val_loss: 2.1402 - val_accuracy: 0.7431\n",
      "Epoch 635/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0658 - accuracy: 0.9779 - val_loss: 2.1211 - val_accuracy: 0.7435\n",
      "Epoch 636/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0577 - accuracy: 0.9796 - val_loss: 2.1405 - val_accuracy: 0.7403\n",
      "Epoch 637/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0404 - accuracy: 0.9855 - val_loss: 2.1342 - val_accuracy: 0.7457\n",
      "Epoch 638/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0453 - accuracy: 0.9844 - val_loss: 2.1403 - val_accuracy: 0.7453\n",
      "Epoch 639/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0510 - accuracy: 0.9817 - val_loss: 2.1612 - val_accuracy: 0.7417\n",
      "Epoch 640/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.0524 - accuracy: 0.9823 - val_loss: 2.1396 - val_accuracy: 0.7431\n",
      "Epoch 641/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0573 - accuracy: 0.9800 - val_loss: 2.1523 - val_accuracy: 0.7445\n",
      "Epoch 642/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0494 - accuracy: 0.9829 - val_loss: 2.1814 - val_accuracy: 0.7377\n",
      "Epoch 643/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0466 - accuracy: 0.9840 - val_loss: 2.1600 - val_accuracy: 0.7440\n",
      "Epoch 644/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0483 - accuracy: 0.9829 - val_loss: 2.1269 - val_accuracy: 0.7487\n",
      "Epoch 645/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0577 - accuracy: 0.9803 - val_loss: 2.1698 - val_accuracy: 0.7432\n",
      "Epoch 646/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0565 - accuracy: 0.9812 - val_loss: 2.1381 - val_accuracy: 0.7453\n",
      "Epoch 647/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0543 - accuracy: 0.9810 - val_loss: 2.1352 - val_accuracy: 0.7467\n",
      "Epoch 648/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0495 - accuracy: 0.9829 - val_loss: 2.1786 - val_accuracy: 0.7448\n",
      "Epoch 649/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0421 - accuracy: 0.9850 - val_loss: 2.1370 - val_accuracy: 0.7480\n",
      "Epoch 650/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.0492 - accuracy: 0.9828 - val_loss: 2.1982 - val_accuracy: 0.7431\n",
      "Epoch 651/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0473 - accuracy: 0.9839 - val_loss: 2.1815 - val_accuracy: 0.7408\n",
      "Epoch 652/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0494 - accuracy: 0.9822 - val_loss: 2.1830 - val_accuracy: 0.7336\n",
      "Epoch 653/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0428 - accuracy: 0.9856 - val_loss: 2.1625 - val_accuracy: 0.7457\n",
      "Epoch 654/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.0620 - accuracy: 0.9791 - val_loss: 2.2068 - val_accuracy: 0.7272\n",
      "Epoch 655/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0824 - accuracy: 0.9731 - val_loss: 2.1187 - val_accuracy: 0.7521\n",
      "Epoch 656/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.0483 - accuracy: 0.9830 - val_loss: 2.1034 - val_accuracy: 0.7511\n",
      "Epoch 657/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0545 - accuracy: 0.9811 - val_loss: 2.1440 - val_accuracy: 0.7511\n",
      "Epoch 658/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0526 - accuracy: 0.9821 - val_loss: 2.1842 - val_accuracy: 0.7423\n",
      "Epoch 659/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0497 - accuracy: 0.9834 - val_loss: 2.1531 - val_accuracy: 0.7530\n",
      "Epoch 660/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0430 - accuracy: 0.9847 - val_loss: 2.1345 - val_accuracy: 0.7491\n",
      "Epoch 661/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0511 - accuracy: 0.9826 - val_loss: 2.1426 - val_accuracy: 0.7481\n",
      "Epoch 662/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0487 - accuracy: 0.9839 - val_loss: 2.1517 - val_accuracy: 0.7400\n",
      "Epoch 663/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0454 - accuracy: 0.9846 - val_loss: 2.1669 - val_accuracy: 0.7361\n",
      "Epoch 664/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0473 - accuracy: 0.9834 - val_loss: 2.1878 - val_accuracy: 0.7388\n",
      "Epoch 665/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0476 - accuracy: 0.9837 - val_loss: 2.1985 - val_accuracy: 0.7385\n",
      "Epoch 666/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0521 - accuracy: 0.9822 - val_loss: 2.1561 - val_accuracy: 0.7465\n",
      "Epoch 667/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0598 - accuracy: 0.9795 - val_loss: 2.1724 - val_accuracy: 0.7483\n",
      "Epoch 668/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0535 - accuracy: 0.9812 - val_loss: 2.1528 - val_accuracy: 0.7469\n",
      "Epoch 669/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0448 - accuracy: 0.9843 - val_loss: 2.1872 - val_accuracy: 0.7452\n",
      "Epoch 670/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0598 - accuracy: 0.9798 - val_loss: 2.1646 - val_accuracy: 0.7373\n",
      "Epoch 671/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0498 - accuracy: 0.9833 - val_loss: 2.1407 - val_accuracy: 0.7482\n",
      "Epoch 672/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.0469 - accuracy: 0.9840 - val_loss: 2.2092 - val_accuracy: 0.7374\n",
      "Epoch 673/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0526 - accuracy: 0.9819 - val_loss: 2.1758 - val_accuracy: 0.7414\n",
      "Epoch 674/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0548 - accuracy: 0.9809 - val_loss: 2.1889 - val_accuracy: 0.7374\n",
      "Epoch 675/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0523 - accuracy: 0.9821 - val_loss: 2.2114 - val_accuracy: 0.7362\n",
      "Epoch 676/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0469 - accuracy: 0.9838 - val_loss: 2.1750 - val_accuracy: 0.7511\n",
      "Epoch 677/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0505 - accuracy: 0.9827 - val_loss: 2.1780 - val_accuracy: 0.7355\n",
      "Epoch 678/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0524 - accuracy: 0.9818 - val_loss: 2.1907 - val_accuracy: 0.7389\n",
      "Epoch 679/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0476 - accuracy: 0.9833 - val_loss: 2.1701 - val_accuracy: 0.7408\n",
      "Epoch 680/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0474 - accuracy: 0.9839 - val_loss: 2.1497 - val_accuracy: 0.7494\n",
      "Epoch 681/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0516 - accuracy: 0.9829 - val_loss: 2.1497 - val_accuracy: 0.7514\n",
      "Epoch 682/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0479 - accuracy: 0.9836 - val_loss: 2.1708 - val_accuracy: 0.7453\n",
      "Epoch 683/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0459 - accuracy: 0.9840 - val_loss: 2.2044 - val_accuracy: 0.7314\n",
      "Epoch 684/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0519 - accuracy: 0.9820 - val_loss: 2.1366 - val_accuracy: 0.7540\n",
      "Epoch 685/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0467 - accuracy: 0.9842 - val_loss: 2.1395 - val_accuracy: 0.7470\n",
      "Epoch 686/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0516 - accuracy: 0.9818 - val_loss: 2.1517 - val_accuracy: 0.7396\n",
      "Epoch 687/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.0525 - accuracy: 0.9819 - val_loss: 2.1714 - val_accuracy: 0.7371\n",
      "Epoch 688/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0476 - accuracy: 0.9833 - val_loss: 2.1272 - val_accuracy: 0.7444\n",
      "Epoch 689/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0525 - accuracy: 0.9819 - val_loss: 2.1383 - val_accuracy: 0.7483\n",
      "Epoch 690/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0542 - accuracy: 0.9814 - val_loss: 2.1628 - val_accuracy: 0.7432\n",
      "Epoch 691/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0459 - accuracy: 0.9838 - val_loss: 2.1405 - val_accuracy: 0.7479\n",
      "Epoch 692/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0407 - accuracy: 0.9862 - val_loss: 2.1533 - val_accuracy: 0.7466\n",
      "Epoch 693/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0407 - accuracy: 0.9857 - val_loss: 2.1760 - val_accuracy: 0.7475\n",
      "Epoch 694/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0548 - accuracy: 0.9815 - val_loss: 2.1628 - val_accuracy: 0.7446\n",
      "Epoch 695/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0533 - accuracy: 0.9818 - val_loss: 2.1623 - val_accuracy: 0.7478\n",
      "Epoch 696/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0531 - accuracy: 0.9821 - val_loss: 2.1667 - val_accuracy: 0.7442\n",
      "Epoch 697/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0472 - accuracy: 0.9843 - val_loss: 2.2557 - val_accuracy: 0.7292\n",
      "Epoch 698/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0505 - accuracy: 0.9834 - val_loss: 2.1755 - val_accuracy: 0.7352\n",
      "Epoch 699/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0485 - accuracy: 0.9826 - val_loss: 2.1816 - val_accuracy: 0.7366\n",
      "Epoch 700/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0520 - accuracy: 0.9819 - val_loss: 2.1817 - val_accuracy: 0.7388\n",
      "Epoch 701/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0476 - accuracy: 0.9835 - val_loss: 2.1815 - val_accuracy: 0.7442\n",
      "Epoch 702/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0503 - accuracy: 0.9831 - val_loss: 2.1603 - val_accuracy: 0.7567\n",
      "Epoch 703/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0480 - accuracy: 0.9836 - val_loss: 2.1383 - val_accuracy: 0.7573\n",
      "Epoch 704/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0535 - accuracy: 0.9807 - val_loss: 2.1623 - val_accuracy: 0.7472\n",
      "Epoch 705/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0432 - accuracy: 0.9854 - val_loss: 2.1555 - val_accuracy: 0.7489\n",
      "Epoch 706/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0428 - accuracy: 0.9848 - val_loss: 2.2016 - val_accuracy: 0.7393\n",
      "Epoch 707/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.0487 - accuracy: 0.9834 - val_loss: 2.1895 - val_accuracy: 0.7375\n",
      "Epoch 708/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0557 - accuracy: 0.9814 - val_loss: 2.2060 - val_accuracy: 0.7305\n",
      "Epoch 709/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0516 - accuracy: 0.9819 - val_loss: 2.1801 - val_accuracy: 0.7435\n",
      "Epoch 710/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0529 - accuracy: 0.9820 - val_loss: 2.1624 - val_accuracy: 0.7393\n",
      "Epoch 711/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0438 - accuracy: 0.9845 - val_loss: 2.1493 - val_accuracy: 0.7434\n",
      "Epoch 712/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0438 - accuracy: 0.9855 - val_loss: 2.1481 - val_accuracy: 0.7486\n",
      "Epoch 713/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0493 - accuracy: 0.9834 - val_loss: 2.1864 - val_accuracy: 0.7397\n",
      "Epoch 714/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0582 - accuracy: 0.9805 - val_loss: 2.1705 - val_accuracy: 0.7432\n",
      "Epoch 715/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0530 - accuracy: 0.9816 - val_loss: 2.1580 - val_accuracy: 0.7459\n",
      "Epoch 716/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.0492 - accuracy: 0.9833 - val_loss: 2.1455 - val_accuracy: 0.7557\n",
      "Epoch 717/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0433 - accuracy: 0.9850 - val_loss: 2.1709 - val_accuracy: 0.7510\n",
      "Epoch 718/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0485 - accuracy: 0.9821 - val_loss: 2.1919 - val_accuracy: 0.7417\n",
      "Epoch 719/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0457 - accuracy: 0.9840 - val_loss: 2.1576 - val_accuracy: 0.7459\n",
      "Epoch 720/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0452 - accuracy: 0.9845 - val_loss: 2.1571 - val_accuracy: 0.7512\n",
      "Epoch 721/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0496 - accuracy: 0.9825 - val_loss: 2.1469 - val_accuracy: 0.7561\n",
      "Epoch 722/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.0480 - accuracy: 0.9840 - val_loss: 2.2025 - val_accuracy: 0.7355\n",
      "Epoch 723/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0535 - accuracy: 0.9817 - val_loss: 2.1807 - val_accuracy: 0.7393\n",
      "Epoch 724/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0439 - accuracy: 0.9856 - val_loss: 2.1831 - val_accuracy: 0.7420\n",
      "Epoch 725/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0446 - accuracy: 0.9843 - val_loss: 2.1802 - val_accuracy: 0.7444\n",
      "Epoch 726/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0455 - accuracy: 0.9848 - val_loss: 2.1500 - val_accuracy: 0.7471\n",
      "Epoch 727/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0493 - accuracy: 0.9825 - val_loss: 2.1684 - val_accuracy: 0.7408\n",
      "Epoch 728/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0521 - accuracy: 0.9819 - val_loss: 2.1752 - val_accuracy: 0.7481\n",
      "Epoch 729/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0503 - accuracy: 0.9828 - val_loss: 2.1381 - val_accuracy: 0.7465\n",
      "Epoch 730/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0422 - accuracy: 0.9845 - val_loss: 2.1691 - val_accuracy: 0.7463\n",
      "Epoch 731/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0478 - accuracy: 0.9831 - val_loss: 2.1943 - val_accuracy: 0.7450\n",
      "Epoch 732/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0441 - accuracy: 0.9847 - val_loss: 2.2033 - val_accuracy: 0.7398\n",
      "Epoch 733/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0484 - accuracy: 0.9834 - val_loss: 2.1631 - val_accuracy: 0.7394\n",
      "Epoch 734/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0515 - accuracy: 0.9827 - val_loss: 2.1638 - val_accuracy: 0.7462\n",
      "Epoch 735/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0466 - accuracy: 0.9830 - val_loss: 2.1895 - val_accuracy: 0.7364\n",
      "Epoch 736/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0477 - accuracy: 0.9838 - val_loss: 2.1625 - val_accuracy: 0.7562\n",
      "Epoch 737/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0472 - accuracy: 0.9838 - val_loss: 2.1538 - val_accuracy: 0.7382\n",
      "Epoch 738/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0491 - accuracy: 0.9830 - val_loss: 2.1978 - val_accuracy: 0.7368\n",
      "Epoch 739/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0359 - accuracy: 0.9880 - val_loss: 2.1749 - val_accuracy: 0.7459\n",
      "Epoch 740/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0555 - accuracy: 0.9814 - val_loss: 2.1572 - val_accuracy: 0.7364\n",
      "Epoch 741/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0598 - accuracy: 0.9798 - val_loss: 2.1661 - val_accuracy: 0.7487\n",
      "Epoch 742/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0547 - accuracy: 0.9813 - val_loss: 2.1615 - val_accuracy: 0.7460\n",
      "Epoch 743/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0493 - accuracy: 0.9825 - val_loss: 2.2014 - val_accuracy: 0.7355\n",
      "Epoch 744/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0424 - accuracy: 0.9861 - val_loss: 2.1631 - val_accuracy: 0.7484\n",
      "Epoch 745/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0418 - accuracy: 0.9853 - val_loss: 2.1978 - val_accuracy: 0.7426\n",
      "Epoch 746/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0428 - accuracy: 0.9851 - val_loss: 2.2137 - val_accuracy: 0.7390\n",
      "Epoch 747/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0450 - accuracy: 0.9842 - val_loss: 2.1617 - val_accuracy: 0.7483\n",
      "Epoch 748/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0492 - accuracy: 0.9834 - val_loss: 2.1776 - val_accuracy: 0.7437\n",
      "Epoch 749/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0491 - accuracy: 0.9830 - val_loss: 2.1664 - val_accuracy: 0.7560\n",
      "Epoch 750/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0446 - accuracy: 0.9844 - val_loss: 2.1961 - val_accuracy: 0.7464\n",
      "Epoch 751/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0488 - accuracy: 0.9839 - val_loss: 2.1892 - val_accuracy: 0.7454\n",
      "Epoch 752/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0514 - accuracy: 0.9821 - val_loss: 2.1838 - val_accuracy: 0.7458\n",
      "Epoch 753/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0436 - accuracy: 0.9847 - val_loss: 2.1941 - val_accuracy: 0.7474\n",
      "Epoch 754/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0418 - accuracy: 0.9855 - val_loss: 2.1603 - val_accuracy: 0.7464\n",
      "Epoch 755/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0437 - accuracy: 0.9852 - val_loss: 2.2074 - val_accuracy: 0.7373\n",
      "Epoch 756/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0396 - accuracy: 0.9864 - val_loss: 2.1836 - val_accuracy: 0.7463\n",
      "Epoch 757/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0456 - accuracy: 0.9847 - val_loss: 2.1705 - val_accuracy: 0.7520\n",
      "Epoch 758/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0577 - accuracy: 0.9804 - val_loss: 2.1785 - val_accuracy: 0.7397\n",
      "Epoch 759/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0491 - accuracy: 0.9830 - val_loss: 2.1752 - val_accuracy: 0.7502\n",
      "Epoch 760/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0460 - accuracy: 0.9847 - val_loss: 2.1710 - val_accuracy: 0.7539\n",
      "Epoch 761/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0441 - accuracy: 0.9848 - val_loss: 2.1812 - val_accuracy: 0.7470\n",
      "Epoch 762/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.0438 - accuracy: 0.9852 - val_loss: 2.1612 - val_accuracy: 0.7542\n",
      "Epoch 763/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0480 - accuracy: 0.9835 - val_loss: 2.2187 - val_accuracy: 0.7279\n",
      "Epoch 764/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0435 - accuracy: 0.9856 - val_loss: 2.2192 - val_accuracy: 0.7337\n",
      "Epoch 765/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0617 - accuracy: 0.9797 - val_loss: 2.1633 - val_accuracy: 0.7453\n",
      "Epoch 766/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0510 - accuracy: 0.9821 - val_loss: 2.2138 - val_accuracy: 0.7422\n",
      "Epoch 767/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0433 - accuracy: 0.9848 - val_loss: 2.1901 - val_accuracy: 0.7396\n",
      "Epoch 768/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0455 - accuracy: 0.9849 - val_loss: 2.2350 - val_accuracy: 0.7408\n",
      "Epoch 769/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0445 - accuracy: 0.9845 - val_loss: 2.2124 - val_accuracy: 0.7416\n",
      "Epoch 770/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0429 - accuracy: 0.9856 - val_loss: 2.2167 - val_accuracy: 0.7335\n",
      "Epoch 771/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0485 - accuracy: 0.9829 - val_loss: 2.1857 - val_accuracy: 0.7411\n",
      "Epoch 772/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.0479 - accuracy: 0.9834 - val_loss: 2.2319 - val_accuracy: 0.7278\n",
      "Epoch 773/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0513 - accuracy: 0.9825 - val_loss: 2.1882 - val_accuracy: 0.7442\n",
      "Epoch 774/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.0409 - accuracy: 0.9850 - val_loss: 2.1596 - val_accuracy: 0.7507\n",
      "Epoch 775/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0495 - accuracy: 0.9838 - val_loss: 2.1944 - val_accuracy: 0.7443\n",
      "Epoch 776/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0446 - accuracy: 0.9849 - val_loss: 2.2086 - val_accuracy: 0.7412\n",
      "Epoch 777/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0411 - accuracy: 0.9852 - val_loss: 2.1831 - val_accuracy: 0.7525\n",
      "Epoch 778/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0465 - accuracy: 0.9839 - val_loss: 2.2061 - val_accuracy: 0.7432\n",
      "Epoch 779/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0525 - accuracy: 0.9820 - val_loss: 2.2118 - val_accuracy: 0.7454\n",
      "Epoch 780/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0442 - accuracy: 0.9851 - val_loss: 2.2008 - val_accuracy: 0.7416\n",
      "Epoch 781/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0467 - accuracy: 0.9837 - val_loss: 2.1676 - val_accuracy: 0.7482\n",
      "Epoch 782/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0492 - accuracy: 0.9837 - val_loss: 2.1796 - val_accuracy: 0.7447\n",
      "Epoch 783/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0459 - accuracy: 0.9839 - val_loss: 2.1713 - val_accuracy: 0.7468\n",
      "Epoch 784/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0518 - accuracy: 0.9822 - val_loss: 2.1676 - val_accuracy: 0.7449\n",
      "Epoch 785/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.0430 - accuracy: 0.9852 - val_loss: 2.1854 - val_accuracy: 0.7446\n",
      "Epoch 786/1000\n",
      "49590/49590 [==============================] - 2s 48us/sample - loss: 0.0409 - accuracy: 0.9856 - val_loss: 2.1880 - val_accuracy: 0.7430\n",
      "Epoch 787/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 0.0425 - accuracy: 0.9852 - val_loss: 2.1564 - val_accuracy: 0.7534\n",
      "Epoch 788/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0458 - accuracy: 0.9842 - val_loss: 2.2036 - val_accuracy: 0.7396\n",
      "Epoch 789/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0443 - accuracy: 0.9847 - val_loss: 2.2153 - val_accuracy: 0.7376\n",
      "Epoch 790/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0525 - accuracy: 0.9822 - val_loss: 2.2118 - val_accuracy: 0.7365\n",
      "Epoch 791/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0498 - accuracy: 0.9829 - val_loss: 2.1956 - val_accuracy: 0.7463\n",
      "Epoch 792/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0400 - accuracy: 0.9865 - val_loss: 2.1914 - val_accuracy: 0.7435\n",
      "Epoch 793/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0430 - accuracy: 0.9855 - val_loss: 2.1824 - val_accuracy: 0.7453\n",
      "Epoch 794/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0421 - accuracy: 0.9856 - val_loss: 2.1982 - val_accuracy: 0.7480\n",
      "Epoch 795/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0442 - accuracy: 0.9848 - val_loss: 2.1762 - val_accuracy: 0.7462\n",
      "Epoch 796/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0469 - accuracy: 0.9844 - val_loss: 2.1702 - val_accuracy: 0.7510\n",
      "Epoch 797/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0529 - accuracy: 0.9815 - val_loss: 2.2082 - val_accuracy: 0.7430\n",
      "Epoch 798/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0472 - accuracy: 0.9831 - val_loss: 2.1928 - val_accuracy: 0.7428\n",
      "Epoch 799/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0429 - accuracy: 0.9851 - val_loss: 2.2292 - val_accuracy: 0.7418\n",
      "Epoch 800/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0603 - accuracy: 0.9798 - val_loss: 2.1855 - val_accuracy: 0.7450\n",
      "Epoch 801/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0378 - accuracy: 0.9862 - val_loss: 2.1623 - val_accuracy: 0.7473\n",
      "Epoch 802/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0337 - accuracy: 0.9885 - val_loss: 2.2021 - val_accuracy: 0.7382\n",
      "Epoch 803/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0408 - accuracy: 0.9856 - val_loss: 2.2497 - val_accuracy: 0.7287\n",
      "Epoch 804/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0484 - accuracy: 0.9836 - val_loss: 2.1822 - val_accuracy: 0.7466\n",
      "Epoch 805/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0515 - accuracy: 0.9827 - val_loss: 2.1931 - val_accuracy: 0.7426\n",
      "Epoch 806/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0445 - accuracy: 0.9842 - val_loss: 2.1981 - val_accuracy: 0.7403\n",
      "Epoch 807/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0449 - accuracy: 0.9843 - val_loss: 2.2586 - val_accuracy: 0.7306\n",
      "Epoch 808/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0529 - accuracy: 0.9821 - val_loss: 2.1712 - val_accuracy: 0.7517\n",
      "Epoch 809/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0381 - accuracy: 0.9864 - val_loss: 2.2254 - val_accuracy: 0.7398\n",
      "Epoch 810/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0412 - accuracy: 0.9861 - val_loss: 2.1786 - val_accuracy: 0.7481\n",
      "Epoch 811/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0416 - accuracy: 0.9855 - val_loss: 2.2433 - val_accuracy: 0.7402\n",
      "Epoch 812/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0407 - accuracy: 0.9856 - val_loss: 2.1814 - val_accuracy: 0.7479\n",
      "Epoch 813/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0459 - accuracy: 0.9849 - val_loss: 2.2058 - val_accuracy: 0.7451\n",
      "Epoch 814/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0640 - accuracy: 0.9787 - val_loss: 2.1683 - val_accuracy: 0.7536\n",
      "Epoch 815/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0428 - accuracy: 0.9851 - val_loss: 2.2218 - val_accuracy: 0.7387\n",
      "Epoch 816/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0395 - accuracy: 0.9863 - val_loss: 2.2076 - val_accuracy: 0.7492\n",
      "Epoch 817/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0409 - accuracy: 0.9858 - val_loss: 2.2240 - val_accuracy: 0.7430\n",
      "Epoch 818/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0392 - accuracy: 0.9863 - val_loss: 2.2243 - val_accuracy: 0.7382\n",
      "Epoch 819/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0432 - accuracy: 0.9851 - val_loss: 2.1893 - val_accuracy: 0.7468\n",
      "Epoch 820/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0508 - accuracy: 0.9832 - val_loss: 2.2527 - val_accuracy: 0.7335\n",
      "Epoch 821/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0521 - accuracy: 0.9812 - val_loss: 2.2107 - val_accuracy: 0.7456\n",
      "Epoch 822/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0480 - accuracy: 0.9834 - val_loss: 2.2553 - val_accuracy: 0.7351\n",
      "Epoch 823/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0452 - accuracy: 0.9849 - val_loss: 2.2436 - val_accuracy: 0.7362\n",
      "Epoch 824/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.0406 - accuracy: 0.9863 - val_loss: 2.1943 - val_accuracy: 0.7460\n",
      "Epoch 825/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.0352 - accuracy: 0.9883 - val_loss: 2.2239 - val_accuracy: 0.7410\n",
      "Epoch 826/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0465 - accuracy: 0.9842 - val_loss: 2.2086 - val_accuracy: 0.7431\n",
      "Epoch 827/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0503 - accuracy: 0.9822 - val_loss: 2.1969 - val_accuracy: 0.7430\n",
      "Epoch 828/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0491 - accuracy: 0.9838 - val_loss: 2.1541 - val_accuracy: 0.7560\n",
      "Epoch 829/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0477 - accuracy: 0.9837 - val_loss: 2.1885 - val_accuracy: 0.7468\n",
      "Epoch 830/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0506 - accuracy: 0.9829 - val_loss: 2.2023 - val_accuracy: 0.7387\n",
      "Epoch 831/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0432 - accuracy: 0.9851 - val_loss: 2.1947 - val_accuracy: 0.7435\n",
      "Epoch 832/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0383 - accuracy: 0.9864 - val_loss: 2.1884 - val_accuracy: 0.7456\n",
      "Epoch 833/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0376 - accuracy: 0.9873 - val_loss: 2.2018 - val_accuracy: 0.7443\n",
      "Epoch 834/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0439 - accuracy: 0.9846 - val_loss: 2.1797 - val_accuracy: 0.7466\n",
      "Epoch 835/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0428 - accuracy: 0.9846 - val_loss: 2.1986 - val_accuracy: 0.7452\n",
      "Epoch 836/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0389 - accuracy: 0.9869 - val_loss: 2.2614 - val_accuracy: 0.7321\n",
      "Epoch 837/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0446 - accuracy: 0.9846 - val_loss: 2.2258 - val_accuracy: 0.7396\n",
      "Epoch 838/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0538 - accuracy: 0.9814 - val_loss: 2.1593 - val_accuracy: 0.7524\n",
      "Epoch 839/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0470 - accuracy: 0.9844 - val_loss: 2.2133 - val_accuracy: 0.7352\n",
      "Epoch 840/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0454 - accuracy: 0.9845 - val_loss: 2.2022 - val_accuracy: 0.7446\n",
      "Epoch 841/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0407 - accuracy: 0.9864 - val_loss: 2.2186 - val_accuracy: 0.7437\n",
      "Epoch 842/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0396 - accuracy: 0.9862 - val_loss: 2.1797 - val_accuracy: 0.7466\n",
      "Epoch 843/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0418 - accuracy: 0.9854 - val_loss: 2.2096 - val_accuracy: 0.7454\n",
      "Epoch 844/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0392 - accuracy: 0.9865 - val_loss: 2.1861 - val_accuracy: 0.7511\n",
      "Epoch 845/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0403 - accuracy: 0.9861 - val_loss: 2.1858 - val_accuracy: 0.7469\n",
      "Epoch 846/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0569 - accuracy: 0.9814 - val_loss: 2.1754 - val_accuracy: 0.7424\n",
      "Epoch 847/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0467 - accuracy: 0.9841 - val_loss: 2.2187 - val_accuracy: 0.7494\n",
      "Epoch 848/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0418 - accuracy: 0.9852 - val_loss: 2.2229 - val_accuracy: 0.7469\n",
      "Epoch 849/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0436 - accuracy: 0.9849 - val_loss: 2.2004 - val_accuracy: 0.7478\n",
      "Epoch 850/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0397 - accuracy: 0.9856 - val_loss: 2.2271 - val_accuracy: 0.7389\n",
      "Epoch 851/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0344 - accuracy: 0.9880 - val_loss: 2.2028 - val_accuracy: 0.7484\n",
      "Epoch 852/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0425 - accuracy: 0.9849 - val_loss: 2.2290 - val_accuracy: 0.7455\n",
      "Epoch 853/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0692 - accuracy: 0.9777 - val_loss: 2.2493 - val_accuracy: 0.7336\n",
      "Epoch 854/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0519 - accuracy: 0.9829 - val_loss: 2.1880 - val_accuracy: 0.7436\n",
      "Epoch 855/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0367 - accuracy: 0.9876 - val_loss: 2.1823 - val_accuracy: 0.7501\n",
      "Epoch 856/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0340 - accuracy: 0.9883 - val_loss: 2.2328 - val_accuracy: 0.7367\n",
      "Epoch 857/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0369 - accuracy: 0.9873 - val_loss: 2.2120 - val_accuracy: 0.7406\n",
      "Epoch 858/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0475 - accuracy: 0.9841 - val_loss: 2.2405 - val_accuracy: 0.7377\n",
      "Epoch 859/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0429 - accuracy: 0.9852 - val_loss: 2.1746 - val_accuracy: 0.7476\n",
      "Epoch 860/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0509 - accuracy: 0.9821 - val_loss: 2.2316 - val_accuracy: 0.7431\n",
      "Epoch 861/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0474 - accuracy: 0.9839 - val_loss: 2.2107 - val_accuracy: 0.7421\n",
      "Epoch 862/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0383 - accuracy: 0.9868 - val_loss: 2.1754 - val_accuracy: 0.7503\n",
      "Epoch 863/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0526 - accuracy: 0.9818 - val_loss: 2.2173 - val_accuracy: 0.7398\n",
      "Epoch 864/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0453 - accuracy: 0.9847 - val_loss: 2.2050 - val_accuracy: 0.7461\n",
      "Epoch 865/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0353 - accuracy: 0.9876 - val_loss: 2.1930 - val_accuracy: 0.7462\n",
      "Epoch 866/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0396 - accuracy: 0.9859 - val_loss: 2.2093 - val_accuracy: 0.7428\n",
      "Epoch 867/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0415 - accuracy: 0.9851 - val_loss: 2.1741 - val_accuracy: 0.7621\n",
      "Epoch 868/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0474 - accuracy: 0.9839 - val_loss: 2.1924 - val_accuracy: 0.7483\n",
      "Epoch 869/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.0446 - accuracy: 0.9851 - val_loss: 2.2684 - val_accuracy: 0.7301\n",
      "Epoch 870/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0441 - accuracy: 0.9843 - val_loss: 2.1994 - val_accuracy: 0.7486\n",
      "Epoch 871/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0478 - accuracy: 0.9836 - val_loss: 2.2161 - val_accuracy: 0.7434\n",
      "Epoch 872/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0448 - accuracy: 0.9842 - val_loss: 2.2042 - val_accuracy: 0.7486\n",
      "Epoch 873/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0370 - accuracy: 0.9873 - val_loss: 2.2143 - val_accuracy: 0.7448\n",
      "Epoch 874/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.0457 - accuracy: 0.9855 - val_loss: 2.2077 - val_accuracy: 0.7462\n",
      "Epoch 875/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.0431 - accuracy: 0.9850 - val_loss: 2.2303 - val_accuracy: 0.7350\n",
      "Epoch 876/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.0363 - accuracy: 0.9879 - val_loss: 2.1856 - val_accuracy: 0.7462\n",
      "Epoch 877/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0365 - accuracy: 0.9877 - val_loss: 2.2804 - val_accuracy: 0.7309\n",
      "Epoch 878/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0484 - accuracy: 0.9837 - val_loss: 2.1997 - val_accuracy: 0.7480\n",
      "Epoch 879/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0416 - accuracy: 0.9860 - val_loss: 2.2303 - val_accuracy: 0.7427\n",
      "Epoch 880/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0445 - accuracy: 0.9849 - val_loss: 2.2599 - val_accuracy: 0.7393\n",
      "Epoch 881/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0438 - accuracy: 0.9844 - val_loss: 2.1926 - val_accuracy: 0.7507\n",
      "Epoch 882/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0445 - accuracy: 0.9846 - val_loss: 2.1863 - val_accuracy: 0.7478\n",
      "Epoch 883/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0453 - accuracy: 0.9846 - val_loss: 2.2377 - val_accuracy: 0.7375\n",
      "Epoch 884/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0356 - accuracy: 0.9880 - val_loss: 2.2125 - val_accuracy: 0.7406\n",
      "Epoch 885/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0440 - accuracy: 0.9844 - val_loss: 2.1643 - val_accuracy: 0.7530\n",
      "Epoch 886/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0517 - accuracy: 0.9825 - val_loss: 2.1615 - val_accuracy: 0.7566\n",
      "Epoch 887/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0469 - accuracy: 0.9835 - val_loss: 2.2062 - val_accuracy: 0.7495\n",
      "Epoch 888/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0379 - accuracy: 0.9865 - val_loss: 2.1867 - val_accuracy: 0.7540\n",
      "Epoch 889/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0353 - accuracy: 0.9879 - val_loss: 2.2001 - val_accuracy: 0.7475\n",
      "Epoch 890/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0397 - accuracy: 0.9861 - val_loss: 2.2653 - val_accuracy: 0.7280\n",
      "Epoch 891/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0430 - accuracy: 0.9848 - val_loss: 2.1884 - val_accuracy: 0.7562\n",
      "Epoch 892/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0452 - accuracy: 0.9846 - val_loss: 2.1890 - val_accuracy: 0.7483\n",
      "Epoch 893/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0445 - accuracy: 0.9845 - val_loss: 2.1972 - val_accuracy: 0.7452\n",
      "Epoch 894/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0389 - accuracy: 0.9862 - val_loss: 2.1839 - val_accuracy: 0.7537\n",
      "Epoch 895/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0414 - accuracy: 0.9856 - val_loss: 2.2243 - val_accuracy: 0.7418\n",
      "Epoch 896/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0438 - accuracy: 0.9850 - val_loss: 2.2486 - val_accuracy: 0.7295\n",
      "Epoch 897/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0366 - accuracy: 0.9876 - val_loss: 2.2311 - val_accuracy: 0.7433\n",
      "Epoch 898/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0421 - accuracy: 0.9847 - val_loss: 2.1980 - val_accuracy: 0.7502\n",
      "Epoch 899/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0438 - accuracy: 0.9848 - val_loss: 2.1899 - val_accuracy: 0.7530\n",
      "Epoch 900/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0475 - accuracy: 0.9834 - val_loss: 2.2091 - val_accuracy: 0.7475\n",
      "Epoch 901/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0371 - accuracy: 0.9869 - val_loss: 2.2669 - val_accuracy: 0.7318\n",
      "Epoch 902/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0556 - accuracy: 0.9815 - val_loss: 2.2112 - val_accuracy: 0.7425\n",
      "Epoch 903/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0391 - accuracy: 0.9865 - val_loss: 2.2274 - val_accuracy: 0.7446\n",
      "Epoch 904/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0345 - accuracy: 0.9876 - val_loss: 2.2005 - val_accuracy: 0.7457\n",
      "Epoch 905/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0377 - accuracy: 0.9867 - val_loss: 2.2652 - val_accuracy: 0.7342\n",
      "Epoch 906/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0534 - accuracy: 0.9822 - val_loss: 2.2356 - val_accuracy: 0.7391\n",
      "Epoch 907/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0378 - accuracy: 0.9867 - val_loss: 2.2258 - val_accuracy: 0.7416\n",
      "Epoch 908/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0418 - accuracy: 0.9855 - val_loss: 2.1942 - val_accuracy: 0.7486\n",
      "Epoch 909/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0430 - accuracy: 0.9850 - val_loss: 2.1892 - val_accuracy: 0.7480\n",
      "Epoch 910/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0418 - accuracy: 0.9858 - val_loss: 2.2186 - val_accuracy: 0.7365\n",
      "Epoch 911/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0402 - accuracy: 0.9857 - val_loss: 2.2127 - val_accuracy: 0.7492\n",
      "Epoch 912/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0371 - accuracy: 0.9873 - val_loss: 2.2395 - val_accuracy: 0.7483\n",
      "Epoch 913/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0473 - accuracy: 0.9844 - val_loss: 2.2123 - val_accuracy: 0.7462\n",
      "Epoch 914/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0368 - accuracy: 0.9869 - val_loss: 2.1798 - val_accuracy: 0.7510\n",
      "Epoch 915/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0424 - accuracy: 0.9859 - val_loss: 2.2344 - val_accuracy: 0.7459\n",
      "Epoch 916/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0547 - accuracy: 0.9814 - val_loss: 2.2303 - val_accuracy: 0.7414\n",
      "Epoch 917/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0421 - accuracy: 0.9856 - val_loss: 2.2035 - val_accuracy: 0.7476\n",
      "Epoch 918/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0330 - accuracy: 0.9888 - val_loss: 2.1959 - val_accuracy: 0.7512\n",
      "Epoch 919/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0331 - accuracy: 0.9889 - val_loss: 2.2245 - val_accuracy: 0.7446\n",
      "Epoch 920/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0418 - accuracy: 0.9862 - val_loss: 2.1928 - val_accuracy: 0.7578\n",
      "Epoch 921/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0460 - accuracy: 0.9841 - val_loss: 2.2468 - val_accuracy: 0.7411\n",
      "Epoch 922/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0391 - accuracy: 0.9864 - val_loss: 2.2052 - val_accuracy: 0.7479\n",
      "Epoch 923/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0398 - accuracy: 0.9862 - val_loss: 2.2525 - val_accuracy: 0.7421\n",
      "Epoch 924/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0433 - accuracy: 0.9851 - val_loss: 2.1975 - val_accuracy: 0.7531\n",
      "Epoch 925/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0516 - accuracy: 0.9819 - val_loss: 2.2780 - val_accuracy: 0.7342\n",
      "Epoch 926/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0422 - accuracy: 0.9851 - val_loss: 2.2330 - val_accuracy: 0.7432\n",
      "Epoch 927/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0388 - accuracy: 0.9861 - val_loss: 2.2537 - val_accuracy: 0.7378\n",
      "Epoch 928/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0364 - accuracy: 0.9875 - val_loss: 2.2623 - val_accuracy: 0.7362\n",
      "Epoch 929/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0405 - accuracy: 0.9864 - val_loss: 2.2177 - val_accuracy: 0.7442\n",
      "Epoch 930/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0408 - accuracy: 0.9861 - val_loss: 2.2233 - val_accuracy: 0.7443\n",
      "Epoch 931/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0398 - accuracy: 0.9864 - val_loss: 2.2128 - val_accuracy: 0.7462\n",
      "Epoch 932/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0428 - accuracy: 0.9850 - val_loss: 2.2186 - val_accuracy: 0.7500\n",
      "Epoch 933/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0401 - accuracy: 0.9860 - val_loss: 2.1966 - val_accuracy: 0.7516\n",
      "Epoch 934/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0338 - accuracy: 0.9882 - val_loss: 2.2338 - val_accuracy: 0.7414\n",
      "Epoch 935/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0415 - accuracy: 0.9856 - val_loss: 2.2122 - val_accuracy: 0.7439\n",
      "Epoch 936/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0497 - accuracy: 0.9833 - val_loss: 2.2258 - val_accuracy: 0.7434\n",
      "Epoch 937/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0425 - accuracy: 0.9845 - val_loss: 2.2463 - val_accuracy: 0.7375\n",
      "Epoch 938/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0384 - accuracy: 0.9872 - val_loss: 2.2390 - val_accuracy: 0.7431\n",
      "Epoch 939/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.0403 - accuracy: 0.9857 - val_loss: 2.2385 - val_accuracy: 0.7472\n",
      "Epoch 940/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.0387 - accuracy: 0.9869 - val_loss: 2.2443 - val_accuracy: 0.7396\n",
      "Epoch 941/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0360 - accuracy: 0.9873 - val_loss: 2.2288 - val_accuracy: 0.7467\n",
      "Epoch 942/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0400 - accuracy: 0.9861 - val_loss: 2.2003 - val_accuracy: 0.7539\n",
      "Epoch 943/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0440 - accuracy: 0.9845 - val_loss: 2.2650 - val_accuracy: 0.7343\n",
      "Epoch 944/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0411 - accuracy: 0.9854 - val_loss: 2.2251 - val_accuracy: 0.7498\n",
      "Epoch 945/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0372 - accuracy: 0.9874 - val_loss: 2.2610 - val_accuracy: 0.7421\n",
      "Epoch 946/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0427 - accuracy: 0.9845 - val_loss: 2.2266 - val_accuracy: 0.7460\n",
      "Epoch 947/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0438 - accuracy: 0.9845 - val_loss: 2.2723 - val_accuracy: 0.7344\n",
      "Epoch 948/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0350 - accuracy: 0.9880 - val_loss: 2.2392 - val_accuracy: 0.7494\n",
      "Epoch 949/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0401 - accuracy: 0.9863 - val_loss: 2.2466 - val_accuracy: 0.7484\n",
      "Epoch 950/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0501 - accuracy: 0.9834 - val_loss: 2.2701 - val_accuracy: 0.7344\n",
      "Epoch 951/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0518 - accuracy: 0.9826 - val_loss: 2.2386 - val_accuracy: 0.7369\n",
      "Epoch 952/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0375 - accuracy: 0.9871 - val_loss: 2.2509 - val_accuracy: 0.7409\n",
      "Epoch 953/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0331 - accuracy: 0.9882 - val_loss: 2.2188 - val_accuracy: 0.7426\n",
      "Epoch 954/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0331 - accuracy: 0.9890 - val_loss: 2.2635 - val_accuracy: 0.7420\n",
      "Epoch 955/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0407 - accuracy: 0.9858 - val_loss: 2.2085 - val_accuracy: 0.7557\n",
      "Epoch 956/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0485 - accuracy: 0.9840 - val_loss: 2.2403 - val_accuracy: 0.7395\n",
      "Epoch 957/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0447 - accuracy: 0.9852 - val_loss: 2.2124 - val_accuracy: 0.7520\n",
      "Epoch 958/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0357 - accuracy: 0.9878 - val_loss: 2.1868 - val_accuracy: 0.7535\n",
      "Epoch 959/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0420 - accuracy: 0.9860 - val_loss: 2.2271 - val_accuracy: 0.7428\n",
      "Epoch 960/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0369 - accuracy: 0.9873 - val_loss: 2.2194 - val_accuracy: 0.7466\n",
      "Epoch 961/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0448 - accuracy: 0.9855 - val_loss: 2.2331 - val_accuracy: 0.7440\n",
      "Epoch 962/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.0468 - accuracy: 0.9839 - val_loss: 2.2328 - val_accuracy: 0.7422\n",
      "Epoch 963/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.0418 - accuracy: 0.9846 - val_loss: 2.1934 - val_accuracy: 0.7482\n",
      "Epoch 964/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0372 - accuracy: 0.9875 - val_loss: 2.1763 - val_accuracy: 0.7566\n",
      "Epoch 965/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0465 - accuracy: 0.9841 - val_loss: 2.2492 - val_accuracy: 0.7407\n",
      "Epoch 966/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0371 - accuracy: 0.9872 - val_loss: 2.2662 - val_accuracy: 0.7370\n",
      "Epoch 967/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0367 - accuracy: 0.9867 - val_loss: 2.2044 - val_accuracy: 0.7510\n",
      "Epoch 968/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0391 - accuracy: 0.9862 - val_loss: 2.2461 - val_accuracy: 0.7409\n",
      "Epoch 969/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0427 - accuracy: 0.9852 - val_loss: 2.2053 - val_accuracy: 0.7469\n",
      "Epoch 970/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0329 - accuracy: 0.9881 - val_loss: 2.2169 - val_accuracy: 0.7437\n",
      "Epoch 971/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0395 - accuracy: 0.9865 - val_loss: 2.2431 - val_accuracy: 0.7471\n",
      "Epoch 972/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0430 - accuracy: 0.9847 - val_loss: 2.2234 - val_accuracy: 0.7443\n",
      "Epoch 973/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0511 - accuracy: 0.9822 - val_loss: 2.2079 - val_accuracy: 0.7478\n",
      "Epoch 974/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0443 - accuracy: 0.9852 - val_loss: 2.2314 - val_accuracy: 0.7407\n",
      "Epoch 975/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0395 - accuracy: 0.9863 - val_loss: 2.2088 - val_accuracy: 0.7479\n",
      "Epoch 976/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0416 - accuracy: 0.9863 - val_loss: 2.2607 - val_accuracy: 0.7419\n",
      "Epoch 977/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0352 - accuracy: 0.9877 - val_loss: 2.2307 - val_accuracy: 0.7495\n",
      "Epoch 978/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0427 - accuracy: 0.9854 - val_loss: 2.2167 - val_accuracy: 0.7429\n",
      "Epoch 979/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0389 - accuracy: 0.9861 - val_loss: 2.2675 - val_accuracy: 0.7390\n",
      "Epoch 980/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0371 - accuracy: 0.9869 - val_loss: 2.2336 - val_accuracy: 0.7460\n",
      "Epoch 981/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0373 - accuracy: 0.9867 - val_loss: 2.2321 - val_accuracy: 0.7506\n",
      "Epoch 982/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0402 - accuracy: 0.9865 - val_loss: 2.2656 - val_accuracy: 0.7365\n",
      "Epoch 983/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0385 - accuracy: 0.9863 - val_loss: 2.2635 - val_accuracy: 0.7393\n",
      "Epoch 984/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0363 - accuracy: 0.9877 - val_loss: 2.2289 - val_accuracy: 0.7457\n",
      "Epoch 985/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0371 - accuracy: 0.9871 - val_loss: 2.2819 - val_accuracy: 0.7427\n",
      "Epoch 986/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0498 - accuracy: 0.9836 - val_loss: 2.2346 - val_accuracy: 0.7401\n",
      "Epoch 987/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0479 - accuracy: 0.9829 - val_loss: 2.2515 - val_accuracy: 0.7387\n",
      "Epoch 988/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0424 - accuracy: 0.9849 - val_loss: 2.1995 - val_accuracy: 0.7453\n",
      "Epoch 989/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0335 - accuracy: 0.9885 - val_loss: 2.2261 - val_accuracy: 0.7491\n",
      "Epoch 990/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0355 - accuracy: 0.9877 - val_loss: 2.1928 - val_accuracy: 0.7526\n",
      "Epoch 991/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0325 - accuracy: 0.9889 - val_loss: 2.2522 - val_accuracy: 0.7447\n",
      "Epoch 992/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0403 - accuracy: 0.9869 - val_loss: 2.2493 - val_accuracy: 0.7398\n",
      "Epoch 993/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0430 - accuracy: 0.9853 - val_loss: 2.2583 - val_accuracy: 0.7385\n",
      "Epoch 994/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0449 - accuracy: 0.9839 - val_loss: 2.2129 - val_accuracy: 0.7506\n",
      "Epoch 995/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0376 - accuracy: 0.9868 - val_loss: 2.2559 - val_accuracy: 0.7362\n",
      "Epoch 996/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0356 - accuracy: 0.9877 - val_loss: 2.2052 - val_accuracy: 0.7513\n",
      "Epoch 997/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0500 - accuracy: 0.9835 - val_loss: 2.1644 - val_accuracy: 0.7562\n",
      "Epoch 998/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0375 - accuracy: 0.9871 - val_loss: 2.2268 - val_accuracy: 0.7434\n",
      "Epoch 999/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.0366 - accuracy: 0.9871 - val_loss: 2.2213 - val_accuracy: 0.7439\n",
      "Epoch 1000/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.0405 - accuracy: 0.9863 - val_loss: 2.2239 - val_accuracy: 0.7493\n"
     ]
    }
   ],
   "source": [
    "# specify network layers\n",
    "binary_ann_overfit = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (13, )),\n",
    "    tf.keras.layers.Dense(100, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(100, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(100, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(100, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "# compile and fit network\n",
    "binary_ann_overfit.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy']) \n",
    "history = binary_ann_overfit.fit(X_train, y_train, epochs = 1000, batch_size = 128, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xd4VGXawOHfk5AekpCE3kLvLYZmA0RBcAXbqqhrWZXVT8VddVfWdRVZ26q7a13bCnYQOyqCiiCiKEWa9A4hlBAgEEib5P3+OGcyJTPJJGQyITz3dc01p8877TznrUeMMSillFIVCQt1ApRSStV9GiyUUkpVSoOFUkqpSmmwUEopVSkNFkoppSqlwUIppVSlNFiokBGRNBExItIggG2vF5GFtZEuFXwiMlREMkOdDhU4DRYqICKyXUSKRCTVa/kK+4SfFpqUeaQlTkTyRGRWqNNyMnEL2nlejytCnTZVd2iwUFWxDRjnnBGRXkBM6JJTzmVAITBCRJrX5gsHkjs6CSQZY+LdHu+FOkGq7tBgoariLeBat/nrgDfdNxCRRBF5U0SyRWSHiNwvImH2unAReUpEDojIVuACH/u+JiJ7RGS3iDwsIuFVSN91wEvAKuBqr2O3FpGP7HTliMjzbutuFpF1InJURNaKSLq93IhIR7ftXheRh+3poSKSKSL3isheYKqINBKRz+3XOGRPt3LbP1lEpopIlr3+E3v5ryJyodt2EfZn1Nf7Ddrp/I3bfAN723QRiRaRt+33d1hElohI0yp8fj7Z7/slEfna/oy+E5G2butPt18r134+vbL37Lb+bhHZb3/nN7gtH21/F0ft38I9J/o+1InRYKGq4icgQUS62SfxK4C3vbZ5DkgE2gNDsIKL8yRwM/AboB+QgZUTcPcG4AA62tuMAG4KJGEi0gYYCrxjP651WxcOfA7sANKAlsB0e91vgUn29gnAGCAnkNcEmgHJQFtgPNb/aao93wbIB5532/4tIBboATQB/mMvfxO4xm270cAeY8wKH685DbfcHTASOGCM+QUrWCYCrYEU4BY7DTXhauAfQCqwAuszRkSSgS+AZ+3X/DfwhYik2Pv5e89gfX6JWN/HjcALItLIXvca8AdjTEOgJ/BtDb0PVV3GGH3oo9IHsB04F7gfeAw4H/gaaAAYrJNwOFYxUHe3/f4AzLenvwVucVs3wt63AdDU3jfGbf04YJ49fT2wsIL03Q+ssKdbACVAP3t+MJANNPCx3xzgTj/HNEBHt/nXgYft6aFAERBdQZr6Aofs6eZAKdDIx3YtgKNAgj3/AfAXP8fsaG8ba8+/AzxgT/8e+BHoXcXvNs1+r4e9Ht3c3vd0t+3j7c+3NfA7YLHX8RbZ31dF73koViBr4LZsPzDInt5p/3YSQv3b14f10JyFqqq3gKuwTgZveq1LBSKxruCddmBdOYJ1Utzltc6pLRAB7LGLUA4DL2NdjQbiWuyrXWNMFvAd1pU2WCe1HcYYh4/9WgNbAnwNb9nGmALnjIjEisjLdvHbEWABkGTnbFoDB40xh7wPYqf3B+BSEUkCRjnfi49tNwPrgAtFJBYrJ/SuvfotrOA33S72eUJEIqrwflKNMUluj3Vu68q+N2NMHnAQ6/tsgef3CK7v3O97tuV4fSfHsQIRwKVYOawddrHX4Cq8DxUEGixUlRhjdmBVdI8GPvJafQAoxjrxO7UBdtvTe7BOIO7rnHZh5SzcT1gJxpgelaXJLiPvBPxVRPbadQgDgXF2xfMuoI2fSuhdQAc/hz6OVYTi1MxrvfeQzXcDXYCBxpgE4GxnEu3XSbaDgS9vYBVF/RZYZIzZ7Wc7cBVFjQXW2gEEY0yxMeYhY0x34HSsIr9r/R+mSsq+NxGJxyp+y7Ifbb22dX7nlb1nv4wxS4wxY7EuFj4BZlQz3aqGaLBQ1XEjcI4x5pj7QmNMCdaf+hERaWhXgt6Fq15jBjBBRFrZZdMT3fbdA3wF/EtEEkQkTEQ6iMiQANJzHVaRWHesop++WOXcsVhX6YuxAtXjYjWvjRaRM+x9/wfcIyKniaWjW+XtCuAqsSrmz8eqg6lIQ6yilcN2Wf6DXu/vS+C/dkV4hIic7bbvJ0A6cCflc2zepmMV4d2KK1eBiAwTkV52TuYIVuAuqeRYgRotImeKSCRW3cXPxphdwCygs4hcZVe2X4H1PXwewHv2SUQiReRqEUk0xhTb76Wm3oeqJg0WqsqMMVuMMUv9rL4DOAZsBRZincym2OtexSomWQn8QvmcybVYxVhrgUNYZfcVNoEVkWjgcuA5Y8xet8c2rGKZ6+wgdiFWef9OIBOrch5jzPvAI3Y6j2KdtJPtw99p73cYq4LXoyWPD09jNSU+gNUYYLbX+t9hncDXY5XP/9G5whiTD3wItPPxuXiwT8KLsHIP7s1bm2F9Zkewiqq+ww7UdmumlypJ/2Hx7Gdxl9u6d7GC30HgNOzWZsaYHKwczN1YDQP+AvzGGHOgsvdcid8B2+3ivFvwbACgQkCM0ZsfKVUXiMgDQGdjTJ06MYrI60CmMeb+UKdFhU596Eik1EnPLra6EeuKWqk6R4uhlAoxEbkZqzL4S2PMglCnRylftBhKKaVUpYKWsxCRKXY3/l/9rBcReVZENovIKrGHWLDXXScim+zHdb72V0opVXuClrOwm8jlAW8aY3r6WD8aq+XMaKw28c8YYwbaZbdLsYaDMMAy4LQKOvYAkJqaatLS0mr2TSilVD23bNmyA8aYxpVtF7QKbmPMAql42OqxWIHEAD+JSJJYI4UOBb42xhwEEJGvsYaWmFbR66WlpbF0qb/WnEoppXwREe8e+D6FsoK7JZ5DP2Tay/wtL0dExovIUhFZmp2dHbSEKqXUqS6UwUJ8LDMVLC+/0JhXjDEZxpiMxo0rzUUppZSqplAGi0w8xwlqhTXOjL/lSimlQiSUwWImcK3dKmoQkGsPYzAH605njezxg0bYy5RSSoVI0Cq4RWQaVmV1qlg3Zn8QawhqjDEvYQ1ANhrYjDW65w32uoMi8g9giX2oyc7KbqWUUqERzNZQ4ypZb4Db/KybgmvwOaWUUiGmw30opZSqlAYLpVS9UlBcQl0Zxmjz/jw+XVHRfaxcftl5iGU7Kux7XCb7aCHfbazd7gI66qxSKqRy84t58NNfmTSmB0mxkSd0rONFDro/MIe7z+vMHcM7eawrdJRw9hPzmHRhD4Z0aUxegYMmCdEe6//8/ipKjWH/0ULeGz+I5bsO0yg2kjbJsXy/KZvvNmbzl5FdeezLdXRrnkBOXiG3n9OJL1fv4cxOqSzedpCuzRNo0jCKvAIHN76xhB05x+ndKomYiHDyCot5dcE2WifH8LvBaRwvcvDZyiz25hYy5YdtANw5vBOjejXjSL6Dr9bspWOTeDo1jcdRYkiKjWRl5mH+8sEqACaP7UF6m0b0bJl4Qp9bIDRYKKVqRE5eITsPHqdfm0ZV2u/NH7fzyYosYiLDueOcTrRIisEYw5uLdnBe96a0SIqpcP/SUsNTX23giv6tOXS8GIDXfthGl2YNSYyJICxMmLd+P8O7NWXfkUIe/XIdz8zdxPq9RxnVsxmdmzZk0/6jDO/alJkrXa30b3l7GXPW7APgzyO78OScDYCVc5m22NVvOL+4hBfmed7GvWVSDLsP55fN3//JatbtOcrBY0Vly576aqPP9/PM3E08M3dTIB8dD3y6BoCJo7pyyxB/dweuGfVm1NmMjAyjw30oVV5xSSmPzlrHH87uQLPEaJ/bbMnOY8K05bx6bQYtkmLYkp3H+0sz+XxVFt/ePZR9RwqICA/zuz/AHdOW89nKLL65awgdm8Qz+9e9LNyczbndmvL6j9u57vQ0OjaO57WF21i35wiv3zCAA3mFzFi6i+e+3Vx2nB8mnsMr323hjUU7aJkUw4G8QtqmxLIj5zjn92xGbGQDjDGc07UJL363heKSUn7dfQSAjLaNWLrjEAnRDThS4PBIX5OGUew/WkjPlgll29cXLZNiWHjvMER89WmumIgsM8ZkVLqdBgul6oal2w/SsUk8SbGR7D6cT0pcJFmH8/lp60GuGtimbLtjhQ5mrsziiozWrNqdS59WiYgIRwqKWbnrMOltGvHi/C10b5HA6F7NWbQlh3Gv/sTZnRtz05ntcJSWsmDjAR68sDulBkqN4ZUFW3lyzga6N0+gT+skpi3eWfZ6d5zTsexkfnqHFH7cksMVGa1JbRjJxn15fL12HyN7NC27CgcYf3Z7XlmwtfY+vJPERX1b8MmK6vUxHjegDROGd2TwY9+WW7fx4VFENqheFbQGC6VqUGmp4Yk5G7g8oxXtG8eXW38grxABUuKjfO6/6+BxPliWyY1ntSMiLIywMIhqEA5A7vFibnv3FxZuPkCfVok8O64fQ56cT4fGcWzJPgbAp7edQfcWCUSEh3HXeyv4aPluLklvyUe/WJWnU67P4Peve/7+GzeMYtaEs/jn7PV8sCyTRrERZcU07qIahNG7VSJLtgdWuXoyio9qQF6hZ07jusFteWNR5WPoJcdFcvBYEfee35Vv1+/jaIGD9XuPAvDAb7rTLjWOQkcJt7z9S9k+r12XwR/fW8HRAgd9WyexYtdhAH75+3ls3p/H5S8v4h9je9C1eQJ7cwu4Y9pyAMb2bcGYPi14+It19GqZyF9Hdy0LDtsfvwBjDO3+Ogvw/M63P35BtT+bQIOF1lkoZXtx/haGdG5M9xYJAJTYZeG/G9SWguISXvpuCws2ZjPrzrPK7Zvx8Ddl071bJdKxcTwfLd/N1kdHExYmTPlhG1N/2A7AS99toUPjeIZ3a8KyHYe4PKM1CzcfAGBlZi5DnpwPUBYoAMa+8AMxEeH0bJlQdlJ3BgqgXKAAq8VM/0dc6fIVKAAKHaUBBYr2qXFsPXCs0u2q4txuTWgUG8n7yzIBePDC7vy89SCz1+wt26ZTk3g27c/j3G5N+WbdPv54biee/sZVpj+0S2MWbMymQXgYRY5SAFonx7DroKvOoG1KLGuyjpAYE0FufjH3jOjM+T2b8caiHfRokcCaLKtYqmF0A44WOBjRvSlfrbVySl//6WwSYyJoEB7GrUOteoF5G/bz7NxNjBvQhpjI8HLvq3PThlzYpwXv/ryTqwa2Ia/Qweb9eTSKjWBAu2S+/tPZdGwSX1ZsdDi/mMxDx/nrqG4ADO/WFKCsVddlp7UCQER456aBHC0o5pyuTdn48ChKSmvngl9zFqreM8ZQVFJadiXvy9GCYnpN+oqUuEiW/f08AFbsOsxFL/zAGR1TGH92B66bsphWjWJ4+8aBNIqLJCG6QdmfPW3iF36P3TIphn5tkvh81R6f650nw1Do2qxh2VWyt3/9tg93v78SgC8mnMnW7GNlV8AAVw9sw81ntaeopJSv1uxlw748OjaOp2+bJCLDwxj36k+A1brHWWG75qGRzFmzl9M7pFLkKKVNSizg+vx+mHgOLZNi2H+kgIkfrebb9fvLgsTfRnfj5rPbA7D7cD6p8ZEYA2EilJQath7I44JnFwLWlfbe3AL+8PYyVu46zLPj+vH6D9t4/qp0mjSMokF4GKWlhsdnr+fK/q3ZduAY2w4c46mvNlBQXMoXE84kOiKcvbkFnNExNaDPclXmYdZkHeGS9JZENQgn+2ghT83ZwKQxPSh0lLD/aCGdmzas6ldEQXEJEeFhhIdVvT4iEJqzUKe8vEIH8VENePG7LTwxewOrJo0gIToCgDVZuXy4bDfbDuTx/FXpZVehpW4XT8ftYosfNufww+Yca1lRCUOfmg9AZHgYRSWltKyktc7uw/lEhPv/owcjUNw6tAPvL93Fgbwij+VNE6KsFkEX9+K+j1czskcznh3XjxH/sW79fWGfFrRJjmF4t6YkuzVj7dEikZgIV7Cde/cQ2qfGlQVLXyfBpfefS1xkA2Iiwzm/ZzMSYyKIi2rAJemtym3755FdWLztYNln2SQhmicv683ibQdpFBfJN+v2Mbxbk7LtfX3mPVokMmF4J9btsXIJzRKjiQoPK9v+o/87w2P7sDDhvtHWlbyzaPGxL9cDkBofRdOEaDr4KHL0p3erJHq3Siqbb9wwin9e1huAmMjwajcLjo7wf5FTmzRYqJNeXqGDwuISj/oCZ65gyvUZvDTfatbYe9JXALx0zWn8c/Z6ttlFKv+cvZ437bLrmIhwVmUeZsn2Q2XlzO7cmz4WlVhFHu5NJP3ZnnO8mu+uvPsv6MbQLk24c/rysuITZ8Xpxf1a8vHy3bRIjGbp/edRUmrocN8sYiLCmTy2B5ekt+LQ8SJS46MY0K4R7VPjCbOvWJslRPPcuH5lr3PomGegad84nrWTRxIbGdhpI9Xt++jWPKHCbW8b1pHbhnkuS4mPYlSv5kDgZfJ3ndfZY/5fl/fh1e+30qdVYP0QmidGk3kon0Yn2N+jPtJiKFUnbcnOIzUuisTYCJ/rN+47Smp8FMlxkfSeNIcjBQ4+ue0MHp21jsszWvPr7lxe/3E7g9on89NWz3EoG4QJMRHhHPWq8AyGpNgIDtt1BcO7NmHu+v2Aqx2+dysigKk39KdRbCQXvfADKXGRFJWUkt6mERf0as7wbk08gqKz+Gbjw6PIOpzP8/M288GyTP55aS+u6G+1oMrJK0RESI7zfwLcsPcoTRpG0chtG0dJKR3/9iVwYhWoJ5NdB4/zy85DjO3r835r9ZIWQ6mT0syVWXRqEs+oZ76nW/MEvrzzLB749FfeXLSD609P4/Uft5dt27lpPD1bJJa1p7/ohR8AWLzNFRy8AwWAo9QEHCh8tdcXgQt6NefQ8SImnNOJ+RuzeXH+Fp/7PzSmB3dOXwHAc1f1476PVvPbjNb0a5NEQXEpDaMbcOvby/hm3X5G92rGrNV7SY6NJDHGCpIGqwVNmIjfMut+bZKIbBBGWmpcWQVvgzBXM0p/LbTcdWlWvhipQfipNxpQ6+RYWifHhjoZdZIGCxVy8zfsZ1D7FI4XlTDBrQJ13Z4jHhXH7oECYOO+PDbuO7Hy/kvTW7Fh3xGPTlrbHhvNrNV7ad84jj25+R4tjc7smMroXs09+j0MbJ/CX0Z2sXMIhi7NEkizK25FhLxCB8ZAbGQDnr7SVczjLOl48ZrTOJJfTJgIg9un0LtVYlnLpcSYCCIqOGmvmjSCKLf29dcMasvMlVkM7pByQp+LUt60GEoF3S87D+EoMQxol8zcdfto3DCK95dm8tZPO/hiwplc8OxCWjWKIfNQ5WX/gWiXGldWH+HNvVPUH8/txB/P7Uyho4Qu988GrEpZ97L2g8eKuOXtZezJzeeOczpxeUZrn8cNhlcWbGFkj2a0TYmrtdf0dvnLi+jarCGTx/YMWRpUcGkxlAqpguISHvj0V+46rwuX/PdHAPqnNSrXnn/Waqs5aU0FCoD7Rndja3YeQ7s0Yd6G/Txut3ABePrKfvxucBqXvvgjg9pbV9/uTWpTvYpskuMimfGHwTWWtqoYf3Zwx/oJRKjeu6p7NFioajHGICJsO3CMxJiIcpWns1bvYcbSTPYfLSxb5qvjl/cAbJWZPn4QV77yk8eyt24cwO9eW8xVA9tw5/BONE2IBqxOTQ2jG/D4l+tpnxrHmzcOAOC0to3Y9Mgoj+Kd+fcMDahVk1KnKg0WqlrGvfoTOXlFbNqfxwW9mvPC1ekA7Mw5zp3vLeeYXYE8f0PlY+67txjy57ZhHTinaxPSfYxo2rd1kt/WOi2SYph6fX/6tk7yaOnjXQ+QlhpHWmroinuUqus0WKiAvbloOw98uoZfHxrp0croi9V7+OWxuZQaw74jheX2cx8bx5ezOjXmM7ehof93bQZxUQ3KegC/N34Q/dOSy/oDgNUfYuoN/flwWSbxURX/jId1bVLheqVU5TRYqEodPFZE1uF8/mmX/fd8cE65bfbkFvjdf3SvZtxwRlpZE1KnYV0ac3bnxvw2ozVndUotu6FLq+QYujZzdeIa2N6zZc+0mwfRJiWWlkkxZfUOSqng0mChAOueB3sOF/Cfbzby+KW9iGoQTm5+MXty8/nNswtxVGGwsuaJ0VwzqC0vfbeFowUOUuKiGNu3JZmH8jl0rIitB47x7fr9PH9VOnF2ruDyjNbkF5Xw4Mw1ZfUfP0w8h2K734A7bRaqVO3TYKHYmp3HOf/6rmz+t6e1omPTeAY8Mjeg/Ts3jadT04ZcNziNAe2Sy5ZnHspn2uKdNLDHRbptWEfAuh/Dpv15ZYHC6brT07iif+uysXAqG3NJKVV7NFicwnYdPE6ho4Q/vbfSY/n7yzL5ZWfg9zb4/I6zfN545W8XdCM1PpIR3Zt5LI+LakDf1knltoe6M2iaUsqTBotT2FlPzPO5/OPlu30u9zYgLZmHxvbwe4eu+KgG3D2iS7XTp5SqOzRYnKKOFlTcVNWfDQ+fT5GjlBlLM7n+9LSgjbGvlKpbTr2Rwk5RO3KOkTbxC+Zt2M/vX19CL3u4bm+D26ew8F7XWNH/uzaDAWlWPUSYWL2dG0ZHcOOZ7TRQKHUK0ZxFPXW0oJj1e4/SPy2Z/UcKeMu+X8MNU5dUuN+7Nw8su6ENwLndm3Ju96a8uWg7GW2T/e+olKrXNFjUU3fPWMlXa/dxz4jOPPXVxoD2+e7PQ8sCxYI/D2P/UVffiWsHpwUjmUqpk4QWQ9VTv+y0ekxXFihuG+YarM59dNM2KbFkpGlOQillCWrOQkTOB54BwoH/GWMe91rfFpgCNAYOAtcYYzLtdSXAanvTncaYMcFMa30xY8kuvli9h4qGnr+4X0smjelBXqGDlkkxVR7MTyl16glasBCRcOAF4DwgE1giIjONMWvdNnsKeNMY84aInAM8BvzOXpdvjOkbrPTVR8YY/vLhKr/r/3dtBje9uZTbz+lIYkxE2d3Y5t8z1G/zV6WUguDmLAYAm40xWwFEZDowFnAPFt2BP9nT84BPgpieemnZjkM0T4xm0/48Zq3a43Ob6Igwvr17KC2SYnyOzqqjrSqlKhPMYNES2OU2nwkM9NpmJXApVlHVxUBDEUkxxuQA0SKyFHAAjxtjygUSERkPjAdo06aN9+p6b/nOQ1z64o9+1183uC15hSX86/I+tZgqpVR9FMxg4asRvndB+j3A8yJyPbAA2I0VHADaGGOyRKQ98K2IrDbGeBSuG2NeAV4B67aqNZn4usxRUsrc9ft9fsBOvxvUlof0VphKqRoSzGCRCbjfsLgVkOW+gTEmC7gEQETigUuNMblu6zDGbBWR+UA/QGtigZe+21JhK6fZfzyLLk0b1mKKlFL1XTBrNZcAnUSknYhEAlcCM903EJFUEXGm4a9YLaMQkUYiEuXcBjgDz7qOU9bbP+3gP99sqnCbxJgIj451Sil1ooIWLIwxDuB2YA6wDphhjFkjIpNFxNkMdiiwQUQ2Yt00+RF7eTdgqYisxKr4ftyrFdUp6/5PfqXEx70lJpzTsWy6sjvHKaVUVQX1rGKMmQXM8lr2gNv0B8AHPvb7EegVzLTVFwPbJVPoKOXqQW35edtBft52kLhIDRZKqZqlZ5WTQNbhfFbuOszeI+VvXfrMlf1olhgNwGvX92f3oXyPe1UrpVRN0GBRxxljOP3xbz2W/XVUV0b3ak6ho6QsUIBV/NSlmVZsK6VqngaLOuzzVVnc/u7ycssbxUbSOjk2BClSSp2qNFjUYR//4nnHujbJsZzeIYXzezXzs4dSSgWHBos6qqTUkBQbWTb/zV1D6NgkPoQpUkqdyjRY1EE5eYXc8/5K5m3ILlvWIim6gj2UUiq4NFjUQac9/E3Z9OD2Kdw7qiux2hxWKRVCegaqY9zvQ5HeJolp4weFMDVKKWXRmxjUIfuPFHDmP+eVzb91o/cgvUopFRqas6hDBjw6t2x61oSziNNhO5RSdYTmLOqIY4WOsumHL+pJ9xYJIUyNUkp50mBRBxQUl9Dnoa/K5i/s3SKEqVFKqfK0nKMO6Pr32WXT39x1NomxESFMjVJKlafBIsQ27z9aNv3rQyN1eHGlVJ2kxVAhtP9IAef+ewFg3Y9CA4VSqq7Ss1OIPDF7Pf+d77pLbM+WiSFMjVJKVUyDRYhM+WFb2fTGh0cR2UAzeUqpukvPUCHSs4WVkxjQLlkDhVKqztOzVAjkHi9m6Y5DxEaG8+LV6aFOjlJKVUqDRQg89uU6ANqmxJESHxXi1CilVOU0WNSy3Pxipi/ZBcA/xvYIcWqUUiowGixq2cyVWQCM6dOCjLTkEKdGKaUCo8Giln2+MoumCVE89ds+oU6KUkoFTINFLVq+8xA/bzvIOV2baAsopdRJRc9Yteji//4IQJemDUOcEqWUqhoNFrUkJ6+wbPqifi1DmBKllKo6DRa15Nm5mwD48NbTSYqNDHFqlFKqajRY1IKDx4p4d/FOxg1ozWltG4U6OUopVWVBDRYicr6IbBCRzSIy0cf6tiIyV0RWich8EWnltu46EdlkP64LZjqDbdGWHIpLDJemt6p8Y6WUqoOCFixEJBx4ARgFdAfGiUh3r82eAt40xvQGJgOP2fsmAw8CA4EBwIMiclJekm/Ye5Tb3v2FlLhIerdKCnVylFKqWoKZsxgAbDbGbDXGFAHTgbFe23QH5trT89zWjwS+NsYcNMYcAr4Gzg9iWoPmm3X7AHhwTA9tLquUOmkF8+zVEtjlNp9pL3O3ErjUnr4YaCgiKQHui4iMF5GlIrI0Ozu7xhJeU1Zn5vLknA0AXNi7eYhTo5RS1RfMYCE+lhmv+XuAISKyHBgC7AYcAe6LMeYVY0yGMSajcePGJ5reGrd6dy4AjRtGIeLrLSml1MkhmDc/ygRau823ArLcNzDGZAGXAIhIPHCpMSZXRDKBoV77zg9iWoNi9+HjACy8d1iIU6KUUicmmDmLJUAnEWknIpHAlcBM9w1EJFVEnGn4KzDFnp4DjBCRRnbF9gh72Ull24FjtEuNI6pBeKiTopRSJyRowcIY4wBuxzrJrwNmGGPWiMhkERljbzYU2CAiG4GmwCP2vgeBf2AFnCXAZHvZSWXTvjzSUmJDnQyllDphQb0HtzFmFjDLa9kDbtMfAB/42XcKrpzGSWf5zkNs2p/HFf1bV76xUkrVcdqWM0jc1xJBAAAgAElEQVQmf74WgAu0FZRSqh7QYBEEv+7OZfnOwwzr0pjmiTGhTo5SSp0wDRZB8JvnFgIwqqfmKpRS9YMGiyAa2rXu9f1QSqnq0GBRw/bk5gPw11FdadIwOsSpUUqpmqHBoob9+f1VAHTWu+EppeqRSoOFiNx+so74WtvyCh0s3HwAgMEdUkKcGqWUqjmB5CyaAUtEZIZ9fwod5MiP5TsPAfDHczsRHaG9tpVS9UelwcIYcz/QCXgNuB7YJCKPikiHIKftpLN5fx4Al2doRzylVP0SUJ2FMcYAe+2HA2gEfCAiTwQxbSedz1ZmkRIXSdMErdhWStUvlQ73ISITgOuAA8D/gD8bY4rtAQA3AX8JbhJPDsYYNu3L4+L0loSHaUmdUieiuLiYzMxMCgoKQp2UeiM6OppWrVoRERFRrf0DGRsqFbjEGLPDfaExplREflOtV62HPlu1h6OFDlo30oEDlTpRmZmZNGzYkLS0NL0XTA0wxpCTk0NmZibt2rWr1jECKYaaBZSN+CoiDUVkoJ2AddV61XrGUVLKhGnLARjbr0WIU6PUya+goICUlBQNFDVEREhJSTmhnFogweJFIM9t/pi9TNnW7z0KwBUZrbUjnlI1RANFzTrRzzOQYCF2BTdgFT8R5KHNTzaLt1kZrzvP7RTilCilakJOTg59+/alb9++NGvWjJYtW5bNFxUVBXSMG264gQ0bNlS4zQsvvMA777xTE0kOukBO+lvtSm5nbuL/gK3BS9LJZ8n2g7RMiqFFko4wq1R9kJKSwooVKwCYNGkS8fHx3HPPPR7bGGMwxhAW5vuae+rUqZW+zm233Xbiia0lgeQsbgFOB3Zj3Vd7IDA+mIk6mRQ5Svl520EGtEsOdVKUUkG2efNmevbsyS233EJ6ejp79uxh/PjxZGRk0KNHDyZPnly27ZlnnsmKFStwOBwkJSUxceJE+vTpw+DBg9m/fz8A999/P08//XTZ9hMnTmTAgAF06dKFH3/8EYBjx45x6aWX0qdPH8aNG0dGRkZZIKtNleYsjDH7se6frXz4eVsOB48VMbqXDkeuVDA89Nka1mYdqdFjdm+RwIMX9qjWvmvXrmXq1Km89NJLADz++OMkJyfjcDgYNmwYl112Gd27d/fYJzc3lyFDhvD4449z1113MWXKFCZOnFju2MYYFi9ezMyZM5k8eTKzZ8/mueeeo1mzZnz44YesXLmS9PT0aqX7RAXSzyIauBHoAZTV3hpjfh/EdJ00Xllglcilt0kKcUqUUrWhQ4cO9O/fv2x+2rRpvPbaazgcDrKysli7dm25YBETE8OoUaMAOO200/j+++99HvuSSy4p22b79u0ALFy4kHvvvReAPn360KNH9YLciQqkzuItYD0wEpgMXA1ok1kgv6iERVtyiIkIJyU+KtTJUapeqm4OIFji4uLKpjdt2sQzzzzD4sWLSUpK4pprrvHZPDUyMrJsOjw8HIfD4fPYUVFR5bZxa18UUoHUWXQ0xvwdOGaMeQO4AOgV3GSdHNZk5eIoNTw3rl+ok6KUCoEjR47QsGFDEhIS2LNnD3PmzKnx1zjzzDOZMWMGAKtXr2bt2rU1/hqBCCRnUWw/HxaRnljjQ6UFLUUnkfeW7AKgSzO9d4VSp6L09HS6d+9Oz549ad++PWeccUaNv8Ydd9zBtddeS+/evUlPT6dnz54kJibW+OtURirL4ojITcCHWLmJ14F44O/GmJeDnroqyMjIMEuXLq3V1xz9zPfsOnScVQ+O0A5EStWgdevW0a1bt1Ano05wOBw4HA6io6PZtGkTI0aMYNOmTTRoUPXubr4+VxFZZozJqGzfCl/NHizwiDHmELAAaF/l1NVjOccKGd2zuQYKpVTQ5OXlMXz4cBwOB8YYXn755WoFihNV4SvagwXeDsyopfScNA4dK2LfkUISYrQzu1IqeJKSkli2bFmokxFQBffXInKPiLQWkWTnI+gpq+MmfbYGgFY6yqxS6hQQyGWxsz+Fe790wylcJOUoKeW7jdn0aJHAFf31rnhKqfovkB7c1Rv8vB5bmXmYw8eLefiinnqvbaXUKSGQHtzX+lpujHmz5pNzcvhpqzXK7OkdUkOcEqWUqh2B1Fn0d3ucBUwCxgRycBE5X0Q2iMhmESk3EIqItBGReSKyXERWichoe3maiOSLyAr78VLA76gWLN1+kI5N4kmOi6x8Y6XUSWfo0KHlOtg9/fTT/N///Z/ffeLj4wHIysrisssu83vcypr4P/300xw/frxsfvTo0Rw+fDjQpAdNpcHCGHOH2+NmoB9Q6VlSRMKBF4BRQHdgnIh099rsfmCGMaYf1mCF/3Vbt8UY09d+3BLg+wm6IkcpS7cfon/aKV/Hr1S9NW7cOKZPn+6xbPr06YwbN67SfVu0aMEHH3xQ7df2DhazZs0iKSn0Y88FkrPwdhwI5C4/A4DNxpitxpgiYDow1msbAyTY04lAVjXSU6uWbj/I0UIHw7o0DnVSlFJBctlll/H5559TWFgIwPbt28nKyqJv374MHz6c9PR0evXqxaefflpu3+3bt9OzZ08A8vPzufLKK+nduzdXXHEF+fn5ZdvdeuutZUObP/jggwA8++yzZGVlMWzYMIYNGwZAWloaBw4cAODf//43PXv2pGfPnmVDm2/fvp1u3bpx880306NHD0aMGOHxOjUlkDqLz7BO6mAFl+4E1u+iJbDLbd55Lwx3k4CvROQOIA44121dOxFZDhwB7jfGlBumUUTGY99bo02bNgEk6cR9s24/kQ3COLOT1lcoVSu+nAh7V9fsMZv1glGP+12dkpLCgAEDmD17NmPHjmX69OlcccUVxMTE8PHHH5OQkMCBAwcYNGgQY8aM8dsx98UXXyQ2NpZVq1axatUqj+HFH3nkEZKTkykpKWH48OGsWrWKCRMm8O9//5t58+aRmup5jlm2bBlTp07l559/xhjDwIEDGTJkCI0aNWLTpk1MmzaNV199lcsvv5wPP/yQa665pmY+K1sgOYungH/Zj8eAs40x5QdiL8/Xp+c9tsg44HVjTCtgNPCW3Wt8D9DGLp66C3hXRBK89sUY84oxJsMYk9G4cfCv9I0xzF2/j9M7pBAbqZ3xlKrP3IuinEVQxhjuu+8+evfuzbnnnsvu3bvZt2+f32MsWLCg7KTdu3dvevfuXbZuxowZpKen069fP9asWVPpAIELFy7k4osvJi4ujvj4eC655JKyoc7btWtH3759Ac/hzWtSIGe8ncAeY0wBgIjEiEiaMaay1GQC7p0QWlG+mOlG4HwAY8wi+94ZqfYNlwrt5ctEZAvQGajdwZ+8LNqaw46c49x81inbxUSp2ldBDiCYLrroIu666y5++eUX8vPzSU9P5/XXXyc7O5tly5YRERFBWlqazyHJ3fnKdWzbto2nnnqKJUuW0KhRI66//vpKj1PROH7Ooc3BGt48GMVQgeQs3gdK3eZL7GWVWQJ0EpF2IhKJVYE902ubncBwABHphnVzpWwRaWxXkCMi7bHqSEJ6329jDBOmrSAyPIzLTmsVyqQopWpBfHw8Q4cO5fe//31ZxXZubi5NmjQhIiKCefPmsWPHjgqPcfbZZ/POO+8A8Ouvv7Jq1SrAGto8Li6OxMRE9u3bx5dfflm2T8OGDTl69KjPY33yySccP36cY8eO8fHHH3PWWWfV1NutVCA5iwZ2BTUAxpgi++RfIWOMwx5Xag4QDkwxxqwRkcnAUmPMTOBu4FUR+RNWEdX1xhgjImcDk0XEgRWcbjHGHKz626s52UcLOZBXSKcm8doRT6lTxLhx47jkkkvKiqOuvvpqLrzwQjIyMujbty9du3atcP9bb72VG264gd69e9O3b18GDBgAWHe869evHz169Cg3tPn48eMZNWoUzZs3Z968eWXL09PTuf7668uOcdNNN9GvX7+gFDn5EsgQ5V8Dz9knd0RkLDDBGDO8FtIXsGAPUb5gYzbXTlnMOzcN5IyOWrmtVDDpEOXBEbQhym23AO+IyPP2fCbgs1d3ffbKgq0kxkTQq1Xt33REKaVCLZCxobYAg0QkHisnUr4wrZ4rdJTww5YD3DqkAwnREaFOjlJK1bpKK7hF5FERSTLG5BljjopIIxF5uDYSV1e8tnAbxkDHJvGhTopSSoVEIK2hRhljygYmse+aNzp4Sap7PvplNwDpbRqFOCVKnToqq09VVXOin2cgwSJcRMoa8YpIDBBVwfb1yuHjRWzNzuOGM9JIS40LdXKUOiVER0eTk5OjAaOGGGPIyckhOjq62scIpIL7bWCuiEy1528A3qj2K55EjDHcNWMlpQbO79Es1MlR6pTRqlUrMjMzyc7ODnVS6o3o6Ghatap+H7FAKrifEJFVWOM2CTAbaFvtVzyJvLdkF9+u38+953dlYPuUUCdHqVNGREQE7drpfdfqkkBHnd2L1Yv7Uqwe1+uClqI6IievkIkfWYOXXZreMsSpUUqp0PKbsxCRzlhDdIwDcoD3sJrODqultIVMaanhhteXAPC30d1oklD9cj6llKoPKiqGWg98D1xojNkMYA/LUe9N+WEbqzJz+U3v5tx0lmaFlVKqomKoS7GKn+aJyKsiMhzfw47XG8YY3v15J0/M2UD7xnE8cVlvv+PUK6XUqcRvzsIY8zHwsYjEARcBfwKaisiLwMfGmK9qKY1Bd9/Hq/lgWSYNwoTjRSWkxkcy5br+es8KpZSyBdIa6hjwDtb4UMnAb4GJQL0JFou25FDkKOXsbk05o2MKY/q0ICX+lOlKopRSlarSpbM9TPjL9qN+KDrO2Udn8VjrgwxqkgKrFkLDO6FFOqR2DHXqlFKqTjjly1nyj+fxkLwM2VgPgI9utp5v+QHCGkCTisesV0qp+i7Qfhb1Vl5YQ65Pmsri01+CMc9BvFtP7ZfOgP8OBEdh6BKolFJ1QKU3PzpZ1OjNj0pL4Zk+kLvTmu99JVxSf0relFLKKdCbH53yOQufwsLgvIdc86umQ8GR0KVHKaVCTIOFP2leN0LfvSw06VBKqTpAg4U/cV732d63JjTpUEqpOkCDhT8iMPJR1/xXf4OZE0KXHqWUCiENFhUZ9H+e87+8oXUXSqlTkgaLiohAw+aey/avDU1alFIqhDRYVOaudZDkdq+ng1tDlxallAoRDRaVEYEjWa55rehWSp2CNFgEorTYeo5JhkXPw/K3Q5sepZSqZRosAvGb/0DTnq75T2+DTd/AsZzQpUkppWqRBotAZPwebv0BImJdy965FKaOCl2alFKqFmmwqIoGXve4OLAhNOlQSqlaFtRgISLni8gGEdksIhN9rG8jIvNEZLmIrBKR0W7r/mrvt0FERgYznQFrOzjUKVBKqZAIWrAQkXDgBWAU0B0YJyLdvTa7H5hhjOkHXAn81963uz3fAzgf+K99vNAa/a/yy+rJqL1KKVWRYOYsBgCbjTFbjTFFwHRgrNc2BkiwpxMBZxvVscB0Y0yhMWYbsNk+XmhFRJdf9lCS3u9CKVXvBTNYtAR2uc1n2svcTQKuEZFMYBZwRxX2RUTGi8hSEVmanZ3tvbr26BAgSql6LpjBQnws8y6zGQe8boxpBYwG3hKRsAD3xRjzijEmwxiT0bhx4xNOcECuer/8skPb4cDm2nl9pZQKgWDegzsTaO023wpXMZPTjVh1EhhjFolINJAa4L6h0XlE+WWvnWs9T8qt3bQopVQtCWbOYgnQSUTaiUgkVoX1TK9tdgLDAUSkGxANZNvbXSkiUSLSDugELA5iWpVSSlUgaMHCGOMAbgfmAOuwWj2tEZHJIjLG3uxu4GYRWQlMA643ljXADGAtMBu4zRhTEqy0Vlm43d/irLs9l2vLKKVUPRXMYiiMMbOwKq7dlz3gNr0WOMPPvo8AjwQzfdUWnQDHsiE2xXN5biYktLTu4a2UUvWIntWqIybZek7p6Ln86Z7ww39qPz1KKRVkGiyqo1kv67mkCKISPdetn1V+e6WUOskFtRiq3hr9pFUE1fFcmLgDjh+EJ9tb60Tjr1Kq/tFgUR2xyTD6Cdd8nFvdRVjoRyVRSqmappfBNcbuR6g5C6VUPaRntpoSGW89a7BQStVDemarKVHOYOE2UknBEcjWe14opU5+WmdRU2JT4egeawTan1+GqAT46QXYu1qHAVFKnfQ0WNSUK96CZ/taQePLv4Q6NUopVaO0GKqmJLeDJj1gwxfl122cA98+rMOBKKVOWpqzqEmRsb6Xv3u59dzzMmjStfbSo5RSNURzFjWpspZQYRqblVInJw0WNak433pu2Nz3+pIiz3lHEaz+QIunlFJ1ngaLmlR0zH4+7nu9I99z/vt/wYc3wnof9RxKKVWHaLCoSQV2E9kRkyE6CYbd77n+w5s8cxF5+zyflVKqjtJgUZOcFdw9L7UGGGzYzJqPa2I9H9wK+36Fo3utR3iEtbzUUftpVUqpKtAa15p0zcewdR5ENbTmncEgKh6O7bemXzrTtf3g261n77oMpZSqYzRY1KTUjtbDyVnk5Bw3ypszmDgKg5supZQ6QVoMFUzO4iVnTsNbeKT1XFJcO+lRSqlq0mARTKV2EIhO9L3eGSwKcl3NbpVSqg7SYBFMJXbOIqEFxDcrv95ZDPXzi/Bsv6ode8W7VoW5UkrVAg0WweTMWYRFwKjHfawvcU0f3WM9O4rg0PZKjlsKn9wK/zuvRpKplKqA1ikCGiyCy1lnERbuKnJyt2ux5/zMO+Crv8EzfeBYjrWs6Dh8eDPk7ramd/7k6tx3/IDn/sUF2htcqZq08yd4uAls/S7UKQk5DRbBlH4tdD4fzrjTyl142/il5/wvb8K2763pvL3W868fwuoZMP8x+OhmmDISjmSVP9aRPfBIU1jyP8/lJQ6YlAiLXz3x91Pb8vb7fq9K1Zbt9v9x67zQpqMO0GARTDGN4Kr3IL4JmJLKtweIjLOeN86xTvI7F1nzUQ1dVzcFR8rvd3iH9bxqhpVtdg494iiwnr9+oHrvIZSe6gT/7hbqVNRtW+ZZxZIqOJyDg2qOXYNFrXF2vItJhr7X+N9u91Lree5D1vOKd6znn/4LRUet6YLD5fcr+1GXwIunw6MtoDAPsH/kpponlIIjMPWC6lWmb18I8x4tv3zDl5Dv4z3UJQW5sOCpun0iXj8L3rrI+m3UNcX58NOLrouWk5ZUvklFio7B421h09c1k5wQ0mBRWxx2sOgwDHpefGLH8hUsnMHAlELOZmv68z+56k1MKaydad3mtSrWfwE7FsJ8HxX0AMcPwr61vte9fgF890/PZYd3wbQr4eNbqpaO6irIrV4/ltn3wbf/gE1zrPkpo6yc3qREq24oVLI3wKr3renDO+3nHdU/Xv4hz4YWNeWr+2H2RNg817Vs3xrYOh82fuVaVuKAOX+DvGxrvrQEfng2eEHGGFj2euAXK+IMFl45i5XT4dGW8ONz5ese3eVssf6vcydX/lqOIjiwyZqecS28dFbl+2z9zno/tUCDRW1plGY9txlcvkf30L9W7VgFPu7pvW+N9eyeg9i/1nUiMAZm/M5zuBFvpaXw/b89W2M5K9OdOZe8/fDCQFdO49Vh8OLgitPrfnXuTLvzRBdsj7eB96+v+n7OgOwMNDt/dK1b/7kVNJzvoeiYNe9dX1SRL+6G5W9XPV1TRsJHN1knFmfRpoRX/TgAhUfhn2nBKaLM3W09O3PU67+wcrxvjoV3f+vabstcWPQ8zLrbml/7KXz9d+vOku7prClZy+GzO+GzCQHuYAcL75z553dBUZ4VFF+roFWicz8JIIcy6254PgOOHbA+h72rKt/nzTHW+6kFGixqS+v+cPtS6H+Tq17CaehESO4Q+LHKgoX9AzywGb64y5p2PzHv+9VVZxFIncmGWVbx1/f/suaPH7RyJ+6vteZjyF4Pi16w5itr5gtWPxInZzPEBm6tw0pLq1cm/PIQeOe3/tc7P4v1n5df9+tH1ijAYBWZeAcv5598xu/g/Rs81zmDgvOK0nli/Okl1zYHNlsB5Idnre1yd1ufp/sxPr0NNn9jBZtPb/dc748zeB3e4boQCKtmsHBeva96r+LtCo9aDSj8mZToeXIH18WFs7Opv2JM53tw5ryd2+cfch37sVaeORR3+9bChtn+03ZouxWYna/j/Pwqej/unCd5799nsVfOZ8OXvv8Lzt/RgU1w1Gt06U3fwCPNXcFw63zr+au/B5a2WhbUYCEi54vIBhHZLCITfaz/j4issB8bReSw27oSt3Uzg5nOWpPayfrxxaa4lkXaQ4G0Hxr4ccqChbH+TM+f5lq3z6uYabb9sfuqs/jpJdi1xDXv7OvhvKNf3n7XOuefv0G09VxcAE+4BTjvP9MGt5Zec+5zTTuDV3iU9VxaAv/pAbP+XD59ldmzAjZ95X+9w624KP+QdVX5wY0w5Xz44AZYbRfnfHobPN3Lek9f3gvZGz0/rzUf+T8uQLF9/5KIGM+0gXWV/Np58J/u8K8u5dP49qVWQF7+Fiz8d8XvFyC+qfV8ZLdn0+zqcH5nFRXTrfvMOln/28/tgJ0n4QVPei4PcwYL+7PxvkAqnxh7P/u9mFLY/oNrtXtRz7cPw7SrrOkXB8O0K3wfcs8q64Jgyf8ga4Xn8UuLrSKw966xfhd+BVhnMe1Kq8m792fp/IyLj1vrwSqKLS2FuZOs5Tlb7G3tfVa+W/nr/e8867dTi4I2kKCIhAMvAOcBmcASEZlpjCkr4DbG/Mlt+zsA927M+caYvsFKX0gltIDTrodmvaH/jdayym7J6s5ZrhmIdZ/5Xu4ogtn3WtN3rrSKyUrcOhGCZ/bf+Z9xnhAd+Z79PL66H0Y+4pr/8Gbfr+u8mnXmLI7shqNZsORVaJkOLdKtP3RKR9/7b/oGUtq7hn13ys2EdZ9Dxg1WrqHPlZ5DqLwxxne23lFoNU8GK2f180vWFV5SG9+vD67jOq86ne8pItYqQsg/5Aqq7vyNLuy8ii7Ot4prvpkEjbtAwxbWZxru1uzaGcgdRW45iwD+xsdyrM/cfZwyZ3oqChbvuTXGKHFAuP1am+dadQ3Z6/zsaH82zmDhq5+Rz93s/0FpCbw+2rXc+bvL2VI+MDn9+BykdobOI63fyTtuJ9OyIGF/ZqUOK7ez7jPrvSS2gms+9Pzejx2AfDu3534x5Kwz8iX/MMQ3tqbn/gO+f8q1zpEPe1bCy2fDBf9y1X2VXWT4yF3/8hak/86aPrLH+g13HgmZFdSTBEkwR50dAGw2xmwFEJHpwFjAT20o44AHg5ieuuXCZzznAynTdPJVrFIVK6fDx39wzU85H+5e77piDmtgnUTdi4+cf2Lnicu7knfR89YP+eoPoEEUPn/44GrR5cxZuB/nk1td0xN91GlkLvU8Abh757dWHY0zAEYnQLNervX+yn+dxXfgusIrLam49ZjzBOg8ITpzepGx8Exf6z2Om+5/f+8KZWfwWfI/VxHXgY3Wc4dzoMv5sOYTaJXh+h5KCl05C191FiUOq6jEOS7Zk+2tHO1FL0KnEdbvzRkkio/B3l+hWU//aQZrmP2EFtb0538KrGLdWXHtb+wz92IeY9xa9Xl9/s6cyfMZ/l/rK/tmY5Ny4dA2z3WHtkGLvq7fuPt3XHzc+ryfHwD37YbJydDrcqt/Uxlnq0Jj1Rn5k3/QChZZyz0DhZMzJ5yzxfWZvHs5DL3Pd1HszNutYLF+FkwfZy174FD57ZZOtS6UgiiYxVAtgV1u85n2snJEpC3QDvjWbXG0iCwVkZ9E5CI/+423t1manZ1dU+kOjcpyFk26V+14GTf6X+ceKMAqfpqU6LpCDguzeq06r7jBOqnnH3aNd+V9i1iAbQtcxQX+6iCcfUQiov0fB6yKaXdFx2HJa763BauVkLvpV8F3T/jf3mnNJ65pZ0fInE0VD/HgrN9wnuic9ypxFLmCob+T47bvXTkJJ+95dyJWkcX711l1NLmZ9msVuuqhfOUsvviT9Rmu/sD6bgGO51gnJmfgLHXLUbx0hvWdude1bF/oecwdP8LMCVaOwlegeONC6yr9wCZXruWnF6xxzGbd47lt1gpruTPgbpoDDyVZtxmG8nVszqtv9yDiXk/iXefkXTTnbOTg/F5LHeUDkiPfChTgFSiwmic/l1H5LZDzD1l1JK8M9b3eWbTbsLnrt39oO3w8Ho5k+t5n9y+uQAGu36m7pVMqTlcNCGbOwtelsr9azCuBD4zx+IW0McZkiUh74FsRWW2M2eJxMGNeAV4ByMjIOLl7zVQWLNzrOQJRUTGKP84TgDMguFs9w3qMtSu2/d1n/NB2aHcW5b7qeY/BsL/CMTuoRyda9RrOK+gK07XLOsnt95cpxXcF/vK3Kj92UZ5rOtftz+rsuVuR756A1oNg9zJrfofbybXYz+fzxm+gpdfV8b5f/b+GhEOhHWDdi/0cha7imLBwOLTD+jwH2U2Sf3nTep55R/ljTr0Abp5bvlis6JireONru5JVwlwn1bmTK85NbFtgPcCzDq6skYSbV4ZYzxf4qadZ+6nnvK9iPffiqGfcSqwnJUKaj2anWStcOYviAs+LoUDkbIL3rq54m/xDFbeKczbZzVxsBe9AvDrMc/7gtvLbVFondOKCmbPIBFq7zbcC/I3dcCUwzX2BMSbLft4KzMezPqP+cQ8W3ceWXz/6SWhbQbNXgAS3jFt1fjzOCt+K7tznbGa56yff65f8zwo23jmL7+x+Gs4rq+ICq1IwkGabT/esOFD4K8Ouqlw/V3b+7F8Ln9ziarbsrqKWTc6Ol4F451L4Z9vyy92D0bf/gGd6W0VwL50JX9zjezunoqMwbVz5uoqpo6zA7M796rsq/TncLya8GwS4cy8GrMjaTypuMed9seAr2L8yxGrdBpC703cx0YnyFRjdOYev8VeXGIgZ15ZfFhFb/eMFKJjBYgnQSUTaiUgkVkAo16pJRLoAjUS0d2EAABI9SURBVIBFbssaiUiUPZ0KnIH/uo76wb3O4vI3y69v0g1uCCALXBMqChaVXQ3tWQH/SPFdvOQodOUsvK8cT4R3s83qyt1V+Tbets535SzcBXv4eH+dK/euthoLVObgFqtYyWPfVTDfR4/76qhq4K3Mus9O7ARbW45W0iR3x8KK1wfCewBRsOrLgixowcIY4wBuB+YA64AZxpg1IjJZRMa4bToOmG6Mx2VDN2CpiKwE5gGPu7eiqpfKmqbaZbO+st3g/xatbQZDT6/K34m7oO0ZVU+LvyKUE/VwE1dlcGk1elUHm6/OjtW1bGrNHcuXX9448WM4i5qC4egJDgDZbkj5Zb5ycMrSpEfQXyKo/SyMMbOMMZ2NMR2MMY/Yyx4wxsx022aSMWai134/GmN6GWP62M8V1GzWE816W8+/tU8yE1bAH3xkpW/0M8bMNR/Bb56GHpe4lkUneLb9D1RND7UQ08g1nefWMSnVR7+Dk1HaWZDSKdSpCEy3MZVvA3DupOod/yK3jomBNpf11qq/7zq873wMOROT7Jr2lSMPlL+m2ieD1M5wdjX6KVWR9uCuK3peCrcugi6jrPmE5tC8d/ntmnaH8fM9K7DTzrKyoeENXCdmZ0bN+acb9x78PcAKtY0V9IitqrAIuPhl17x73cNp11ey8wkO4lZbRj/pGo8rmKpyQrjWTz/W6ARX7rUifa5yTbfoZ/V/qUzvK1x9DMCzDs3J/cLBH3+5Z28jHrE+e6fuYwP4TfnxhwVVb0RSmciGvpe36l/xfm0GQ+8rA3+d7he5+r8EkQaLukLECgSBaNHPdZvWG76Ea93K/9sPdW0Drjb4ptT6QZ1ZSQVcjTMQneR7VXJ7KzdUjh0kHjwEPS+r/CX63wTtznbND769yqmsUGyqa9rXsCzxTfHf0K8GRSUEvm0jH5XiYJ2IfbUcS+0MQ9wy+HFu7zmhJST6bPXuqaTY1X8GrI5u7s77h6tJd9ffWCd7XyorBj3tBnjwMJx+e/mK3SH3Vp5OXyLjPHMpAe3jJxg4tRlk9fmY6FUXdl0l/aSa9oSudofE5A5w2+Lqv68apMHiZBVv92BuEO3Zprz7GLh3uzUWFbh1erJbtZw7ybVtfz+9rL1d/YHv5Rm/r3xfUwoxfoJFZKzVkehmtxvL3LUeHjho/clE/A9l4ayfaXO61Rv2us+sP9Wf1lRcQQ/WSct9mPhGaXDlNGjUDkb6qOCNS7WumsEztzfgD9BpZGBXy94iG1onp3S7ZUtkvGsoD/AdYKMCvOIG/4ElItb3KLPdxlhNm528P/dARtrN2293yLS5B/DffwWn3+HqI9DxXBh0Kz65X0Cc+1D59RLm+l038RqGxDt43LaEckY+6vtmZBf8y/uF4G8++jQ4xTfxv85dtNd3EeGnPhKsQDLyEVcuJ66x1Zv/rHs8Ry3ofL7bTrXTa0CDxclqzHMw+ilXDsKd+8nLX49YgAuesk7KlWnexzV9zv2u6VFPwp+3Wn98f0ypq9evN+cfu6VbEUdsimtcIfDfuc3ZM9ld4y7W1ay/PiBOZ0zwLMYrLbWu5O5cAYNv85HOGLjkFavnbJJ9xX7O32H0E3D1DOvEldi6/H7enLlBsE4I925zBb2Wp3lecf5+jo8DeBXLjXnO/2tFJcD9+63Ae+1MV11FRAz0vKT89s7mrRc+A5d6VREa4xr6ZchE/Go/1LOeortbX9o2A63P6ah98k1oYQWkuMZ4iIy3ctinXWcfw0cdi/tvuVE7r/29mozHpZb/jQ++DR7w0aKo/RDPIHLjV77r/Jr0sIZi6XBO+XXuwn0EJKe0s1wXCu7anWUF3OT21nwru09Og0hXkVu/a6ybqp0ZYLPjGqLBoq7rMhr6+ugIFJsMA26ufJgQf+Px+/L3A64raHfuZcinuQ0pEN4A4lKsMXWuqaCDk/t4RG1Od037ahvu/QfzFyxaZsDpE+Dil8qv81WM4X2F6n7C8S6WuXYmDBjvmh9r31woLMyVPu+r8wkr4K+Z/9/e2cdYUV0B/HfYhQVBPpYFinyvLKArBZHCohLwawuCVSsoaAsqlogSsNJWqW20labVGLWk1mitn/UrWrWEpFCLqGm1KERUFBX8qNKqYPyKTWsQTv+4d/bNm5335r3lLY+dPb9k8mbu3J2d8+68Offcc+85rveci2+EVtVXR15yItnjzt37N//7QyOLsw7OoYTBXauyyr2Qa6c4RQpO7lN/C8siK96DhX9HnQujI0N/uhcmL3NDmg0XupdvVs8WaFwBky/NtizinMaBcghe8vNWwejZbnEjuCniAPWnu/8Tq4RDz7IIzL4zs1g0+vwUEjcr69K+XWfdAYMmxNcZeBQs2+p+g7louCh+wWGgIM5dDRNzWFbglOmSF7JHAkZOd89X44rMtTr3gDFz465QckxZHOjMvR9O24dMaOHAbLk4ZSXMvsv90E68qvn5cO8qPJYdJp91AW4W19Tlbrioo+/9xc0Njyq/uDnl4HqwjVfHj83HKYtjL3GfNSPcZ1hZRL+b2ilwkk9WM+SYbF9S8PKJTv2tqHRKsTGy5iPo/VV2cYr/e+tdDzy6ihsyvdqqHu4lEJ4Y8NOP3HDZ+WszM6/Ci91GTG9+vTBhC7OyExz8tezzcal6m1AY0QhXfpyxWs9+EObcl5l916WXU0xhy6JDzOtl+rVuWLOPb4d+h8MZt8GCtc73dnYkzEZc3Kvo4rz6011vO46o8pgfs1bju4+Gru2fi1EzmtcLrMqm/5+nozbtl9kKP8hnE7YGo9Zx1PFdXZt9/5VV7vkK2qB6mIuh1ruI9Ab7QOu70I3yMvY7bgHcgDyzWQKTH1yPZvHG7IBtIi7QWdCzXbI5/+KjxRvd+PuvQr3CQRMyPbVgPLxjAavMZ1zvcmhsvD07NEe+/By5HKSXvJz5gY49G56+Nve1OnZxL+agpxswerZLtzr6zNz/v6LKBfobMQ2O+7EL3DcklCAqPCEh6Gn3OyJjaY3x1t2YOS4L2rvPZl4agxtc5+Hu09z+7LtcD/6r/8Ebf3b/a1yoPQOCl25YMc5b5eI/PX1ttn8hYFCDW6mfK6jiqBkuUm/4uknTZTt3h7ocyYJqpzYvi1M4xaQIDhRw4y9c+Jc4OcPDSWfd6yIPhy2kgMmX+kRDkZmGURY+2bzsgieax3TqMcBNj+/W1w3zxc0eO4AwZZF2RjQW5pcIU1Pn/uaqUM9namg2RvWw5sMoYapr8+dYGDge3nyisDUgA8a5bcJCF/YjIF/2tKDntfCpTAwiyPZTVA+DH2yD6+pyW12DG5qX9T40frw7zJz73Av++J84RRtWFFH61Tvn74BxTiEsfTF76OWchzIhIgIGTYArfFl9yC9w3hrXO42bRhnnu6qd4raGRfFO+snLXFa7fC/nwOka+AriXrKl4pSVPsNdEQ7d4Dk8erHbwtR/u3m4/8Nmui2WiCURpyz61sf7Ebv2dluUYMJE1NI7ADFlYZSO2uPgrfWZH+ikxdA/JiXJ7Ltg59biZvdEx57zKYuZN8Lwk1xI6os25A5REsw4CjvtS0HdiW4rlMETM/vBcEVA1cEZf0MS+ZRS/emwfoWzjKLkGnvPlSUuzJTLnDUaDEcFlkXw2XNw6VLoNim8Yv4mz1BRsAC2UEZOhycPyUzNjl563qrcfo4UYMqiPXLmPcUlWyqUOfdlYj9BdjKkMJ27Z78gAfqMculac9G1xg3VdO3jFFK+l8BB1ZmEMdGplWEqOxVvdbVVaoa3QNYCJkd07OwmWjQde2sxmJRx8fPFDRvlvZ0c+bBzccWHyXUK4aJ/OOuuW1/n2G66H/8bqhnpFmUOGNeyiAltBFMW7ZG46YhxzLojM0umEDodBJ1yLAZL4oK/5neyVnSERX93OSOeWZl/JolRGgI/Sa44ZXFUVrnp1IFvKN+agmIYNTPj2M/nfwPXw9c9pfvffQ9r7rsC52NZ93O3PmNYTEj0lCGaz8RsQ4wfP143biwi9LNhGPnZu9cNXU28sPAFaK3Bnt2uF9+hwvkYeg8vLrOkkRcR2aSqeVIQOsyyMAwjng4d4IQC8o20NuHpozVtJGBjCrF1FoZhGEYipiwMwzCMRExZGIZhGImYsjAMwzASMWVhGIZhJGLKwjAMw0jElIVhGIaRiCkLwzAMI5HUrOAWkV3AP/fhEjVAQjjR1GEyp5/2Ji+YzMUyRFX7JFVKjbLYV0RkYyFL3tOEyZx+2pu8YDK3FjYMZRiGYSRiysIwDMNIxJRFhlvLfQNlwGROP+1NXjCZWwXzWRiGYRiJmGVhGIZhJGLKwjAMw0ik3SsLEZkmIq+LyHYRubzc91MqRGSQiKwXka0i8oqILPXl1SLyuIhs85+9fLmIyEr/PbwkIgm5Kw9cRKRCRF4QkdX+eJiIbPAyPyginXx5lT/e7s8PLed9txQR6SkiD4vIa769J6W9nUXk+/653iIi94tI57S1s4jcLiI7RWRLqKzodhWR+b7+NhGZ39L7adfKQkQqgJuA6cDhwFwROby8d1UyvgKWqephQANwsZftcmCdqtYB6/wxuO+gzm8LgZv3/y2XjKXA1tDxNcANXuZPgAW+fAHwiaoOB27w9doivwbWqOooYAxO9tS2s4gMAJYA41X1CKACmEP62vlOYFqkrKh2FZFq4EpgIjABuDJQMEWjqu12AyYBa0PHy4Hl5b6vVpL1T8BJwOtAf1/WH3jd798CzA3Vb6rXljZgoP8RHQ+sBgS3srUy2ubAWmCS36/09aTcMhQpb3fg7eh9p7mdgQHAe0C1b7fVwDfT2M7AUGBLS9sVmAvcEirPqlfM1q4tCzIPXcAOX5YqvNl9JLAB6Keq7wP4z76+Wlq+ixuBHwF7/XFv4FNV/cofh+Vqktmf/8zXb0vUAruAO/zQ220i0pUUt7Oq/gu4DngXeB/XbptIdzsHFNuuJWvv9q4sJKYsVXOJRaQb8EfgElX9PF/VmLI29V2IyExgp6puChfHVNUCzrUVKoFxwM2qeiTwHzJDE3G0eZn9MMqpwDDgEKArbhgmSpraOYlcMpZM9vauLHYAg0LHA4F/l+leSo6IdMQpintV9RFf/KGI9Pfn+wM7fXkavotjgG+JyDvAA7ihqBuBniJS6euE5WqS2Z/vAXy8P2+4BOwAdqjqBn/8ME55pLmdTwTeVtVdqrobeAQ4mnS3c0Cx7Vqy9m7vyuJ5oM7PouiEc5KtKvM9lQQREeD3wFZVvT50ahUQzIiYj/NlBOXz/KyKBuCzwNxtK6jqclUdqKpDcW35hKqeA6wHZvlqUZmD72KWr9+mepyq+gHwnoiM9EUnAK+S4nbGDT81iMhB/jkPZE5tO4cotl3XAo0i0stbZI2+rHjK7cAp9wacDLwBvAlcUe77KaFcx+LMzZeAzX47GTdWuw7Y5j+rfX3BzQx7E3gZN9Ok7HLsg/xTgdV+vxZ4DtgOPARU+fLO/ni7P19b7vtuoaxjgY2+rR8DeqW9nYGfAa8BW4B7gKq0tTNwP84nsxtnISxoSbsC53vZtwPntfR+LNyHYRiGkUh7H4YyDMMwCsCUhWEYhpGIKQvDMAwjEVMWhmEYRiKmLAzDMIxETFkYRgIiskdENoe2kkUnFpGh4aiihnGgUplcxTDaPf9V1bHlvgnDKCdmWRhGCxGRd0TkGhF5zm/DffkQEVnn8wqsE5HBvryfiDwqIi/67Wh/qQoR+Z3Pz/AXEeni6y8RkVf9dR4ok5iGAZiyMIxC6BIZhjordO5zVZ0A/AYXhwq/f7eqfh24F1jpy1cCT6nqGFz8pld8eR1wk6rWA58CZ/jyy4Ej/XUubC3hDKMQbAW3YSQgIl+oareY8neA41X1LR+08QNV7S0iH+FyDuz25e+rao2I7AIGquqXoWsMBR5Xl8wGEbkM6KiqK0RkDfAFLoTHY6r6RSuLahg5McvCMPYNzbGfq04cX4b295DxJc7Axfs5CtgUiqhqGPsdUxaGsW+cFfp81u8/g4t6C3AO8De/vw5YBE15wrvnuqiIdAAGqep6XDKnnkAz68Yw9hfWUzGMZLqIyObQ8RpVDabPVonIBlzHa64vWwLcLiI/xGWxO8+XLwVuFZEFOAtiES6qaBwVwB9EpAcuougNqvppySQyjCIxn4VhtBDvsxivqh+V+14Mo7WxYSjDMAwjEbMsDMMwjETMsjAMwzASMWVhGIZhJGLKwjAMw0jElIVhGIaRiCkLwzAMI5H/A8J76djfpr/GAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy vs. Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Training', 'Validation'], loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "[0.6948566506003924, 0.9157715]\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "[2.185305051145047, 0.75455934]\n"
     ]
    }
   ],
   "source": [
    "print(binary_ann_overfit.evaluate(X_train, y_train, verbose=0))\n",
    "print(binary_ann_overfit.evaluate(X_test, y_test, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 49590 samples, validate on 21253 samples\n",
      "Epoch 1/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 0.5212 - accuracy: 0.8224 - val_loss: 0.4979 - val_accuracy: 0.8229\n",
      "Epoch 2/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4737 - accuracy: 0.8266 - val_loss: 0.4733 - val_accuracy: 0.8233\n",
      "Epoch 3/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4589 - accuracy: 0.8267 - val_loss: 0.4624 - val_accuracy: 0.8233\n",
      "Epoch 4/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.4512 - accuracy: 0.8266 - val_loss: 0.4582 - val_accuracy: 0.8230\n",
      "Epoch 5/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.4457 - accuracy: 0.8267 - val_loss: 0.4531 - val_accuracy: 0.8233\n",
      "Epoch 6/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4420 - accuracy: 0.8267 - val_loss: 0.4510 - val_accuracy: 0.8233\n",
      "Epoch 7/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4393 - accuracy: 0.8266 - val_loss: 0.4485 - val_accuracy: 0.8232\n",
      "Epoch 8/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4376 - accuracy: 0.8266 - val_loss: 0.4519 - val_accuracy: 0.8233\n",
      "Epoch 9/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4361 - accuracy: 0.8266 - val_loss: 0.4521 - val_accuracy: 0.8233\n",
      "Epoch 10/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4356 - accuracy: 0.8267 - val_loss: 0.4439 - val_accuracy: 0.8233\n",
      "Epoch 11/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.4340 - accuracy: 0.8267 - val_loss: 0.4438 - val_accuracy: 0.8233\n",
      "Epoch 12/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.4336 - accuracy: 0.8267 - val_loss: 0.4453 - val_accuracy: 0.8233\n",
      "Epoch 13/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4327 - accuracy: 0.8266 - val_loss: 0.4416 - val_accuracy: 0.8233\n",
      "Epoch 14/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4322 - accuracy: 0.8266 - val_loss: 0.4432 - val_accuracy: 0.8233\n",
      "Epoch 15/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4318 - accuracy: 0.8267 - val_loss: 0.4450 - val_accuracy: 0.8233\n",
      "Epoch 16/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4314 - accuracy: 0.8265 - val_loss: 0.4413 - val_accuracy: 0.8233\n",
      "Epoch 17/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4309 - accuracy: 0.8267 - val_loss: 0.4422 - val_accuracy: 0.8233\n",
      "Epoch 18/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4308 - accuracy: 0.8268 - val_loss: 0.4415 - val_accuracy: 0.8233\n",
      "Epoch 19/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4304 - accuracy: 0.8267 - val_loss: 0.4430 - val_accuracy: 0.8233\n",
      "Epoch 20/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4304 - accuracy: 0.8266 - val_loss: 0.4444 - val_accuracy: 0.8233\n",
      "Epoch 21/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4305 - accuracy: 0.8267 - val_loss: 0.4398 - val_accuracy: 0.8233\n",
      "Epoch 22/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4296 - accuracy: 0.8266 - val_loss: 0.4436 - val_accuracy: 0.8233\n",
      "Epoch 23/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4299 - accuracy: 0.8267 - val_loss: 0.4427 - val_accuracy: 0.8233\n",
      "Epoch 24/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4292 - accuracy: 0.8266 - val_loss: 0.4414 - val_accuracy: 0.8233\n",
      "Epoch 25/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4296 - accuracy: 0.8266 - val_loss: 0.4414 - val_accuracy: 0.8233\n",
      "Epoch 26/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4293 - accuracy: 0.8266 - val_loss: 0.4403 - val_accuracy: 0.8233\n",
      "Epoch 27/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4291 - accuracy: 0.8268 - val_loss: 0.4392 - val_accuracy: 0.8233\n",
      "Epoch 28/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4286 - accuracy: 0.8267 - val_loss: 0.4389 - val_accuracy: 0.8230\n",
      "Epoch 29/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4282 - accuracy: 0.8269 - val_loss: 0.4389 - val_accuracy: 0.8232\n",
      "Epoch 30/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.4285 - accuracy: 0.8264 - val_loss: 0.4387 - val_accuracy: 0.8232\n",
      "Epoch 31/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4285 - accuracy: 0.8267 - val_loss: 0.4388 - val_accuracy: 0.8233\n",
      "Epoch 32/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4283 - accuracy: 0.8266 - val_loss: 0.4389 - val_accuracy: 0.8233\n",
      "Epoch 33/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4279 - accuracy: 0.8268 - val_loss: 0.4418 - val_accuracy: 0.8231\n",
      "Epoch 34/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4278 - accuracy: 0.8267 - val_loss: 0.4425 - val_accuracy: 0.8232\n",
      "Epoch 35/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4282 - accuracy: 0.8265 - val_loss: 0.4401 - val_accuracy: 0.8231\n",
      "Epoch 36/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4279 - accuracy: 0.8265 - val_loss: 0.4386 - val_accuracy: 0.8232\n",
      "Epoch 37/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4277 - accuracy: 0.8266 - val_loss: 0.4384 - val_accuracy: 0.8234\n",
      "Epoch 38/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4276 - accuracy: 0.8268 - val_loss: 0.4378 - val_accuracy: 0.8232\n",
      "Epoch 39/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4272 - accuracy: 0.8269 - val_loss: 0.4374 - val_accuracy: 0.8233\n",
      "Epoch 40/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4279 - accuracy: 0.8265 - val_loss: 0.4408 - val_accuracy: 0.8233\n",
      "Epoch 41/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4275 - accuracy: 0.8268 - val_loss: 0.4437 - val_accuracy: 0.8232\n",
      "Epoch 42/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4272 - accuracy: 0.8266 - val_loss: 0.4428 - val_accuracy: 0.8234\n",
      "Epoch 43/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4272 - accuracy: 0.8270 - val_loss: 0.4394 - val_accuracy: 0.8233\n",
      "Epoch 44/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4269 - accuracy: 0.8268 - val_loss: 0.4438 - val_accuracy: 0.8232\n",
      "Epoch 45/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4267 - accuracy: 0.8269 - val_loss: 0.4444 - val_accuracy: 0.8234\n",
      "Epoch 46/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4274 - accuracy: 0.8270 - val_loss: 0.4393 - val_accuracy: 0.8232\n",
      "Epoch 47/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4270 - accuracy: 0.8266 - val_loss: 0.4390 - val_accuracy: 0.8232\n",
      "Epoch 48/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4270 - accuracy: 0.8268 - val_loss: 0.4391 - val_accuracy: 0.8233\n",
      "Epoch 49/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4267 - accuracy: 0.8267 - val_loss: 0.4378 - val_accuracy: 0.8233\n",
      "Epoch 50/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4268 - accuracy: 0.8267 - val_loss: 0.4396 - val_accuracy: 0.8233\n",
      "Epoch 51/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4266 - accuracy: 0.8268 - val_loss: 0.4410 - val_accuracy: 0.8233\n",
      "Epoch 52/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4268 - accuracy: 0.8270 - val_loss: 0.4380 - val_accuracy: 0.8230\n",
      "Epoch 53/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4266 - accuracy: 0.8269 - val_loss: 0.4381 - val_accuracy: 0.8231\n",
      "Epoch 54/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4265 - accuracy: 0.8268 - val_loss: 0.4383 - val_accuracy: 0.8234\n",
      "Epoch 55/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4264 - accuracy: 0.8270 - val_loss: 0.4452 - val_accuracy: 0.8235\n",
      "Epoch 56/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4269 - accuracy: 0.8266 - val_loss: 0.4385 - val_accuracy: 0.8230\n",
      "Epoch 57/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4261 - accuracy: 0.8267 - val_loss: 0.4410 - val_accuracy: 0.8229\n",
      "Epoch 58/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4263 - accuracy: 0.8268 - val_loss: 0.4382 - val_accuracy: 0.8233\n",
      "Epoch 59/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4260 - accuracy: 0.8268 - val_loss: 0.4401 - val_accuracy: 0.8233\n",
      "Epoch 60/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4267 - accuracy: 0.8269 - val_loss: 0.4397 - val_accuracy: 0.8230\n",
      "Epoch 61/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4264 - accuracy: 0.8269 - val_loss: 0.4415 - val_accuracy: 0.8232\n",
      "Epoch 62/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4263 - accuracy: 0.8268 - val_loss: 0.4383 - val_accuracy: 0.8232\n",
      "Epoch 63/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4265 - accuracy: 0.8266 - val_loss: 0.4397 - val_accuracy: 0.8230\n",
      "Epoch 64/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4264 - accuracy: 0.8265 - val_loss: 0.4439 - val_accuracy: 0.8233\n",
      "Epoch 65/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4257 - accuracy: 0.8264 - val_loss: 0.4384 - val_accuracy: 0.8235\n",
      "Epoch 66/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4265 - accuracy: 0.8269 - val_loss: 0.4379 - val_accuracy: 0.8232\n",
      "Epoch 67/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4263 - accuracy: 0.8266 - val_loss: 0.4391 - val_accuracy: 0.8235\n",
      "Epoch 68/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4258 - accuracy: 0.8265 - val_loss: 0.4395 - val_accuracy: 0.8231\n",
      "Epoch 69/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4263 - accuracy: 0.8267 - val_loss: 0.4385 - val_accuracy: 0.8232\n",
      "Epoch 70/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4258 - accuracy: 0.8266 - val_loss: 0.4396 - val_accuracy: 0.8234\n",
      "Epoch 71/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4264 - accuracy: 0.8267 - val_loss: 0.4372 - val_accuracy: 0.8234\n",
      "Epoch 72/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4262 - accuracy: 0.8267 - val_loss: 0.4397 - val_accuracy: 0.8233\n",
      "Epoch 73/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4259 - accuracy: 0.8267 - val_loss: 0.4443 - val_accuracy: 0.8234\n",
      "Epoch 74/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4259 - accuracy: 0.8264 - val_loss: 0.4400 - val_accuracy: 0.8232\n",
      "Epoch 75/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4254 - accuracy: 0.8267 - val_loss: 0.4387 - val_accuracy: 0.8230\n",
      "Epoch 76/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4257 - accuracy: 0.8266 - val_loss: 0.4405 - val_accuracy: 0.8233\n",
      "Epoch 77/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4255 - accuracy: 0.8270 - val_loss: 0.4376 - val_accuracy: 0.8235\n",
      "Epoch 78/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4263 - accuracy: 0.8272 - val_loss: 0.4383 - val_accuracy: 0.8236\n",
      "Epoch 79/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4254 - accuracy: 0.8266 - val_loss: 0.4382 - val_accuracy: 0.8232\n",
      "Epoch 80/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4257 - accuracy: 0.8264 - val_loss: 0.4383 - val_accuracy: 0.8229\n",
      "Epoch 81/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4258 - accuracy: 0.8268 - val_loss: 0.4388 - val_accuracy: 0.8235\n",
      "Epoch 82/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4254 - accuracy: 0.8270 - val_loss: 0.4394 - val_accuracy: 0.8234\n",
      "Epoch 83/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4255 - accuracy: 0.8271 - val_loss: 0.4379 - val_accuracy: 0.8234\n",
      "Epoch 84/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4252 - accuracy: 0.8269 - val_loss: 0.4397 - val_accuracy: 0.8231\n",
      "Epoch 85/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4257 - accuracy: 0.8266 - val_loss: 0.4383 - val_accuracy: 0.8236\n",
      "Epoch 86/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4256 - accuracy: 0.8267 - val_loss: 0.4396 - val_accuracy: 0.8234\n",
      "Epoch 87/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4258 - accuracy: 0.8263 - val_loss: 0.4386 - val_accuracy: 0.8231\n",
      "Epoch 88/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4260 - accuracy: 0.8268 - val_loss: 0.4375 - val_accuracy: 0.8235\n",
      "Epoch 89/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4260 - accuracy: 0.8268 - val_loss: 0.4392 - val_accuracy: 0.8231\n",
      "Epoch 90/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4254 - accuracy: 0.8265 - val_loss: 0.4385 - val_accuracy: 0.8234\n",
      "Epoch 91/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4253 - accuracy: 0.8268 - val_loss: 0.4399 - val_accuracy: 0.8232\n",
      "Epoch 92/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4252 - accuracy: 0.8266 - val_loss: 0.4400 - val_accuracy: 0.8234\n",
      "Epoch 93/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4252 - accuracy: 0.8269 - val_loss: 0.4392 - val_accuracy: 0.8236\n",
      "Epoch 94/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4256 - accuracy: 0.8270 - val_loss: 0.4382 - val_accuracy: 0.8228\n",
      "Epoch 95/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4255 - accuracy: 0.8271 - val_loss: 0.4376 - val_accuracy: 0.8235\n",
      "Epoch 96/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4254 - accuracy: 0.8268 - val_loss: 0.4369 - val_accuracy: 0.8239\n",
      "Epoch 97/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4259 - accuracy: 0.8267 - val_loss: 0.4413 - val_accuracy: 0.8229\n",
      "Epoch 98/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4253 - accuracy: 0.8265 - val_loss: 0.4375 - val_accuracy: 0.8237\n",
      "Epoch 99/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4255 - accuracy: 0.8266 - val_loss: 0.4373 - val_accuracy: 0.8233\n",
      "Epoch 100/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4255 - accuracy: 0.8267 - val_loss: 0.4391 - val_accuracy: 0.8232\n",
      "Epoch 101/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4254 - accuracy: 0.8267 - val_loss: 0.4376 - val_accuracy: 0.8237\n",
      "Epoch 102/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4257 - accuracy: 0.8265 - val_loss: 0.4363 - val_accuracy: 0.8234\n",
      "Epoch 103/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4255 - accuracy: 0.8266 - val_loss: 0.4404 - val_accuracy: 0.8233\n",
      "Epoch 104/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4255 - accuracy: 0.8267 - val_loss: 0.4382 - val_accuracy: 0.8233\n",
      "Epoch 105/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4254 - accuracy: 0.8269 - val_loss: 0.4427 - val_accuracy: 0.8236\n",
      "Epoch 106/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4252 - accuracy: 0.8270 - val_loss: 0.4395 - val_accuracy: 0.8236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4252 - accuracy: 0.8268 - val_loss: 0.4384 - val_accuracy: 0.8235\n",
      "Epoch 108/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4258 - accuracy: 0.8266 - val_loss: 0.4377 - val_accuracy: 0.8238\n",
      "Epoch 109/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4257 - accuracy: 0.8268 - val_loss: 0.4365 - val_accuracy: 0.8234\n",
      "Epoch 110/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4250 - accuracy: 0.8269 - val_loss: 0.4380 - val_accuracy: 0.8234\n",
      "Epoch 111/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4253 - accuracy: 0.8266 - val_loss: 0.4374 - val_accuracy: 0.8236\n",
      "Epoch 112/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4254 - accuracy: 0.8271 - val_loss: 0.4369 - val_accuracy: 0.8233\n",
      "Epoch 113/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4253 - accuracy: 0.8273 - val_loss: 0.4366 - val_accuracy: 0.8237\n",
      "Epoch 114/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4252 - accuracy: 0.8267 - val_loss: 0.4368 - val_accuracy: 0.8234\n",
      "Epoch 115/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4253 - accuracy: 0.8267 - val_loss: 0.4380 - val_accuracy: 0.8232\n",
      "Epoch 116/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4252 - accuracy: 0.8269 - val_loss: 0.4360 - val_accuracy: 0.8235\n",
      "Epoch 117/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4256 - accuracy: 0.8268 - val_loss: 0.4417 - val_accuracy: 0.8236\n",
      "Epoch 118/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4256 - accuracy: 0.8266 - val_loss: 0.4378 - val_accuracy: 0.8236\n",
      "Epoch 119/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4253 - accuracy: 0.8269 - val_loss: 0.4396 - val_accuracy: 0.8232\n",
      "Epoch 120/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4253 - accuracy: 0.8269 - val_loss: 0.4368 - val_accuracy: 0.8237\n",
      "Epoch 121/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4250 - accuracy: 0.8269 - val_loss: 0.4366 - val_accuracy: 0.8238\n",
      "Epoch 122/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4248 - accuracy: 0.8269 - val_loss: 0.4417 - val_accuracy: 0.8233\n",
      "Epoch 123/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4255 - accuracy: 0.8266 - val_loss: 0.4370 - val_accuracy: 0.8233\n",
      "Epoch 124/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4253 - accuracy: 0.8268 - val_loss: 0.4423 - val_accuracy: 0.8233\n",
      "Epoch 125/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4251 - accuracy: 0.8265 - val_loss: 0.4388 - val_accuracy: 0.8234\n",
      "Epoch 126/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4248 - accuracy: 0.8267 - val_loss: 0.4392 - val_accuracy: 0.8237\n",
      "Epoch 127/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4249 - accuracy: 0.8267 - val_loss: 0.4391 - val_accuracy: 0.8234\n",
      "Epoch 128/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4255 - accuracy: 0.8265 - val_loss: 0.4369 - val_accuracy: 0.8236\n",
      "Epoch 129/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4249 - accuracy: 0.8266 - val_loss: 0.4385 - val_accuracy: 0.8233\n",
      "Epoch 130/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4250 - accuracy: 0.8266 - val_loss: 0.4398 - val_accuracy: 0.8234\n",
      "Epoch 131/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4251 - accuracy: 0.8270 - val_loss: 0.4382 - val_accuracy: 0.8234\n",
      "Epoch 132/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4252 - accuracy: 0.8269 - val_loss: 0.4401 - val_accuracy: 0.8233\n",
      "Epoch 133/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4248 - accuracy: 0.8269 - val_loss: 0.4402 - val_accuracy: 0.8233\n",
      "Epoch 134/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4250 - accuracy: 0.8269 - val_loss: 0.4377 - val_accuracy: 0.8233\n",
      "Epoch 135/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4250 - accuracy: 0.8269 - val_loss: 0.4391 - val_accuracy: 0.8238\n",
      "Epoch 136/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4250 - accuracy: 0.8271 - val_loss: 0.4367 - val_accuracy: 0.8236\n",
      "Epoch 137/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4251 - accuracy: 0.8268 - val_loss: 0.4384 - val_accuracy: 0.8235\n",
      "Epoch 138/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4251 - accuracy: 0.8271 - val_loss: 0.4390 - val_accuracy: 0.8238\n",
      "Epoch 139/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4250 - accuracy: 0.8269 - val_loss: 0.4385 - val_accuracy: 0.8236\n",
      "Epoch 140/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4252 - accuracy: 0.8270 - val_loss: 0.4374 - val_accuracy: 0.8233\n",
      "Epoch 141/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4252 - accuracy: 0.8269 - val_loss: 0.4421 - val_accuracy: 0.8233\n",
      "Epoch 142/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4253 - accuracy: 0.8266 - val_loss: 0.4385 - val_accuracy: 0.8231\n",
      "Epoch 143/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4254 - accuracy: 0.8268 - val_loss: 0.4381 - val_accuracy: 0.8241\n",
      "Epoch 144/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4247 - accuracy: 0.8270 - val_loss: 0.4389 - val_accuracy: 0.8237\n",
      "Epoch 145/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4246 - accuracy: 0.8269 - val_loss: 0.4375 - val_accuracy: 0.8230\n",
      "Epoch 146/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4247 - accuracy: 0.8266 - val_loss: 0.4379 - val_accuracy: 0.8236\n",
      "Epoch 147/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4250 - accuracy: 0.8269 - val_loss: 0.4374 - val_accuracy: 0.8237\n",
      "Epoch 148/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4248 - accuracy: 0.8267 - val_loss: 0.4367 - val_accuracy: 0.8239\n",
      "Epoch 149/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4248 - accuracy: 0.8267 - val_loss: 0.4384 - val_accuracy: 0.8239\n",
      "Epoch 150/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4247 - accuracy: 0.8268 - val_loss: 0.4391 - val_accuracy: 0.8238\n",
      "Epoch 151/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4251 - accuracy: 0.8267 - val_loss: 0.4376 - val_accuracy: 0.8237\n",
      "Epoch 152/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4247 - accuracy: 0.8267 - val_loss: 0.4388 - val_accuracy: 0.8241\n",
      "Epoch 153/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4250 - accuracy: 0.8270 - val_loss: 0.4372 - val_accuracy: 0.8232\n",
      "Epoch 154/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4253 - accuracy: 0.8265 - val_loss: 0.4370 - val_accuracy: 0.8230\n",
      "Epoch 155/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4250 - accuracy: 0.8264 - val_loss: 0.4383 - val_accuracy: 0.8233\n",
      "Epoch 156/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4242 - accuracy: 0.8267 - val_loss: 0.4358 - val_accuracy: 0.8240\n",
      "Epoch 157/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4252 - accuracy: 0.8267 - val_loss: 0.4371 - val_accuracy: 0.8239\n",
      "Epoch 158/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4246 - accuracy: 0.8266 - val_loss: 0.4394 - val_accuracy: 0.8233\n",
      "Epoch 159/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4248 - accuracy: 0.8269 - val_loss: 0.4402 - val_accuracy: 0.8234\n",
      "Epoch 160/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4249 - accuracy: 0.8270 - val_loss: 0.4409 - val_accuracy: 0.8233\n",
      "Epoch 161/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4249 - accuracy: 0.8270 - val_loss: 0.4418 - val_accuracy: 0.8234\n",
      "Epoch 162/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4246 - accuracy: 0.8271 - val_loss: 0.4386 - val_accuracy: 0.8232\n",
      "Epoch 163/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4244 - accuracy: 0.8273 - val_loss: 0.4375 - val_accuracy: 0.8235\n",
      "Epoch 164/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4249 - accuracy: 0.8269 - val_loss: 0.4379 - val_accuracy: 0.8236\n",
      "Epoch 165/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4244 - accuracy: 0.8269 - val_loss: 0.4377 - val_accuracy: 0.8244\n",
      "Epoch 166/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4250 - accuracy: 0.8268 - val_loss: 0.4363 - val_accuracy: 0.8239\n",
      "Epoch 167/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4251 - accuracy: 0.8267 - val_loss: 0.4395 - val_accuracy: 0.8234\n",
      "Epoch 168/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4248 - accuracy: 0.8264 - val_loss: 0.4375 - val_accuracy: 0.8236\n",
      "Epoch 169/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4246 - accuracy: 0.8268 - val_loss: 0.4371 - val_accuracy: 0.8236\n",
      "Epoch 170/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4247 - accuracy: 0.8271 - val_loss: 0.4382 - val_accuracy: 0.8236\n",
      "Epoch 171/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4243 - accuracy: 0.8270 - val_loss: 0.4391 - val_accuracy: 0.8233\n",
      "Epoch 172/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4248 - accuracy: 0.8269 - val_loss: 0.4376 - val_accuracy: 0.8236\n",
      "Epoch 173/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4245 - accuracy: 0.8267 - val_loss: 0.4382 - val_accuracy: 0.8241\n",
      "Epoch 174/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4242 - accuracy: 0.8269 - val_loss: 0.4400 - val_accuracy: 0.8229\n",
      "Epoch 175/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4249 - accuracy: 0.8269 - val_loss: 0.4400 - val_accuracy: 0.8236\n",
      "Epoch 176/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4247 - accuracy: 0.8273 - val_loss: 0.4374 - val_accuracy: 0.8232\n",
      "Epoch 177/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4242 - accuracy: 0.8268 - val_loss: 0.4377 - val_accuracy: 0.8235\n",
      "Epoch 178/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4247 - accuracy: 0.8267 - val_loss: 0.4388 - val_accuracy: 0.8234\n",
      "Epoch 179/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4245 - accuracy: 0.8267 - val_loss: 0.4403 - val_accuracy: 0.8230\n",
      "Epoch 180/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4245 - accuracy: 0.8268 - val_loss: 0.4358 - val_accuracy: 0.8240\n",
      "Epoch 181/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4244 - accuracy: 0.8269 - val_loss: 0.4383 - val_accuracy: 0.8235\n",
      "Epoch 182/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4246 - accuracy: 0.8267 - val_loss: 0.4409 - val_accuracy: 0.8236\n",
      "Epoch 183/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4245 - accuracy: 0.8269 - val_loss: 0.4376 - val_accuracy: 0.8237\n",
      "Epoch 184/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4240 - accuracy: 0.8271 - val_loss: 0.4395 - val_accuracy: 0.8240\n",
      "Epoch 185/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4243 - accuracy: 0.8265 - val_loss: 0.4397 - val_accuracy: 0.8235\n",
      "Epoch 186/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4246 - accuracy: 0.8266 - val_loss: 0.4370 - val_accuracy: 0.8235\n",
      "Epoch 187/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4244 - accuracy: 0.8265 - val_loss: 0.4397 - val_accuracy: 0.8232\n",
      "Epoch 188/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4247 - accuracy: 0.8269 - val_loss: 0.4391 - val_accuracy: 0.8236\n",
      "Epoch 189/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4245 - accuracy: 0.8268 - val_loss: 0.4367 - val_accuracy: 0.8239\n",
      "Epoch 190/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4244 - accuracy: 0.8268 - val_loss: 0.4408 - val_accuracy: 0.8232\n",
      "Epoch 191/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4246 - accuracy: 0.8270 - val_loss: 0.4387 - val_accuracy: 0.8232\n",
      "Epoch 192/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4246 - accuracy: 0.8274 - val_loss: 0.4390 - val_accuracy: 0.8233\n",
      "Epoch 193/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4243 - accuracy: 0.8268 - val_loss: 0.4372 - val_accuracy: 0.8240\n",
      "Epoch 194/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4246 - accuracy: 0.8270 - val_loss: 0.4365 - val_accuracy: 0.8240\n",
      "Epoch 195/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4241 - accuracy: 0.8268 - val_loss: 0.4390 - val_accuracy: 0.8234\n",
      "Epoch 196/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4242 - accuracy: 0.8268 - val_loss: 0.4374 - val_accuracy: 0.8234\n",
      "Epoch 197/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4248 - accuracy: 0.8267 - val_loss: 0.4373 - val_accuracy: 0.8238\n",
      "Epoch 198/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4245 - accuracy: 0.8271 - val_loss: 0.4405 - val_accuracy: 0.8221\n",
      "Epoch 199/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4246 - accuracy: 0.8268 - val_loss: 0.4374 - val_accuracy: 0.8239\n",
      "Epoch 200/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4245 - accuracy: 0.8265 - val_loss: 0.4367 - val_accuracy: 0.8238\n",
      "Epoch 201/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4246 - accuracy: 0.8273 - val_loss: 0.4373 - val_accuracy: 0.8237\n",
      "Epoch 202/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4243 - accuracy: 0.8273 - val_loss: 0.4392 - val_accuracy: 0.8234\n",
      "Epoch 203/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4248 - accuracy: 0.8267 - val_loss: 0.4382 - val_accuracy: 0.8235\n",
      "Epoch 204/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4243 - accuracy: 0.8270 - val_loss: 0.4371 - val_accuracy: 0.8231\n",
      "Epoch 205/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4243 - accuracy: 0.8265 - val_loss: 0.4378 - val_accuracy: 0.8236\n",
      "Epoch 206/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4243 - accuracy: 0.8269 - val_loss: 0.4379 - val_accuracy: 0.8236\n",
      "Epoch 207/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4247 - accuracy: 0.8270 - val_loss: 0.4408 - val_accuracy: 0.8234\n",
      "Epoch 208/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4243 - accuracy: 0.8269 - val_loss: 0.4378 - val_accuracy: 0.8235\n",
      "Epoch 209/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4240 - accuracy: 0.8264 - val_loss: 0.4396 - val_accuracy: 0.8232\n",
      "Epoch 210/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4248 - accuracy: 0.8269 - val_loss: 0.4386 - val_accuracy: 0.8234\n",
      "Epoch 211/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4239 - accuracy: 0.8268 - val_loss: 0.4364 - val_accuracy: 0.8239\n",
      "Epoch 212/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4243 - accuracy: 0.8272 - val_loss: 0.4362 - val_accuracy: 0.8239\n",
      "Epoch 213/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4244 - accuracy: 0.8267 - val_loss: 0.4361 - val_accuracy: 0.8240\n",
      "Epoch 214/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4246 - accuracy: 0.8270 - val_loss: 0.4368 - val_accuracy: 0.8237\n",
      "Epoch 215/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4241 - accuracy: 0.8269 - val_loss: 0.4421 - val_accuracy: 0.8236\n",
      "Epoch 216/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4243 - accuracy: 0.8269 - val_loss: 0.4395 - val_accuracy: 0.8236\n",
      "Epoch 217/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4245 - accuracy: 0.8271 - val_loss: 0.4406 - val_accuracy: 0.8236\n",
      "Epoch 218/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4241 - accuracy: 0.8271 - val_loss: 0.4373 - val_accuracy: 0.8234\n",
      "Epoch 219/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4241 - accuracy: 0.8265 - val_loss: 0.4374 - val_accuracy: 0.8238\n",
      "Epoch 220/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4241 - accuracy: 0.8271 - val_loss: 0.4365 - val_accuracy: 0.8241\n",
      "Epoch 221/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4241 - accuracy: 0.8267 - val_loss: 0.4378 - val_accuracy: 0.8240\n",
      "Epoch 222/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4243 - accuracy: 0.8268 - val_loss: 0.4372 - val_accuracy: 0.8240\n",
      "Epoch 223/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4241 - accuracy: 0.8268 - val_loss: 0.4371 - val_accuracy: 0.8243\n",
      "Epoch 224/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4243 - accuracy: 0.8268 - val_loss: 0.4372 - val_accuracy: 0.8235\n",
      "Epoch 225/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4242 - accuracy: 0.8268 - val_loss: 0.4388 - val_accuracy: 0.8234\n",
      "Epoch 226/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4242 - accuracy: 0.8271 - val_loss: 0.4380 - val_accuracy: 0.8242\n",
      "Epoch 227/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4241 - accuracy: 0.8265 - val_loss: 0.4417 - val_accuracy: 0.8233\n",
      "Epoch 228/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4243 - accuracy: 0.8268 - val_loss: 0.4378 - val_accuracy: 0.8235\n",
      "Epoch 229/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4237 - accuracy: 0.8267 - val_loss: 0.4380 - val_accuracy: 0.8236\n",
      "Epoch 230/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4242 - accuracy: 0.8271 - val_loss: 0.4368 - val_accuracy: 0.8235\n",
      "Epoch 231/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4238 - accuracy: 0.8271 - val_loss: 0.4396 - val_accuracy: 0.8236\n",
      "Epoch 232/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4240 - accuracy: 0.8269 - val_loss: 0.4380 - val_accuracy: 0.8242\n",
      "Epoch 233/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4246 - accuracy: 0.8268 - val_loss: 0.4377 - val_accuracy: 0.8241\n",
      "Epoch 234/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4244 - accuracy: 0.8267 - val_loss: 0.4380 - val_accuracy: 0.8230\n",
      "Epoch 235/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4245 - accuracy: 0.8269 - val_loss: 0.4392 - val_accuracy: 0.8237\n",
      "Epoch 236/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4237 - accuracy: 0.8268 - val_loss: 0.4386 - val_accuracy: 0.8235\n",
      "Epoch 237/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4240 - accuracy: 0.8274 - val_loss: 0.4384 - val_accuracy: 0.8235\n",
      "Epoch 238/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4240 - accuracy: 0.8264 - val_loss: 0.4364 - val_accuracy: 0.8241\n",
      "Epoch 239/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4237 - accuracy: 0.8267 - val_loss: 0.4390 - val_accuracy: 0.8238\n",
      "Epoch 240/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4241 - accuracy: 0.8264 - val_loss: 0.4393 - val_accuracy: 0.8236\n",
      "Epoch 241/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4239 - accuracy: 0.8267 - val_loss: 0.4391 - val_accuracy: 0.8232\n",
      "Epoch 242/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4236 - accuracy: 0.8269 - val_loss: 0.4387 - val_accuracy: 0.8235\n",
      "Epoch 243/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4242 - accuracy: 0.8269 - val_loss: 0.4375 - val_accuracy: 0.8234\n",
      "Epoch 244/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4237 - accuracy: 0.8269 - val_loss: 0.4390 - val_accuracy: 0.8229\n",
      "Epoch 245/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4239 - accuracy: 0.8272 - val_loss: 0.4431 - val_accuracy: 0.8234\n",
      "Epoch 246/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4243 - accuracy: 0.8267 - val_loss: 0.4411 - val_accuracy: 0.8238\n",
      "Epoch 247/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4242 - accuracy: 0.8270 - val_loss: 0.4429 - val_accuracy: 0.8233\n",
      "Epoch 248/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4244 - accuracy: 0.8269 - val_loss: 0.4394 - val_accuracy: 0.8234\n",
      "Epoch 249/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4238 - accuracy: 0.8268 - val_loss: 0.4362 - val_accuracy: 0.8251\n",
      "Epoch 250/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4234 - accuracy: 0.8269 - val_loss: 0.4419 - val_accuracy: 0.8233\n",
      "Epoch 251/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4244 - accuracy: 0.8272 - val_loss: 0.4379 - val_accuracy: 0.8238\n",
      "Epoch 252/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4236 - accuracy: 0.8269 - val_loss: 0.4398 - val_accuracy: 0.8235\n",
      "Epoch 253/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4241 - accuracy: 0.8266 - val_loss: 0.4380 - val_accuracy: 0.8233\n",
      "Epoch 254/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4239 - accuracy: 0.8270 - val_loss: 0.4364 - val_accuracy: 0.8238\n",
      "Epoch 255/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4243 - accuracy: 0.8263 - val_loss: 0.4382 - val_accuracy: 0.8236\n",
      "Epoch 256/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4238 - accuracy: 0.8266 - val_loss: 0.4386 - val_accuracy: 0.8233\n",
      "Epoch 257/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4240 - accuracy: 0.8268 - val_loss: 0.4385 - val_accuracy: 0.8232\n",
      "Epoch 258/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4241 - accuracy: 0.8270 - val_loss: 0.4391 - val_accuracy: 0.8238\n",
      "Epoch 259/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4236 - accuracy: 0.8270 - val_loss: 0.4372 - val_accuracy: 0.8243\n",
      "Epoch 260/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4242 - accuracy: 0.8268 - val_loss: 0.4368 - val_accuracy: 0.8236\n",
      "Epoch 261/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4237 - accuracy: 0.8268 - val_loss: 0.4398 - val_accuracy: 0.8231\n",
      "Epoch 262/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4240 - accuracy: 0.8269 - val_loss: 0.4406 - val_accuracy: 0.8236\n",
      "Epoch 263/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4236 - accuracy: 0.8271 - val_loss: 0.4401 - val_accuracy: 0.8236\n",
      "Epoch 264/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4238 - accuracy: 0.8269 - val_loss: 0.4363 - val_accuracy: 0.8239\n",
      "Epoch 265/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.4245 - accuracy: 0.8269 - val_loss: 0.4368 - val_accuracy: 0.8236\n",
      "Epoch 266/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 0.4238 - accuracy: 0.8271 - val_loss: 0.4379 - val_accuracy: 0.8237\n",
      "Epoch 267/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.4239 - accuracy: 0.8266 - val_loss: 0.4377 - val_accuracy: 0.8239\n",
      "Epoch 268/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.4238 - accuracy: 0.8270 - val_loss: 0.4363 - val_accuracy: 0.8238\n",
      "Epoch 269/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.4237 - accuracy: 0.8269 - val_loss: 0.4390 - val_accuracy: 0.8237\n",
      "Epoch 270/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.4241 - accuracy: 0.8271 - val_loss: 0.4380 - val_accuracy: 0.8241\n",
      "Epoch 271/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4237 - accuracy: 0.8268 - val_loss: 0.4377 - val_accuracy: 0.8238\n",
      "Epoch 272/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.4239 - accuracy: 0.8271 - val_loss: 0.4379 - val_accuracy: 0.8237\n",
      "Epoch 273/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4237 - accuracy: 0.8270 - val_loss: 0.4368 - val_accuracy: 0.8235\n",
      "Epoch 274/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4237 - accuracy: 0.8270 - val_loss: 0.4366 - val_accuracy: 0.8241\n",
      "Epoch 275/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4235 - accuracy: 0.8268 - val_loss: 0.4404 - val_accuracy: 0.8232\n",
      "Epoch 276/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4240 - accuracy: 0.8269 - val_loss: 0.4394 - val_accuracy: 0.8236\n",
      "Epoch 277/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.4244 - accuracy: 0.8268 - val_loss: 0.4373 - val_accuracy: 0.8235\n",
      "Epoch 278/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.4237 - accuracy: 0.8270 - val_loss: 0.4384 - val_accuracy: 0.8240\n",
      "Epoch 279/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.4240 - accuracy: 0.8264 - val_loss: 0.4375 - val_accuracy: 0.8236\n",
      "Epoch 280/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.4243 - accuracy: 0.8268 - val_loss: 0.4370 - val_accuracy: 0.8238\n",
      "Epoch 281/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4239 - accuracy: 0.8268 - val_loss: 0.4381 - val_accuracy: 0.8235\n",
      "Epoch 282/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.4244 - accuracy: 0.8266 - val_loss: 0.4406 - val_accuracy: 0.8236\n",
      "Epoch 283/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.4242 - accuracy: 0.8270 - val_loss: 0.4391 - val_accuracy: 0.8239\n",
      "Epoch 284/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.4238 - accuracy: 0.8268 - val_loss: 0.4381 - val_accuracy: 0.8238\n",
      "Epoch 285/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 0.4236 - accuracy: 0.8268 - val_loss: 0.4387 - val_accuracy: 0.8236\n",
      "Epoch 286/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4234 - accuracy: 0.8269 - val_loss: 0.4386 - val_accuracy: 0.8237\n",
      "Epoch 287/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4237 - accuracy: 0.8270 - val_loss: 0.4390 - val_accuracy: 0.8234\n",
      "Epoch 288/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4238 - accuracy: 0.8271 - val_loss: 0.4378 - val_accuracy: 0.8235\n",
      "Epoch 289/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4238 - accuracy: 0.8271 - val_loss: 0.4380 - val_accuracy: 0.8236\n",
      "Epoch 290/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.4232 - accuracy: 0.8272 - val_loss: 0.4367 - val_accuracy: 0.8235\n",
      "Epoch 291/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.4235 - accuracy: 0.8268 - val_loss: 0.4415 - val_accuracy: 0.8233\n",
      "Epoch 292/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.4241 - accuracy: 0.8264 - val_loss: 0.4407 - val_accuracy: 0.8232\n",
      "Epoch 293/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4235 - accuracy: 0.8273 - val_loss: 0.4379 - val_accuracy: 0.8235\n",
      "Epoch 294/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4239 - accuracy: 0.8268 - val_loss: 0.4362 - val_accuracy: 0.8236\n",
      "Epoch 295/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4238 - accuracy: 0.8269 - val_loss: 0.4399 - val_accuracy: 0.8234\n",
      "Epoch 296/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4233 - accuracy: 0.8271 - val_loss: 0.4424 - val_accuracy: 0.8236\n",
      "Epoch 297/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4237 - accuracy: 0.8272 - val_loss: 0.4363 - val_accuracy: 0.8241\n",
      "Epoch 298/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4235 - accuracy: 0.8266 - val_loss: 0.4394 - val_accuracy: 0.8231\n",
      "Epoch 299/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4242 - accuracy: 0.8270 - val_loss: 0.4381 - val_accuracy: 0.8235\n",
      "Epoch 300/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.4237 - accuracy: 0.8269 - val_loss: 0.4378 - val_accuracy: 0.8240\n",
      "Epoch 301/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.4236 - accuracy: 0.8269 - val_loss: 0.4389 - val_accuracy: 0.8235\n",
      "Epoch 302/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.4239 - accuracy: 0.8266 - val_loss: 0.4363 - val_accuracy: 0.8240\n",
      "Epoch 303/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.4231 - accuracy: 0.8269 - val_loss: 0.4386 - val_accuracy: 0.8239\n",
      "Epoch 304/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.4236 - accuracy: 0.8265 - val_loss: 0.4378 - val_accuracy: 0.8236\n",
      "Epoch 305/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4238 - accuracy: 0.8271 - val_loss: 0.4372 - val_accuracy: 0.8237\n",
      "Epoch 306/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4235 - accuracy: 0.8267 - val_loss: 0.4372 - val_accuracy: 0.8239\n",
      "Epoch 307/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4236 - accuracy: 0.8265 - val_loss: 0.4366 - val_accuracy: 0.8235\n",
      "Epoch 308/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4236 - accuracy: 0.8271 - val_loss: 0.4437 - val_accuracy: 0.8233\n",
      "Epoch 309/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4242 - accuracy: 0.8268 - val_loss: 0.4390 - val_accuracy: 0.8230\n",
      "Epoch 310/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4237 - accuracy: 0.8268 - val_loss: 0.4383 - val_accuracy: 0.8233\n",
      "Epoch 311/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4231 - accuracy: 0.8268 - val_loss: 0.4396 - val_accuracy: 0.8232\n",
      "Epoch 312/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4237 - accuracy: 0.8271 - val_loss: 0.4434 - val_accuracy: 0.8236\n",
      "Epoch 313/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4239 - accuracy: 0.8272 - val_loss: 0.4400 - val_accuracy: 0.8236\n",
      "Epoch 314/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4237 - accuracy: 0.8272 - val_loss: 0.4366 - val_accuracy: 0.8237\n",
      "Epoch 315/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4236 - accuracy: 0.8270 - val_loss: 0.4371 - val_accuracy: 0.8238\n",
      "Epoch 316/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4232 - accuracy: 0.8272 - val_loss: 0.4400 - val_accuracy: 0.8232\n",
      "Epoch 317/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4234 - accuracy: 0.8269 - val_loss: 0.4365 - val_accuracy: 0.8244\n",
      "Epoch 318/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4236 - accuracy: 0.8272 - val_loss: 0.4392 - val_accuracy: 0.8233\n",
      "Epoch 319/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4234 - accuracy: 0.8268 - val_loss: 0.4393 - val_accuracy: 0.8238\n",
      "Epoch 320/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4236 - accuracy: 0.8265 - val_loss: 0.4371 - val_accuracy: 0.8236\n",
      "Epoch 321/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4237 - accuracy: 0.8270 - val_loss: 0.4368 - val_accuracy: 0.8235\n",
      "Epoch 322/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4235 - accuracy: 0.8270 - val_loss: 0.4428 - val_accuracy: 0.8242\n",
      "Epoch 323/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4235 - accuracy: 0.8271 - val_loss: 0.4384 - val_accuracy: 0.8236\n",
      "Epoch 324/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4238 - accuracy: 0.8271 - val_loss: 0.4361 - val_accuracy: 0.8236\n",
      "Epoch 325/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4233 - accuracy: 0.8273 - val_loss: 0.4363 - val_accuracy: 0.8245\n",
      "Epoch 326/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 0.4231 - accuracy: 0.8269 - val_loss: 0.4390 - val_accuracy: 0.8235\n",
      "Epoch 327/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4234 - accuracy: 0.8269 - val_loss: 0.4382 - val_accuracy: 0.8236\n",
      "Epoch 328/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.4237 - accuracy: 0.8268 - val_loss: 0.4393 - val_accuracy: 0.8230\n",
      "Epoch 329/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4238 - accuracy: 0.8270 - val_loss: 0.4369 - val_accuracy: 0.8242\n",
      "Epoch 330/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.4236 - accuracy: 0.8270 - val_loss: 0.4388 - val_accuracy: 0.8242\n",
      "Epoch 331/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 0.4237 - accuracy: 0.8272 - val_loss: 0.4366 - val_accuracy: 0.8234\n",
      "Epoch 332/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.4232 - accuracy: 0.8269 - val_loss: 0.4401 - val_accuracy: 0.8236\n",
      "Epoch 333/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4236 - accuracy: 0.8272 - val_loss: 0.4391 - val_accuracy: 0.8233\n",
      "Epoch 334/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4230 - accuracy: 0.8271 - val_loss: 0.4374 - val_accuracy: 0.8238\n",
      "Epoch 335/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4236 - accuracy: 0.8267 - val_loss: 0.4379 - val_accuracy: 0.8244\n",
      "Epoch 336/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4234 - accuracy: 0.8271 - val_loss: 0.4374 - val_accuracy: 0.8236\n",
      "Epoch 337/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4233 - accuracy: 0.8267 - val_loss: 0.4383 - val_accuracy: 0.8237\n",
      "Epoch 338/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4237 - accuracy: 0.8273 - val_loss: 0.4376 - val_accuracy: 0.8239\n",
      "Epoch 339/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4232 - accuracy: 0.8268 - val_loss: 0.4428 - val_accuracy: 0.8223\n",
      "Epoch 340/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4232 - accuracy: 0.8271 - val_loss: 0.4380 - val_accuracy: 0.8242\n",
      "Epoch 341/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4230 - accuracy: 0.8268 - val_loss: 0.4383 - val_accuracy: 0.8236\n",
      "Epoch 342/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4234 - accuracy: 0.8269 - val_loss: 0.4369 - val_accuracy: 0.8242\n",
      "Epoch 343/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.4236 - accuracy: 0.8269 - val_loss: 0.4412 - val_accuracy: 0.8237\n",
      "Epoch 344/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4237 - accuracy: 0.8273 - val_loss: 0.4373 - val_accuracy: 0.8236\n",
      "Epoch 345/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4233 - accuracy: 0.8266 - val_loss: 0.4371 - val_accuracy: 0.8237\n",
      "Epoch 346/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4232 - accuracy: 0.8273 - val_loss: 0.4369 - val_accuracy: 0.8245\n",
      "Epoch 347/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4239 - accuracy: 0.8267 - val_loss: 0.4369 - val_accuracy: 0.8236\n",
      "Epoch 348/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4236 - accuracy: 0.8266 - val_loss: 0.4364 - val_accuracy: 0.8245\n",
      "Epoch 349/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4236 - accuracy: 0.8271 - val_loss: 0.4478 - val_accuracy: 0.8233\n",
      "Epoch 350/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4235 - accuracy: 0.8273 - val_loss: 0.4403 - val_accuracy: 0.8232\n",
      "Epoch 351/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4237 - accuracy: 0.8269 - val_loss: 0.4369 - val_accuracy: 0.8240\n",
      "Epoch 352/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4229 - accuracy: 0.8277 - val_loss: 0.4375 - val_accuracy: 0.8237\n",
      "Epoch 353/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4234 - accuracy: 0.8272 - val_loss: 0.4383 - val_accuracy: 0.8239\n",
      "Epoch 354/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.4228 - accuracy: 0.8271 - val_loss: 0.4376 - val_accuracy: 0.8229\n",
      "Epoch 355/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.4232 - accuracy: 0.8268 - val_loss: 0.4410 - val_accuracy: 0.8239\n",
      "Epoch 356/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4235 - accuracy: 0.8270 - val_loss: 0.4372 - val_accuracy: 0.8239\n",
      "Epoch 357/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4231 - accuracy: 0.8270 - val_loss: 0.4381 - val_accuracy: 0.8239\n",
      "Epoch 358/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4233 - accuracy: 0.8272 - val_loss: 0.4364 - val_accuracy: 0.8237\n",
      "Epoch 359/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4230 - accuracy: 0.8274 - val_loss: 0.4420 - val_accuracy: 0.8235\n",
      "Epoch 360/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4236 - accuracy: 0.8269 - val_loss: 0.4383 - val_accuracy: 0.8237\n",
      "Epoch 361/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4230 - accuracy: 0.8272 - val_loss: 0.4360 - val_accuracy: 0.8245\n",
      "Epoch 362/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4231 - accuracy: 0.8270 - val_loss: 0.4384 - val_accuracy: 0.8241\n",
      "Epoch 363/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4229 - accuracy: 0.8264 - val_loss: 0.4395 - val_accuracy: 0.8232\n",
      "Epoch 364/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4233 - accuracy: 0.8272 - val_loss: 0.4422 - val_accuracy: 0.8234\n",
      "Epoch 365/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4238 - accuracy: 0.8266 - val_loss: 0.4372 - val_accuracy: 0.8236\n",
      "Epoch 366/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.4231 - accuracy: 0.8266 - val_loss: 0.4396 - val_accuracy: 0.8236\n",
      "Epoch 367/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.4229 - accuracy: 0.8270 - val_loss: 0.4363 - val_accuracy: 0.8247\n",
      "Epoch 368/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4231 - accuracy: 0.8267 - val_loss: 0.4379 - val_accuracy: 0.8236\n",
      "Epoch 369/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4234 - accuracy: 0.8274 - val_loss: 0.4390 - val_accuracy: 0.8235\n",
      "Epoch 370/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4236 - accuracy: 0.8274 - val_loss: 0.4379 - val_accuracy: 0.8238\n",
      "Epoch 371/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4233 - accuracy: 0.8270 - val_loss: 0.4364 - val_accuracy: 0.8241\n",
      "Epoch 372/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4234 - accuracy: 0.8271 - val_loss: 0.4383 - val_accuracy: 0.8239\n",
      "Epoch 373/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4228 - accuracy: 0.8272 - val_loss: 0.4376 - val_accuracy: 0.8241\n",
      "Epoch 374/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4227 - accuracy: 0.8272 - val_loss: 0.4365 - val_accuracy: 0.8242\n",
      "Epoch 375/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4234 - accuracy: 0.8271 - val_loss: 0.4438 - val_accuracy: 0.8231\n",
      "Epoch 376/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4232 - accuracy: 0.8270 - val_loss: 0.4361 - val_accuracy: 0.8244\n",
      "Epoch 377/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4235 - accuracy: 0.8277 - val_loss: 0.4370 - val_accuracy: 0.8237\n",
      "Epoch 378/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4232 - accuracy: 0.8270 - val_loss: 0.4383 - val_accuracy: 0.8236\n",
      "Epoch 379/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4231 - accuracy: 0.8273 - val_loss: 0.4365 - val_accuracy: 0.8243\n",
      "Epoch 380/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4233 - accuracy: 0.8270 - val_loss: 0.4383 - val_accuracy: 0.8236\n",
      "Epoch 381/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4228 - accuracy: 0.8273 - val_loss: 0.4398 - val_accuracy: 0.8234\n",
      "Epoch 382/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4232 - accuracy: 0.8269 - val_loss: 0.4395 - val_accuracy: 0.8224\n",
      "Epoch 383/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4232 - accuracy: 0.8269 - val_loss: 0.4387 - val_accuracy: 0.8241\n",
      "Epoch 384/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4228 - accuracy: 0.8268 - val_loss: 0.4370 - val_accuracy: 0.8241\n",
      "Epoch 385/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4230 - accuracy: 0.8272 - val_loss: 0.4360 - val_accuracy: 0.8239\n",
      "Epoch 386/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4231 - accuracy: 0.8269 - val_loss: 0.4376 - val_accuracy: 0.8233\n",
      "Epoch 387/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4229 - accuracy: 0.8270 - val_loss: 0.4406 - val_accuracy: 0.8226\n",
      "Epoch 388/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4235 - accuracy: 0.8268 - val_loss: 0.4364 - val_accuracy: 0.8241\n",
      "Epoch 389/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4237 - accuracy: 0.8272 - val_loss: 0.4362 - val_accuracy: 0.8236\n",
      "Epoch 390/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4228 - accuracy: 0.8276 - val_loss: 0.4380 - val_accuracy: 0.8233\n",
      "Epoch 391/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4226 - accuracy: 0.8274 - val_loss: 0.4386 - val_accuracy: 0.8239\n",
      "Epoch 392/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4230 - accuracy: 0.8270 - val_loss: 0.4376 - val_accuracy: 0.8234\n",
      "Epoch 393/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4228 - accuracy: 0.8270 - val_loss: 0.4399 - val_accuracy: 0.8237\n",
      "Epoch 394/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4234 - accuracy: 0.8265 - val_loss: 0.4391 - val_accuracy: 0.8233\n",
      "Epoch 395/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4230 - accuracy: 0.8269 - val_loss: 0.4382 - val_accuracy: 0.8235\n",
      "Epoch 396/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4229 - accuracy: 0.8276 - val_loss: 0.4368 - val_accuracy: 0.8242\n",
      "Epoch 397/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4234 - accuracy: 0.8269 - val_loss: 0.4382 - val_accuracy: 0.8235\n",
      "Epoch 398/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4233 - accuracy: 0.8266 - val_loss: 0.4389 - val_accuracy: 0.8237\n",
      "Epoch 399/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4229 - accuracy: 0.8268 - val_loss: 0.4440 - val_accuracy: 0.8207\n",
      "Epoch 400/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4235 - accuracy: 0.8271 - val_loss: 0.4405 - val_accuracy: 0.8231\n",
      "Epoch 401/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4228 - accuracy: 0.8265 - val_loss: 0.4391 - val_accuracy: 0.8233\n",
      "Epoch 402/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4228 - accuracy: 0.8271 - val_loss: 0.4372 - val_accuracy: 0.8239\n",
      "Epoch 403/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4232 - accuracy: 0.8272 - val_loss: 0.4399 - val_accuracy: 0.8234\n",
      "Epoch 404/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4230 - accuracy: 0.8271 - val_loss: 0.4402 - val_accuracy: 0.8234\n",
      "Epoch 405/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4228 - accuracy: 0.8273 - val_loss: 0.4382 - val_accuracy: 0.8234\n",
      "Epoch 406/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4228 - accuracy: 0.8269 - val_loss: 0.4357 - val_accuracy: 0.8236\n",
      "Epoch 407/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4227 - accuracy: 0.8270 - val_loss: 0.4412 - val_accuracy: 0.8236\n",
      "Epoch 408/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4238 - accuracy: 0.8264 - val_loss: 0.4361 - val_accuracy: 0.8244\n",
      "Epoch 409/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4233 - accuracy: 0.8276 - val_loss: 0.4399 - val_accuracy: 0.8234\n",
      "Epoch 410/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4227 - accuracy: 0.8271 - val_loss: 0.4374 - val_accuracy: 0.8242\n",
      "Epoch 411/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4237 - accuracy: 0.8268 - val_loss: 0.4364 - val_accuracy: 0.8235\n",
      "Epoch 412/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4234 - accuracy: 0.8269 - val_loss: 0.4360 - val_accuracy: 0.8237\n",
      "Epoch 413/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4235 - accuracy: 0.8270 - val_loss: 0.4474 - val_accuracy: 0.8230\n",
      "Epoch 414/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4227 - accuracy: 0.8268 - val_loss: 0.4386 - val_accuracy: 0.8237\n",
      "Epoch 415/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4228 - accuracy: 0.8273 - val_loss: 0.4372 - val_accuracy: 0.8237\n",
      "Epoch 416/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4235 - accuracy: 0.8271 - val_loss: 0.4364 - val_accuracy: 0.8237\n",
      "Epoch 417/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4227 - accuracy: 0.8270 - val_loss: 0.4365 - val_accuracy: 0.8242\n",
      "Epoch 418/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4231 - accuracy: 0.8277 - val_loss: 0.4391 - val_accuracy: 0.8230\n",
      "Epoch 419/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4231 - accuracy: 0.8270 - val_loss: 0.4366 - val_accuracy: 0.8235\n",
      "Epoch 420/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4231 - accuracy: 0.8266 - val_loss: 0.4377 - val_accuracy: 0.8243\n",
      "Epoch 421/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4229 - accuracy: 0.8275 - val_loss: 0.4370 - val_accuracy: 0.8240\n",
      "Epoch 422/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4237 - accuracy: 0.8270 - val_loss: 0.4369 - val_accuracy: 0.8240\n",
      "Epoch 423/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4226 - accuracy: 0.8268 - val_loss: 0.4379 - val_accuracy: 0.8232\n",
      "Epoch 424/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4232 - accuracy: 0.8269 - val_loss: 0.4398 - val_accuracy: 0.8236\n",
      "Epoch 425/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4229 - accuracy: 0.8273 - val_loss: 0.4382 - val_accuracy: 0.8233\n",
      "Epoch 426/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4232 - accuracy: 0.8269 - val_loss: 0.4389 - val_accuracy: 0.8238\n",
      "Epoch 427/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4233 - accuracy: 0.8266 - val_loss: 0.4372 - val_accuracy: 0.8235\n",
      "Epoch 428/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4232 - accuracy: 0.8271 - val_loss: 0.4365 - val_accuracy: 0.8234\n",
      "Epoch 429/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4229 - accuracy: 0.8273 - val_loss: 0.4375 - val_accuracy: 0.8238\n",
      "Epoch 430/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4229 - accuracy: 0.8270 - val_loss: 0.4373 - val_accuracy: 0.8238\n",
      "Epoch 431/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4229 - accuracy: 0.8271 - val_loss: 0.4392 - val_accuracy: 0.8232\n",
      "Epoch 432/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4229 - accuracy: 0.8273 - val_loss: 0.4376 - val_accuracy: 0.8237\n",
      "Epoch 433/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4231 - accuracy: 0.8272 - val_loss: 0.4390 - val_accuracy: 0.8235\n",
      "Epoch 434/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4229 - accuracy: 0.8269 - val_loss: 0.4368 - val_accuracy: 0.8234\n",
      "Epoch 435/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4231 - accuracy: 0.8269 - val_loss: 0.4363 - val_accuracy: 0.8239\n",
      "Epoch 436/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4226 - accuracy: 0.8275 - val_loss: 0.4382 - val_accuracy: 0.8236\n",
      "Epoch 437/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4227 - accuracy: 0.8269 - val_loss: 0.4363 - val_accuracy: 0.8244\n",
      "Epoch 438/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4234 - accuracy: 0.8270 - val_loss: 0.4378 - val_accuracy: 0.8237\n",
      "Epoch 439/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4229 - accuracy: 0.8268 - val_loss: 0.4378 - val_accuracy: 0.8236\n",
      "Epoch 440/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4231 - accuracy: 0.8264 - val_loss: 0.4378 - val_accuracy: 0.8241\n",
      "Epoch 441/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4231 - accuracy: 0.8271 - val_loss: 0.4373 - val_accuracy: 0.8238\n",
      "Epoch 442/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4234 - accuracy: 0.8270 - val_loss: 0.4372 - val_accuracy: 0.8236\n",
      "Epoch 443/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4227 - accuracy: 0.8270 - val_loss: 0.4382 - val_accuracy: 0.8241\n",
      "Epoch 444/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4232 - accuracy: 0.8273 - val_loss: 0.4383 - val_accuracy: 0.8234\n",
      "Epoch 445/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4230 - accuracy: 0.8265 - val_loss: 0.4374 - val_accuracy: 0.8237\n",
      "Epoch 446/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4230 - accuracy: 0.8268 - val_loss: 0.4391 - val_accuracy: 0.8229\n",
      "Epoch 447/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4233 - accuracy: 0.8268 - val_loss: 0.4386 - val_accuracy: 0.8238\n",
      "Epoch 448/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4226 - accuracy: 0.8272 - val_loss: 0.4387 - val_accuracy: 0.8239\n",
      "Epoch 449/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4230 - accuracy: 0.8267 - val_loss: 0.4393 - val_accuracy: 0.8225\n",
      "Epoch 450/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4234 - accuracy: 0.8273 - val_loss: 0.4390 - val_accuracy: 0.8235\n",
      "Epoch 451/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4229 - accuracy: 0.8274 - val_loss: 0.4372 - val_accuracy: 0.8239\n",
      "Epoch 452/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4229 - accuracy: 0.8271 - val_loss: 0.4367 - val_accuracy: 0.8244\n",
      "Epoch 453/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4231 - accuracy: 0.8274 - val_loss: 0.4361 - val_accuracy: 0.8242\n",
      "Epoch 454/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4233 - accuracy: 0.8271 - val_loss: 0.4393 - val_accuracy: 0.8238\n",
      "Epoch 455/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4230 - accuracy: 0.8273 - val_loss: 0.4385 - val_accuracy: 0.8237\n",
      "Epoch 456/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4228 - accuracy: 0.8272 - val_loss: 0.4404 - val_accuracy: 0.8233\n",
      "Epoch 457/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4228 - accuracy: 0.8271 - val_loss: 0.4388 - val_accuracy: 0.8233\n",
      "Epoch 458/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4229 - accuracy: 0.8272 - val_loss: 0.4400 - val_accuracy: 0.8233\n",
      "Epoch 459/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4233 - accuracy: 0.8266 - val_loss: 0.4404 - val_accuracy: 0.8224\n",
      "Epoch 460/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4232 - accuracy: 0.8269 - val_loss: 0.4381 - val_accuracy: 0.8238\n",
      "Epoch 461/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4234 - accuracy: 0.8268 - val_loss: 0.4371 - val_accuracy: 0.8235\n",
      "Epoch 462/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4231 - accuracy: 0.8272 - val_loss: 0.4368 - val_accuracy: 0.8234\n",
      "Epoch 463/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4230 - accuracy: 0.8272 - val_loss: 0.4364 - val_accuracy: 0.8246\n",
      "Epoch 464/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4226 - accuracy: 0.8271 - val_loss: 0.4411 - val_accuracy: 0.8227\n",
      "Epoch 465/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.4229 - accuracy: 0.8270 - val_loss: 0.4373 - val_accuracy: 0.8240\n",
      "Epoch 466/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4230 - accuracy: 0.8269 - val_loss: 0.4363 - val_accuracy: 0.8241\n",
      "Epoch 467/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4230 - accuracy: 0.8272 - val_loss: 0.4373 - val_accuracy: 0.8240\n",
      "Epoch 468/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4227 - accuracy: 0.8268 - val_loss: 0.4386 - val_accuracy: 0.8243\n",
      "Epoch 469/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.4233 - accuracy: 0.8274 - val_loss: 0.4420 - val_accuracy: 0.8235\n",
      "Epoch 470/1000\n",
      "49590/49590 [==============================] - 2s 44us/sample - loss: 0.4232 - accuracy: 0.8271 - val_loss: 0.4361 - val_accuracy: 0.8235\n",
      "Epoch 471/1000\n",
      "49590/49590 [==============================] - 2s 43us/sample - loss: 0.4232 - accuracy: 0.8272 - val_loss: 0.4371 - val_accuracy: 0.8236\n",
      "Epoch 472/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.4230 - accuracy: 0.8273 - val_loss: 0.4378 - val_accuracy: 0.8239\n",
      "Epoch 473/1000\n",
      "49590/49590 [==============================] - 2s 43us/sample - loss: 0.4228 - accuracy: 0.8268 - val_loss: 0.4370 - val_accuracy: 0.8242\n",
      "Epoch 474/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4228 - accuracy: 0.8270 - val_loss: 0.4382 - val_accuracy: 0.8239\n",
      "Epoch 475/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4231 - accuracy: 0.8271 - val_loss: 0.4372 - val_accuracy: 0.8228\n",
      "Epoch 476/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4230 - accuracy: 0.8271 - val_loss: 0.4382 - val_accuracy: 0.8232\n",
      "Epoch 477/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4226 - accuracy: 0.8273 - val_loss: 0.4366 - val_accuracy: 0.8244\n",
      "Epoch 478/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.4229 - accuracy: 0.8274 - val_loss: 0.4376 - val_accuracy: 0.8237\n",
      "Epoch 479/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4237 - accuracy: 0.8272 - val_loss: 0.4397 - val_accuracy: 0.8236\n",
      "Epoch 480/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.4226 - accuracy: 0.8275 - val_loss: 0.4364 - val_accuracy: 0.8242\n",
      "Epoch 481/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.4229 - accuracy: 0.8270 - val_loss: 0.4430 - val_accuracy: 0.8234\n",
      "Epoch 482/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4230 - accuracy: 0.8269 - val_loss: 0.4366 - val_accuracy: 0.8239\n",
      "Epoch 483/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4229 - accuracy: 0.8271 - val_loss: 0.4452 - val_accuracy: 0.8232\n",
      "Epoch 484/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.4225 - accuracy: 0.8268 - val_loss: 0.4374 - val_accuracy: 0.8242\n",
      "Epoch 485/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4231 - accuracy: 0.8268 - val_loss: 0.4388 - val_accuracy: 0.8231\n",
      "Epoch 486/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4229 - accuracy: 0.8268 - val_loss: 0.4404 - val_accuracy: 0.8234\n",
      "Epoch 487/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4229 - accuracy: 0.8270 - val_loss: 0.4391 - val_accuracy: 0.8237\n",
      "Epoch 488/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4230 - accuracy: 0.8267 - val_loss: 0.4403 - val_accuracy: 0.8234\n",
      "Epoch 489/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.4231 - accuracy: 0.8271 - val_loss: 0.4424 - val_accuracy: 0.8229\n",
      "Epoch 490/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4234 - accuracy: 0.8270 - val_loss: 0.4375 - val_accuracy: 0.8238\n",
      "Epoch 491/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4230 - accuracy: 0.8269 - val_loss: 0.4374 - val_accuracy: 0.8236\n",
      "Epoch 492/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4227 - accuracy: 0.8269 - val_loss: 0.4381 - val_accuracy: 0.8233\n",
      "Epoch 493/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4227 - accuracy: 0.8270 - val_loss: 0.4381 - val_accuracy: 0.8236\n",
      "Epoch 494/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4231 - accuracy: 0.8272 - val_loss: 0.4367 - val_accuracy: 0.8244\n",
      "Epoch 495/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4227 - accuracy: 0.8270 - val_loss: 0.4401 - val_accuracy: 0.8240\n",
      "Epoch 496/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4228 - accuracy: 0.8270 - val_loss: 0.4372 - val_accuracy: 0.8235\n",
      "Epoch 497/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4225 - accuracy: 0.8267 - val_loss: 0.4410 - val_accuracy: 0.8233\n",
      "Epoch 498/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4229 - accuracy: 0.8272 - val_loss: 0.4377 - val_accuracy: 0.8238\n",
      "Epoch 499/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4233 - accuracy: 0.8273 - val_loss: 0.4384 - val_accuracy: 0.8235\n",
      "Epoch 500/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4224 - accuracy: 0.8266 - val_loss: 0.4381 - val_accuracy: 0.8234\n",
      "Epoch 501/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4230 - accuracy: 0.8269 - val_loss: 0.4369 - val_accuracy: 0.8235\n",
      "Epoch 502/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4228 - accuracy: 0.8269 - val_loss: 0.4368 - val_accuracy: 0.8241\n",
      "Epoch 503/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4226 - accuracy: 0.8270 - val_loss: 0.4365 - val_accuracy: 0.8242\n",
      "Epoch 504/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.4229 - accuracy: 0.8270 - val_loss: 0.4387 - val_accuracy: 0.8233\n",
      "Epoch 505/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4227 - accuracy: 0.8271 - val_loss: 0.4368 - val_accuracy: 0.8250\n",
      "Epoch 506/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4229 - accuracy: 0.8272 - val_loss: 0.4428 - val_accuracy: 0.8234\n",
      "Epoch 507/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4228 - accuracy: 0.8271 - val_loss: 0.4393 - val_accuracy: 0.8227\n",
      "Epoch 508/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4230 - accuracy: 0.8269 - val_loss: 0.4450 - val_accuracy: 0.8222\n",
      "Epoch 509/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4225 - accuracy: 0.8273 - val_loss: 0.4370 - val_accuracy: 0.8238\n",
      "Epoch 510/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4224 - accuracy: 0.8274 - val_loss: 0.4376 - val_accuracy: 0.8239\n",
      "Epoch 511/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4230 - accuracy: 0.8271 - val_loss: 0.4364 - val_accuracy: 0.8241\n",
      "Epoch 512/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4230 - accuracy: 0.8270 - val_loss: 0.4359 - val_accuracy: 0.8236\n",
      "Epoch 513/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4226 - accuracy: 0.8269 - val_loss: 0.4365 - val_accuracy: 0.8250\n",
      "Epoch 514/1000\n",
      "49590/49590 [==============================] - 2s 43us/sample - loss: 0.4226 - accuracy: 0.8270 - val_loss: 0.4375 - val_accuracy: 0.8239\n",
      "Epoch 515/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.4226 - accuracy: 0.8272 - val_loss: 0.4388 - val_accuracy: 0.8242\n",
      "Epoch 516/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4228 - accuracy: 0.8269 - val_loss: 0.4432 - val_accuracy: 0.8217\n",
      "Epoch 517/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4233 - accuracy: 0.8267 - val_loss: 0.4450 - val_accuracy: 0.8233\n",
      "Epoch 518/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4230 - accuracy: 0.8271 - val_loss: 0.4368 - val_accuracy: 0.8236\n",
      "Epoch 519/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.4229 - accuracy: 0.8270 - val_loss: 0.4365 - val_accuracy: 0.8237\n",
      "Epoch 520/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.4225 - accuracy: 0.8269 - val_loss: 0.4372 - val_accuracy: 0.8238\n",
      "Epoch 521/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4224 - accuracy: 0.8267 - val_loss: 0.4425 - val_accuracy: 0.8225\n",
      "Epoch 522/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4230 - accuracy: 0.8269 - val_loss: 0.4370 - val_accuracy: 0.8230\n",
      "Epoch 523/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4228 - accuracy: 0.8271 - val_loss: 0.4384 - val_accuracy: 0.8243\n",
      "Epoch 524/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4228 - accuracy: 0.8269 - val_loss: 0.4429 - val_accuracy: 0.8233\n",
      "Epoch 525/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4229 - accuracy: 0.8276 - val_loss: 0.4416 - val_accuracy: 0.8236\n",
      "Epoch 526/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4227 - accuracy: 0.8271 - val_loss: 0.4406 - val_accuracy: 0.8236\n",
      "Epoch 527/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4230 - accuracy: 0.8269 - val_loss: 0.4399 - val_accuracy: 0.8237\n",
      "Epoch 528/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4222 - accuracy: 0.8271 - val_loss: 0.4399 - val_accuracy: 0.8214\n",
      "Epoch 529/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4228 - accuracy: 0.8267 - val_loss: 0.4392 - val_accuracy: 0.8236\n",
      "Epoch 530/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4229 - accuracy: 0.8273 - val_loss: 0.4375 - val_accuracy: 0.8240\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4228 - accuracy: 0.8272 - val_loss: 0.4367 - val_accuracy: 0.8242\n",
      "Epoch 532/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4222 - accuracy: 0.8272 - val_loss: 0.4363 - val_accuracy: 0.8242\n",
      "Epoch 533/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4226 - accuracy: 0.8266 - val_loss: 0.4367 - val_accuracy: 0.8243\n",
      "Epoch 534/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4224 - accuracy: 0.8272 - val_loss: 0.4432 - val_accuracy: 0.8233\n",
      "Epoch 535/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4228 - accuracy: 0.8273 - val_loss: 0.4390 - val_accuracy: 0.8235\n",
      "Epoch 536/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4228 - accuracy: 0.8275 - val_loss: 0.4371 - val_accuracy: 0.8245\n",
      "Epoch 537/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4226 - accuracy: 0.8270 - val_loss: 0.4430 - val_accuracy: 0.8234\n",
      "Epoch 538/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4226 - accuracy: 0.8270 - val_loss: 0.4374 - val_accuracy: 0.8241\n",
      "Epoch 539/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4225 - accuracy: 0.8268 - val_loss: 0.4462 - val_accuracy: 0.8238\n",
      "Epoch 540/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4229 - accuracy: 0.8271 - val_loss: 0.4370 - val_accuracy: 0.8244\n",
      "Epoch 541/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4230 - accuracy: 0.8270 - val_loss: 0.4352 - val_accuracy: 0.8241\n",
      "Epoch 542/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4228 - accuracy: 0.8267 - val_loss: 0.4366 - val_accuracy: 0.8240\n",
      "Epoch 543/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4229 - accuracy: 0.8270 - val_loss: 0.4366 - val_accuracy: 0.8242\n",
      "Epoch 544/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4223 - accuracy: 0.8272 - val_loss: 0.4375 - val_accuracy: 0.8226\n",
      "Epoch 545/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.4232 - accuracy: 0.8270 - val_loss: 0.4356 - val_accuracy: 0.8248\n",
      "Epoch 546/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4225 - accuracy: 0.8266 - val_loss: 0.4377 - val_accuracy: 0.8238\n",
      "Epoch 547/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4221 - accuracy: 0.8277 - val_loss: 0.4359 - val_accuracy: 0.8240\n",
      "Epoch 548/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4225 - accuracy: 0.8265 - val_loss: 0.4359 - val_accuracy: 0.8240\n",
      "Epoch 549/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4226 - accuracy: 0.8273 - val_loss: 0.4382 - val_accuracy: 0.8236\n",
      "Epoch 550/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4224 - accuracy: 0.8272 - val_loss: 0.4464 - val_accuracy: 0.8234\n",
      "Epoch 551/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4227 - accuracy: 0.8272 - val_loss: 0.4370 - val_accuracy: 0.8241\n",
      "Epoch 552/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4232 - accuracy: 0.8264 - val_loss: 0.4367 - val_accuracy: 0.8243\n",
      "Epoch 553/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4230 - accuracy: 0.8270 - val_loss: 0.4361 - val_accuracy: 0.8245\n",
      "Epoch 554/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4228 - accuracy: 0.8273 - val_loss: 0.4384 - val_accuracy: 0.8239\n",
      "Epoch 555/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4228 - accuracy: 0.8273 - val_loss: 0.4392 - val_accuracy: 0.8237\n",
      "Epoch 556/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4225 - accuracy: 0.8273 - val_loss: 0.4450 - val_accuracy: 0.8234\n",
      "Epoch 557/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4226 - accuracy: 0.8269 - val_loss: 0.4374 - val_accuracy: 0.8243\n",
      "Epoch 558/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.4231 - accuracy: 0.8272 - val_loss: 0.4366 - val_accuracy: 0.8232\n",
      "Epoch 559/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.4226 - accuracy: 0.8272 - val_loss: 0.4365 - val_accuracy: 0.8239\n",
      "Epoch 560/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.4225 - accuracy: 0.8268 - val_loss: 0.4370 - val_accuracy: 0.8244\n",
      "Epoch 561/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4226 - accuracy: 0.8273 - val_loss: 0.4372 - val_accuracy: 0.8245\n",
      "Epoch 562/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4225 - accuracy: 0.8271 - val_loss: 0.4363 - val_accuracy: 0.8236\n",
      "Epoch 563/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4226 - accuracy: 0.8271 - val_loss: 0.4393 - val_accuracy: 0.8230\n",
      "Epoch 564/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4230 - accuracy: 0.8275 - val_loss: 0.4376 - val_accuracy: 0.8230\n",
      "Epoch 565/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4227 - accuracy: 0.8269 - val_loss: 0.4376 - val_accuracy: 0.8237\n",
      "Epoch 566/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.4224 - accuracy: 0.8270 - val_loss: 0.4387 - val_accuracy: 0.8234\n",
      "Epoch 567/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.4227 - accuracy: 0.8270 - val_loss: 0.4371 - val_accuracy: 0.8244\n",
      "Epoch 568/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4220 - accuracy: 0.8273 - val_loss: 0.4379 - val_accuracy: 0.8235\n",
      "Epoch 569/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4226 - accuracy: 0.8269 - val_loss: 0.4362 - val_accuracy: 0.8238\n",
      "Epoch 570/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4225 - accuracy: 0.8277 - val_loss: 0.4374 - val_accuracy: 0.8242\n",
      "Epoch 571/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4228 - accuracy: 0.8268 - val_loss: 0.4364 - val_accuracy: 0.8237\n",
      "Epoch 572/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4221 - accuracy: 0.8271 - val_loss: 0.4371 - val_accuracy: 0.8236\n",
      "Epoch 573/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.4223 - accuracy: 0.8274 - val_loss: 0.4391 - val_accuracy: 0.8237\n",
      "Epoch 574/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4226 - accuracy: 0.8269 - val_loss: 0.4370 - val_accuracy: 0.8240\n",
      "Epoch 575/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4222 - accuracy: 0.8270 - val_loss: 0.4383 - val_accuracy: 0.8238\n",
      "Epoch 576/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4224 - accuracy: 0.8272 - val_loss: 0.4392 - val_accuracy: 0.8234\n",
      "Epoch 577/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4222 - accuracy: 0.8269 - val_loss: 0.4408 - val_accuracy: 0.8233\n",
      "Epoch 578/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4228 - accuracy: 0.8269 - val_loss: 0.4360 - val_accuracy: 0.8236\n",
      "Epoch 579/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4225 - accuracy: 0.8270 - val_loss: 0.4405 - val_accuracy: 0.8231\n",
      "Epoch 580/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4224 - accuracy: 0.8272 - val_loss: 0.4387 - val_accuracy: 0.8234\n",
      "Epoch 581/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4228 - accuracy: 0.8274 - val_loss: 0.4367 - val_accuracy: 0.8242\n",
      "Epoch 582/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4229 - accuracy: 0.8272 - val_loss: 0.4398 - val_accuracy: 0.8238\n",
      "Epoch 583/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4226 - accuracy: 0.8273 - val_loss: 0.4377 - val_accuracy: 0.8240\n",
      "Epoch 584/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4222 - accuracy: 0.8269 - val_loss: 0.4369 - val_accuracy: 0.8238\n",
      "Epoch 585/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4227 - accuracy: 0.8270 - val_loss: 0.4390 - val_accuracy: 0.8237\n",
      "Epoch 586/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4228 - accuracy: 0.8271 - val_loss: 0.4372 - val_accuracy: 0.8237\n",
      "Epoch 587/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4225 - accuracy: 0.8271 - val_loss: 0.4387 - val_accuracy: 0.8245\n",
      "Epoch 588/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4226 - accuracy: 0.8266 - val_loss: 0.4389 - val_accuracy: 0.8235\n",
      "Epoch 589/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4227 - accuracy: 0.8273 - val_loss: 0.4389 - val_accuracy: 0.8236\n",
      "Epoch 590/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4225 - accuracy: 0.8273 - val_loss: 0.4417 - val_accuracy: 0.8234\n",
      "Epoch 591/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4222 - accuracy: 0.8273 - val_loss: 0.4383 - val_accuracy: 0.8242\n",
      "Epoch 592/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4232 - accuracy: 0.8270 - val_loss: 0.4366 - val_accuracy: 0.8241\n",
      "Epoch 593/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4226 - accuracy: 0.8270 - val_loss: 0.4424 - val_accuracy: 0.8236\n",
      "Epoch 594/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4228 - accuracy: 0.8270 - val_loss: 0.4425 - val_accuracy: 0.8220\n",
      "Epoch 595/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4227 - accuracy: 0.8271 - val_loss: 0.4373 - val_accuracy: 0.8236\n",
      "Epoch 596/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4226 - accuracy: 0.8276 - val_loss: 0.4394 - val_accuracy: 0.8223\n",
      "Epoch 597/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4227 - accuracy: 0.8272 - val_loss: 0.4426 - val_accuracy: 0.8235\n",
      "Epoch 598/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4224 - accuracy: 0.8275 - val_loss: 0.4409 - val_accuracy: 0.8236\n",
      "Epoch 599/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4229 - accuracy: 0.8269 - val_loss: 0.4363 - val_accuracy: 0.8238\n",
      "Epoch 600/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4224 - accuracy: 0.8275 - val_loss: 0.4384 - val_accuracy: 0.8230\n",
      "Epoch 601/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4225 - accuracy: 0.8270 - val_loss: 0.4397 - val_accuracy: 0.8232\n",
      "Epoch 602/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4229 - accuracy: 0.8269 - val_loss: 0.4377 - val_accuracy: 0.8237\n",
      "Epoch 603/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4228 - accuracy: 0.8273 - val_loss: 0.4401 - val_accuracy: 0.8229\n",
      "Epoch 604/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4224 - accuracy: 0.8271 - val_loss: 0.4371 - val_accuracy: 0.8234\n",
      "Epoch 605/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4224 - accuracy: 0.8273 - val_loss: 0.4387 - val_accuracy: 0.8235\n",
      "Epoch 606/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4222 - accuracy: 0.8269 - val_loss: 0.4380 - val_accuracy: 0.8236\n",
      "Epoch 607/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4227 - accuracy: 0.8271 - val_loss: 0.4368 - val_accuracy: 0.8243\n",
      "Epoch 608/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4226 - accuracy: 0.8267 - val_loss: 0.4375 - val_accuracy: 0.8228\n",
      "Epoch 609/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4228 - accuracy: 0.8269 - val_loss: 0.4419 - val_accuracy: 0.8233\n",
      "Epoch 610/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4221 - accuracy: 0.8274 - val_loss: 0.4398 - val_accuracy: 0.8228\n",
      "Epoch 611/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4221 - accuracy: 0.8271 - val_loss: 0.4380 - val_accuracy: 0.8226\n",
      "Epoch 612/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4224 - accuracy: 0.8273 - val_loss: 0.4390 - val_accuracy: 0.8239\n",
      "Epoch 613/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4227 - accuracy: 0.8266 - val_loss: 0.4369 - val_accuracy: 0.8238\n",
      "Epoch 614/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4223 - accuracy: 0.8273 - val_loss: 0.4417 - val_accuracy: 0.8236\n",
      "Epoch 615/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4227 - accuracy: 0.8271 - val_loss: 0.4408 - val_accuracy: 0.8223\n",
      "Epoch 616/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4223 - accuracy: 0.8268 - val_loss: 0.4391 - val_accuracy: 0.8233\n",
      "Epoch 617/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4225 - accuracy: 0.8274 - val_loss: 0.4399 - val_accuracy: 0.8236\n",
      "Epoch 618/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4219 - accuracy: 0.8272 - val_loss: 0.4373 - val_accuracy: 0.8236\n",
      "Epoch 619/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4223 - accuracy: 0.8271 - val_loss: 0.4385 - val_accuracy: 0.8224\n",
      "Epoch 620/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4221 - accuracy: 0.8269 - val_loss: 0.4381 - val_accuracy: 0.8236\n",
      "Epoch 621/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4224 - accuracy: 0.8269 - val_loss: 0.4418 - val_accuracy: 0.8235\n",
      "Epoch 622/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4228 - accuracy: 0.8270 - val_loss: 0.4395 - val_accuracy: 0.8244\n",
      "Epoch 623/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.4218 - accuracy: 0.8275 - val_loss: 0.4427 - val_accuracy: 0.8235\n",
      "Epoch 624/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.4222 - accuracy: 0.8267 - val_loss: 0.4393 - val_accuracy: 0.8236\n",
      "Epoch 625/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4221 - accuracy: 0.8270 - val_loss: 0.4364 - val_accuracy: 0.8238\n",
      "Epoch 626/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4224 - accuracy: 0.8271 - val_loss: 0.4369 - val_accuracy: 0.8239\n",
      "Epoch 627/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4225 - accuracy: 0.8276 - val_loss: 0.4376 - val_accuracy: 0.8239\n",
      "Epoch 628/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4221 - accuracy: 0.8272 - val_loss: 0.4383 - val_accuracy: 0.8232\n",
      "Epoch 629/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4224 - accuracy: 0.8270 - val_loss: 0.4386 - val_accuracy: 0.8230\n",
      "Epoch 630/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4222 - accuracy: 0.8276 - val_loss: 0.4378 - val_accuracy: 0.8236\n",
      "Epoch 631/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4223 - accuracy: 0.8274 - val_loss: 0.4365 - val_accuracy: 0.8244\n",
      "Epoch 632/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4226 - accuracy: 0.8272 - val_loss: 0.4410 - val_accuracy: 0.8239\n",
      "Epoch 633/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4227 - accuracy: 0.8271 - val_loss: 0.4384 - val_accuracy: 0.8233\n",
      "Epoch 634/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4225 - accuracy: 0.8270 - val_loss: 0.4359 - val_accuracy: 0.8241\n",
      "Epoch 635/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4226 - accuracy: 0.8272 - val_loss: 0.4386 - val_accuracy: 0.8238\n",
      "Epoch 636/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4223 - accuracy: 0.8275 - val_loss: 0.4384 - val_accuracy: 0.8235\n",
      "Epoch 637/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4225 - accuracy: 0.8277 - val_loss: 0.4376 - val_accuracy: 0.8237\n",
      "Epoch 638/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4225 - accuracy: 0.8273 - val_loss: 0.4360 - val_accuracy: 0.8238\n",
      "Epoch 639/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4229 - accuracy: 0.8268 - val_loss: 0.4383 - val_accuracy: 0.8242\n",
      "Epoch 640/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4223 - accuracy: 0.8270 - val_loss: 0.4389 - val_accuracy: 0.8239\n",
      "Epoch 641/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4222 - accuracy: 0.8269 - val_loss: 0.4381 - val_accuracy: 0.8236\n",
      "Epoch 642/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4226 - accuracy: 0.8272 - val_loss: 0.4416 - val_accuracy: 0.8206\n",
      "Epoch 643/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4224 - accuracy: 0.8273 - val_loss: 0.4376 - val_accuracy: 0.8242\n",
      "Epoch 644/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4225 - accuracy: 0.8276 - val_loss: 0.4405 - val_accuracy: 0.8235\n",
      "Epoch 645/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4228 - accuracy: 0.8274 - val_loss: 0.4353 - val_accuracy: 0.8240\n",
      "Epoch 646/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4224 - accuracy: 0.8269 - val_loss: 0.4393 - val_accuracy: 0.8236\n",
      "Epoch 647/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4226 - accuracy: 0.8274 - val_loss: 0.4380 - val_accuracy: 0.8233\n",
      "Epoch 648/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4227 - accuracy: 0.8270 - val_loss: 0.4403 - val_accuracy: 0.8230\n",
      "Epoch 649/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4225 - accuracy: 0.8272 - val_loss: 0.4387 - val_accuracy: 0.8231\n",
      "Epoch 650/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4230 - accuracy: 0.8268 - val_loss: 0.4379 - val_accuracy: 0.8235\n",
      "Epoch 651/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4226 - accuracy: 0.8275 - val_loss: 0.4388 - val_accuracy: 0.8235\n",
      "Epoch 652/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4224 - accuracy: 0.8271 - val_loss: 0.4392 - val_accuracy: 0.8229\n",
      "Epoch 653/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4228 - accuracy: 0.8268 - val_loss: 0.4380 - val_accuracy: 0.8236\n",
      "Epoch 654/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4231 - accuracy: 0.8266 - val_loss: 0.4429 - val_accuracy: 0.8235\n",
      "Epoch 655/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4223 - accuracy: 0.8276 - val_loss: 0.4376 - val_accuracy: 0.8234\n",
      "Epoch 656/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4222 - accuracy: 0.8269 - val_loss: 0.4383 - val_accuracy: 0.8229\n",
      "Epoch 657/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4220 - accuracy: 0.8269 - val_loss: 0.4377 - val_accuracy: 0.8229\n",
      "Epoch 658/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4227 - accuracy: 0.8272 - val_loss: 0.4379 - val_accuracy: 0.8234\n",
      "Epoch 659/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4225 - accuracy: 0.8270 - val_loss: 0.4376 - val_accuracy: 0.8239\n",
      "Epoch 660/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4230 - accuracy: 0.8271 - val_loss: 0.4379 - val_accuracy: 0.8224\n",
      "Epoch 661/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.4220 - accuracy: 0.8273 - val_loss: 0.4385 - val_accuracy: 0.8244\n",
      "Epoch 662/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4224 - accuracy: 0.8271 - val_loss: 0.4378 - val_accuracy: 0.8236\n",
      "Epoch 663/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4222 - accuracy: 0.8274 - val_loss: 0.4393 - val_accuracy: 0.8232\n",
      "Epoch 664/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4226 - accuracy: 0.8270 - val_loss: 0.4387 - val_accuracy: 0.8238\n",
      "Epoch 665/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.4225 - accuracy: 0.8269 - val_loss: 0.4363 - val_accuracy: 0.8240\n",
      "Epoch 666/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.4221 - accuracy: 0.8270 - val_loss: 0.4415 - val_accuracy: 0.8230\n",
      "Epoch 667/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.4219 - accuracy: 0.8275 - val_loss: 0.4381 - val_accuracy: 0.8237\n",
      "Epoch 668/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4219 - accuracy: 0.8276 - val_loss: 0.4385 - val_accuracy: 0.8241\n",
      "Epoch 669/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4228 - accuracy: 0.8270 - val_loss: 0.4371 - val_accuracy: 0.8239\n",
      "Epoch 670/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4222 - accuracy: 0.8275 - val_loss: 0.4381 - val_accuracy: 0.8231\n",
      "Epoch 671/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.4224 - accuracy: 0.8276 - val_loss: 0.4378 - val_accuracy: 0.8234\n",
      "Epoch 672/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4224 - accuracy: 0.8269 - val_loss: 0.4404 - val_accuracy: 0.8228\n",
      "Epoch 673/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.4220 - accuracy: 0.8274 - val_loss: 0.4385 - val_accuracy: 0.8236\n",
      "Epoch 674/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4221 - accuracy: 0.8275 - val_loss: 0.4373 - val_accuracy: 0.8236\n",
      "Epoch 675/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4224 - accuracy: 0.8271 - val_loss: 0.4370 - val_accuracy: 0.8237\n",
      "Epoch 676/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4221 - accuracy: 0.8276 - val_loss: 0.4368 - val_accuracy: 0.8234\n",
      "Epoch 677/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4224 - accuracy: 0.8274 - val_loss: 0.4365 - val_accuracy: 0.8238\n",
      "Epoch 678/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4220 - accuracy: 0.8272 - val_loss: 0.4377 - val_accuracy: 0.8248\n",
      "Epoch 679/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4224 - accuracy: 0.8275 - val_loss: 0.4426 - val_accuracy: 0.8235\n",
      "Epoch 680/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4224 - accuracy: 0.8273 - val_loss: 0.4404 - val_accuracy: 0.8222\n",
      "Epoch 681/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4227 - accuracy: 0.8275 - val_loss: 0.4385 - val_accuracy: 0.8233\n",
      "Epoch 682/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4225 - accuracy: 0.8271 - val_loss: 0.4386 - val_accuracy: 0.8239\n",
      "Epoch 683/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4225 - accuracy: 0.8272 - val_loss: 0.4385 - val_accuracy: 0.8229\n",
      "Epoch 684/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4219 - accuracy: 0.8276 - val_loss: 0.4369 - val_accuracy: 0.8233\n",
      "Epoch 685/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4224 - accuracy: 0.8270 - val_loss: 0.4356 - val_accuracy: 0.8244\n",
      "Epoch 686/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4221 - accuracy: 0.8275 - val_loss: 0.4377 - val_accuracy: 0.8235\n",
      "Epoch 687/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4221 - accuracy: 0.8277 - val_loss: 0.4369 - val_accuracy: 0.8238\n",
      "Epoch 688/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4222 - accuracy: 0.8275 - val_loss: 0.4371 - val_accuracy: 0.8235\n",
      "Epoch 689/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4222 - accuracy: 0.8271 - val_loss: 0.4398 - val_accuracy: 0.8231\n",
      "Epoch 690/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4224 - accuracy: 0.8273 - val_loss: 0.4406 - val_accuracy: 0.8236\n",
      "Epoch 691/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4226 - accuracy: 0.8273 - val_loss: 0.4367 - val_accuracy: 0.8231\n",
      "Epoch 692/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4225 - accuracy: 0.8277 - val_loss: 0.4395 - val_accuracy: 0.8218\n",
      "Epoch 693/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4224 - accuracy: 0.8271 - val_loss: 0.4370 - val_accuracy: 0.8245\n",
      "Epoch 694/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4220 - accuracy: 0.8269 - val_loss: 0.4388 - val_accuracy: 0.8239\n",
      "Epoch 695/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4222 - accuracy: 0.8274 - val_loss: 0.4373 - val_accuracy: 0.8233\n",
      "Epoch 696/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4224 - accuracy: 0.8273 - val_loss: 0.4382 - val_accuracy: 0.8229\n",
      "Epoch 697/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4223 - accuracy: 0.8276 - val_loss: 0.4363 - val_accuracy: 0.8235\n",
      "Epoch 698/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4224 - accuracy: 0.8278 - val_loss: 0.4377 - val_accuracy: 0.8234\n",
      "Epoch 699/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4222 - accuracy: 0.8271 - val_loss: 0.4367 - val_accuracy: 0.8229\n",
      "Epoch 700/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4223 - accuracy: 0.8272 - val_loss: 0.4363 - val_accuracy: 0.8236\n",
      "Epoch 701/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4224 - accuracy: 0.8272 - val_loss: 0.4371 - val_accuracy: 0.8236\n",
      "Epoch 702/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.4224 - accuracy: 0.8271 - val_loss: 0.4364 - val_accuracy: 0.8238\n",
      "Epoch 703/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4219 - accuracy: 0.8278 - val_loss: 0.4386 - val_accuracy: 0.8230\n",
      "Epoch 704/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.4224 - accuracy: 0.8265 - val_loss: 0.4364 - val_accuracy: 0.8239\n",
      "Epoch 705/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.4219 - accuracy: 0.8271 - val_loss: 0.4369 - val_accuracy: 0.8235\n",
      "Epoch 706/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4225 - accuracy: 0.8273 - val_loss: 0.4377 - val_accuracy: 0.8234\n",
      "Epoch 707/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4220 - accuracy: 0.8277 - val_loss: 0.4367 - val_accuracy: 0.8234\n",
      "Epoch 708/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4223 - accuracy: 0.8275 - val_loss: 0.4388 - val_accuracy: 0.8238\n",
      "Epoch 709/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4220 - accuracy: 0.8270 - val_loss: 0.4365 - val_accuracy: 0.8243\n",
      "Epoch 710/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4220 - accuracy: 0.8274 - val_loss: 0.4409 - val_accuracy: 0.8216\n",
      "Epoch 711/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4219 - accuracy: 0.8275 - val_loss: 0.4401 - val_accuracy: 0.8225\n",
      "Epoch 712/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4223 - accuracy: 0.8277 - val_loss: 0.4362 - val_accuracy: 0.8236\n",
      "Epoch 713/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.4219 - accuracy: 0.8277 - val_loss: 0.4383 - val_accuracy: 0.8237\n",
      "Epoch 714/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4224 - accuracy: 0.8272 - val_loss: 0.4426 - val_accuracy: 0.8235\n",
      "Epoch 715/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4222 - accuracy: 0.8269 - val_loss: 0.4377 - val_accuracy: 0.8236\n",
      "Epoch 716/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4222 - accuracy: 0.8276 - val_loss: 0.4411 - val_accuracy: 0.8236\n",
      "Epoch 717/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4221 - accuracy: 0.8272 - val_loss: 0.4367 - val_accuracy: 0.8239\n",
      "Epoch 718/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4216 - accuracy: 0.8272 - val_loss: 0.4389 - val_accuracy: 0.8235\n",
      "Epoch 719/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.4221 - accuracy: 0.8269 - val_loss: 0.4370 - val_accuracy: 0.8242\n",
      "Epoch 720/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.4219 - accuracy: 0.8275 - val_loss: 0.4380 - val_accuracy: 0.8234\n",
      "Epoch 721/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.4222 - accuracy: 0.8271 - val_loss: 0.4386 - val_accuracy: 0.8236\n",
      "Epoch 722/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.4221 - accuracy: 0.8274 - val_loss: 0.4399 - val_accuracy: 0.8233\n",
      "Epoch 723/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.4221 - accuracy: 0.8277 - val_loss: 0.4408 - val_accuracy: 0.8211\n",
      "Epoch 724/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.4220 - accuracy: 0.8269 - val_loss: 0.4355 - val_accuracy: 0.8244\n",
      "Epoch 725/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4220 - accuracy: 0.8269 - val_loss: 0.4381 - val_accuracy: 0.8229\n",
      "Epoch 726/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 0.4216 - accuracy: 0.8280 - val_loss: 0.4388 - val_accuracy: 0.8233\n",
      "Epoch 727/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4221 - accuracy: 0.8273 - val_loss: 0.4443 - val_accuracy: 0.8231\n",
      "Epoch 728/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4223 - accuracy: 0.8276 - val_loss: 0.4363 - val_accuracy: 0.8239\n",
      "Epoch 729/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4223 - accuracy: 0.8272 - val_loss: 0.4391 - val_accuracy: 0.8233\n",
      "Epoch 730/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4220 - accuracy: 0.8275 - val_loss: 0.4378 - val_accuracy: 0.8243\n",
      "Epoch 731/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4220 - accuracy: 0.8273 - val_loss: 0.4371 - val_accuracy: 0.8237\n",
      "Epoch 732/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4229 - accuracy: 0.8272 - val_loss: 0.4382 - val_accuracy: 0.8232\n",
      "Epoch 733/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4222 - accuracy: 0.8274 - val_loss: 0.4370 - val_accuracy: 0.8234\n",
      "Epoch 734/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4217 - accuracy: 0.8277 - val_loss: 0.4365 - val_accuracy: 0.8237\n",
      "Epoch 735/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4222 - accuracy: 0.8272 - val_loss: 0.4386 - val_accuracy: 0.8232\n",
      "Epoch 736/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4219 - accuracy: 0.8277 - val_loss: 0.4386 - val_accuracy: 0.8222\n",
      "Epoch 737/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4216 - accuracy: 0.8271 - val_loss: 0.4413 - val_accuracy: 0.8236\n",
      "Epoch 738/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4219 - accuracy: 0.8278 - val_loss: 0.4378 - val_accuracy: 0.8238\n",
      "Epoch 739/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4222 - accuracy: 0.8274 - val_loss: 0.4361 - val_accuracy: 0.8234\n",
      "Epoch 740/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.4221 - accuracy: 0.8273 - val_loss: 0.4386 - val_accuracy: 0.8228\n",
      "Epoch 741/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.4223 - accuracy: 0.8276 - val_loss: 0.4372 - val_accuracy: 0.8233\n",
      "Epoch 742/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 0.4221 - accuracy: 0.8273 - val_loss: 0.4443 - val_accuracy: 0.8165\n",
      "Epoch 743/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.4225 - accuracy: 0.8276 - val_loss: 0.4396 - val_accuracy: 0.8231\n",
      "Epoch 744/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4223 - accuracy: 0.8272 - val_loss: 0.4424 - val_accuracy: 0.8236\n",
      "Epoch 745/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4224 - accuracy: 0.8275 - val_loss: 0.4371 - val_accuracy: 0.8238\n",
      "Epoch 746/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.4223 - accuracy: 0.8274 - val_loss: 0.4396 - val_accuracy: 0.8234\n",
      "Epoch 747/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 0.4220 - accuracy: 0.8274 - val_loss: 0.4370 - val_accuracy: 0.8245\n",
      "Epoch 748/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.4217 - accuracy: 0.8272 - val_loss: 0.4419 - val_accuracy: 0.8213\n",
      "Epoch 749/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.4223 - accuracy: 0.8273 - val_loss: 0.4364 - val_accuracy: 0.8233\n",
      "Epoch 750/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.4220 - accuracy: 0.8280 - val_loss: 0.4394 - val_accuracy: 0.8234\n",
      "Epoch 751/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4222 - accuracy: 0.8272 - val_loss: 0.4436 - val_accuracy: 0.8236\n",
      "Epoch 752/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4220 - accuracy: 0.8274 - val_loss: 0.4410 - val_accuracy: 0.8225\n",
      "Epoch 753/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4217 - accuracy: 0.8273 - val_loss: 0.4383 - val_accuracy: 0.8230\n",
      "Epoch 754/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.4220 - accuracy: 0.8273 - val_loss: 0.4391 - val_accuracy: 0.8223\n",
      "Epoch 755/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4220 - accuracy: 0.8271 - val_loss: 0.4360 - val_accuracy: 0.8244\n",
      "Epoch 756/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4220 - accuracy: 0.8274 - val_loss: 0.4367 - val_accuracy: 0.8238\n",
      "Epoch 757/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4228 - accuracy: 0.8264 - val_loss: 0.4378 - val_accuracy: 0.8236\n",
      "Epoch 758/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4223 - accuracy: 0.8275 - val_loss: 0.4366 - val_accuracy: 0.8236\n",
      "Epoch 759/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4223 - accuracy: 0.8276 - val_loss: 0.4383 - val_accuracy: 0.8230\n",
      "Epoch 760/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4224 - accuracy: 0.8270 - val_loss: 0.4385 - val_accuracy: 0.8230\n",
      "Epoch 761/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4222 - accuracy: 0.8272 - val_loss: 0.4380 - val_accuracy: 0.8241\n",
      "Epoch 762/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.4226 - accuracy: 0.8274 - val_loss: 0.4373 - val_accuracy: 0.8236\n",
      "Epoch 763/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4222 - accuracy: 0.8273 - val_loss: 0.4361 - val_accuracy: 0.8239\n",
      "Epoch 764/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4221 - accuracy: 0.8269 - val_loss: 0.4382 - val_accuracy: 0.8234\n",
      "Epoch 765/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4216 - accuracy: 0.8275 - val_loss: 0.4398 - val_accuracy: 0.8231\n",
      "Epoch 766/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4219 - accuracy: 0.8274 - val_loss: 0.4382 - val_accuracy: 0.8224\n",
      "Epoch 767/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4222 - accuracy: 0.8273 - val_loss: 0.4378 - val_accuracy: 0.8241\n",
      "Epoch 768/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4223 - accuracy: 0.8269 - val_loss: 0.4365 - val_accuracy: 0.8235\n",
      "Epoch 769/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4219 - accuracy: 0.8273 - val_loss: 0.4396 - val_accuracy: 0.8238\n",
      "Epoch 770/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4222 - accuracy: 0.8273 - val_loss: 0.4371 - val_accuracy: 0.8248\n",
      "Epoch 771/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4223 - accuracy: 0.8273 - val_loss: 0.4403 - val_accuracy: 0.8236\n",
      "Epoch 772/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4221 - accuracy: 0.8270 - val_loss: 0.4373 - val_accuracy: 0.8233\n",
      "Epoch 773/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4223 - accuracy: 0.8274 - val_loss: 0.4426 - val_accuracy: 0.8239\n",
      "Epoch 774/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4223 - accuracy: 0.8273 - val_loss: 0.4384 - val_accuracy: 0.8232\n",
      "Epoch 775/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4224 - accuracy: 0.8275 - val_loss: 0.4376 - val_accuracy: 0.8234\n",
      "Epoch 776/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4216 - accuracy: 0.8274 - val_loss: 0.4407 - val_accuracy: 0.8235\n",
      "Epoch 777/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.4221 - accuracy: 0.8269 - val_loss: 0.4425 - val_accuracy: 0.8233\n",
      "Epoch 778/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.4217 - accuracy: 0.8269 - val_loss: 0.4427 - val_accuracy: 0.8234\n",
      "Epoch 779/1000\n",
      "49590/49590 [==============================] - 2s 44us/sample - loss: 0.4230 - accuracy: 0.8270 - val_loss: 0.4372 - val_accuracy: 0.8233\n",
      "Epoch 780/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 0.4221 - accuracy: 0.8275 - val_loss: 0.4373 - val_accuracy: 0.8230\n",
      "Epoch 781/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 0.4223 - accuracy: 0.8275 - val_loss: 0.4371 - val_accuracy: 0.8236\n",
      "Epoch 782/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.4219 - accuracy: 0.8269 - val_loss: 0.4387 - val_accuracy: 0.8235\n",
      "Epoch 783/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4220 - accuracy: 0.8277 - val_loss: 0.4391 - val_accuracy: 0.8231\n",
      "Epoch 784/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4226 - accuracy: 0.8273 - val_loss: 0.4364 - val_accuracy: 0.8238\n",
      "Epoch 785/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4219 - accuracy: 0.8274 - val_loss: 0.4370 - val_accuracy: 0.8249\n",
      "Epoch 786/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4221 - accuracy: 0.8275 - val_loss: 0.4366 - val_accuracy: 0.8233\n",
      "Epoch 787/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.4216 - accuracy: 0.8272 - val_loss: 0.4376 - val_accuracy: 0.8232\n",
      "Epoch 788/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4227 - accuracy: 0.8272 - val_loss: 0.4379 - val_accuracy: 0.8239\n",
      "Epoch 789/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4213 - accuracy: 0.8274 - val_loss: 0.4375 - val_accuracy: 0.8235\n",
      "Epoch 790/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4227 - accuracy: 0.8269 - val_loss: 0.4375 - val_accuracy: 0.8241\n",
      "Epoch 791/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4220 - accuracy: 0.8277 - val_loss: 0.4384 - val_accuracy: 0.8228\n",
      "Epoch 792/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4216 - accuracy: 0.8278 - val_loss: 0.4385 - val_accuracy: 0.8242\n",
      "Epoch 793/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4220 - accuracy: 0.8276 - val_loss: 0.4389 - val_accuracy: 0.8235\n",
      "Epoch 794/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4218 - accuracy: 0.8275 - val_loss: 0.4395 - val_accuracy: 0.8230\n",
      "Epoch 795/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4217 - accuracy: 0.8277 - val_loss: 0.4394 - val_accuracy: 0.8236\n",
      "Epoch 796/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4227 - accuracy: 0.8275 - val_loss: 0.4372 - val_accuracy: 0.8235\n",
      "Epoch 797/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4221 - accuracy: 0.8272 - val_loss: 0.4371 - val_accuracy: 0.8236\n",
      "Epoch 798/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4219 - accuracy: 0.8271 - val_loss: 0.4394 - val_accuracy: 0.8239\n",
      "Epoch 799/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4221 - accuracy: 0.8271 - val_loss: 0.4362 - val_accuracy: 0.8229\n",
      "Epoch 800/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4217 - accuracy: 0.8269 - val_loss: 0.4392 - val_accuracy: 0.8232\n",
      "Epoch 801/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4220 - accuracy: 0.8279 - val_loss: 0.4391 - val_accuracy: 0.8235\n",
      "Epoch 802/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.4224 - accuracy: 0.8274 - val_loss: 0.4389 - val_accuracy: 0.8231\n",
      "Epoch 803/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.4219 - accuracy: 0.8270 - val_loss: 0.4365 - val_accuracy: 0.8236\n",
      "Epoch 804/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4220 - accuracy: 0.8271 - val_loss: 0.4386 - val_accuracy: 0.8240\n",
      "Epoch 805/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.4223 - accuracy: 0.8276 - val_loss: 0.4381 - val_accuracy: 0.8241\n",
      "Epoch 806/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4219 - accuracy: 0.8275 - val_loss: 0.4380 - val_accuracy: 0.8230\n",
      "Epoch 807/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4219 - accuracy: 0.8273 - val_loss: 0.4373 - val_accuracy: 0.8223\n",
      "Epoch 808/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.4219 - accuracy: 0.8273 - val_loss: 0.4391 - val_accuracy: 0.8231\n",
      "Epoch 809/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.4218 - accuracy: 0.8275 - val_loss: 0.4361 - val_accuracy: 0.8237\n",
      "Epoch 810/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4217 - accuracy: 0.8269 - val_loss: 0.4416 - val_accuracy: 0.8222\n",
      "Epoch 811/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4222 - accuracy: 0.8269 - val_loss: 0.4369 - val_accuracy: 0.8235\n",
      "Epoch 812/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.4217 - accuracy: 0.8275 - val_loss: 0.4366 - val_accuracy: 0.8232\n",
      "Epoch 813/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4224 - accuracy: 0.8272 - val_loss: 0.4372 - val_accuracy: 0.8236\n",
      "Epoch 814/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4219 - accuracy: 0.8275 - val_loss: 0.4376 - val_accuracy: 0.8240\n",
      "Epoch 815/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4218 - accuracy: 0.8273 - val_loss: 0.4384 - val_accuracy: 0.8229\n",
      "Epoch 816/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4219 - accuracy: 0.8275 - val_loss: 0.4401 - val_accuracy: 0.8221\n",
      "Epoch 817/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.4218 - accuracy: 0.8276 - val_loss: 0.4402 - val_accuracy: 0.8226\n",
      "Epoch 818/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 0.4220 - accuracy: 0.8278 - val_loss: 0.4373 - val_accuracy: 0.8236\n",
      "Epoch 819/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4219 - accuracy: 0.8278 - val_loss: 0.4381 - val_accuracy: 0.8238\n",
      "Epoch 820/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.4222 - accuracy: 0.8274 - val_loss: 0.4375 - val_accuracy: 0.8230\n",
      "Epoch 821/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4215 - accuracy: 0.8275 - val_loss: 0.4394 - val_accuracy: 0.8231\n",
      "Epoch 822/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4221 - accuracy: 0.8272 - val_loss: 0.4382 - val_accuracy: 0.8234\n",
      "Epoch 823/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.4222 - accuracy: 0.8268 - val_loss: 0.4406 - val_accuracy: 0.8231\n",
      "Epoch 824/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4218 - accuracy: 0.8274 - val_loss: 0.4430 - val_accuracy: 0.8235\n",
      "Epoch 825/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 0.4221 - accuracy: 0.8273 - val_loss: 0.4354 - val_accuracy: 0.8238\n",
      "Epoch 826/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 0.4219 - accuracy: 0.8277 - val_loss: 0.4369 - val_accuracy: 0.8245\n",
      "Epoch 827/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4217 - accuracy: 0.8277 - val_loss: 0.4387 - val_accuracy: 0.8237\n",
      "Epoch 828/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4221 - accuracy: 0.8275 - val_loss: 0.4396 - val_accuracy: 0.8228\n",
      "Epoch 829/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4220 - accuracy: 0.8279 - val_loss: 0.4370 - val_accuracy: 0.8240\n",
      "Epoch 830/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4220 - accuracy: 0.8271 - val_loss: 0.4370 - val_accuracy: 0.8234\n",
      "Epoch 831/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4219 - accuracy: 0.8269 - val_loss: 0.4370 - val_accuracy: 0.8240\n",
      "Epoch 832/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4219 - accuracy: 0.8277 - val_loss: 0.4385 - val_accuracy: 0.8235\n",
      "Epoch 833/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4224 - accuracy: 0.8275 - val_loss: 0.4376 - val_accuracy: 0.8234\n",
      "Epoch 834/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4218 - accuracy: 0.8273 - val_loss: 0.4376 - val_accuracy: 0.8238\n",
      "Epoch 835/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4220 - accuracy: 0.8273 - val_loss: 0.4379 - val_accuracy: 0.8237\n",
      "Epoch 836/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4220 - accuracy: 0.8277 - val_loss: 0.4394 - val_accuracy: 0.8232\n",
      "Epoch 837/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4216 - accuracy: 0.8280 - val_loss: 0.4372 - val_accuracy: 0.8237\n",
      "Epoch 838/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4217 - accuracy: 0.8273 - val_loss: 0.4427 - val_accuracy: 0.8228\n",
      "Epoch 839/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4220 - accuracy: 0.8272 - val_loss: 0.4398 - val_accuracy: 0.8232\n",
      "Epoch 840/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4223 - accuracy: 0.8276 - val_loss: 0.4387 - val_accuracy: 0.8230\n",
      "Epoch 841/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4220 - accuracy: 0.8274 - val_loss: 0.4374 - val_accuracy: 0.8233\n",
      "Epoch 842/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4218 - accuracy: 0.8278 - val_loss: 0.4379 - val_accuracy: 0.8227\n",
      "Epoch 843/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4216 - accuracy: 0.8276 - val_loss: 0.4387 - val_accuracy: 0.8240\n",
      "Epoch 844/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4221 - accuracy: 0.8268 - val_loss: 0.4408 - val_accuracy: 0.8226\n",
      "Epoch 845/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4215 - accuracy: 0.8275 - val_loss: 0.4393 - val_accuracy: 0.8223\n",
      "Epoch 846/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4218 - accuracy: 0.8269 - val_loss: 0.4433 - val_accuracy: 0.8228\n",
      "Epoch 847/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4219 - accuracy: 0.8279 - val_loss: 0.4365 - val_accuracy: 0.8239\n",
      "Epoch 848/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4220 - accuracy: 0.8270 - val_loss: 0.4414 - val_accuracy: 0.8223\n",
      "Epoch 849/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4216 - accuracy: 0.8274 - val_loss: 0.4377 - val_accuracy: 0.8244\n",
      "Epoch 850/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4216 - accuracy: 0.8279 - val_loss: 0.4383 - val_accuracy: 0.8231\n",
      "Epoch 851/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4217 - accuracy: 0.8276 - val_loss: 0.4374 - val_accuracy: 0.8242\n",
      "Epoch 852/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4219 - accuracy: 0.8273 - val_loss: 0.4426 - val_accuracy: 0.8234\n",
      "Epoch 853/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4217 - accuracy: 0.8270 - val_loss: 0.4407 - val_accuracy: 0.8240\n",
      "Epoch 854/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4219 - accuracy: 0.8271 - val_loss: 0.4369 - val_accuracy: 0.8233\n",
      "Epoch 855/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4219 - accuracy: 0.8272 - val_loss: 0.4376 - val_accuracy: 0.8247\n",
      "Epoch 856/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4219 - accuracy: 0.8272 - val_loss: 0.4378 - val_accuracy: 0.8230\n",
      "Epoch 857/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4215 - accuracy: 0.8269 - val_loss: 0.4391 - val_accuracy: 0.8239\n",
      "Epoch 858/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4223 - accuracy: 0.8271 - val_loss: 0.4379 - val_accuracy: 0.8233\n",
      "Epoch 859/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.4222 - accuracy: 0.8276 - val_loss: 0.4385 - val_accuracy: 0.8229\n",
      "Epoch 860/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4215 - accuracy: 0.8273 - val_loss: 0.4372 - val_accuracy: 0.8225\n",
      "Epoch 861/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.4216 - accuracy: 0.8276 - val_loss: 0.4383 - val_accuracy: 0.8232\n",
      "Epoch 862/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4213 - accuracy: 0.8276 - val_loss: 0.4357 - val_accuracy: 0.8240\n",
      "Epoch 863/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4219 - accuracy: 0.8273 - val_loss: 0.4365 - val_accuracy: 0.8240\n",
      "Epoch 864/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4220 - accuracy: 0.8271 - val_loss: 0.4372 - val_accuracy: 0.8233\n",
      "Epoch 865/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4216 - accuracy: 0.8274 - val_loss: 0.4383 - val_accuracy: 0.8225\n",
      "Epoch 866/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4224 - accuracy: 0.8269 - val_loss: 0.4415 - val_accuracy: 0.8226\n",
      "Epoch 867/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4215 - accuracy: 0.8272 - val_loss: 0.4379 - val_accuracy: 0.8234\n",
      "Epoch 868/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4215 - accuracy: 0.8273 - val_loss: 0.4378 - val_accuracy: 0.8235\n",
      "Epoch 869/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4223 - accuracy: 0.8278 - val_loss: 0.4377 - val_accuracy: 0.8238\n",
      "Epoch 870/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4222 - accuracy: 0.8277 - val_loss: 0.4411 - val_accuracy: 0.8236\n",
      "Epoch 871/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4220 - accuracy: 0.8276 - val_loss: 0.4395 - val_accuracy: 0.8231\n",
      "Epoch 872/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4216 - accuracy: 0.8274 - val_loss: 0.4404 - val_accuracy: 0.8230\n",
      "Epoch 873/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4219 - accuracy: 0.8276 - val_loss: 0.4387 - val_accuracy: 0.8228\n",
      "Epoch 874/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4217 - accuracy: 0.8278 - val_loss: 0.4377 - val_accuracy: 0.8235\n",
      "Epoch 875/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4220 - accuracy: 0.8274 - val_loss: 0.4361 - val_accuracy: 0.8235\n",
      "Epoch 876/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4220 - accuracy: 0.8278 - val_loss: 0.4382 - val_accuracy: 0.8239\n",
      "Epoch 877/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4219 - accuracy: 0.8275 - val_loss: 0.4411 - val_accuracy: 0.8230\n",
      "Epoch 878/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4226 - accuracy: 0.8278 - val_loss: 0.4384 - val_accuracy: 0.8232\n",
      "Epoch 879/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4219 - accuracy: 0.8271 - val_loss: 0.4406 - val_accuracy: 0.8234\n",
      "Epoch 880/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4222 - accuracy: 0.8270 - val_loss: 0.4395 - val_accuracy: 0.8234\n",
      "Epoch 881/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4221 - accuracy: 0.8274 - val_loss: 0.4373 - val_accuracy: 0.8232\n",
      "Epoch 882/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4218 - accuracy: 0.8267 - val_loss: 0.4364 - val_accuracy: 0.8242\n",
      "Epoch 883/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4216 - accuracy: 0.8277 - val_loss: 0.4406 - val_accuracy: 0.8235\n",
      "Epoch 884/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4221 - accuracy: 0.8272 - val_loss: 0.4374 - val_accuracy: 0.8237\n",
      "Epoch 885/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4217 - accuracy: 0.8274 - val_loss: 0.4364 - val_accuracy: 0.8232\n",
      "Epoch 886/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4215 - accuracy: 0.8278 - val_loss: 0.4388 - val_accuracy: 0.8241\n",
      "Epoch 887/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.4222 - accuracy: 0.8266 - val_loss: 0.4363 - val_accuracy: 0.8233\n",
      "Epoch 888/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.4218 - accuracy: 0.8266 - val_loss: 0.4370 - val_accuracy: 0.8244\n",
      "Epoch 889/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.4216 - accuracy: 0.8279 - val_loss: 0.4396 - val_accuracy: 0.8236\n",
      "Epoch 890/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 0.4215 - accuracy: 0.8270 - val_loss: 0.4371 - val_accuracy: 0.8238\n",
      "Epoch 891/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.4216 - accuracy: 0.8273 - val_loss: 0.4381 - val_accuracy: 0.8233\n",
      "Epoch 892/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.4222 - accuracy: 0.8274 - val_loss: 0.4426 - val_accuracy: 0.8229\n",
      "Epoch 893/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.4221 - accuracy: 0.8271 - val_loss: 0.4375 - val_accuracy: 0.8231\n",
      "Epoch 894/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4223 - accuracy: 0.8267 - val_loss: 0.4450 - val_accuracy: 0.8185\n",
      "Epoch 895/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4220 - accuracy: 0.8275 - val_loss: 0.4398 - val_accuracy: 0.8233\n",
      "Epoch 896/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4219 - accuracy: 0.8271 - val_loss: 0.4392 - val_accuracy: 0.8232\n",
      "Epoch 897/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4220 - accuracy: 0.8269 - val_loss: 0.4365 - val_accuracy: 0.8237\n",
      "Epoch 898/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4222 - accuracy: 0.8271 - val_loss: 0.4373 - val_accuracy: 0.8237\n",
      "Epoch 899/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4213 - accuracy: 0.8274 - val_loss: 0.4381 - val_accuracy: 0.8228\n",
      "Epoch 900/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4218 - accuracy: 0.8278 - val_loss: 0.4392 - val_accuracy: 0.8224\n",
      "Epoch 901/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4222 - accuracy: 0.8275 - val_loss: 0.4403 - val_accuracy: 0.8231\n",
      "Epoch 902/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4223 - accuracy: 0.8277 - val_loss: 0.4390 - val_accuracy: 0.8234\n",
      "Epoch 903/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4221 - accuracy: 0.8271 - val_loss: 0.4378 - val_accuracy: 0.8228\n",
      "Epoch 904/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4216 - accuracy: 0.8276 - val_loss: 0.4381 - val_accuracy: 0.8234\n",
      "Epoch 905/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4221 - accuracy: 0.8272 - val_loss: 0.4398 - val_accuracy: 0.8210\n",
      "Epoch 906/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4220 - accuracy: 0.8275 - val_loss: 0.4406 - val_accuracy: 0.8225\n",
      "Epoch 907/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4220 - accuracy: 0.8275 - val_loss: 0.4393 - val_accuracy: 0.8234\n",
      "Epoch 908/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4220 - accuracy: 0.8272 - val_loss: 0.4375 - val_accuracy: 0.8233\n",
      "Epoch 909/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4215 - accuracy: 0.8270 - val_loss: 0.4385 - val_accuracy: 0.8226\n",
      "Epoch 910/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4217 - accuracy: 0.8269 - val_loss: 0.4391 - val_accuracy: 0.8236\n",
      "Epoch 911/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4218 - accuracy: 0.8270 - val_loss: 0.4370 - val_accuracy: 0.8238\n",
      "Epoch 912/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4219 - accuracy: 0.8270 - val_loss: 0.4366 - val_accuracy: 0.8238\n",
      "Epoch 913/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4213 - accuracy: 0.8275 - val_loss: 0.4369 - val_accuracy: 0.8230\n",
      "Epoch 914/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.4220 - accuracy: 0.8276 - val_loss: 0.4373 - val_accuracy: 0.8225\n",
      "Epoch 915/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4219 - accuracy: 0.8268 - val_loss: 0.4392 - val_accuracy: 0.8228\n",
      "Epoch 916/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.4220 - accuracy: 0.8273 - val_loss: 0.4366 - val_accuracy: 0.8234\n",
      "Epoch 917/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.4219 - accuracy: 0.8275 - val_loss: 0.4380 - val_accuracy: 0.8238\n",
      "Epoch 918/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.4213 - accuracy: 0.8277 - val_loss: 0.4382 - val_accuracy: 0.8231\n",
      "Epoch 919/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.4220 - accuracy: 0.8268 - val_loss: 0.4374 - val_accuracy: 0.8239\n",
      "Epoch 920/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.4212 - accuracy: 0.8275 - val_loss: 0.4367 - val_accuracy: 0.8231\n",
      "Epoch 921/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4215 - accuracy: 0.8269 - val_loss: 0.4394 - val_accuracy: 0.8217\n",
      "Epoch 922/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.4219 - accuracy: 0.8274 - val_loss: 0.4374 - val_accuracy: 0.8231\n",
      "Epoch 923/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4218 - accuracy: 0.8271 - val_loss: 0.4376 - val_accuracy: 0.8228\n",
      "Epoch 924/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4220 - accuracy: 0.8274 - val_loss: 0.4368 - val_accuracy: 0.8232\n",
      "Epoch 925/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4219 - accuracy: 0.8270 - val_loss: 0.4371 - val_accuracy: 0.8240\n",
      "Epoch 926/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4215 - accuracy: 0.8274 - val_loss: 0.4378 - val_accuracy: 0.8237\n",
      "Epoch 927/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4220 - accuracy: 0.8270 - val_loss: 0.4383 - val_accuracy: 0.8229\n",
      "Epoch 928/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4221 - accuracy: 0.8270 - val_loss: 0.4412 - val_accuracy: 0.8229\n",
      "Epoch 929/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.4224 - accuracy: 0.8272 - val_loss: 0.4388 - val_accuracy: 0.8230\n",
      "Epoch 930/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 0.4218 - accuracy: 0.8273 - val_loss: 0.4386 - val_accuracy: 0.8231\n",
      "Epoch 931/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4216 - accuracy: 0.8270 - val_loss: 0.4385 - val_accuracy: 0.8224\n",
      "Epoch 932/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4215 - accuracy: 0.8274 - val_loss: 0.4359 - val_accuracy: 0.8239\n",
      "Epoch 933/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 0.4220 - accuracy: 0.8271 - val_loss: 0.4367 - val_accuracy: 0.8232\n",
      "Epoch 934/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4223 - accuracy: 0.8273 - val_loss: 0.4373 - val_accuracy: 0.8235\n",
      "Epoch 935/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4220 - accuracy: 0.8275 - val_loss: 0.4386 - val_accuracy: 0.8225\n",
      "Epoch 936/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4218 - accuracy: 0.8272 - val_loss: 0.4375 - val_accuracy: 0.8234\n",
      "Epoch 937/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.4218 - accuracy: 0.8273 - val_loss: 0.4381 - val_accuracy: 0.8229\n",
      "Epoch 938/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.4219 - accuracy: 0.8272 - val_loss: 0.4387 - val_accuracy: 0.8234\n",
      "Epoch 939/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 0.4219 - accuracy: 0.8275 - val_loss: 0.4411 - val_accuracy: 0.8231\n",
      "Epoch 940/1000\n",
      "49590/49590 [==============================] - 2s 50us/sample - loss: 0.4222 - accuracy: 0.8275 - val_loss: 0.4370 - val_accuracy: 0.8234\n",
      "Epoch 941/1000\n",
      "49590/49590 [==============================] - 3s 63us/sample - loss: 0.4218 - accuracy: 0.8267 - val_loss: 0.4418 - val_accuracy: 0.8223\n",
      "Epoch 942/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 0.4224 - accuracy: 0.8266 - val_loss: 0.4400 - val_accuracy: 0.8235\n",
      "Epoch 943/1000\n",
      "49590/49590 [==============================] - 2s 50us/sample - loss: 0.4217 - accuracy: 0.8273 - val_loss: 0.4401 - val_accuracy: 0.8224\n",
      "Epoch 944/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 0.4214 - accuracy: 0.8271 - val_loss: 0.4374 - val_accuracy: 0.8238\n",
      "Epoch 945/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 0.4221 - accuracy: 0.8277 - val_loss: 0.4402 - val_accuracy: 0.8243\n",
      "Epoch 946/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 0.4219 - accuracy: 0.8271 - val_loss: 0.4378 - val_accuracy: 0.8241\n",
      "Epoch 947/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 0.4218 - accuracy: 0.8272 - val_loss: 0.4402 - val_accuracy: 0.8234\n",
      "Epoch 948/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4220 - accuracy: 0.8276 - val_loss: 0.4386 - val_accuracy: 0.8237\n",
      "Epoch 949/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.4215 - accuracy: 0.8278 - val_loss: 0.4388 - val_accuracy: 0.8237\n",
      "Epoch 950/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 0.4228 - accuracy: 0.8275 - val_loss: 0.4366 - val_accuracy: 0.8234\n",
      "Epoch 951/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.4220 - accuracy: 0.8271 - val_loss: 0.4388 - val_accuracy: 0.8232\n",
      "Epoch 952/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4219 - accuracy: 0.8273 - val_loss: 0.4408 - val_accuracy: 0.8224\n",
      "Epoch 953/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4222 - accuracy: 0.8273 - val_loss: 0.4435 - val_accuracy: 0.8232\n",
      "Epoch 954/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4216 - accuracy: 0.8271 - val_loss: 0.4402 - val_accuracy: 0.8234\n",
      "Epoch 955/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4215 - accuracy: 0.8279 - val_loss: 0.4364 - val_accuracy: 0.8239\n",
      "Epoch 956/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 0.4218 - accuracy: 0.8275 - val_loss: 0.4375 - val_accuracy: 0.8232\n",
      "Epoch 957/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 0.4221 - accuracy: 0.8276 - val_loss: 0.4388 - val_accuracy: 0.8242\n",
      "Epoch 958/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4221 - accuracy: 0.8270 - val_loss: 0.4394 - val_accuracy: 0.8228\n",
      "Epoch 959/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.4219 - accuracy: 0.8269 - val_loss: 0.4439 - val_accuracy: 0.8238\n",
      "Epoch 960/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 0.4217 - accuracy: 0.8270 - val_loss: 0.4394 - val_accuracy: 0.8234\n",
      "Epoch 961/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4214 - accuracy: 0.8268 - val_loss: 0.4389 - val_accuracy: 0.8218\n",
      "Epoch 962/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4218 - accuracy: 0.8274 - val_loss: 0.4414 - val_accuracy: 0.8221\n",
      "Epoch 963/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 0.4219 - accuracy: 0.8271 - val_loss: 0.4407 - val_accuracy: 0.8221\n",
      "Epoch 964/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 0.4215 - accuracy: 0.8273 - val_loss: 0.4401 - val_accuracy: 0.8236\n",
      "Epoch 965/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 0.4218 - accuracy: 0.8273 - val_loss: 0.4394 - val_accuracy: 0.8225\n",
      "Epoch 966/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4221 - accuracy: 0.8275 - val_loss: 0.4401 - val_accuracy: 0.8230\n",
      "Epoch 967/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4218 - accuracy: 0.8267 - val_loss: 0.4383 - val_accuracy: 0.8228\n",
      "Epoch 968/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4217 - accuracy: 0.8274 - val_loss: 0.4375 - val_accuracy: 0.8226\n",
      "Epoch 969/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4215 - accuracy: 0.8271 - val_loss: 0.4375 - val_accuracy: 0.8233\n",
      "Epoch 970/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4218 - accuracy: 0.8269 - val_loss: 0.4392 - val_accuracy: 0.8229\n",
      "Epoch 971/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4216 - accuracy: 0.8271 - val_loss: 0.4379 - val_accuracy: 0.8232\n",
      "Epoch 972/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4211 - accuracy: 0.8273 - val_loss: 0.4403 - val_accuracy: 0.8233\n",
      "Epoch 973/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4216 - accuracy: 0.8274 - val_loss: 0.4389 - val_accuracy: 0.8213\n",
      "Epoch 974/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4223 - accuracy: 0.8273 - val_loss: 0.4382 - val_accuracy: 0.8232\n",
      "Epoch 975/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4219 - accuracy: 0.8273 - val_loss: 0.4409 - val_accuracy: 0.8229\n",
      "Epoch 976/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4215 - accuracy: 0.8270 - val_loss: 0.4395 - val_accuracy: 0.8221\n",
      "Epoch 977/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4221 - accuracy: 0.8270 - val_loss: 0.4380 - val_accuracy: 0.8238\n",
      "Epoch 978/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4215 - accuracy: 0.8274 - val_loss: 0.4396 - val_accuracy: 0.8233\n",
      "Epoch 979/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4216 - accuracy: 0.8276 - val_loss: 0.4378 - val_accuracy: 0.8224\n",
      "Epoch 980/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4218 - accuracy: 0.8274 - val_loss: 0.4391 - val_accuracy: 0.8233\n",
      "Epoch 981/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4216 - accuracy: 0.8273 - val_loss: 0.4383 - val_accuracy: 0.8232\n",
      "Epoch 982/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4219 - accuracy: 0.8273 - val_loss: 0.4377 - val_accuracy: 0.8235\n",
      "Epoch 983/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4213 - accuracy: 0.8274 - val_loss: 0.4405 - val_accuracy: 0.8239\n",
      "Epoch 984/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4219 - accuracy: 0.8277 - val_loss: 0.4372 - val_accuracy: 0.8240\n",
      "Epoch 985/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4216 - accuracy: 0.8273 - val_loss: 0.4358 - val_accuracy: 0.8236\n",
      "Epoch 986/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4217 - accuracy: 0.8278 - val_loss: 0.4414 - val_accuracy: 0.8231\n",
      "Epoch 987/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 0.4216 - accuracy: 0.8273 - val_loss: 0.4371 - val_accuracy: 0.8231\n",
      "Epoch 988/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4221 - accuracy: 0.8274 - val_loss: 0.4366 - val_accuracy: 0.8235\n",
      "Epoch 989/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4219 - accuracy: 0.8281 - val_loss: 0.4369 - val_accuracy: 0.8242\n",
      "Epoch 990/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4222 - accuracy: 0.8273 - val_loss: 0.4374 - val_accuracy: 0.8244\n",
      "Epoch 991/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4216 - accuracy: 0.8273 - val_loss: 0.4412 - val_accuracy: 0.8204\n",
      "Epoch 992/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4218 - accuracy: 0.8272 - val_loss: 0.4383 - val_accuracy: 0.8230\n",
      "Epoch 993/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4218 - accuracy: 0.8271 - val_loss: 0.4406 - val_accuracy: 0.8226\n",
      "Epoch 994/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4218 - accuracy: 0.8276 - val_loss: 0.4386 - val_accuracy: 0.8217\n",
      "Epoch 995/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 0.4214 - accuracy: 0.8271 - val_loss: 0.4412 - val_accuracy: 0.8204\n",
      "Epoch 996/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 0.4221 - accuracy: 0.8276 - val_loss: 0.4378 - val_accuracy: 0.8226\n",
      "Epoch 997/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 0.4216 - accuracy: 0.8274 - val_loss: 0.4392 - val_accuracy: 0.8242\n",
      "Epoch 998/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 0.4217 - accuracy: 0.8272 - val_loss: 0.4372 - val_accuracy: 0.8232\n",
      "Epoch 999/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 0.4217 - accuracy: 0.8276 - val_loss: 0.4389 - val_accuracy: 0.8229\n",
      "Epoch 1000/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 0.4218 - accuracy: 0.8275 - val_loss: 0.4403 - val_accuracy: 0.8232\n"
     ]
    }
   ],
   "source": [
    "# address overfitting\n",
    "binary_ann = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (13, )),\n",
    "    tf.keras.layers.Dense(100, activation = 'relu', \n",
    "                       kernel_regularizer = tf.keras.regularizers.l2(l = 0.001)),\n",
    "    tf.keras.layers.Dense(100, activation = 'relu', \n",
    "                       kernel_regularizer = tf.keras.regularizers.l2(l = 0.001)),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "# compile and fit network\n",
    "binary_ann.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy']) \n",
    "history = binary_ann.fit(X_train, y_train, epochs = 1000, batch_size = 128, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy vs. Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Training', 'Validation'], loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4265898541269143, 0.82619315]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_ann.evaluate(X_train, y_train, verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df = pd.read_csv('data/songs_all_decade_clean.csv')\n",
    "\n",
    "songs_df_clean = songs_df.drop(columns = ['Artist', 'Track Name', 'Track ID'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(songs_df_clean.loc[:, songs_df_clean.columns != 'Popularity'], \n",
    "                                                    songs_df_clean.Popularity, test_size = 0.2, \n",
    "                                                    random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_cols = ['Key', 'Time Signature']\n",
    "# X_train_num = X_train.drop(cat_cols, axis = 1)\n",
    "# X_test_num = X_test.drop(cat_cols, axis = 1)\n",
    "# num_features = X_train_num.columns.tolist()\n",
    "# num_index_train = X_train.index.tolist()\n",
    "# num_index_test = X_test.index.tolist()\n",
    "\n",
    "# X_train_dum = pd.get_dummies(X_train[cat_cols], columns = cat_cols)\n",
    "# X_test_dum = pd.get_dummies(X_test[cat_cols], columns = cat_cols)\n",
    "\n",
    "# scaler = MinMaxScaler().fit(X_train_num)\n",
    "# X_train_scaled = pd.DataFrame(scaler.transform(X_train_num), index = num_index_train, columns = num_features)\n",
    "# X_test_scaled = pd.DataFrame(scaler.transform(X_test_num), index = num_index_test, columns = num_features)\n",
    "\n",
    "# X_train = pd.concat([X_train_dum, X_train_scaled], axis = 1)\n",
    "# X_test = pd.concat([X_test_dum, X_test_scaled], axis = 1)\n",
    "\n",
    "cat_cols = ['Key', 'Time Signature', 'Mode']\n",
    "X_train_num = X_train.drop(cat_cols, axis = 1)\n",
    "X_test_num = X_test.drop(cat_cols, axis = 1)\n",
    "num_features = X_train_num.columns.tolist()\n",
    "num_index_train = X_train.index.tolist()\n",
    "num_index_test = X_test.index.tolist()\n",
    "\n",
    "# X_train_dum = pd.get_dummies(X_train[cat_cols], columns = cat_cols)\n",
    "# X_test_dum = pd.get_dummies(X_test[cat_cols], columns = cat_cols)\n",
    "X_train_dum = X_train[cat_cols]\n",
    "X_test_dum = X_test[cat_cols]\n",
    "\n",
    "scaler = MinMaxScaler().fit(X_train_num)\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(X_train_num), index = num_index_train, columns = num_features)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test_num), index = num_index_test, columns = num_features)\n",
    "\n",
    "X_train = pd.concat([X_train_dum, X_train_scaled], axis = 1)\n",
    "X_test = pd.concat([X_test_dum, X_test_scaled], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 49590 samples, validate on 21253 samples\n",
      "Epoch 1/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 296.4575 - mean_squared_error: 296.4574 - val_loss: 171.3547 - val_mean_squared_error: 171.3547\n",
      "Epoch 2/1000\n",
      "49590/49590 [==============================] - 2s 47us/sample - loss: 169.1547 - mean_squared_error: 169.1546 - val_loss: 166.5109 - val_mean_squared_error: 166.5109\n",
      "Epoch 3/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 165.9703 - mean_squared_error: 165.9703 - val_loss: 165.3780 - val_mean_squared_error: 165.3781\n",
      "Epoch 4/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 164.2333 - mean_squared_error: 164.2332 - val_loss: 165.3335 - val_mean_squared_error: 165.3336\n",
      "Epoch 5/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 163.4994 - mean_squared_error: 163.4993 - val_loss: 165.1122 - val_mean_squared_error: 165.1122\n",
      "Epoch 6/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 162.7764 - mean_squared_error: 162.7764 - val_loss: 162.2497 - val_mean_squared_error: 162.2496\n",
      "Epoch 7/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 161.9775 - mean_squared_error: 161.9775 - val_loss: 161.6213 - val_mean_squared_error: 161.6212\n",
      "Epoch 8/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 162.0358 - mean_squared_error: 162.0357 - val_loss: 161.4130 - val_mean_squared_error: 161.4129\n",
      "Epoch 9/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 161.3209 - mean_squared_error: 161.3208 - val_loss: 161.5466 - val_mean_squared_error: 161.5466\n",
      "Epoch 10/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 161.8321 - mean_squared_error: 161.8321 - val_loss: 161.3025 - val_mean_squared_error: 161.3025\n",
      "Epoch 11/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 161.5605 - mean_squared_error: 161.5606 - val_loss: 161.0014 - val_mean_squared_error: 161.0015\n",
      "Epoch 12/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 161.4150 - mean_squared_error: 161.4151 - val_loss: 160.8932 - val_mean_squared_error: 160.8932\n",
      "Epoch 13/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 161.1501 - mean_squared_error: 161.1501 - val_loss: 160.9319 - val_mean_squared_error: 160.9319\n",
      "Epoch 14/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 160.8874 - mean_squared_error: 160.8875 - val_loss: 161.1348 - val_mean_squared_error: 161.1348\n",
      "Epoch 15/1000\n",
      "49590/49590 [==============================] - 2s 43us/sample - loss: 161.2221 - mean_squared_error: 161.2221 - val_loss: 161.8353 - val_mean_squared_error: 161.8352\n",
      "Epoch 16/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 161.0025 - mean_squared_error: 161.0024 - val_loss: 161.5429 - val_mean_squared_error: 161.5429\n",
      "Epoch 17/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 160.8740 - mean_squared_error: 160.8740 - val_loss: 161.9952 - val_mean_squared_error: 161.9951\n",
      "Epoch 18/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 160.4989 - mean_squared_error: 160.4990 - val_loss: 160.9645 - val_mean_squared_error: 160.9645\n",
      "Epoch 19/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 160.1348 - mean_squared_error: 160.1349 - val_loss: 159.8030 - val_mean_squared_error: 159.8031\n",
      "Epoch 20/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 160.2997 - mean_squared_error: 160.2997 - val_loss: 160.1977 - val_mean_squared_error: 160.1977\n",
      "Epoch 21/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 160.0068 - mean_squared_error: 160.0068 - val_loss: 161.1513 - val_mean_squared_error: 161.1513\n",
      "Epoch 22/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 159.5024 - mean_squared_error: 159.5024 - val_loss: 159.8520 - val_mean_squared_error: 159.8520\n",
      "Epoch 23/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 159.1301 - mean_squared_error: 159.1300 - val_loss: 158.9396 - val_mean_squared_error: 158.9396\n",
      "Epoch 24/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 158.7986 - mean_squared_error: 158.7987 - val_loss: 159.4236 - val_mean_squared_error: 159.4236\n",
      "Epoch 25/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 158.7986 - mean_squared_error: 158.7986 - val_loss: 160.7142 - val_mean_squared_error: 160.7142\n",
      "Epoch 26/1000\n",
      "49590/49590 [==============================] - 2s 44us/sample - loss: 158.5488 - mean_squared_error: 158.5488 - val_loss: 158.2069 - val_mean_squared_error: 158.2069\n",
      "Epoch 27/1000\n",
      "49590/49590 [==============================] - 2s 43us/sample - loss: 158.1493 - mean_squared_error: 158.1494 - val_loss: 157.8070 - val_mean_squared_error: 157.8070\n",
      "Epoch 28/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 158.7211 - mean_squared_error: 158.7212 - val_loss: 161.1054 - val_mean_squared_error: 161.1054\n",
      "Epoch 29/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 158.1392 - mean_squared_error: 158.1391 - val_loss: 158.3963 - val_mean_squared_error: 158.3963\n",
      "Epoch 30/1000\n",
      "49590/49590 [==============================] - 3s 54us/sample - loss: 157.4367 - mean_squared_error: 157.4367 - val_loss: 157.4240 - val_mean_squared_error: 157.4240\n",
      "Epoch 31/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 157.1345 - mean_squared_error: 157.1345 - val_loss: 160.1960 - val_mean_squared_error: 160.1960\n",
      "Epoch 32/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 156.7468 - mean_squared_error: 156.7468 - val_loss: 157.6112 - val_mean_squared_error: 157.6112\n",
      "Epoch 33/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 156.8536 - mean_squared_error: 156.8536 - val_loss: 157.1921 - val_mean_squared_error: 157.1920\n",
      "Epoch 34/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 155.5331 - mean_squared_error: 155.5331 - val_loss: 158.6053 - val_mean_squared_error: 158.6053\n",
      "Epoch 35/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 154.8118 - mean_squared_error: 154.8117 - val_loss: 156.0149 - val_mean_squared_error: 156.0150\n",
      "Epoch 36/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 154.0962 - mean_squared_error: 154.0963 - val_loss: 153.9890 - val_mean_squared_error: 153.9890\n",
      "Epoch 37/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 153.7158 - mean_squared_error: 153.7159 - val_loss: 153.6358 - val_mean_squared_error: 153.6358\n",
      "Epoch 38/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 152.5239 - mean_squared_error: 152.5239 - val_loss: 153.2402 - val_mean_squared_error: 153.2402\n",
      "Epoch 39/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 152.2952 - mean_squared_error: 152.2952 - val_loss: 153.2842 - val_mean_squared_error: 153.2843\n",
      "Epoch 40/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 152.1441 - mean_squared_error: 152.1441 - val_loss: 153.0077 - val_mean_squared_error: 153.0077\n",
      "Epoch 41/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 151.8106 - mean_squared_error: 151.8106 - val_loss: 152.4565 - val_mean_squared_error: 152.4565\n",
      "Epoch 42/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 151.3331 - mean_squared_error: 151.3332 - val_loss: 153.4324 - val_mean_squared_error: 153.4324\n",
      "Epoch 43/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 151.1134 - mean_squared_error: 151.1134 - val_loss: 151.4727 - val_mean_squared_error: 151.4728\n",
      "Epoch 44/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 150.3027 - mean_squared_error: 150.3028 - val_loss: 150.7257 - val_mean_squared_error: 150.7257\n",
      "Epoch 45/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 149.5829 - mean_squared_error: 149.5830 - val_loss: 155.5843 - val_mean_squared_error: 155.5843\n",
      "Epoch 46/1000\n",
      "49590/49590 [==============================] - 2s 44us/sample - loss: 149.6754 - mean_squared_error: 149.6754 - val_loss: 150.6457 - val_mean_squared_error: 150.6456\n",
      "Epoch 47/1000\n",
      "49590/49590 [==============================] - 2s 49us/sample - loss: 149.0271 - mean_squared_error: 149.0271 - val_loss: 150.1836 - val_mean_squared_error: 150.1836\n",
      "Epoch 48/1000\n",
      "49590/49590 [==============================] - 2s 45us/sample - loss: 148.9678 - mean_squared_error: 148.9678 - val_loss: 151.3402 - val_mean_squared_error: 151.3402\n",
      "Epoch 49/1000\n",
      "49590/49590 [==============================] - 2s 49us/sample - loss: 148.8060 - mean_squared_error: 148.8060 - val_loss: 149.8382 - val_mean_squared_error: 149.8382\n",
      "Epoch 50/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 148.8692 - mean_squared_error: 148.8692 - val_loss: 150.7434 - val_mean_squared_error: 150.7434\n",
      "Epoch 51/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 148.5276 - mean_squared_error: 148.5275 - val_loss: 162.6799 - val_mean_squared_error: 162.6799\n",
      "Epoch 52/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 148.2619 - mean_squared_error: 148.2619 - val_loss: 149.2787 - val_mean_squared_error: 149.2787\n",
      "Epoch 53/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 148.0213 - mean_squared_error: 148.0213 - val_loss: 148.8918 - val_mean_squared_error: 148.8918\n",
      "Epoch 54/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 147.7342 - mean_squared_error: 147.7341 - val_loss: 149.6236 - val_mean_squared_error: 149.6235\n",
      "Epoch 55/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 148.8591 - mean_squared_error: 148.8591 - val_loss: 149.6788 - val_mean_squared_error: 149.6789\n",
      "Epoch 56/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 147.7779 - mean_squared_error: 147.7779 - val_loss: 148.7676 - val_mean_squared_error: 148.7676\n",
      "Epoch 57/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 147.1548 - mean_squared_error: 147.1547 - val_loss: 150.0645 - val_mean_squared_error: 150.0645\n",
      "Epoch 58/1000\n",
      "49590/49590 [==============================] - 2s 43us/sample - loss: 147.5948 - mean_squared_error: 147.5947 - val_loss: 148.9912 - val_mean_squared_error: 148.9912\n",
      "Epoch 59/1000\n",
      "49590/49590 [==============================] - 2s 44us/sample - loss: 147.4368 - mean_squared_error: 147.4368 - val_loss: 148.6562 - val_mean_squared_error: 148.6561\n",
      "Epoch 60/1000\n",
      "49590/49590 [==============================] - 2s 47us/sample - loss: 147.0920 - mean_squared_error: 147.0920 - val_loss: 149.2660 - val_mean_squared_error: 149.2660\n",
      "Epoch 61/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 146.8365 - mean_squared_error: 146.8365 - val_loss: 151.9844 - val_mean_squared_error: 151.9845\n",
      "Epoch 62/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 147.3670 - mean_squared_error: 147.3670 - val_loss: 154.0349 - val_mean_squared_error: 154.0349\n",
      "Epoch 63/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 146.9173 - mean_squared_error: 146.9173 - val_loss: 148.6410 - val_mean_squared_error: 148.6409\n",
      "Epoch 64/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 147.2428 - mean_squared_error: 147.2427 - val_loss: 149.0780 - val_mean_squared_error: 149.0781\n",
      "Epoch 65/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 147.4003 - mean_squared_error: 147.4003 - val_loss: 149.2116 - val_mean_squared_error: 149.2115\n",
      "Epoch 66/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 147.4541 - mean_squared_error: 147.4541 - val_loss: 150.5588 - val_mean_squared_error: 150.5588\n",
      "Epoch 67/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 146.4999 - mean_squared_error: 146.4998 - val_loss: 149.7403 - val_mean_squared_error: 149.7403\n",
      "Epoch 68/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 146.9701 - mean_squared_error: 146.9701 - val_loss: 149.0845 - val_mean_squared_error: 149.0845\n",
      "Epoch 69/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 146.6056 - mean_squared_error: 146.6055 - val_loss: 149.7888 - val_mean_squared_error: 149.7888\n",
      "Epoch 70/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 146.1972 - mean_squared_error: 146.1972 - val_loss: 148.2329 - val_mean_squared_error: 148.2329\n",
      "Epoch 71/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 147.2263 - mean_squared_error: 147.2263 - val_loss: 148.6056 - val_mean_squared_error: 148.6056\n",
      "Epoch 72/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 147.0622 - mean_squared_error: 147.0621 - val_loss: 148.7782 - val_mean_squared_error: 148.7782\n",
      "Epoch 73/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 146.4063 - mean_squared_error: 146.4064 - val_loss: 147.7014 - val_mean_squared_error: 147.7014s - loss: 146\n",
      "Epoch 74/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 146.2229 - mean_squared_error: 146.2229 - val_loss: 149.8223 - val_mean_squared_error: 149.8222\n",
      "Epoch 75/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 146.2410 - mean_squared_error: 146.2410 - val_loss: 148.9662 - val_mean_squared_error: 148.9662\n",
      "Epoch 76/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 145.8764 - mean_squared_error: 145.8764 - val_loss: 148.5229 - val_mean_squared_error: 148.5229\n",
      "Epoch 77/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 146.2576 - mean_squared_error: 146.2576 - val_loss: 147.7768 - val_mean_squared_error: 147.7767\n",
      "Epoch 78/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 146.0237 - mean_squared_error: 146.0238 - val_loss: 148.6052 - val_mean_squared_error: 148.6052\n",
      "Epoch 79/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 145.9148 - mean_squared_error: 145.9148 - val_loss: 147.7776 - val_mean_squared_error: 147.7776\n",
      "Epoch 80/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 145.8768 - mean_squared_error: 145.8769 - val_loss: 147.2988 - val_mean_squared_error: 147.2988\n",
      "Epoch 81/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 145.6551 - mean_squared_error: 145.6552 - val_loss: 149.2316 - val_mean_squared_error: 149.2316\n",
      "Epoch 82/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 145.9782 - mean_squared_error: 145.9781 - val_loss: 148.1096 - val_mean_squared_error: 148.1096\n",
      "Epoch 83/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 145.5210 - mean_squared_error: 145.5210 - val_loss: 148.6197 - val_mean_squared_error: 148.6196\n",
      "Epoch 84/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 145.1300 - mean_squared_error: 145.1300 - val_loss: 149.1858 - val_mean_squared_error: 149.1857\n",
      "Epoch 85/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 145.0701 - mean_squared_error: 145.0701 - val_loss: 147.1473 - val_mean_squared_error: 147.1473\n",
      "Epoch 86/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 146.0510 - mean_squared_error: 146.0509 - val_loss: 149.8203 - val_mean_squared_error: 149.8204\n",
      "Epoch 87/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 145.1932 - mean_squared_error: 145.1933 - val_loss: 147.3767 - val_mean_squared_error: 147.3767\n",
      "Epoch 88/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 144.9665 - mean_squared_error: 144.9665 - val_loss: 150.1453 - val_mean_squared_error: 150.1453\n",
      "Epoch 89/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 144.5969 - mean_squared_error: 144.5969 - val_loss: 148.3629 - val_mean_squared_error: 148.3628\n",
      "Epoch 90/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 2s 41us/sample - loss: 144.9718 - mean_squared_error: 144.9718 - val_loss: 146.7529 - val_mean_squared_error: 146.7528\n",
      "Epoch 91/1000\n",
      "49590/49590 [==============================] - 2s 45us/sample - loss: 144.9027 - mean_squared_error: 144.9027 - val_loss: 146.6388 - val_mean_squared_error: 146.6389\n",
      "Epoch 92/1000\n",
      "49590/49590 [==============================] - 2s 43us/sample - loss: 143.9533 - mean_squared_error: 143.9533 - val_loss: 147.1598 - val_mean_squared_error: 147.1597\n",
      "Epoch 93/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 143.8178 - mean_squared_error: 143.8178 - val_loss: 146.0659 - val_mean_squared_error: 146.0658\n",
      "Epoch 94/1000\n",
      "49590/49590 [==============================] - 2s 49us/sample - loss: 143.9536 - mean_squared_error: 143.9537 - val_loss: 146.2225 - val_mean_squared_error: 146.2225\n",
      "Epoch 95/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 143.5499 - mean_squared_error: 143.5500 - val_loss: 148.4219 - val_mean_squared_error: 148.4219\n",
      "Epoch 96/1000\n",
      "49590/49590 [==============================] - 2s 50us/sample - loss: 143.5733 - mean_squared_error: 143.5732 - val_loss: 147.6419 - val_mean_squared_error: 147.6419\n",
      "Epoch 97/1000\n",
      "49590/49590 [==============================] - 3s 55us/sample - loss: 143.4842 - mean_squared_error: 143.4842 - val_loss: 149.5538 - val_mean_squared_error: 149.5538\n",
      "Epoch 98/1000\n",
      "49590/49590 [==============================] - 2s 46us/sample - loss: 143.6613 - mean_squared_error: 143.6613 - val_loss: 154.1434 - val_mean_squared_error: 154.1434\n",
      "Epoch 99/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 142.9419 - mean_squared_error: 142.9419 - val_loss: 146.4414 - val_mean_squared_error: 146.4414\n",
      "Epoch 100/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 142.4351 - mean_squared_error: 142.4350 - val_loss: 147.0851 - val_mean_squared_error: 147.0851\n",
      "Epoch 101/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 142.7944 - mean_squared_error: 142.7944 - val_loss: 146.8547 - val_mean_squared_error: 146.8547\n",
      "Epoch 102/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 142.6035 - mean_squared_error: 142.6035 - val_loss: 146.2133 - val_mean_squared_error: 146.2133\n",
      "Epoch 103/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 142.3511 - mean_squared_error: 142.3512 - val_loss: 145.3028 - val_mean_squared_error: 145.3028\n",
      "Epoch 104/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 142.3594 - mean_squared_error: 142.3594 - val_loss: 146.5676 - val_mean_squared_error: 146.5677\n",
      "Epoch 105/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 142.0048 - mean_squared_error: 142.0049 - val_loss: 146.3873 - val_mean_squared_error: 146.3873\n",
      "Epoch 106/1000\n",
      "49590/49590 [==============================] - 2s 47us/sample - loss: 141.9306 - mean_squared_error: 141.9306 - val_loss: 146.1108 - val_mean_squared_error: 146.1108\n",
      "Epoch 107/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 141.9156 - mean_squared_error: 141.9155 - val_loss: 146.1433 - val_mean_squared_error: 146.1433\n",
      "Epoch 108/1000\n",
      "49590/49590 [==============================] - 2s 50us/sample - loss: 141.3957 - mean_squared_error: 141.3957 - val_loss: 145.3339 - val_mean_squared_error: 145.3339\n",
      "Epoch 109/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 141.8356 - mean_squared_error: 141.8356 - val_loss: 146.1030 - val_mean_squared_error: 146.1030\n",
      "Epoch 110/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 141.2632 - mean_squared_error: 141.2632 - val_loss: 145.4182 - val_mean_squared_error: 145.4182\n",
      "Epoch 111/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 141.3012 - mean_squared_error: 141.3012 - val_loss: 145.2664 - val_mean_squared_error: 145.2664\n",
      "Epoch 112/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 141.8490 - mean_squared_error: 141.8490 - val_loss: 144.3646 - val_mean_squared_error: 144.3646\n",
      "Epoch 113/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 141.5702 - mean_squared_error: 141.5702 - val_loss: 144.3932 - val_mean_squared_error: 144.3932\n",
      "Epoch 114/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 141.6711 - mean_squared_error: 141.6710 - val_loss: 144.0760 - val_mean_squared_error: 144.0760\n",
      "Epoch 115/1000\n",
      "49590/49590 [==============================] - 2s 45us/sample - loss: 140.7829 - mean_squared_error: 140.7830 - val_loss: 145.2148 - val_mean_squared_error: 145.2148\n",
      "Epoch 116/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 140.7930 - mean_squared_error: 140.7930 - val_loss: 146.5754 - val_mean_squared_error: 146.5754\n",
      "Epoch 117/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 140.4006 - mean_squared_error: 140.4005 - val_loss: 144.1800 - val_mean_squared_error: 144.1800\n",
      "Epoch 118/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 140.6660 - mean_squared_error: 140.6660 - val_loss: 147.5275 - val_mean_squared_error: 147.5275\n",
      "Epoch 119/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 140.5696 - mean_squared_error: 140.5697 - val_loss: 144.0796 - val_mean_squared_error: 144.0796\n",
      "Epoch 120/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 140.0260 - mean_squared_error: 140.0261 - val_loss: 145.5523 - val_mean_squared_error: 145.5524\n",
      "Epoch 121/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 140.3016 - mean_squared_error: 140.3016 - val_loss: 146.3193 - val_mean_squared_error: 146.3193\n",
      "Epoch 122/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 140.2550 - mean_squared_error: 140.2549 - val_loss: 144.1808 - val_mean_squared_error: 144.1808\n",
      "Epoch 123/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 140.5644 - mean_squared_error: 140.5643 - val_loss: 144.2074 - val_mean_squared_error: 144.2074\n",
      "Epoch 124/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 140.1796 - mean_squared_error: 140.1796 - val_loss: 143.9125 - val_mean_squared_error: 143.9126\n",
      "Epoch 125/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 140.3169 - mean_squared_error: 140.3169 - val_loss: 147.3832 - val_mean_squared_error: 147.3832\n",
      "Epoch 126/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 140.3547 - mean_squared_error: 140.3547 - val_loss: 145.1395 - val_mean_squared_error: 145.1395\n",
      "Epoch 127/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 140.5471 - mean_squared_error: 140.5471 - val_loss: 144.2444 - val_mean_squared_error: 144.2444\n",
      "Epoch 128/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 139.6433 - mean_squared_error: 139.6433 - val_loss: 143.8842 - val_mean_squared_error: 143.8841\n",
      "Epoch 129/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 140.0834 - mean_squared_error: 140.0834 - val_loss: 144.6479 - val_mean_squared_error: 144.6479\n",
      "Epoch 130/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 139.9244 - mean_squared_error: 139.9244 - val_loss: 146.0021 - val_mean_squared_error: 146.0021\n",
      "Epoch 131/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 139.7995 - mean_squared_error: 139.7995 - val_loss: 151.4921 - val_mean_squared_error: 151.4920\n",
      "Epoch 132/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 140.0506 - mean_squared_error: 140.0506 - val_loss: 144.2707 - val_mean_squared_error: 144.2707\n",
      "Epoch 133/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 139.1530 - mean_squared_error: 139.1530 - val_loss: 145.2848 - val_mean_squared_error: 145.2847\n",
      "Epoch 134/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 139.7324 - mean_squared_error: 139.7324 - val_loss: 143.2060 - val_mean_squared_error: 143.2060\n",
      "Epoch 135/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 139.2633 - mean_squared_error: 139.2633 - val_loss: 143.7533 - val_mean_squared_error: 143.7533\n",
      "Epoch 136/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 139.3087 - mean_squared_error: 139.3087 - val_loss: 143.3088 - val_mean_squared_error: 143.3088\n",
      "Epoch 137/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 139.3061 - mean_squared_error: 139.3060 - val_loss: 143.8355 - val_mean_squared_error: 143.8355\n",
      "Epoch 138/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 138.9439 - mean_squared_error: 138.9438 - val_loss: 144.1990 - val_mean_squared_error: 144.1990\n",
      "Epoch 139/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 139.5796 - mean_squared_error: 139.5796 - val_loss: 144.1852 - val_mean_squared_error: 144.1852\n",
      "Epoch 140/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 138.8737 - mean_squared_error: 138.8737 - val_loss: 145.2254 - val_mean_squared_error: 145.2255\n",
      "Epoch 141/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 138.8894 - mean_squared_error: 138.8895 - val_loss: 143.7516 - val_mean_squared_error: 143.7516\n",
      "Epoch 142/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 139.0303 - mean_squared_error: 139.0303 - val_loss: 144.0082 - val_mean_squared_error: 144.0082\n",
      "Epoch 143/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 138.8492 - mean_squared_error: 138.8493 - val_loss: 146.6711 - val_mean_squared_error: 146.6711\n",
      "Epoch 144/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 139.1139 - mean_squared_error: 139.1139 - val_loss: 145.6342 - val_mean_squared_error: 145.6342\n",
      "Epoch 145/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 138.9187 - mean_squared_error: 138.9186 - val_loss: 143.0820 - val_mean_squared_error: 143.0821\n",
      "Epoch 146/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 138.9050 - mean_squared_error: 138.9049 - val_loss: 146.5009 - val_mean_squared_error: 146.5009\n",
      "Epoch 147/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 138.2921 - mean_squared_error: 138.2922 - val_loss: 144.1631 - val_mean_squared_error: 144.1630\n",
      "Epoch 148/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 138.9007 - mean_squared_error: 138.9008 - val_loss: 142.6735 - val_mean_squared_error: 142.6735\n",
      "Epoch 149/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 138.4951 - mean_squared_error: 138.4951 - val_loss: 143.5700 - val_mean_squared_error: 143.5700\n",
      "Epoch 150/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 138.2034 - mean_squared_error: 138.2034 - val_loss: 142.8049 - val_mean_squared_error: 142.8049\n",
      "Epoch 151/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 138.7511 - mean_squared_error: 138.7511 - val_loss: 142.8348 - val_mean_squared_error: 142.8347\n",
      "Epoch 152/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 138.1331 - mean_squared_error: 138.1331 - val_loss: 146.1537 - val_mean_squared_error: 146.1536\n",
      "Epoch 153/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 137.9892 - mean_squared_error: 137.9892 - val_loss: 143.8005 - val_mean_squared_error: 143.8005\n",
      "Epoch 154/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 138.1443 - mean_squared_error: 138.1443 - val_loss: 142.7327 - val_mean_squared_error: 142.7327\n",
      "Epoch 155/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 137.9023 - mean_squared_error: 137.9024 - val_loss: 142.2147 - val_mean_squared_error: 142.2147\n",
      "Epoch 156/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 138.5340 - mean_squared_error: 138.5340 - val_loss: 145.1988 - val_mean_squared_error: 145.1987\n",
      "Epoch 157/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 138.5435 - mean_squared_error: 138.5435 - val_loss: 147.6281 - val_mean_squared_error: 147.6281\n",
      "Epoch 158/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 137.8891 - mean_squared_error: 137.8891 - val_loss: 143.0547 - val_mean_squared_error: 143.0546\n",
      "Epoch 159/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 138.0427 - mean_squared_error: 138.0426 - val_loss: 143.2144 - val_mean_squared_error: 143.2144\n",
      "Epoch 160/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 137.8747 - mean_squared_error: 137.8748 - val_loss: 143.2621 - val_mean_squared_error: 143.2621\n",
      "Epoch 161/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 138.3526 - mean_squared_error: 138.3526 - val_loss: 142.3647 - val_mean_squared_error: 142.3647\n",
      "Epoch 162/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 138.0084 - mean_squared_error: 138.0083 - val_loss: 143.2450 - val_mean_squared_error: 143.2450\n",
      "Epoch 163/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 137.5925 - mean_squared_error: 137.5924 - val_loss: 142.5234 - val_mean_squared_error: 142.5234\n",
      "Epoch 164/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 137.6128 - mean_squared_error: 137.6129 - val_loss: 142.4987 - val_mean_squared_error: 142.4987\n",
      "Epoch 165/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 137.6564 - mean_squared_error: 137.6564 - val_loss: 142.6624 - val_mean_squared_error: 142.6624\n",
      "Epoch 166/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 138.0432 - mean_squared_error: 138.0431 - val_loss: 143.4819 - val_mean_squared_error: 143.4818\n",
      "Epoch 167/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 137.3572 - mean_squared_error: 137.3572 - val_loss: 144.9932 - val_mean_squared_error: 144.9932\n",
      "Epoch 168/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 137.3945 - mean_squared_error: 137.3945 - val_loss: 143.9767 - val_mean_squared_error: 143.9767\n",
      "Epoch 169/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 137.7689 - mean_squared_error: 137.7690 - val_loss: 141.8148 - val_mean_squared_error: 141.8148\n",
      "Epoch 170/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 137.2560 - mean_squared_error: 137.2561 - val_loss: 149.4271 - val_mean_squared_error: 149.4271\n",
      "Epoch 171/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 137.7287 - mean_squared_error: 137.7287 - val_loss: 142.6259 - val_mean_squared_error: 142.6260\n",
      "Epoch 172/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 137.2755 - mean_squared_error: 137.2756 - val_loss: 142.2231 - val_mean_squared_error: 142.2232\n",
      "Epoch 173/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 137.1129 - mean_squared_error: 137.1129 - val_loss: 142.5834 - val_mean_squared_error: 142.5834\n",
      "Epoch 174/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 137.5115 - mean_squared_error: 137.5115 - val_loss: 142.8752 - val_mean_squared_error: 142.8752\n",
      "Epoch 175/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 137.0704 - mean_squared_error: 137.0704 - val_loss: 142.7872 - val_mean_squared_error: 142.7872\n",
      "Epoch 176/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 136.9297 - mean_squared_error: 136.9297 - val_loss: 145.4791 - val_mean_squared_error: 145.4791\n",
      "Epoch 177/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 137.1130 - mean_squared_error: 137.1130 - val_loss: 143.0400 - val_mean_squared_error: 143.0400\n",
      "Epoch 178/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 137.3304 - mean_squared_error: 137.3304 - val_loss: 143.8177 - val_mean_squared_error: 143.8177\n",
      "Epoch 179/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 136.8718 - mean_squared_error: 136.8718 - val_loss: 143.2548 - val_mean_squared_error: 143.2549\n",
      "Epoch 180/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 29us/sample - loss: 136.9488 - mean_squared_error: 136.9488 - val_loss: 143.2055 - val_mean_squared_error: 143.2055\n",
      "Epoch 181/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 136.8511 - mean_squared_error: 136.8511 - val_loss: 142.6247 - val_mean_squared_error: 142.6247\n",
      "Epoch 182/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 136.6410 - mean_squared_error: 136.6409 - val_loss: 144.8220 - val_mean_squared_error: 144.8220\n",
      "Epoch 183/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 136.6266 - mean_squared_error: 136.6266 - val_loss: 144.7115 - val_mean_squared_error: 144.7115\n",
      "Epoch 184/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 136.9028 - mean_squared_error: 136.9029 - val_loss: 142.3721 - val_mean_squared_error: 142.3721\n",
      "Epoch 185/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 136.9841 - mean_squared_error: 136.9841 - val_loss: 142.2637 - val_mean_squared_error: 142.2636\n",
      "Epoch 186/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 136.5943 - mean_squared_error: 136.5942 - val_loss: 145.5812 - val_mean_squared_error: 145.5812\n",
      "Epoch 187/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 136.9509 - mean_squared_error: 136.9509 - val_loss: 142.1590 - val_mean_squared_error: 142.1590\n",
      "Epoch 188/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 136.4217 - mean_squared_error: 136.4216 - val_loss: 143.0999 - val_mean_squared_error: 143.0998\n",
      "Epoch 189/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 136.1724 - mean_squared_error: 136.1724 - val_loss: 144.4515 - val_mean_squared_error: 144.4515\n",
      "Epoch 190/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 136.7301 - mean_squared_error: 136.7301 - val_loss: 144.7015 - val_mean_squared_error: 144.7015\n",
      "Epoch 191/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 136.4181 - mean_squared_error: 136.4182 - val_loss: 143.1255 - val_mean_squared_error: 143.1255\n",
      "Epoch 192/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 136.4545 - mean_squared_error: 136.4545 - val_loss: 142.8981 - val_mean_squared_error: 142.8982\n",
      "Epoch 193/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 136.2193 - mean_squared_error: 136.2194 - val_loss: 142.1391 - val_mean_squared_error: 142.1391\n",
      "Epoch 194/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 136.3116 - mean_squared_error: 136.3116 - val_loss: 142.9167 - val_mean_squared_error: 142.9167\n",
      "Epoch 195/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 136.0855 - mean_squared_error: 136.0855 - val_loss: 144.4332 - val_mean_squared_error: 144.4332\n",
      "Epoch 196/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 136.4965 - mean_squared_error: 136.4966 - val_loss: 142.7214 - val_mean_squared_error: 142.7214\n",
      "Epoch 197/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 136.2401 - mean_squared_error: 136.2401 - val_loss: 142.1712 - val_mean_squared_error: 142.1712\n",
      "Epoch 198/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 135.9135 - mean_squared_error: 135.9135 - val_loss: 142.6092 - val_mean_squared_error: 142.6092\n",
      "Epoch 199/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 136.4704 - mean_squared_error: 136.4705 - val_loss: 142.5061 - val_mean_squared_error: 142.5060\n",
      "Epoch 200/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 136.1717 - mean_squared_error: 136.1717 - val_loss: 142.1567 - val_mean_squared_error: 142.1567\n",
      "Epoch 201/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 135.7339 - mean_squared_error: 135.7338 - val_loss: 142.5582 - val_mean_squared_error: 142.5583\n",
      "Epoch 202/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 135.9656 - mean_squared_error: 135.9657 - val_loss: 142.0530 - val_mean_squared_error: 142.0530\n",
      "Epoch 203/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 135.5063 - mean_squared_error: 135.5063 - val_loss: 146.0336 - val_mean_squared_error: 146.0335\n",
      "Epoch 204/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 135.8102 - mean_squared_error: 135.8102 - val_loss: 143.1945 - val_mean_squared_error: 143.1945\n",
      "Epoch 205/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 135.6216 - mean_squared_error: 135.6216 - val_loss: 142.6961 - val_mean_squared_error: 142.6960\n",
      "Epoch 206/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 136.0139 - mean_squared_error: 136.0139 - val_loss: 142.5855 - val_mean_squared_error: 142.5856\n",
      "Epoch 207/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 135.4699 - mean_squared_error: 135.4699 - val_loss: 142.3774 - val_mean_squared_error: 142.3774\n",
      "Epoch 208/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 135.4709 - mean_squared_error: 135.4709 - val_loss: 142.1137 - val_mean_squared_error: 142.1137\n",
      "Epoch 209/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 135.4690 - mean_squared_error: 135.4690 - val_loss: 143.5870 - val_mean_squared_error: 143.5870\n",
      "Epoch 210/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 135.3827 - mean_squared_error: 135.3827 - val_loss: 142.7027 - val_mean_squared_error: 142.7027\n",
      "Epoch 211/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 135.4613 - mean_squared_error: 135.4612 - val_loss: 142.4265 - val_mean_squared_error: 142.4265\n",
      "Epoch 212/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 135.5864 - mean_squared_error: 135.5864 - val_loss: 142.3655 - val_mean_squared_error: 142.3654\n",
      "Epoch 213/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 135.4513 - mean_squared_error: 135.4512 - val_loss: 141.9390 - val_mean_squared_error: 141.9389\n",
      "Epoch 214/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 135.1520 - mean_squared_error: 135.1520 - val_loss: 142.2360 - val_mean_squared_error: 142.2360\n",
      "Epoch 215/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 135.0790 - mean_squared_error: 135.0791 - val_loss: 142.1758 - val_mean_squared_error: 142.1758\n",
      "Epoch 216/1000\n",
      "49590/49590 [==============================] - 2s 43us/sample - loss: 135.0068 - mean_squared_error: 135.0068 - val_loss: 143.5237 - val_mean_squared_error: 143.5238\n",
      "Epoch 217/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 135.4078 - mean_squared_error: 135.4078 - val_loss: 143.0784 - val_mean_squared_error: 143.0784\n",
      "Epoch 218/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 135.0146 - mean_squared_error: 135.0146 - val_loss: 142.6126 - val_mean_squared_error: 142.6127\n",
      "Epoch 219/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 134.9425 - mean_squared_error: 134.9425 - val_loss: 142.8811 - val_mean_squared_error: 142.8811\n",
      "Epoch 220/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 135.1089 - mean_squared_error: 135.1089 - val_loss: 142.0531 - val_mean_squared_error: 142.0531\n",
      "Epoch 221/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 135.2346 - mean_squared_error: 135.2346 - val_loss: 142.0427 - val_mean_squared_error: 142.0427\n",
      "Epoch 222/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 134.7604 - mean_squared_error: 134.7604 - val_loss: 143.0784 - val_mean_squared_error: 143.0784\n",
      "Epoch 223/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 135.0229 - mean_squared_error: 135.0228 - val_loss: 141.5800 - val_mean_squared_error: 141.5801\n",
      "Epoch 224/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 135.3409 - mean_squared_error: 135.3409 - val_loss: 143.6908 - val_mean_squared_error: 143.6908\n",
      "Epoch 225/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 135.0192 - mean_squared_error: 135.0193 - val_loss: 141.5026 - val_mean_squared_error: 141.5026\n",
      "Epoch 226/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 134.6610 - mean_squared_error: 134.6610 - val_loss: 142.2609 - val_mean_squared_error: 142.2609\n",
      "Epoch 227/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 134.7765 - mean_squared_error: 134.7765 - val_loss: 142.4871 - val_mean_squared_error: 142.4871\n",
      "Epoch 228/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 134.8565 - mean_squared_error: 134.8565 - val_loss: 142.5128 - val_mean_squared_error: 142.5127\n",
      "Epoch 229/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 134.6819 - mean_squared_error: 134.6819 - val_loss: 142.3720 - val_mean_squared_error: 142.3720\n",
      "Epoch 230/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 134.0617 - mean_squared_error: 134.0618 - val_loss: 142.0482 - val_mean_squared_error: 142.0483\n",
      "Epoch 231/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 134.2145 - mean_squared_error: 134.2146 - val_loss: 143.3056 - val_mean_squared_error: 143.3056\n",
      "Epoch 232/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 134.3029 - mean_squared_error: 134.3029 - val_loss: 146.8658 - val_mean_squared_error: 146.8658\n",
      "Epoch 233/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 134.6860 - mean_squared_error: 134.6861 - val_loss: 145.2910 - val_mean_squared_error: 145.2910\n",
      "Epoch 234/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 134.2165 - mean_squared_error: 134.2166 - val_loss: 142.8585 - val_mean_squared_error: 142.8585\n",
      "Epoch 235/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 134.2825 - mean_squared_error: 134.2825 - val_loss: 143.1445 - val_mean_squared_error: 143.1445\n",
      "Epoch 236/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 134.2561 - mean_squared_error: 134.2560 - val_loss: 143.6767 - val_mean_squared_error: 143.6767\n",
      "Epoch 237/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 133.9381 - mean_squared_error: 133.9381 - val_loss: 142.1481 - val_mean_squared_error: 142.1481\n",
      "Epoch 238/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 133.9809 - mean_squared_error: 133.9810 - val_loss: 141.9650 - val_mean_squared_error: 141.9650\n",
      "Epoch 239/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 134.1350 - mean_squared_error: 134.1350 - val_loss: 142.5993 - val_mean_squared_error: 142.5992\n",
      "Epoch 240/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 134.0574 - mean_squared_error: 134.0574 - val_loss: 141.8880 - val_mean_squared_error: 141.8880\n",
      "Epoch 241/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 134.1511 - mean_squared_error: 134.1511 - val_loss: 143.0743 - val_mean_squared_error: 143.0743\n",
      "Epoch 242/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 134.1938 - mean_squared_error: 134.1938 - val_loss: 141.7725 - val_mean_squared_error: 141.7725\n",
      "Epoch 243/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 133.6697 - mean_squared_error: 133.6697 - val_loss: 143.8869 - val_mean_squared_error: 143.8869\n",
      "Epoch 244/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 134.0686 - mean_squared_error: 134.0686 - val_loss: 141.9774 - val_mean_squared_error: 141.9774\n",
      "Epoch 245/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 133.4520 - mean_squared_error: 133.4520 - val_loss: 142.7225 - val_mean_squared_error: 142.7225\n",
      "Epoch 246/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 133.3899 - mean_squared_error: 133.3899 - val_loss: 145.0066 - val_mean_squared_error: 145.0067\n",
      "Epoch 247/1000\n",
      "49590/49590 [==============================] - 2s 46us/sample - loss: 133.8517 - mean_squared_error: 133.8516 - val_loss: 142.6184 - val_mean_squared_error: 142.6184\n",
      "Epoch 248/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 133.8338 - mean_squared_error: 133.8338 - val_loss: 144.7730 - val_mean_squared_error: 144.7730\n",
      "Epoch 249/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 133.3366 - mean_squared_error: 133.3366 - val_loss: 143.1791 - val_mean_squared_error: 143.1791\n",
      "Epoch 250/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 133.7056 - mean_squared_error: 133.7056 - val_loss: 142.7707 - val_mean_squared_error: 142.7707\n",
      "Epoch 251/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 133.2245 - mean_squared_error: 133.2245 - val_loss: 141.3367 - val_mean_squared_error: 141.3367\n",
      "Epoch 252/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 133.7571 - mean_squared_error: 133.7571 - val_loss: 144.0981 - val_mean_squared_error: 144.0981\n",
      "Epoch 253/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 133.4385 - mean_squared_error: 133.4385 - val_loss: 141.9676 - val_mean_squared_error: 141.9676\n",
      "Epoch 254/1000\n",
      "49590/49590 [==============================] - 2s 45us/sample - loss: 133.2073 - mean_squared_error: 133.2074 - val_loss: 142.6262 - val_mean_squared_error: 142.6262\n",
      "Epoch 255/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 133.1709 - mean_squared_error: 133.1709 - val_loss: 142.1092 - val_mean_squared_error: 142.1092\n",
      "Epoch 256/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 132.8456 - mean_squared_error: 132.8456 - val_loss: 142.3849 - val_mean_squared_error: 142.3849\n",
      "Epoch 257/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 132.8977 - mean_squared_error: 132.8977 - val_loss: 141.8113 - val_mean_squared_error: 141.8113\n",
      "Epoch 258/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 132.9986 - mean_squared_error: 132.9987 - val_loss: 143.3033 - val_mean_squared_error: 143.3033\n",
      "Epoch 259/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 132.7324 - mean_squared_error: 132.7324 - val_loss: 142.5731 - val_mean_squared_error: 142.5730\n",
      "Epoch 260/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 133.1213 - mean_squared_error: 133.1213 - val_loss: 142.4042 - val_mean_squared_error: 142.4042\n",
      "Epoch 261/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 133.0801 - mean_squared_error: 133.0801 - val_loss: 141.6792 - val_mean_squared_error: 141.6793\n",
      "Epoch 262/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 132.7771 - mean_squared_error: 132.7771 - val_loss: 142.3942 - val_mean_squared_error: 142.3942\n",
      "Epoch 263/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 132.7566 - mean_squared_error: 132.7566 - val_loss: 142.4972 - val_mean_squared_error: 142.4971\n",
      "Epoch 264/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 132.4878 - mean_squared_error: 132.4879 - val_loss: 142.3321 - val_mean_squared_error: 142.3321\n",
      "Epoch 265/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 132.5514 - mean_squared_error: 132.5514 - val_loss: 143.9140 - val_mean_squared_error: 143.9140\n",
      "Epoch 266/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 132.9785 - mean_squared_error: 132.9785 - val_loss: 142.3586 - val_mean_squared_error: 142.3587\n",
      "Epoch 267/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 132.3939 - mean_squared_error: 132.3938 - val_loss: 143.1701 - val_mean_squared_error: 143.1702\n",
      "Epoch 268/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 132.7350 - mean_squared_error: 132.7350 - val_loss: 146.6472 - val_mean_squared_error: 146.6472\n",
      "Epoch 269/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 132.2805 - mean_squared_error: 132.2804 - val_loss: 144.9297 - val_mean_squared_error: 144.9297\n",
      "Epoch 270/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 28us/sample - loss: 132.5941 - mean_squared_error: 132.5941 - val_loss: 142.0463 - val_mean_squared_error: 142.0463\n",
      "Epoch 271/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 132.5052 - mean_squared_error: 132.5052 - val_loss: 141.9155 - val_mean_squared_error: 141.9156\n",
      "Epoch 272/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 132.2899 - mean_squared_error: 132.2899 - val_loss: 141.7361 - val_mean_squared_error: 141.7361\n",
      "Epoch 273/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 132.0030 - mean_squared_error: 132.0031 - val_loss: 142.5364 - val_mean_squared_error: 142.5364\n",
      "Epoch 274/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 131.9778 - mean_squared_error: 131.9778 - val_loss: 141.9124 - val_mean_squared_error: 141.9124\n",
      "Epoch 275/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 132.3955 - mean_squared_error: 132.3956 - val_loss: 143.2206 - val_mean_squared_error: 143.2206\n",
      "Epoch 276/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 132.1364 - mean_squared_error: 132.1364 - val_loss: 142.1552 - val_mean_squared_error: 142.1552\n",
      "Epoch 277/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 131.6144 - mean_squared_error: 131.6143 - val_loss: 147.3920 - val_mean_squared_error: 147.3920\n",
      "Epoch 278/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 131.9761 - mean_squared_error: 131.9760 - val_loss: 146.1663 - val_mean_squared_error: 146.1663\n",
      "Epoch 279/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 132.4159 - mean_squared_error: 132.4159 - val_loss: 142.3912 - val_mean_squared_error: 142.3912\n",
      "Epoch 280/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 131.6734 - mean_squared_error: 131.6733 - val_loss: 142.6099 - val_mean_squared_error: 142.6099\n",
      "Epoch 281/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 131.7608 - mean_squared_error: 131.7607 - val_loss: 142.7375 - val_mean_squared_error: 142.7375\n",
      "Epoch 282/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 131.8490 - mean_squared_error: 131.8489 - val_loss: 142.3289 - val_mean_squared_error: 142.3289\n",
      "Epoch 283/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 131.6848 - mean_squared_error: 131.6849 - val_loss: 142.3633 - val_mean_squared_error: 142.3633\n",
      "Epoch 284/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 131.6856 - mean_squared_error: 131.6855 - val_loss: 142.5854 - val_mean_squared_error: 142.5855\n",
      "Epoch 285/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 131.6941 - mean_squared_error: 131.6942 - val_loss: 141.8982 - val_mean_squared_error: 141.8983\n",
      "Epoch 286/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 131.4285 - mean_squared_error: 131.4285 - val_loss: 142.1894 - val_mean_squared_error: 142.1894\n",
      "Epoch 287/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 131.7874 - mean_squared_error: 131.7874 - val_loss: 142.6185 - val_mean_squared_error: 142.6185\n",
      "Epoch 288/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 131.4314 - mean_squared_error: 131.4315 - val_loss: 142.4393 - val_mean_squared_error: 142.4393\n",
      "Epoch 289/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 131.3712 - mean_squared_error: 131.3712 - val_loss: 142.8387 - val_mean_squared_error: 142.8387\n",
      "Epoch 290/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 131.6399 - mean_squared_error: 131.6399 - val_loss: 145.1669 - val_mean_squared_error: 145.1668\n",
      "Epoch 291/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 131.1657 - mean_squared_error: 131.1657 - val_loss: 145.5765 - val_mean_squared_error: 145.5765\n",
      "Epoch 292/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 131.3881 - mean_squared_error: 131.3882 - val_loss: 143.0014 - val_mean_squared_error: 143.0014\n",
      "Epoch 293/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 131.0421 - mean_squared_error: 131.0421 - val_loss: 143.6630 - val_mean_squared_error: 143.6629\n",
      "Epoch 294/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 131.1657 - mean_squared_error: 131.1656 - val_loss: 142.9695 - val_mean_squared_error: 142.9695\n",
      "Epoch 295/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 131.2956 - mean_squared_error: 131.2956 - val_loss: 141.6163 - val_mean_squared_error: 141.6162\n",
      "Epoch 296/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 131.8340 - mean_squared_error: 131.8340 - val_loss: 142.6775 - val_mean_squared_error: 142.6775\n",
      "Epoch 297/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 130.8346 - mean_squared_error: 130.8347 - val_loss: 145.5610 - val_mean_squared_error: 145.5610\n",
      "Epoch 298/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 131.2816 - mean_squared_error: 131.2816 - val_loss: 142.6217 - val_mean_squared_error: 142.6217\n",
      "Epoch 299/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 130.7272 - mean_squared_error: 130.7273 - val_loss: 145.7285 - val_mean_squared_error: 145.7285\n",
      "Epoch 300/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 131.1192 - mean_squared_error: 131.1192 - val_loss: 143.6840 - val_mean_squared_error: 143.6839\n",
      "Epoch 301/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 130.5531 - mean_squared_error: 130.5532 - val_loss: 143.2121 - val_mean_squared_error: 143.2122\n",
      "Epoch 302/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 130.9021 - mean_squared_error: 130.9021 - val_loss: 142.0435 - val_mean_squared_error: 142.0435\n",
      "Epoch 303/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 130.8008 - mean_squared_error: 130.8008 - val_loss: 143.2501 - val_mean_squared_error: 143.2502\n",
      "Epoch 304/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 130.5001 - mean_squared_error: 130.5001 - val_loss: 143.3139 - val_mean_squared_error: 143.3139\n",
      "Epoch 305/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 130.2818 - mean_squared_error: 130.2819 - val_loss: 143.8712 - val_mean_squared_error: 143.8712\n",
      "Epoch 306/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 130.5276 - mean_squared_error: 130.5276 - val_loss: 142.5076 - val_mean_squared_error: 142.5076\n",
      "Epoch 307/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 130.3839 - mean_squared_error: 130.3839 - val_loss: 146.3431 - val_mean_squared_error: 146.3431\n",
      "Epoch 308/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 130.2252 - mean_squared_error: 130.2252 - val_loss: 143.5401 - val_mean_squared_error: 143.5401\n",
      "Epoch 309/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 130.2513 - mean_squared_error: 130.2514 - val_loss: 142.5953 - val_mean_squared_error: 142.5953\n",
      "Epoch 310/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 130.6586 - mean_squared_error: 130.6585 - val_loss: 143.2167 - val_mean_squared_error: 143.2167\n",
      "Epoch 311/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 129.9774 - mean_squared_error: 129.9774 - val_loss: 143.7919 - val_mean_squared_error: 143.7918\n",
      "Epoch 312/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 130.1216 - mean_squared_error: 130.1216 - val_loss: 143.1701 - val_mean_squared_error: 143.1700\n",
      "Epoch 313/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 130.1494 - mean_squared_error: 130.1494 - val_loss: 143.4412 - val_mean_squared_error: 143.4412\n",
      "Epoch 314/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 130.1700 - mean_squared_error: 130.1700 - val_loss: 144.7468 - val_mean_squared_error: 144.7468\n",
      "Epoch 315/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 130.0096 - mean_squared_error: 130.0096 - val_loss: 144.1090 - val_mean_squared_error: 144.1091\n",
      "Epoch 316/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 129.6919 - mean_squared_error: 129.6919 - val_loss: 144.4675 - val_mean_squared_error: 144.4675\n",
      "Epoch 317/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 130.1650 - mean_squared_error: 130.1649 - val_loss: 144.3278 - val_mean_squared_error: 144.3278\n",
      "Epoch 318/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 129.6018 - mean_squared_error: 129.6019 - val_loss: 147.3287 - val_mean_squared_error: 147.3287\n",
      "Epoch 319/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 130.1797 - mean_squared_error: 130.1797 - val_loss: 145.2710 - val_mean_squared_error: 145.2710\n",
      "Epoch 320/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 129.5569 - mean_squared_error: 129.5570 - val_loss: 146.1653 - val_mean_squared_error: 146.1653\n",
      "Epoch 321/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 129.7486 - mean_squared_error: 129.7486 - val_loss: 144.3573 - val_mean_squared_error: 144.3574\n",
      "Epoch 322/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 129.7976 - mean_squared_error: 129.7976 - val_loss: 143.1940 - val_mean_squared_error: 143.1940\n",
      "Epoch 323/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 129.8573 - mean_squared_error: 129.8573 - val_loss: 143.0913 - val_mean_squared_error: 143.0912\n",
      "Epoch 324/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 129.4582 - mean_squared_error: 129.4583 - val_loss: 145.0104 - val_mean_squared_error: 145.0104\n",
      "Epoch 325/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 129.8213 - mean_squared_error: 129.8214 - val_loss: 144.9184 - val_mean_squared_error: 144.9184\n",
      "Epoch 326/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 129.4206 - mean_squared_error: 129.4205 - val_loss: 143.4412 - val_mean_squared_error: 143.4412\n",
      "Epoch 327/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 129.1662 - mean_squared_error: 129.1661 - val_loss: 143.5506 - val_mean_squared_error: 143.5507\n",
      "Epoch 328/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 129.7990 - mean_squared_error: 129.7991 - val_loss: 142.8555 - val_mean_squared_error: 142.8555\n",
      "Epoch 329/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 129.3718 - mean_squared_error: 129.3718 - val_loss: 144.2531 - val_mean_squared_error: 144.2530\n",
      "Epoch 330/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 129.2281 - mean_squared_error: 129.2281 - val_loss: 145.0201 - val_mean_squared_error: 145.0201\n",
      "Epoch 331/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 129.2558 - mean_squared_error: 129.2558 - val_loss: 145.7053 - val_mean_squared_error: 145.7053\n",
      "Epoch 332/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 129.2538 - mean_squared_error: 129.2538 - val_loss: 143.3849 - val_mean_squared_error: 143.3849\n",
      "Epoch 333/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 128.8865 - mean_squared_error: 128.8864 - val_loss: 146.2201 - val_mean_squared_error: 146.2201\n",
      "Epoch 334/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 129.5980 - mean_squared_error: 129.5980 - val_loss: 144.4841 - val_mean_squared_error: 144.4841\n",
      "Epoch 335/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 129.2164 - mean_squared_error: 129.2164 - val_loss: 147.0040 - val_mean_squared_error: 147.0039\n",
      "Epoch 336/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 129.3051 - mean_squared_error: 129.3052 - val_loss: 145.7431 - val_mean_squared_error: 145.7430\n",
      "Epoch 337/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 128.9568 - mean_squared_error: 128.9568 - val_loss: 143.2168 - val_mean_squared_error: 143.2168\n",
      "Epoch 338/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 129.1464 - mean_squared_error: 129.1464 - val_loss: 146.3997 - val_mean_squared_error: 146.3998\n",
      "Epoch 339/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 129.3230 - mean_squared_error: 129.3230 - val_loss: 147.7988 - val_mean_squared_error: 147.7988\n",
      "Epoch 340/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 128.8992 - mean_squared_error: 128.8993 - val_loss: 145.0834 - val_mean_squared_error: 145.0834\n",
      "Epoch 341/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 128.7386 - mean_squared_error: 128.7385 - val_loss: 143.4835 - val_mean_squared_error: 143.4835\n",
      "Epoch 342/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 128.6347 - mean_squared_error: 128.6348 - val_loss: 144.1853 - val_mean_squared_error: 144.1853\n",
      "Epoch 343/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 128.5334 - mean_squared_error: 128.5334 - val_loss: 145.3362 - val_mean_squared_error: 145.3362\n",
      "Epoch 344/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 128.5236 - mean_squared_error: 128.5236 - val_loss: 145.5477 - val_mean_squared_error: 145.5477\n",
      "Epoch 345/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 128.7959 - mean_squared_error: 128.7959 - val_loss: 142.8539 - val_mean_squared_error: 142.8539\n",
      "Epoch 346/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 128.7425 - mean_squared_error: 128.7426 - val_loss: 143.6215 - val_mean_squared_error: 143.6215\n",
      "Epoch 347/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 128.1702 - mean_squared_error: 128.1702 - val_loss: 144.9264 - val_mean_squared_error: 144.9264\n",
      "Epoch 348/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 128.1038 - mean_squared_error: 128.1038 - val_loss: 145.8589 - val_mean_squared_error: 145.8589\n",
      "Epoch 349/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 128.1840 - mean_squared_error: 128.1841 - val_loss: 143.7583 - val_mean_squared_error: 143.7582\n",
      "Epoch 350/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 128.0054 - mean_squared_error: 128.0054 - val_loss: 143.9712 - val_mean_squared_error: 143.9712\n",
      "Epoch 351/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 128.3215 - mean_squared_error: 128.3215 - val_loss: 144.3895 - val_mean_squared_error: 144.3896\n",
      "Epoch 352/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 128.4176 - mean_squared_error: 128.4177 - val_loss: 143.1700 - val_mean_squared_error: 143.1700\n",
      "Epoch 353/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 128.1995 - mean_squared_error: 128.1995 - val_loss: 144.2513 - val_mean_squared_error: 144.2513\n",
      "Epoch 354/1000\n",
      "49590/49590 [==============================] - 2s 44us/sample - loss: 128.1008 - mean_squared_error: 128.1008 - val_loss: 143.8651 - val_mean_squared_error: 143.8651\n",
      "Epoch 355/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 127.7130 - mean_squared_error: 127.7130 - val_loss: 145.2449 - val_mean_squared_error: 145.2449\n",
      "Epoch 356/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 127.8851 - mean_squared_error: 127.8851 - val_loss: 145.8266 - val_mean_squared_error: 145.8266\n",
      "Epoch 357/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 127.9721 - mean_squared_error: 127.9721 - val_loss: 145.1275 - val_mean_squared_error: 145.1275\n",
      "Epoch 358/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 128.1327 - mean_squared_error: 128.1327 - val_loss: 145.4527 - val_mean_squared_error: 145.4527\n",
      "Epoch 359/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 127.8262 - mean_squared_error: 127.8262 - val_loss: 144.8208 - val_mean_squared_error: 144.8207\n",
      "Epoch 360/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 2s 30us/sample - loss: 128.0028 - mean_squared_error: 128.0028 - val_loss: 145.0707 - val_mean_squared_error: 145.0707\n",
      "Epoch 361/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 127.8482 - mean_squared_error: 127.8482 - val_loss: 144.5542 - val_mean_squared_error: 144.5542\n",
      "Epoch 362/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 127.8641 - mean_squared_error: 127.8641 - val_loss: 144.2421 - val_mean_squared_error: 144.2421\n",
      "Epoch 363/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 127.6900 - mean_squared_error: 127.6899 - val_loss: 147.2797 - val_mean_squared_error: 147.2798\n",
      "Epoch 364/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 127.5717 - mean_squared_error: 127.5717 - val_loss: 146.7247 - val_mean_squared_error: 146.7247\n",
      "Epoch 365/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 127.2105 - mean_squared_error: 127.2105 - val_loss: 145.6444 - val_mean_squared_error: 145.6444\n",
      "Epoch 366/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 127.3562 - mean_squared_error: 127.3562 - val_loss: 144.4183 - val_mean_squared_error: 144.4182\n",
      "Epoch 367/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 127.7765 - mean_squared_error: 127.7765 - val_loss: 144.2760 - val_mean_squared_error: 144.2760\n",
      "Epoch 368/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 127.2808 - mean_squared_error: 127.2808 - val_loss: 145.5337 - val_mean_squared_error: 145.5337\n",
      "Epoch 369/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 127.1239 - mean_squared_error: 127.1240 - val_loss: 146.3906 - val_mean_squared_error: 146.3906\n",
      "Epoch 370/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 126.9587 - mean_squared_error: 126.9586 - val_loss: 145.0675 - val_mean_squared_error: 145.0675\n",
      "Epoch 371/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 126.8776 - mean_squared_error: 126.8776 - val_loss: 145.4740 - val_mean_squared_error: 145.4740\n",
      "Epoch 372/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 126.8279 - mean_squared_error: 126.8279 - val_loss: 145.6083 - val_mean_squared_error: 145.6083\n",
      "Epoch 373/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 127.3214 - mean_squared_error: 127.3213 - val_loss: 146.6255 - val_mean_squared_error: 146.6255\n",
      "Epoch 374/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 126.8210 - mean_squared_error: 126.8210 - val_loss: 146.1056 - val_mean_squared_error: 146.1056\n",
      "Epoch 375/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 127.1296 - mean_squared_error: 127.1297 - val_loss: 145.9007 - val_mean_squared_error: 145.9007\n",
      "Epoch 376/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 126.9428 - mean_squared_error: 126.9428 - val_loss: 144.6124 - val_mean_squared_error: 144.6124\n",
      "Epoch 377/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 126.7098 - mean_squared_error: 126.7097 - val_loss: 144.3938 - val_mean_squared_error: 144.3937\n",
      "Epoch 378/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 126.6435 - mean_squared_error: 126.6435 - val_loss: 145.9932 - val_mean_squared_error: 145.9932\n",
      "Epoch 379/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 126.6581 - mean_squared_error: 126.6582 - val_loss: 144.0364 - val_mean_squared_error: 144.0363\n",
      "Epoch 380/1000\n",
      "49590/49590 [==============================] - 3s 54us/sample - loss: 126.5022 - mean_squared_error: 126.5022 - val_loss: 143.5719 - val_mean_squared_error: 143.5719\n",
      "Epoch 381/1000\n",
      "49590/49590 [==============================] - 2s 45us/sample - loss: 126.7386 - mean_squared_error: 126.7386 - val_loss: 143.9728 - val_mean_squared_error: 143.9727\n",
      "Epoch 382/1000\n",
      "49590/49590 [==============================] - 2s 44us/sample - loss: 126.6903 - mean_squared_error: 126.6904 - val_loss: 145.3840 - val_mean_squared_error: 145.3840\n",
      "Epoch 383/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 126.6723 - mean_squared_error: 126.6722 - val_loss: 145.5509 - val_mean_squared_error: 145.5508\n",
      "Epoch 384/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 126.8717 - mean_squared_error: 126.8717 - val_loss: 144.4145 - val_mean_squared_error: 144.4145\n",
      "Epoch 385/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 126.2234 - mean_squared_error: 126.2234 - val_loss: 146.4610 - val_mean_squared_error: 146.4610\n",
      "Epoch 386/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 126.1665 - mean_squared_error: 126.1665 - val_loss: 145.6680 - val_mean_squared_error: 145.6680\n",
      "Epoch 387/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 126.0408 - mean_squared_error: 126.0408 - val_loss: 145.3430 - val_mean_squared_error: 145.3430\n",
      "Epoch 388/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 126.0900 - mean_squared_error: 126.0900 - val_loss: 145.9499 - val_mean_squared_error: 145.9500\n",
      "Epoch 389/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 126.2021 - mean_squared_error: 126.2020 - val_loss: 145.3950 - val_mean_squared_error: 145.3950\n",
      "Epoch 390/1000\n",
      "49590/49590 [==============================] - 2s 44us/sample - loss: 126.2411 - mean_squared_error: 126.2412 - val_loss: 147.4074 - val_mean_squared_error: 147.4074\n",
      "Epoch 391/1000\n",
      "49590/49590 [==============================] - 2s 47us/sample - loss: 126.4156 - mean_squared_error: 126.4156 - val_loss: 146.7611 - val_mean_squared_error: 146.7611\n",
      "Epoch 392/1000\n",
      "49590/49590 [==============================] - 2s 44us/sample - loss: 126.1816 - mean_squared_error: 126.1817 - val_loss: 148.6401 - val_mean_squared_error: 148.6401\n",
      "Epoch 393/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 126.0771 - mean_squared_error: 126.0771 - val_loss: 145.7649 - val_mean_squared_error: 145.7649\n",
      "Epoch 394/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 126.2157 - mean_squared_error: 126.2157 - val_loss: 144.5131 - val_mean_squared_error: 144.5131\n",
      "Epoch 395/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 125.9185 - mean_squared_error: 125.9185 - val_loss: 146.1026 - val_mean_squared_error: 146.1026\n",
      "Epoch 396/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 125.7395 - mean_squared_error: 125.7395 - val_loss: 144.2428 - val_mean_squared_error: 144.2428\n",
      "Epoch 397/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 126.1432 - mean_squared_error: 126.1432 - val_loss: 145.3289 - val_mean_squared_error: 145.3289\n",
      "Epoch 398/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 126.0600 - mean_squared_error: 126.0600 - val_loss: 146.1099 - val_mean_squared_error: 146.1098\n",
      "Epoch 399/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 125.4348 - mean_squared_error: 125.4348 - val_loss: 144.6859 - val_mean_squared_error: 144.6859\n",
      "Epoch 400/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 125.5050 - mean_squared_error: 125.5050 - val_loss: 146.1068 - val_mean_squared_error: 146.1068\n",
      "Epoch 401/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 125.8333 - mean_squared_error: 125.8333 - val_loss: 148.0640 - val_mean_squared_error: 148.0641\n",
      "Epoch 402/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 125.6420 - mean_squared_error: 125.6420 - val_loss: 148.2105 - val_mean_squared_error: 148.2105\n",
      "Epoch 403/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 125.5220 - mean_squared_error: 125.5220 - val_loss: 146.7265 - val_mean_squared_error: 146.7264\n",
      "Epoch 404/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 125.3720 - mean_squared_error: 125.3719 - val_loss: 146.7951 - val_mean_squared_error: 146.7951\n",
      "Epoch 405/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 125.2598 - mean_squared_error: 125.2598 - val_loss: 145.5378 - val_mean_squared_error: 145.5378\n",
      "Epoch 406/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 125.0888 - mean_squared_error: 125.0888 - val_loss: 146.2271 - val_mean_squared_error: 146.2272\n",
      "Epoch 407/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 125.4346 - mean_squared_error: 125.4345 - val_loss: 146.9108 - val_mean_squared_error: 146.9109\n",
      "Epoch 408/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 124.9389 - mean_squared_error: 124.9389 - val_loss: 147.0307 - val_mean_squared_error: 147.0306\n",
      "Epoch 409/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 125.3576 - mean_squared_error: 125.3575 - val_loss: 146.2578 - val_mean_squared_error: 146.2578\n",
      "Epoch 410/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 125.1149 - mean_squared_error: 125.1150 - val_loss: 147.8831 - val_mean_squared_error: 147.8831\n",
      "Epoch 411/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 125.0837 - mean_squared_error: 125.0837 - val_loss: 148.0621 - val_mean_squared_error: 148.0621\n",
      "Epoch 412/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 124.7609 - mean_squared_error: 124.7609 - val_loss: 145.9852 - val_mean_squared_error: 145.9852\n",
      "Epoch 413/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 124.7612 - mean_squared_error: 124.7613 - val_loss: 147.8794 - val_mean_squared_error: 147.8794\n",
      "Epoch 414/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 125.1758 - mean_squared_error: 125.1758 - val_loss: 150.3229 - val_mean_squared_error: 150.3229\n",
      "Epoch 415/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 124.6884 - mean_squared_error: 124.6883 - val_loss: 146.0307 - val_mean_squared_error: 146.0307\n",
      "Epoch 416/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 124.6418 - mean_squared_error: 124.6418 - val_loss: 147.3803 - val_mean_squared_error: 147.3803\n",
      "Epoch 417/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 124.6078 - mean_squared_error: 124.6077 - val_loss: 146.9921 - val_mean_squared_error: 146.9921\n",
      "Epoch 418/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 124.8658 - mean_squared_error: 124.8658 - val_loss: 147.8582 - val_mean_squared_error: 147.8582\n",
      "Epoch 419/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 124.8683 - mean_squared_error: 124.8683 - val_loss: 147.0302 - val_mean_squared_error: 147.0302\n",
      "Epoch 420/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 124.9638 - mean_squared_error: 124.9639 - val_loss: 146.7276 - val_mean_squared_error: 146.7276\n",
      "Epoch 421/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 124.5301 - mean_squared_error: 124.5301 - val_loss: 146.1080 - val_mean_squared_error: 146.1079\n",
      "Epoch 422/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 124.8545 - mean_squared_error: 124.8545 - val_loss: 146.3479 - val_mean_squared_error: 146.3479\n",
      "Epoch 423/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 124.2026 - mean_squared_error: 124.2026 - val_loss: 147.1168 - val_mean_squared_error: 147.1167\n",
      "Epoch 424/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 124.1618 - mean_squared_error: 124.1618 - val_loss: 148.1807 - val_mean_squared_error: 148.1806\n",
      "Epoch 425/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 124.4669 - mean_squared_error: 124.4669 - val_loss: 148.4404 - val_mean_squared_error: 148.4405\n",
      "Epoch 426/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 124.0654 - mean_squared_error: 124.0654 - val_loss: 147.3814 - val_mean_squared_error: 147.3814\n",
      "Epoch 427/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 124.1223 - mean_squared_error: 124.1222 - val_loss: 147.4446 - val_mean_squared_error: 147.4446\n",
      "Epoch 428/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 124.3285 - mean_squared_error: 124.3285 - val_loss: 148.3414 - val_mean_squared_error: 148.3413\n",
      "Epoch 429/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 124.0233 - mean_squared_error: 124.0233 - val_loss: 148.1635 - val_mean_squared_error: 148.1635\n",
      "Epoch 430/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 124.1990 - mean_squared_error: 124.1990 - val_loss: 147.3887 - val_mean_squared_error: 147.3887\n",
      "Epoch 431/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 124.0116 - mean_squared_error: 124.0116 - val_loss: 147.9308 - val_mean_squared_error: 147.9307\n",
      "Epoch 432/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 124.2684 - mean_squared_error: 124.2684 - val_loss: 147.5111 - val_mean_squared_error: 147.5111\n",
      "Epoch 433/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 123.8892 - mean_squared_error: 123.8892 - val_loss: 147.0766 - val_mean_squared_error: 147.0766\n",
      "Epoch 434/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 123.7527 - mean_squared_error: 123.7528 - val_loss: 146.7593 - val_mean_squared_error: 146.7594\n",
      "Epoch 435/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 123.8964 - mean_squared_error: 123.8963 - val_loss: 149.2265 - val_mean_squared_error: 149.2264\n",
      "Epoch 436/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 124.0400 - mean_squared_error: 124.0400 - val_loss: 148.3457 - val_mean_squared_error: 148.3456\n",
      "Epoch 437/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 123.9740 - mean_squared_error: 123.9740 - val_loss: 146.9202 - val_mean_squared_error: 146.9202\n",
      "Epoch 438/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 123.3667 - mean_squared_error: 123.3667 - val_loss: 147.6698 - val_mean_squared_error: 147.6697\n",
      "Epoch 439/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 123.6931 - mean_squared_error: 123.6931 - val_loss: 147.0326 - val_mean_squared_error: 147.0326\n",
      "Epoch 440/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 123.3372 - mean_squared_error: 123.3372 - val_loss: 147.2041 - val_mean_squared_error: 147.2041\n",
      "Epoch 441/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 123.1972 - mean_squared_error: 123.1972 - val_loss: 149.1872 - val_mean_squared_error: 149.1872\n",
      "Epoch 442/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 123.2893 - mean_squared_error: 123.2893 - val_loss: 151.7179 - val_mean_squared_error: 151.7180\n",
      "Epoch 443/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 123.5678 - mean_squared_error: 123.5678 - val_loss: 146.8194 - val_mean_squared_error: 146.8194\n",
      "Epoch 444/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 122.9338 - mean_squared_error: 122.9338 - val_loss: 148.1352 - val_mean_squared_error: 148.1352\n",
      "Epoch 445/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 123.0100 - mean_squared_error: 123.0100 - val_loss: 147.7115 - val_mean_squared_error: 147.7115\n",
      "Epoch 446/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 122.9853 - mean_squared_error: 122.9853 - val_loss: 150.6376 - val_mean_squared_error: 150.6377\n",
      "Epoch 447/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 123.2349 - mean_squared_error: 123.2349 - val_loss: 148.4400 - val_mean_squared_error: 148.4401\n",
      "Epoch 448/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 122.9669 - mean_squared_error: 122.9670 - val_loss: 147.7816 - val_mean_squared_error: 147.7816\n",
      "Epoch 449/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 123.1734 - mean_squared_error: 123.1734 - val_loss: 147.5354 - val_mean_squared_error: 147.5354\n",
      "Epoch 450/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 28us/sample - loss: 123.1682 - mean_squared_error: 123.1682 - val_loss: 149.1330 - val_mean_squared_error: 149.1330\n",
      "Epoch 451/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 122.8955 - mean_squared_error: 122.8955 - val_loss: 147.8614 - val_mean_squared_error: 147.8613\n",
      "Epoch 452/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 123.0204 - mean_squared_error: 123.0204 - val_loss: 147.6934 - val_mean_squared_error: 147.6934\n",
      "Epoch 453/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 123.2802 - mean_squared_error: 123.2803 - val_loss: 151.2622 - val_mean_squared_error: 151.2622\n",
      "Epoch 454/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 123.0849 - mean_squared_error: 123.0848 - val_loss: 148.1669 - val_mean_squared_error: 148.1668\n",
      "Epoch 455/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 122.8855 - mean_squared_error: 122.8855 - val_loss: 149.3667 - val_mean_squared_error: 149.3666\n",
      "Epoch 456/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 122.7222 - mean_squared_error: 122.7222 - val_loss: 148.7320 - val_mean_squared_error: 148.7320\n",
      "Epoch 457/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 122.8144 - mean_squared_error: 122.8143 - val_loss: 150.5643 - val_mean_squared_error: 150.5643\n",
      "Epoch 458/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 122.9285 - mean_squared_error: 122.9285 - val_loss: 149.1198 - val_mean_squared_error: 149.1198\n",
      "Epoch 459/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 122.5125 - mean_squared_error: 122.5125 - val_loss: 148.9392 - val_mean_squared_error: 148.9392\n",
      "Epoch 460/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 122.4898 - mean_squared_error: 122.4898 - val_loss: 147.5591 - val_mean_squared_error: 147.5591\n",
      "Epoch 461/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 122.3833 - mean_squared_error: 122.3833 - val_loss: 147.4083 - val_mean_squared_error: 147.4083\n",
      "Epoch 462/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 122.4017 - mean_squared_error: 122.4017 - val_loss: 147.8701 - val_mean_squared_error: 147.8701\n",
      "Epoch 463/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 122.1204 - mean_squared_error: 122.1204 - val_loss: 150.0636 - val_mean_squared_error: 150.0636\n",
      "Epoch 464/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 122.7317 - mean_squared_error: 122.7317 - val_loss: 151.2026 - val_mean_squared_error: 151.2025\n",
      "Epoch 465/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 122.6213 - mean_squared_error: 122.6213 - val_loss: 148.2479 - val_mean_squared_error: 148.2479\n",
      "Epoch 466/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 122.3256 - mean_squared_error: 122.3256 - val_loss: 148.6066 - val_mean_squared_error: 148.6066\n",
      "Epoch 467/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 121.8739 - mean_squared_error: 121.8739 - val_loss: 149.0269 - val_mean_squared_error: 149.0269\n",
      "Epoch 468/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 122.0884 - mean_squared_error: 122.0885 - val_loss: 150.0443 - val_mean_squared_error: 150.0444\n",
      "Epoch 469/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 122.0349 - mean_squared_error: 122.0350 - val_loss: 148.6004 - val_mean_squared_error: 148.6004\n",
      "Epoch 470/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 122.0752 - mean_squared_error: 122.0752 - val_loss: 151.4263 - val_mean_squared_error: 151.4263\n",
      "Epoch 471/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 121.9082 - mean_squared_error: 121.9082 - val_loss: 148.9713 - val_mean_squared_error: 148.9714\n",
      "Epoch 472/1000\n",
      "49590/49590 [==============================] - 2s 48us/sample - loss: 121.9677 - mean_squared_error: 121.9678 - val_loss: 149.4153 - val_mean_squared_error: 149.4153\n",
      "Epoch 473/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 121.7819 - mean_squared_error: 121.7819 - val_loss: 149.7106 - val_mean_squared_error: 149.7105\n",
      "Epoch 474/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 121.7114 - mean_squared_error: 121.7113 - val_loss: 147.8922 - val_mean_squared_error: 147.8922\n",
      "Epoch 475/1000\n",
      "49590/49590 [==============================] - 2s 43us/sample - loss: 121.8475 - mean_squared_error: 121.8475 - val_loss: 148.6716 - val_mean_squared_error: 148.6716\n",
      "Epoch 476/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 121.5748 - mean_squared_error: 121.5749 - val_loss: 147.4932 - val_mean_squared_error: 147.4931\n",
      "Epoch 477/1000\n",
      "49590/49590 [==============================] - 2s 46us/sample - loss: 121.7949 - mean_squared_error: 121.7949 - val_loss: 149.3547 - val_mean_squared_error: 149.3547\n",
      "Epoch 478/1000\n",
      "49590/49590 [==============================] - 3s 52us/sample - loss: 121.7147 - mean_squared_error: 121.7147 - val_loss: 148.9735 - val_mean_squared_error: 148.9735\n",
      "Epoch 479/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 121.3497 - mean_squared_error: 121.3497 - val_loss: 148.3824 - val_mean_squared_error: 148.3823\n",
      "Epoch 480/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 121.6481 - mean_squared_error: 121.6481 - val_loss: 148.0567 - val_mean_squared_error: 148.0567\n",
      "Epoch 481/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 121.3424 - mean_squared_error: 121.3424 - val_loss: 152.1917 - val_mean_squared_error: 152.1917\n",
      "Epoch 482/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 121.2841 - mean_squared_error: 121.2842 - val_loss: 148.5700 - val_mean_squared_error: 148.5699\n",
      "Epoch 483/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 121.6130 - mean_squared_error: 121.6130 - val_loss: 148.2380 - val_mean_squared_error: 148.2380\n",
      "Epoch 484/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 121.3268 - mean_squared_error: 121.3268 - val_loss: 149.7197 - val_mean_squared_error: 149.7197\n",
      "Epoch 485/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 121.5163 - mean_squared_error: 121.5164 - val_loss: 148.6096 - val_mean_squared_error: 148.6096\n",
      "Epoch 486/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 120.9699 - mean_squared_error: 120.9699 - val_loss: 150.3979 - val_mean_squared_error: 150.3980\n",
      "Epoch 487/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 121.0042 - mean_squared_error: 121.0042 - val_loss: 151.4619 - val_mean_squared_error: 151.4619\n",
      "Epoch 488/1000\n",
      "49590/49590 [==============================] - 2s 45us/sample - loss: 121.0401 - mean_squared_error: 121.0400 - val_loss: 151.2009 - val_mean_squared_error: 151.2008120.8076 - mean_s\n",
      "Epoch 489/1000\n",
      "49590/49590 [==============================] - 3s 58us/sample - loss: 121.1153 - mean_squared_error: 121.1153 - val_loss: 149.7222 - val_mean_squared_error: 149.7222\n",
      "Epoch 490/1000\n",
      "49590/49590 [==============================] - 3s 61us/sample - loss: 121.1583 - mean_squared_error: 121.1583 - val_loss: 149.3577 - val_mean_squared_error: 149.3577\n",
      "Epoch 491/1000\n",
      "49590/49590 [==============================] - 2s 45us/sample - loss: 121.1313 - mean_squared_error: 121.1313 - val_loss: 150.7756 - val_mean_squared_error: 150.7757\n",
      "Epoch 492/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 120.6898 - mean_squared_error: 120.6897 - val_loss: 150.2984 - val_mean_squared_error: 150.2984\n",
      "Epoch 493/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 121.0660 - mean_squared_error: 121.0660 - val_loss: 148.7990 - val_mean_squared_error: 148.7990\n",
      "Epoch 494/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 120.9772 - mean_squared_error: 120.9772 - val_loss: 150.3642 - val_mean_squared_error: 150.3642\n",
      "Epoch 495/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 121.0423 - mean_squared_error: 121.0423 - val_loss: 151.0383 - val_mean_squared_error: 151.0383\n",
      "Epoch 496/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 120.7731 - mean_squared_error: 120.7732 - val_loss: 150.6101 - val_mean_squared_error: 150.6101\n",
      "Epoch 497/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 120.5321 - mean_squared_error: 120.5322 - val_loss: 149.3141 - val_mean_squared_error: 149.3141\n",
      "Epoch 498/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 120.8479 - mean_squared_error: 120.8479 - val_loss: 150.5653 - val_mean_squared_error: 150.5653\n",
      "Epoch 499/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 120.4816 - mean_squared_error: 120.4816 - val_loss: 148.6519 - val_mean_squared_error: 148.6519\n",
      "Epoch 500/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 120.7897 - mean_squared_error: 120.7897 - val_loss: 149.2393 - val_mean_squared_error: 149.2393\n",
      "Epoch 501/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 120.2963 - mean_squared_error: 120.2963 - val_loss: 150.8873 - val_mean_squared_error: 150.8873\n",
      "Epoch 502/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 121.0918 - mean_squared_error: 121.0918 - val_loss: 149.0193 - val_mean_squared_error: 149.0193\n",
      "Epoch 503/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 120.4380 - mean_squared_error: 120.4380 - val_loss: 149.0281 - val_mean_squared_error: 149.0281\n",
      "Epoch 504/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 120.0642 - mean_squared_error: 120.0642 - val_loss: 152.3965 - val_mean_squared_error: 152.3966\n",
      "Epoch 505/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 120.6346 - mean_squared_error: 120.6346 - val_loss: 151.2094 - val_mean_squared_error: 151.2094\n",
      "Epoch 506/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 120.6890 - mean_squared_error: 120.6889 - val_loss: 150.4898 - val_mean_squared_error: 150.4898\n",
      "Epoch 507/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 120.1194 - mean_squared_error: 120.1194 - val_loss: 149.3579 - val_mean_squared_error: 149.3580\n",
      "Epoch 508/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 119.9052 - mean_squared_error: 119.9052 - val_loss: 151.8418 - val_mean_squared_error: 151.8418\n",
      "Epoch 509/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 119.8906 - mean_squared_error: 119.8906 - val_loss: 151.7590 - val_mean_squared_error: 151.7590\n",
      "Epoch 510/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 120.1292 - mean_squared_error: 120.1293 - val_loss: 150.1505 - val_mean_squared_error: 150.1505\n",
      "Epoch 511/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 120.0279 - mean_squared_error: 120.0279 - val_loss: 151.7333 - val_mean_squared_error: 151.7333\n",
      "Epoch 512/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 119.7152 - mean_squared_error: 119.7152 - val_loss: 149.3472 - val_mean_squared_error: 149.3472\n",
      "Epoch 513/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 119.7820 - mean_squared_error: 119.7820 - val_loss: 152.9813 - val_mean_squared_error: 152.9813\n",
      "Epoch 514/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 120.2561 - mean_squared_error: 120.2561 - val_loss: 149.1582 - val_mean_squared_error: 149.1582\n",
      "Epoch 515/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 119.7217 - mean_squared_error: 119.7218 - val_loss: 148.8598 - val_mean_squared_error: 148.8598\n",
      "Epoch 516/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 120.1312 - mean_squared_error: 120.1312 - val_loss: 149.3129 - val_mean_squared_error: 149.3129\n",
      "Epoch 517/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 119.6409 - mean_squared_error: 119.6409 - val_loss: 150.5953 - val_mean_squared_error: 150.5953\n",
      "Epoch 518/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 119.7518 - mean_squared_error: 119.7518 - val_loss: 151.5670 - val_mean_squared_error: 151.5671\n",
      "Epoch 519/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 119.6275 - mean_squared_error: 119.6276 - val_loss: 150.4018 - val_mean_squared_error: 150.4018\n",
      "Epoch 520/1000\n",
      "49590/49590 [==============================] - 2s 43us/sample - loss: 119.8900 - mean_squared_error: 119.8900 - val_loss: 150.8537 - val_mean_squared_error: 150.8537\n",
      "Epoch 521/1000\n",
      "49590/49590 [==============================] - 3s 52us/sample - loss: 119.9358 - mean_squared_error: 119.9358 - val_loss: 149.4399 - val_mean_squared_error: 149.4399\n",
      "Epoch 522/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 119.4693 - mean_squared_error: 119.4693 - val_loss: 149.9029 - val_mean_squared_error: 149.9029\n",
      "Epoch 523/1000\n",
      "49590/49590 [==============================] - 2s 49us/sample - loss: 119.4936 - mean_squared_error: 119.4936 - val_loss: 151.4665 - val_mean_squared_error: 151.4665\n",
      "Epoch 524/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 119.4256 - mean_squared_error: 119.4256 - val_loss: 151.6703 - val_mean_squared_error: 151.6703\n",
      "Epoch 525/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 119.7850 - mean_squared_error: 119.7849 - val_loss: 149.3550 - val_mean_squared_error: 149.3551\n",
      "Epoch 526/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 119.3761 - mean_squared_error: 119.3761 - val_loss: 149.6958 - val_mean_squared_error: 149.6958\n",
      "Epoch 527/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 119.3601 - mean_squared_error: 119.3601 - val_loss: 150.7976 - val_mean_squared_error: 150.7976\n",
      "Epoch 528/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 119.1248 - mean_squared_error: 119.1248 - val_loss: 150.4060 - val_mean_squared_error: 150.4061\n",
      "Epoch 529/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 119.3672 - mean_squared_error: 119.3672 - val_loss: 150.0687 - val_mean_squared_error: 150.0686\n",
      "Epoch 530/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 119.7798 - mean_squared_error: 119.7799 - val_loss: 150.4247 - val_mean_squared_error: 150.4247\n",
      "Epoch 531/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 119.3009 - mean_squared_error: 119.3009 - val_loss: 151.7158 - val_mean_squared_error: 151.7159\n",
      "Epoch 532/1000\n",
      "49590/49590 [==============================] - 2s 50us/sample - loss: 119.2717 - mean_squared_error: 119.2716 - val_loss: 150.6507 - val_mean_squared_error: 150.6507\n",
      "Epoch 533/1000\n",
      "49590/49590 [==============================] - 2s 45us/sample - loss: 118.9993 - mean_squared_error: 118.9993 - val_loss: 149.4467 - val_mean_squared_error: 149.4467\n",
      "Epoch 534/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 119.1302 - mean_squared_error: 119.1302 - val_loss: 150.2138 - val_mean_squared_error: 150.2138\n",
      "Epoch 535/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 118.8783 - mean_squared_error: 118.8783 - val_loss: 151.6555 - val_mean_squared_error: 151.6555\n",
      "Epoch 536/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 118.9261 - mean_squared_error: 118.9261 - val_loss: 149.7489 - val_mean_squared_error: 149.7489\n",
      "Epoch 537/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 119.0125 - mean_squared_error: 119.0125 - val_loss: 149.6483 - val_mean_squared_error: 149.6483\n",
      "Epoch 538/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 118.8289 - mean_squared_error: 118.8289 - val_loss: 149.8230 - val_mean_squared_error: 149.8230\n",
      "Epoch 539/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 118.9425 - mean_squared_error: 118.9426 - val_loss: 149.6916 - val_mean_squared_error: 149.6916\n",
      "Epoch 540/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 30us/sample - loss: 118.4335 - mean_squared_error: 118.4335 - val_loss: 151.1965 - val_mean_squared_error: 151.1965\n",
      "Epoch 541/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 118.6753 - mean_squared_error: 118.6752 - val_loss: 152.4501 - val_mean_squared_error: 152.4501\n",
      "Epoch 542/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 118.8654 - mean_squared_error: 118.8654 - val_loss: 150.8341 - val_mean_squared_error: 150.8341\n",
      "Epoch 543/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 118.6550 - mean_squared_error: 118.6550 - val_loss: 151.0391 - val_mean_squared_error: 151.0391\n",
      "Epoch 544/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 119.0155 - mean_squared_error: 119.0155 - val_loss: 151.1912 - val_mean_squared_error: 151.1913\n",
      "Epoch 545/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 118.8968 - mean_squared_error: 118.8968 - val_loss: 152.5518 - val_mean_squared_error: 152.5517\n",
      "Epoch 546/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 118.6713 - mean_squared_error: 118.6713 - val_loss: 150.8449 - val_mean_squared_error: 150.8449\n",
      "Epoch 547/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 118.2983 - mean_squared_error: 118.2983 - val_loss: 150.8914 - val_mean_squared_error: 150.8914\n",
      "Epoch 548/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 118.3152 - mean_squared_error: 118.3152 - val_loss: 150.7410 - val_mean_squared_error: 150.7410\n",
      "Epoch 549/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 118.5277 - mean_squared_error: 118.5278 - val_loss: 150.6222 - val_mean_squared_error: 150.6222\n",
      "Epoch 550/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 118.2868 - mean_squared_error: 118.2867 - val_loss: 151.0960 - val_mean_squared_error: 151.0960\n",
      "Epoch 551/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 118.1774 - mean_squared_error: 118.1774 - val_loss: 151.9653 - val_mean_squared_error: 151.9653\n",
      "Epoch 552/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 118.4152 - mean_squared_error: 118.4152 - val_loss: 152.8275 - val_mean_squared_error: 152.8275\n",
      "Epoch 553/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 117.8920 - mean_squared_error: 117.8920 - val_loss: 150.8146 - val_mean_squared_error: 150.8147\n",
      "Epoch 554/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 118.3906 - mean_squared_error: 118.3906 - val_loss: 152.3183 - val_mean_squared_error: 152.3183\n",
      "Epoch 555/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 118.1196 - mean_squared_error: 118.1196 - val_loss: 150.5081 - val_mean_squared_error: 150.5081\n",
      "Epoch 556/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 117.9385 - mean_squared_error: 117.9385 - val_loss: 150.3697 - val_mean_squared_error: 150.3697\n",
      "Epoch 557/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 118.0712 - mean_squared_error: 118.0712 - val_loss: 152.0879 - val_mean_squared_error: 152.0879\n",
      "Epoch 558/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 118.3045 - mean_squared_error: 118.3044 - val_loss: 151.2736 - val_mean_squared_error: 151.2737\n",
      "Epoch 559/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 118.4322 - mean_squared_error: 118.4322 - val_loss: 150.4022 - val_mean_squared_error: 150.4023\n",
      "Epoch 560/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 117.9993 - mean_squared_error: 117.9993 - val_loss: 152.0306 - val_mean_squared_error: 152.0306\n",
      "Epoch 561/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 118.0081 - mean_squared_error: 118.0081 - val_loss: 152.4643 - val_mean_squared_error: 152.4643\n",
      "Epoch 562/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 117.8959 - mean_squared_error: 117.8959 - val_loss: 151.3346 - val_mean_squared_error: 151.3347\n",
      "Epoch 563/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 117.7213 - mean_squared_error: 117.7213 - val_loss: 152.0139 - val_mean_squared_error: 152.0139\n",
      "Epoch 564/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 117.7180 - mean_squared_error: 117.7179 - val_loss: 151.8414 - val_mean_squared_error: 151.8414\n",
      "Epoch 565/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 117.7573 - mean_squared_error: 117.7572 - val_loss: 151.6082 - val_mean_squared_error: 151.6083\n",
      "Epoch 566/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 117.7457 - mean_squared_error: 117.7457 - val_loss: 151.4501 - val_mean_squared_error: 151.4501\n",
      "Epoch 567/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 117.7338 - mean_squared_error: 117.7338 - val_loss: 150.8653 - val_mean_squared_error: 150.8652\n",
      "Epoch 568/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 117.6702 - mean_squared_error: 117.6703 - val_loss: 151.8689 - val_mean_squared_error: 151.8689\n",
      "Epoch 569/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 117.3746 - mean_squared_error: 117.3745 - val_loss: 152.3032 - val_mean_squared_error: 152.3032\n",
      "Epoch 570/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 117.5988 - mean_squared_error: 117.5987 - val_loss: 152.7360 - val_mean_squared_error: 152.7359\n",
      "Epoch 571/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 117.8521 - mean_squared_error: 117.8520 - val_loss: 152.4068 - val_mean_squared_error: 152.4068\n",
      "Epoch 572/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 117.6822 - mean_squared_error: 117.6822 - val_loss: 151.4050 - val_mean_squared_error: 151.4050\n",
      "Epoch 573/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 117.5680 - mean_squared_error: 117.5681 - val_loss: 151.4345 - val_mean_squared_error: 151.4345\n",
      "Epoch 574/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 117.6148 - mean_squared_error: 117.6148 - val_loss: 152.5137 - val_mean_squared_error: 152.5137\n",
      "Epoch 575/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 117.4506 - mean_squared_error: 117.4506 - val_loss: 151.1158 - val_mean_squared_error: 151.1158\n",
      "Epoch 576/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 117.0399 - mean_squared_error: 117.0400 - val_loss: 152.3413 - val_mean_squared_error: 152.3413\n",
      "Epoch 577/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 117.2374 - mean_squared_error: 117.2374 - val_loss: 153.2023 - val_mean_squared_error: 153.2023\n",
      "Epoch 578/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 117.2167 - mean_squared_error: 117.2167 - val_loss: 154.0463 - val_mean_squared_error: 154.0463\n",
      "Epoch 579/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 117.7601 - mean_squared_error: 117.7600 - val_loss: 152.4310 - val_mean_squared_error: 152.4311\n",
      "Epoch 580/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 118.0043 - mean_squared_error: 118.0043 - val_loss: 151.2753 - val_mean_squared_error: 151.2753\n",
      "Epoch 581/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 117.2890 - mean_squared_error: 117.2890 - val_loss: 150.6572 - val_mean_squared_error: 150.6572\n",
      "Epoch 582/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 117.1748 - mean_squared_error: 117.1748 - val_loss: 153.7122 - val_mean_squared_error: 153.7122\n",
      "Epoch 583/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 117.0489 - mean_squared_error: 117.0489 - val_loss: 153.0673 - val_mean_squared_error: 153.0672\n",
      "Epoch 584/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 117.0965 - mean_squared_error: 117.0967 - val_loss: 151.5618 - val_mean_squared_error: 151.5618\n",
      "Epoch 585/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 117.4034 - mean_squared_error: 117.4034 - val_loss: 152.1805 - val_mean_squared_error: 152.1805\n",
      "Epoch 586/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 117.1747 - mean_squared_error: 117.1746 - val_loss: 152.3458 - val_mean_squared_error: 152.3458\n",
      "Epoch 587/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 116.8277 - mean_squared_error: 116.8277 - val_loss: 152.3186 - val_mean_squared_error: 152.3186\n",
      "Epoch 588/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 117.0913 - mean_squared_error: 117.0913 - val_loss: 150.9509 - val_mean_squared_error: 150.9509\n",
      "Epoch 589/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 117.3807 - mean_squared_error: 117.3807 - val_loss: 152.0775 - val_mean_squared_error: 152.0775\n",
      "Epoch 590/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 116.9318 - mean_squared_error: 116.9318 - val_loss: 151.4578 - val_mean_squared_error: 151.4577\n",
      "Epoch 591/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 116.7502 - mean_squared_error: 116.7501 - val_loss: 153.3661 - val_mean_squared_error: 153.3661\n",
      "Epoch 592/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 116.8143 - mean_squared_error: 116.8143 - val_loss: 151.9472 - val_mean_squared_error: 151.9472\n",
      "Epoch 593/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 117.0415 - mean_squared_error: 117.0415 - val_loss: 150.5895 - val_mean_squared_error: 150.5895\n",
      "Epoch 594/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 116.8914 - mean_squared_error: 116.8914 - val_loss: 154.7670 - val_mean_squared_error: 154.7670\n",
      "Epoch 595/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 116.9095 - mean_squared_error: 116.9095 - val_loss: 152.4692 - val_mean_squared_error: 152.4692\n",
      "Epoch 596/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 116.4821 - mean_squared_error: 116.4821 - val_loss: 151.9489 - val_mean_squared_error: 151.9489\n",
      "Epoch 597/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 116.8421 - mean_squared_error: 116.8421 - val_loss: 154.2253 - val_mean_squared_error: 154.2253\n",
      "Epoch 598/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 116.4458 - mean_squared_error: 116.4458 - val_loss: 151.9546 - val_mean_squared_error: 151.9546\n",
      "Epoch 599/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 116.5836 - mean_squared_error: 116.5836 - val_loss: 152.3598 - val_mean_squared_error: 152.3598\n",
      "Epoch 600/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 117.1059 - mean_squared_error: 117.1059 - val_loss: 153.4676 - val_mean_squared_error: 153.4676\n",
      "Epoch 601/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 116.4364 - mean_squared_error: 116.4364 - val_loss: 152.1434 - val_mean_squared_error: 152.1434\n",
      "Epoch 602/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 116.2195 - mean_squared_error: 116.2194 - val_loss: 153.7119 - val_mean_squared_error: 153.7119\n",
      "Epoch 603/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 116.1834 - mean_squared_error: 116.1833 - val_loss: 153.1565 - val_mean_squared_error: 153.1565\n",
      "Epoch 604/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 116.3306 - mean_squared_error: 116.3306 - val_loss: 153.5166 - val_mean_squared_error: 153.5166\n",
      "Epoch 605/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 116.4737 - mean_squared_error: 116.4737 - val_loss: 152.7687 - val_mean_squared_error: 152.7687\n",
      "Epoch 606/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 116.3461 - mean_squared_error: 116.3462 - val_loss: 154.4013 - val_mean_squared_error: 154.4013\n",
      "Epoch 607/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 116.4205 - mean_squared_error: 116.4205 - val_loss: 152.3345 - val_mean_squared_error: 152.3345\n",
      "Epoch 608/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 116.1422 - mean_squared_error: 116.1422 - val_loss: 152.3003 - val_mean_squared_error: 152.3003\n",
      "Epoch 609/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 116.1968 - mean_squared_error: 116.1968 - val_loss: 151.7947 - val_mean_squared_error: 151.7947\n",
      "Epoch 610/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 116.1957 - mean_squared_error: 116.1958 - val_loss: 153.5761 - val_mean_squared_error: 153.5761\n",
      "Epoch 611/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 115.8197 - mean_squared_error: 115.8197 - val_loss: 152.1472 - val_mean_squared_error: 152.1472\n",
      "Epoch 612/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 115.6044 - mean_squared_error: 115.6044 - val_loss: 152.7233 - val_mean_squared_error: 152.7233\n",
      "Epoch 613/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 115.7993 - mean_squared_error: 115.7993 - val_loss: 152.5259 - val_mean_squared_error: 152.5259\n",
      "Epoch 614/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 115.7350 - mean_squared_error: 115.7350 - val_loss: 152.9407 - val_mean_squared_error: 152.9407\n",
      "Epoch 615/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 115.7603 - mean_squared_error: 115.7602 - val_loss: 154.4778 - val_mean_squared_error: 154.4778\n",
      "Epoch 616/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 115.8466 - mean_squared_error: 115.8466 - val_loss: 153.1059 - val_mean_squared_error: 153.1059\n",
      "Epoch 617/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 115.8745 - mean_squared_error: 115.8745 - val_loss: 153.7942 - val_mean_squared_error: 153.7941\n",
      "Epoch 618/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 116.0644 - mean_squared_error: 116.0644 - val_loss: 152.3996 - val_mean_squared_error: 152.3996\n",
      "Epoch 619/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 115.6952 - mean_squared_error: 115.6952 - val_loss: 153.4522 - val_mean_squared_error: 153.4522\n",
      "Epoch 620/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 115.5216 - mean_squared_error: 115.5215 - val_loss: 152.1576 - val_mean_squared_error: 152.1575\n",
      "Epoch 621/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 115.7684 - mean_squared_error: 115.7684 - val_loss: 155.8965 - val_mean_squared_error: 155.8965d_error: 115.65\n",
      "Epoch 622/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 115.9007 - mean_squared_error: 115.9007 - val_loss: 154.5284 - val_mean_squared_error: 154.5284\n",
      "Epoch 623/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 116.0985 - mean_squared_error: 116.0984 - val_loss: 154.9363 - val_mean_squared_error: 154.9363\n",
      "Epoch 624/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 115.7637 - mean_squared_error: 115.7637 - val_loss: 155.6967 - val_mean_squared_error: 155.6967\n",
      "Epoch 625/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 115.6734 - mean_squared_error: 115.6734 - val_loss: 153.6869 - val_mean_squared_error: 153.6869\n",
      "Epoch 626/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 115.3884 - mean_squared_error: 115.3884 - val_loss: 154.7411 - val_mean_squared_error: 154.7411\n",
      "Epoch 627/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 115.4755 - mean_squared_error: 115.4755 - val_loss: 154.4751 - val_mean_squared_error: 154.4751\n",
      "Epoch 628/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 115.5945 - mean_squared_error: 115.5944 - val_loss: 153.4862 - val_mean_squared_error: 153.4862\n",
      "Epoch 629/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 115.4405 - mean_squared_error: 115.4405 - val_loss: 152.6589 - val_mean_squared_error: 152.6589\n",
      "Epoch 630/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 30us/sample - loss: 115.2593 - mean_squared_error: 115.2592 - val_loss: 153.1487 - val_mean_squared_error: 153.1487\n",
      "Epoch 631/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 115.3801 - mean_squared_error: 115.3800 - val_loss: 153.5916 - val_mean_squared_error: 153.5916\n",
      "Epoch 632/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 115.5076 - mean_squared_error: 115.5076 - val_loss: 155.9644 - val_mean_squared_error: 155.9644\n",
      "Epoch 633/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 115.1516 - mean_squared_error: 115.1516 - val_loss: 153.4402 - val_mean_squared_error: 153.4402\n",
      "Epoch 634/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 115.2914 - mean_squared_error: 115.2913 - val_loss: 153.5923 - val_mean_squared_error: 153.5923\n",
      "Epoch 635/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 115.3194 - mean_squared_error: 115.3194 - val_loss: 153.5684 - val_mean_squared_error: 153.5685\n",
      "Epoch 636/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 115.1766 - mean_squared_error: 115.1767 - val_loss: 153.7163 - val_mean_squared_error: 153.7163\n",
      "Epoch 637/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 114.9567 - mean_squared_error: 114.9567 - val_loss: 154.2190 - val_mean_squared_error: 154.2189\n",
      "Epoch 638/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 115.3190 - mean_squared_error: 115.3190 - val_loss: 154.3227 - val_mean_squared_error: 154.3227\n",
      "Epoch 639/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 114.8113 - mean_squared_error: 114.8114 - val_loss: 153.8245 - val_mean_squared_error: 153.8244\n",
      "Epoch 640/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 115.0668 - mean_squared_error: 115.0668 - val_loss: 155.2595 - val_mean_squared_error: 155.2595\n",
      "Epoch 641/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 115.1781 - mean_squared_error: 115.1781 - val_loss: 154.3717 - val_mean_squared_error: 154.3718\n",
      "Epoch 642/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 115.0437 - mean_squared_error: 115.0437 - val_loss: 154.6634 - val_mean_squared_error: 154.6634\n",
      "Epoch 643/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 114.7785 - mean_squared_error: 114.7785 - val_loss: 152.2233 - val_mean_squared_error: 152.2233\n",
      "Epoch 644/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 114.7704 - mean_squared_error: 114.7704 - val_loss: 154.5905 - val_mean_squared_error: 154.5905\n",
      "Epoch 645/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 114.8948 - mean_squared_error: 114.8948 - val_loss: 153.6612 - val_mean_squared_error: 153.6612\n",
      "Epoch 646/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 114.9948 - mean_squared_error: 114.9948 - val_loss: 154.4233 - val_mean_squared_error: 154.4234\n",
      "Epoch 647/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 114.6770 - mean_squared_error: 114.6770 - val_loss: 154.5059 - val_mean_squared_error: 154.5059\n",
      "Epoch 648/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 114.4517 - mean_squared_error: 114.4517 - val_loss: 156.2145 - val_mean_squared_error: 156.2145\n",
      "Epoch 649/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 115.0268 - mean_squared_error: 115.0267 - val_loss: 154.4164 - val_mean_squared_error: 154.4163\n",
      "Epoch 650/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 114.4886 - mean_squared_error: 114.4886 - val_loss: 153.8256 - val_mean_squared_error: 153.8256\n",
      "Epoch 651/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 115.1057 - mean_squared_error: 115.1057 - val_loss: 153.6501 - val_mean_squared_error: 153.6501\n",
      "Epoch 652/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 114.3363 - mean_squared_error: 114.3363 - val_loss: 154.1315 - val_mean_squared_error: 154.1315\n",
      "Epoch 653/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 114.4210 - mean_squared_error: 114.4210 - val_loss: 155.2024 - val_mean_squared_error: 155.2025\n",
      "Epoch 654/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 114.4344 - mean_squared_error: 114.4344 - val_loss: 153.6546 - val_mean_squared_error: 153.6547\n",
      "Epoch 655/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 114.8664 - mean_squared_error: 114.8664 - val_loss: 152.6806 - val_mean_squared_error: 152.6806\n",
      "Epoch 656/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 114.4037 - mean_squared_error: 114.4037 - val_loss: 153.7394 - val_mean_squared_error: 153.7395\n",
      "Epoch 657/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 114.5255 - mean_squared_error: 114.5255 - val_loss: 154.4505 - val_mean_squared_error: 154.4506\n",
      "Epoch 658/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 114.2545 - mean_squared_error: 114.2545 - val_loss: 158.0026 - val_mean_squared_error: 158.0026\n",
      "Epoch 659/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 114.6260 - mean_squared_error: 114.6261 - val_loss: 153.6141 - val_mean_squared_error: 153.6142\n",
      "Epoch 660/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 114.2539 - mean_squared_error: 114.2539 - val_loss: 153.1495 - val_mean_squared_error: 153.1495\n",
      "Epoch 661/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 114.3405 - mean_squared_error: 114.3405 - val_loss: 154.2662 - val_mean_squared_error: 154.2663\n",
      "Epoch 662/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 114.0113 - mean_squared_error: 114.0113 - val_loss: 154.8266 - val_mean_squared_error: 154.8267\n",
      "Epoch 663/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 114.2744 - mean_squared_error: 114.2744 - val_loss: 156.4245 - val_mean_squared_error: 156.4245\n",
      "Epoch 664/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 114.3396 - mean_squared_error: 114.3396 - val_loss: 154.9605 - val_mean_squared_error: 154.9605\n",
      "Epoch 665/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 114.3307 - mean_squared_error: 114.3307 - val_loss: 155.5115 - val_mean_squared_error: 155.5115\n",
      "Epoch 666/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 113.9982 - mean_squared_error: 113.9982 - val_loss: 154.6441 - val_mean_squared_error: 154.6441\n",
      "Epoch 667/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 114.1461 - mean_squared_error: 114.1461 - val_loss: 154.1697 - val_mean_squared_error: 154.1697\n",
      "Epoch 668/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 114.4291 - mean_squared_error: 114.4292 - val_loss: 157.3796 - val_mean_squared_error: 157.3796\n",
      "Epoch 669/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 113.7033 - mean_squared_error: 113.7034 - val_loss: 153.1803 - val_mean_squared_error: 153.1803\n",
      "Epoch 670/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 114.1294 - mean_squared_error: 114.1294 - val_loss: 154.8089 - val_mean_squared_error: 154.8089\n",
      "Epoch 671/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 114.0436 - mean_squared_error: 114.0435 - val_loss: 155.6053 - val_mean_squared_error: 155.6053\n",
      "Epoch 672/1000\n",
      "49590/49590 [==============================] - 2s 45us/sample - loss: 114.1130 - mean_squared_error: 114.1130 - val_loss: 155.6323 - val_mean_squared_error: 155.6323\n",
      "Epoch 673/1000\n",
      "49590/49590 [==============================] - 2s 45us/sample - loss: 114.0024 - mean_squared_error: 114.0024 - val_loss: 155.0128 - val_mean_squared_error: 155.0128\n",
      "Epoch 674/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 114.2323 - mean_squared_error: 114.2323 - val_loss: 156.3531 - val_mean_squared_error: 156.3531\n",
      "Epoch 675/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 113.6568 - mean_squared_error: 113.6568 - val_loss: 155.3291 - val_mean_squared_error: 155.3291\n",
      "Epoch 676/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 114.0659 - mean_squared_error: 114.0659 - val_loss: 154.7195 - val_mean_squared_error: 154.7195\n",
      "Epoch 677/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 113.9874 - mean_squared_error: 113.9874 - val_loss: 154.9267 - val_mean_squared_error: 154.9266\n",
      "Epoch 678/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 114.0160 - mean_squared_error: 114.0161 - val_loss: 157.3771 - val_mean_squared_error: 157.3771\n",
      "Epoch 679/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 114.1594 - mean_squared_error: 114.1595 - val_loss: 154.3466 - val_mean_squared_error: 154.3466\n",
      "Epoch 680/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 113.7090 - mean_squared_error: 113.7090 - val_loss: 153.8801 - val_mean_squared_error: 153.8802\n",
      "Epoch 681/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 113.6019 - mean_squared_error: 113.6019 - val_loss: 155.2006 - val_mean_squared_error: 155.2006\n",
      "Epoch 682/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 113.6590 - mean_squared_error: 113.6589 - val_loss: 155.9946 - val_mean_squared_error: 155.9946\n",
      "Epoch 683/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 113.6351 - mean_squared_error: 113.6351 - val_loss: 154.4550 - val_mean_squared_error: 154.4550\n",
      "Epoch 684/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 113.3990 - mean_squared_error: 113.3991 - val_loss: 155.0464 - val_mean_squared_error: 155.0464\n",
      "Epoch 685/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 113.5107 - mean_squared_error: 113.5107 - val_loss: 155.5091 - val_mean_squared_error: 155.5092\n",
      "Epoch 686/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 113.3242 - mean_squared_error: 113.3242 - val_loss: 155.2555 - val_mean_squared_error: 155.2556\n",
      "Epoch 687/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 113.7660 - mean_squared_error: 113.7660 - val_loss: 157.1830 - val_mean_squared_error: 157.1830\n",
      "Epoch 688/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 113.5946 - mean_squared_error: 113.5946 - val_loss: 155.8512 - val_mean_squared_error: 155.8512\n",
      "Epoch 689/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 113.5797 - mean_squared_error: 113.5798 - val_loss: 155.4453 - val_mean_squared_error: 155.4453\n",
      "Epoch 690/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 113.5932 - mean_squared_error: 113.5932 - val_loss: 158.6390 - val_mean_squared_error: 158.6390\n",
      "Epoch 691/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 113.3548 - mean_squared_error: 113.3548 - val_loss: 155.3059 - val_mean_squared_error: 155.3059\n",
      "Epoch 692/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 113.2620 - mean_squared_error: 113.2620 - val_loss: 156.4227 - val_mean_squared_error: 156.4227\n",
      "Epoch 693/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 113.2779 - mean_squared_error: 113.2779 - val_loss: 153.6151 - val_mean_squared_error: 153.6151\n",
      "Epoch 694/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 113.0403 - mean_squared_error: 113.0404 - val_loss: 156.0752 - val_mean_squared_error: 156.0751\n",
      "Epoch 695/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 113.3325 - mean_squared_error: 113.3324 - val_loss: 154.8049 - val_mean_squared_error: 154.8049\n",
      "Epoch 696/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 113.0131 - mean_squared_error: 113.0132 - val_loss: 157.4063 - val_mean_squared_error: 157.4062\n",
      "Epoch 697/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 113.2430 - mean_squared_error: 113.2430 - val_loss: 157.2524 - val_mean_squared_error: 157.2524\n",
      "Epoch 698/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 113.4457 - mean_squared_error: 113.4457 - val_loss: 156.6696 - val_mean_squared_error: 156.6696\n",
      "Epoch 699/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 113.6097 - mean_squared_error: 113.6096 - val_loss: 155.1877 - val_mean_squared_error: 155.1876\n",
      "Epoch 700/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 112.8691 - mean_squared_error: 112.8692 - val_loss: 155.6292 - val_mean_squared_error: 155.6292\n",
      "Epoch 701/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 113.5777 - mean_squared_error: 113.5777 - val_loss: 154.4289 - val_mean_squared_error: 154.4289\n",
      "Epoch 702/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 113.2427 - mean_squared_error: 113.2427 - val_loss: 156.4015 - val_mean_squared_error: 156.4015\n",
      "Epoch 703/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 112.6102 - mean_squared_error: 112.6102 - val_loss: 155.2096 - val_mean_squared_error: 155.2096\n",
      "Epoch 704/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 112.7570 - mean_squared_error: 112.7570 - val_loss: 155.9862 - val_mean_squared_error: 155.9862\n",
      "Epoch 705/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 112.7733 - mean_squared_error: 112.7734 - val_loss: 155.5504 - val_mean_squared_error: 155.5504\n",
      "Epoch 706/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 113.2393 - mean_squared_error: 113.2393 - val_loss: 155.9355 - val_mean_squared_error: 155.9355\n",
      "Epoch 707/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 113.0253 - mean_squared_error: 113.0253 - val_loss: 156.4049 - val_mean_squared_error: 156.4048\n",
      "Epoch 708/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 112.9080 - mean_squared_error: 112.9080 - val_loss: 155.0330 - val_mean_squared_error: 155.0331\n",
      "Epoch 709/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 112.7671 - mean_squared_error: 112.7671 - val_loss: 156.2559 - val_mean_squared_error: 156.2559\n",
      "Epoch 710/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 112.7704 - mean_squared_error: 112.7705 - val_loss: 156.6935 - val_mean_squared_error: 156.6935\n",
      "Epoch 711/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 113.0209 - mean_squared_error: 113.0209 - val_loss: 154.9889 - val_mean_squared_error: 154.9889\n",
      "Epoch 712/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 112.8330 - mean_squared_error: 112.8330 - val_loss: 157.3646 - val_mean_squared_error: 157.3646\n",
      "Epoch 713/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 112.6707 - mean_squared_error: 112.6707 - val_loss: 156.2075 - val_mean_squared_error: 156.2076\n",
      "Epoch 714/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 112.7813 - mean_squared_error: 112.7813 - val_loss: 157.9498 - val_mean_squared_error: 157.9498\n",
      "Epoch 715/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 112.7737 - mean_squared_error: 112.7737 - val_loss: 156.9253 - val_mean_squared_error: 156.9253\n",
      "Epoch 716/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 112.4331 - mean_squared_error: 112.4331 - val_loss: 157.0335 - val_mean_squared_error: 157.0336\n",
      "Epoch 717/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 112.7475 - mean_squared_error: 112.7475 - val_loss: 155.9111 - val_mean_squared_error: 155.9111\n",
      "Epoch 718/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 112.7215 - mean_squared_error: 112.7215 - val_loss: 157.1514 - val_mean_squared_error: 157.1514\n",
      "Epoch 719/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 112.6915 - mean_squared_error: 112.6915 - val_loss: 157.3322 - val_mean_squared_error: 157.3322\n",
      "Epoch 720/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 2s 32us/sample - loss: 112.2102 - mean_squared_error: 112.2102 - val_loss: 155.9264 - val_mean_squared_error: 155.9264\n",
      "Epoch 721/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 112.5695 - mean_squared_error: 112.5695 - val_loss: 155.2111 - val_mean_squared_error: 155.2112\n",
      "Epoch 722/1000\n",
      "49590/49590 [==============================] - 3s 56us/sample - loss: 112.9998 - mean_squared_error: 112.9998 - val_loss: 160.8412 - val_mean_squared_error: 160.8411\n",
      "Epoch 723/1000\n",
      "49590/49590 [==============================] - 3s 52us/sample - loss: 112.5350 - mean_squared_error: 112.5350 - val_loss: 157.5534 - val_mean_squared_error: 157.5534\n",
      "Epoch 724/1000\n",
      "49590/49590 [==============================] - 3s 61us/sample - loss: 112.3424 - mean_squared_error: 112.3424 - val_loss: 158.1206 - val_mean_squared_error: 158.1206\n",
      "Epoch 725/1000\n",
      "49590/49590 [==============================] - 2s 49us/sample - loss: 112.6607 - mean_squared_error: 112.6607 - val_loss: 157.5685 - val_mean_squared_error: 157.5686\n",
      "Epoch 726/1000\n",
      "49590/49590 [==============================] - 3s 59us/sample - loss: 112.4660 - mean_squared_error: 112.4660 - val_loss: 156.1414 - val_mean_squared_error: 156.1414\n",
      "Epoch 727/1000\n",
      "49590/49590 [==============================] - 2s 46us/sample - loss: 112.4746 - mean_squared_error: 112.4746 - val_loss: 156.9064 - val_mean_squared_error: 156.9064\n",
      "Epoch 728/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 112.3717 - mean_squared_error: 112.3717 - val_loss: 156.8061 - val_mean_squared_error: 156.8061\n",
      "Epoch 729/1000\n",
      "49590/49590 [==============================] - 2s 46us/sample - loss: 112.5858 - mean_squared_error: 112.5858 - val_loss: 160.0560 - val_mean_squared_error: 160.0560\n",
      "Epoch 730/1000\n",
      "49590/49590 [==============================] - 2s 43us/sample - loss: 112.5885 - mean_squared_error: 112.5885 - val_loss: 156.9184 - val_mean_squared_error: 156.9183\n",
      "Epoch 731/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 112.3971 - mean_squared_error: 112.3972 - val_loss: 155.8416 - val_mean_squared_error: 155.8416\n",
      "Epoch 732/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 111.8585 - mean_squared_error: 111.8585 - val_loss: 156.8434 - val_mean_squared_error: 156.8435\n",
      "Epoch 733/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 112.1895 - mean_squared_error: 112.1894 - val_loss: 156.9967 - val_mean_squared_error: 156.9967\n",
      "Epoch 734/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 111.7882 - mean_squared_error: 111.7882 - val_loss: 159.5450 - val_mean_squared_error: 159.5450\n",
      "Epoch 735/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 112.5270 - mean_squared_error: 112.5270 - val_loss: 156.9653 - val_mean_squared_error: 156.9654\n",
      "Epoch 736/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 111.7946 - mean_squared_error: 111.7945 - val_loss: 157.8510 - val_mean_squared_error: 157.8510\n",
      "Epoch 737/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 112.0219 - mean_squared_error: 112.0219 - val_loss: 155.6879 - val_mean_squared_error: 155.6879\n",
      "Epoch 738/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 112.0834 - mean_squared_error: 112.0834 - val_loss: 155.7321 - val_mean_squared_error: 155.7322\n",
      "Epoch 739/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 111.7833 - mean_squared_error: 111.7833 - val_loss: 157.1389 - val_mean_squared_error: 157.1389\n",
      "Epoch 740/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 112.2961 - mean_squared_error: 112.2961 - val_loss: 159.8171 - val_mean_squared_error: 159.8170\n",
      "Epoch 741/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 112.2430 - mean_squared_error: 112.2430 - val_loss: 156.1163 - val_mean_squared_error: 156.1163\n",
      "Epoch 742/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 111.9849 - mean_squared_error: 111.9849 - val_loss: 160.2056 - val_mean_squared_error: 160.2056\n",
      "Epoch 743/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 111.7702 - mean_squared_error: 111.7702 - val_loss: 156.6491 - val_mean_squared_error: 156.6491\n",
      "Epoch 744/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 111.7734 - mean_squared_error: 111.7734 - val_loss: 156.1522 - val_mean_squared_error: 156.1521\n",
      "Epoch 745/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 111.6571 - mean_squared_error: 111.6571 - val_loss: 157.0072 - val_mean_squared_error: 157.0072\n",
      "Epoch 746/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 112.1939 - mean_squared_error: 112.1939 - val_loss: 156.6013 - val_mean_squared_error: 156.6013\n",
      "Epoch 747/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 111.7957 - mean_squared_error: 111.7956 - val_loss: 159.5321 - val_mean_squared_error: 159.5321\n",
      "Epoch 748/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 112.0353 - mean_squared_error: 112.0353 - val_loss: 157.4756 - val_mean_squared_error: 157.4756\n",
      "Epoch 749/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 111.6438 - mean_squared_error: 111.6437 - val_loss: 158.3858 - val_mean_squared_error: 158.3858\n",
      "Epoch 750/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 111.2330 - mean_squared_error: 111.2330 - val_loss: 158.7890 - val_mean_squared_error: 158.7890\n",
      "Epoch 751/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 111.8100 - mean_squared_error: 111.8100 - val_loss: 158.9726 - val_mean_squared_error: 158.9725\n",
      "Epoch 752/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 111.2004 - mean_squared_error: 111.2005 - val_loss: 159.2445 - val_mean_squared_error: 159.2445\n",
      "Epoch 753/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 111.8012 - mean_squared_error: 111.8012 - val_loss: 155.8506 - val_mean_squared_error: 155.8506\n",
      "Epoch 754/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 111.4700 - mean_squared_error: 111.4700 - val_loss: 157.3641 - val_mean_squared_error: 157.3641\n",
      "Epoch 755/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 111.6778 - mean_squared_error: 111.6778 - val_loss: 158.2291 - val_mean_squared_error: 158.2292\n",
      "Epoch 756/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 111.6253 - mean_squared_error: 111.6254 - val_loss: 156.4434 - val_mean_squared_error: 156.4434\n",
      "Epoch 757/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 111.3686 - mean_squared_error: 111.3686 - val_loss: 159.9969 - val_mean_squared_error: 159.9969\n",
      "Epoch 758/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 111.5936 - mean_squared_error: 111.5936 - val_loss: 159.3992 - val_mean_squared_error: 159.3992\n",
      "Epoch 759/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 111.4307 - mean_squared_error: 111.4308 - val_loss: 157.8561 - val_mean_squared_error: 157.8560\n",
      "Epoch 760/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 111.5664 - mean_squared_error: 111.5664 - val_loss: 156.4423 - val_mean_squared_error: 156.4423\n",
      "Epoch 761/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 111.1642 - mean_squared_error: 111.1642 - val_loss: 156.7887 - val_mean_squared_error: 156.7887\n",
      "Epoch 762/1000\n",
      "49590/49590 [==============================] - 2s 43us/sample - loss: 111.6955 - mean_squared_error: 111.6955 - val_loss: 157.4129 - val_mean_squared_error: 157.4129\n",
      "Epoch 763/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 111.5190 - mean_squared_error: 111.5190 - val_loss: 159.8269 - val_mean_squared_error: 159.8269\n",
      "Epoch 764/1000\n",
      "49590/49590 [==============================] - 2s 44us/sample - loss: 111.2620 - mean_squared_error: 111.2620 - val_loss: 158.3922 - val_mean_squared_error: 158.3922\n",
      "Epoch 765/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 111.5215 - mean_squared_error: 111.5214 - val_loss: 158.1408 - val_mean_squared_error: 158.1408\n",
      "Epoch 766/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 111.7682 - mean_squared_error: 111.7682 - val_loss: 157.2729 - val_mean_squared_error: 157.2728\n",
      "Epoch 767/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 111.2046 - mean_squared_error: 111.2045 - val_loss: 158.0016 - val_mean_squared_error: 158.0016\n",
      "Epoch 768/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 111.0336 - mean_squared_error: 111.0336 - val_loss: 159.0566 - val_mean_squared_error: 159.0566\n",
      "Epoch 769/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 111.2395 - mean_squared_error: 111.2395 - val_loss: 157.9151 - val_mean_squared_error: 157.9152\n",
      "Epoch 770/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 111.0484 - mean_squared_error: 111.0484 - val_loss: 158.1315 - val_mean_squared_error: 158.1315\n",
      "Epoch 771/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 111.2980 - mean_squared_error: 111.2980 - val_loss: 158.1472 - val_mean_squared_error: 158.1472\n",
      "Epoch 772/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 111.3067 - mean_squared_error: 111.3067 - val_loss: 159.5112 - val_mean_squared_error: 159.5112\n",
      "Epoch 773/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 111.1411 - mean_squared_error: 111.1410 - val_loss: 158.0166 - val_mean_squared_error: 158.0166\n",
      "Epoch 774/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 111.0434 - mean_squared_error: 111.0434 - val_loss: 157.5695 - val_mean_squared_error: 157.5695\n",
      "Epoch 775/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 111.1169 - mean_squared_error: 111.1169 - val_loss: 158.5502 - val_mean_squared_error: 158.5502\n",
      "Epoch 776/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 110.9526 - mean_squared_error: 110.9526 - val_loss: 159.2230 - val_mean_squared_error: 159.2230\n",
      "Epoch 777/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 111.0636 - mean_squared_error: 111.0637 - val_loss: 158.5442 - val_mean_squared_error: 158.5442\n",
      "Epoch 778/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 110.7023 - mean_squared_error: 110.7023 - val_loss: 160.0065 - val_mean_squared_error: 160.0065\n",
      "Epoch 779/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 110.8366 - mean_squared_error: 110.8365 - val_loss: 157.2261 - val_mean_squared_error: 157.2261\n",
      "Epoch 780/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 111.0191 - mean_squared_error: 111.0192 - val_loss: 158.5156 - val_mean_squared_error: 158.5156\n",
      "Epoch 781/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 110.5276 - mean_squared_error: 110.5277 - val_loss: 161.0214 - val_mean_squared_error: 161.0214\n",
      "Epoch 782/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 110.8194 - mean_squared_error: 110.8194 - val_loss: 159.0970 - val_mean_squared_error: 159.0970\n",
      "Epoch 783/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 111.1673 - mean_squared_error: 111.1673 - val_loss: 158.7645 - val_mean_squared_error: 158.7645\n",
      "Epoch 784/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 110.6641 - mean_squared_error: 110.6641 - val_loss: 159.0636 - val_mean_squared_error: 159.0636\n",
      "Epoch 785/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 110.8165 - mean_squared_error: 110.8166 - val_loss: 158.5524 - val_mean_squared_error: 158.5524\n",
      "Epoch 786/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 110.7318 - mean_squared_error: 110.7318 - val_loss: 156.7838 - val_mean_squared_error: 156.7837\n",
      "Epoch 787/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 111.0752 - mean_squared_error: 111.0752 - val_loss: 157.5606 - val_mean_squared_error: 157.5606\n",
      "Epoch 788/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 110.6988 - mean_squared_error: 110.6988 - val_loss: 158.7368 - val_mean_squared_error: 158.7368\n",
      "Epoch 789/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 110.7018 - mean_squared_error: 110.7018 - val_loss: 159.7728 - val_mean_squared_error: 159.7727\n",
      "Epoch 790/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 110.5561 - mean_squared_error: 110.5561 - val_loss: 160.3490 - val_mean_squared_error: 160.3490\n",
      "Epoch 791/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 110.5424 - mean_squared_error: 110.5424 - val_loss: 158.7521 - val_mean_squared_error: 158.7521\n",
      "Epoch 792/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 110.9470 - mean_squared_error: 110.9470 - val_loss: 158.1688 - val_mean_squared_error: 158.1688\n",
      "Epoch 793/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 110.9868 - mean_squared_error: 110.9868 - val_loss: 158.1258 - val_mean_squared_error: 158.1258\n",
      "Epoch 794/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 110.4919 - mean_squared_error: 110.4919 - val_loss: 158.9242 - val_mean_squared_error: 158.9242\n",
      "Epoch 795/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 110.7421 - mean_squared_error: 110.7421 - val_loss: 157.8732 - val_mean_squared_error: 157.8733\n",
      "Epoch 796/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 110.6197 - mean_squared_error: 110.6196 - val_loss: 161.3936 - val_mean_squared_error: 161.3936\n",
      "Epoch 797/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 110.9585 - mean_squared_error: 110.9585 - val_loss: 157.3875 - val_mean_squared_error: 157.3875\n",
      "Epoch 798/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 110.4850 - mean_squared_error: 110.4850 - val_loss: 161.0483 - val_mean_squared_error: 161.0483\n",
      "Epoch 799/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 110.3731 - mean_squared_error: 110.3730 - val_loss: 158.8323 - val_mean_squared_error: 158.8322\n",
      "Epoch 800/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 110.6024 - mean_squared_error: 110.6023 - val_loss: 161.5620 - val_mean_squared_error: 161.5620\n",
      "Epoch 801/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 110.6034 - mean_squared_error: 110.6035 - val_loss: 160.3510 - val_mean_squared_error: 160.3510\n",
      "Epoch 802/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 110.7842 - mean_squared_error: 110.7843 - val_loss: 160.7728 - val_mean_squared_error: 160.7728\n",
      "Epoch 803/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 110.0083 - mean_squared_error: 110.0083 - val_loss: 160.1342 - val_mean_squared_error: 160.1342\n",
      "Epoch 804/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 110.0991 - mean_squared_error: 110.0991 - val_loss: 159.5056 - val_mean_squared_error: 159.5056\n",
      "Epoch 805/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 110.4460 - mean_squared_error: 110.4460 - val_loss: 158.7225 - val_mean_squared_error: 158.7225\n",
      "Epoch 806/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 110.2261 - mean_squared_error: 110.2261 - val_loss: 158.3918 - val_mean_squared_error: 158.3918\n",
      "Epoch 807/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 110.2560 - mean_squared_error: 110.2560 - val_loss: 161.0811 - val_mean_squared_error: 161.0811\n",
      "Epoch 808/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 110.3304 - mean_squared_error: 110.3303 - val_loss: 158.6885 - val_mean_squared_error: 158.6885\n",
      "Epoch 809/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 110.0117 - mean_squared_error: 110.0117 - val_loss: 160.0001 - val_mean_squared_error: 160.0001\n",
      "Epoch 810/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 2s 31us/sample - loss: 110.0869 - mean_squared_error: 110.0869 - val_loss: 159.9101 - val_mean_squared_error: 159.9101\n",
      "Epoch 811/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 110.2300 - mean_squared_error: 110.2300 - val_loss: 159.2744 - val_mean_squared_error: 159.2744\n",
      "Epoch 812/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 110.1649 - mean_squared_error: 110.1648 - val_loss: 159.6544 - val_mean_squared_error: 159.6544\n",
      "Epoch 813/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 109.8957 - mean_squared_error: 109.8958 - val_loss: 159.4759 - val_mean_squared_error: 159.4759\n",
      "Epoch 814/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 109.9124 - mean_squared_error: 109.9124 - val_loss: 161.0306 - val_mean_squared_error: 161.0305\n",
      "Epoch 815/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 110.0605 - mean_squared_error: 110.0605 - val_loss: 160.2987 - val_mean_squared_error: 160.2986\n",
      "Epoch 816/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 109.9321 - mean_squared_error: 109.9321 - val_loss: 159.1042 - val_mean_squared_error: 159.1043\n",
      "Epoch 817/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 109.7795 - mean_squared_error: 109.7795 - val_loss: 160.1654 - val_mean_squared_error: 160.1655\n",
      "Epoch 818/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 109.9076 - mean_squared_error: 109.9076 - val_loss: 158.5530 - val_mean_squared_error: 158.5530\n",
      "Epoch 819/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 109.3947 - mean_squared_error: 109.3948 - val_loss: 160.4335 - val_mean_squared_error: 160.4335\n",
      "Epoch 820/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 109.7242 - mean_squared_error: 109.7242 - val_loss: 158.4817 - val_mean_squared_error: 158.4817\n",
      "Epoch 821/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 109.8707 - mean_squared_error: 109.8707 - val_loss: 161.2815 - val_mean_squared_error: 161.2815\n",
      "Epoch 822/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 109.6171 - mean_squared_error: 109.6171 - val_loss: 161.4282 - val_mean_squared_error: 161.4282\n",
      "Epoch 823/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 109.7376 - mean_squared_error: 109.7377 - val_loss: 161.1696 - val_mean_squared_error: 161.1697\n",
      "Epoch 824/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 110.0145 - mean_squared_error: 110.0145 - val_loss: 162.4733 - val_mean_squared_error: 162.4733\n",
      "Epoch 825/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 109.7735 - mean_squared_error: 109.7735 - val_loss: 161.0430 - val_mean_squared_error: 161.0431\n",
      "Epoch 826/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 109.9571 - mean_squared_error: 109.9572 - val_loss: 160.3245 - val_mean_squared_error: 160.3245\n",
      "Epoch 827/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 109.8546 - mean_squared_error: 109.8546 - val_loss: 159.3038 - val_mean_squared_error: 159.3037\n",
      "Epoch 828/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 109.7796 - mean_squared_error: 109.7796 - val_loss: 158.4327 - val_mean_squared_error: 158.4327\n",
      "Epoch 829/1000\n",
      "49590/49590 [==============================] - 2s 50us/sample - loss: 109.4444 - mean_squared_error: 109.4444 - val_loss: 160.4160 - val_mean_squared_error: 160.4160\n",
      "Epoch 830/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 109.7550 - mean_squared_error: 109.7551 - val_loss: 159.4589 - val_mean_squared_error: 159.4589\n",
      "Epoch 831/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 109.5052 - mean_squared_error: 109.5052 - val_loss: 161.4436 - val_mean_squared_error: 161.4435\n",
      "Epoch 832/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 109.6590 - mean_squared_error: 109.6591 - val_loss: 161.5689 - val_mean_squared_error: 161.5689\n",
      "Epoch 833/1000\n",
      "49590/49590 [==============================] - 2s 44us/sample - loss: 109.3949 - mean_squared_error: 109.3948 - val_loss: 160.4148 - val_mean_squared_error: 160.4148\n",
      "Epoch 834/1000\n",
      "49590/49590 [==============================] - 2s 49us/sample - loss: 109.8833 - mean_squared_error: 109.8833 - val_loss: 159.5925 - val_mean_squared_error: 159.5925\n",
      "Epoch 835/1000\n",
      "49590/49590 [==============================] - 2s 44us/sample - loss: 109.4079 - mean_squared_error: 109.4078 - val_loss: 160.3515 - val_mean_squared_error: 160.3515\n",
      "Epoch 836/1000\n",
      "49590/49590 [==============================] - 2s 46us/sample - loss: 109.5404 - mean_squared_error: 109.5404 - val_loss: 160.6953 - val_mean_squared_error: 160.6953\n",
      "Epoch 837/1000\n",
      "49590/49590 [==============================] - 2s 46us/sample - loss: 109.7275 - mean_squared_error: 109.7276 - val_loss: 160.3069 - val_mean_squared_error: 160.3069\n",
      "Epoch 838/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 109.3462 - mean_squared_error: 109.3461 - val_loss: 160.7483 - val_mean_squared_error: 160.7483\n",
      "Epoch 839/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 109.4162 - mean_squared_error: 109.4162 - val_loss: 163.5180 - val_mean_squared_error: 163.5180\n",
      "Epoch 840/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 109.2080 - mean_squared_error: 109.2080 - val_loss: 160.4655 - val_mean_squared_error: 160.4655\n",
      "Epoch 841/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 109.2405 - mean_squared_error: 109.2406 - val_loss: 162.2145 - val_mean_squared_error: 162.2145\n",
      "Epoch 842/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 109.4224 - mean_squared_error: 109.4224 - val_loss: 160.7096 - val_mean_squared_error: 160.7097\n",
      "Epoch 843/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 109.3835 - mean_squared_error: 109.3835 - val_loss: 164.2497 - val_mean_squared_error: 164.2498\n",
      "Epoch 844/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 109.3235 - mean_squared_error: 109.3236 - val_loss: 160.9391 - val_mean_squared_error: 160.9390\n",
      "Epoch 845/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 109.0233 - mean_squared_error: 109.0233 - val_loss: 161.2595 - val_mean_squared_error: 161.2595\n",
      "Epoch 846/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 109.2611 - mean_squared_error: 109.2610 - val_loss: 162.3507 - val_mean_squared_error: 162.3506\n",
      "Epoch 847/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 109.2267 - mean_squared_error: 109.2267 - val_loss: 160.8869 - val_mean_squared_error: 160.8869\n",
      "Epoch 848/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 109.4659 - mean_squared_error: 109.4659 - val_loss: 162.1639 - val_mean_squared_error: 162.1639\n",
      "Epoch 849/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 108.8875 - mean_squared_error: 108.8875 - val_loss: 161.3069 - val_mean_squared_error: 161.3069\n",
      "Epoch 850/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 109.2119 - mean_squared_error: 109.2119 - val_loss: 160.6270 - val_mean_squared_error: 160.6270\n",
      "Epoch 851/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 109.4543 - mean_squared_error: 109.4543 - val_loss: 161.3791 - val_mean_squared_error: 161.3792\n",
      "Epoch 852/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.9273 - mean_squared_error: 108.9273 - val_loss: 161.0431 - val_mean_squared_error: 161.0431\n",
      "Epoch 853/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 109.1045 - mean_squared_error: 109.1045 - val_loss: 163.2844 - val_mean_squared_error: 163.2844\n",
      "Epoch 854/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 109.1757 - mean_squared_error: 109.1757 - val_loss: 161.6600 - val_mean_squared_error: 161.6599\n",
      "Epoch 855/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 108.8273 - mean_squared_error: 108.8273 - val_loss: 161.6236 - val_mean_squared_error: 161.6235\n",
      "Epoch 856/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.5739 - mean_squared_error: 108.5738 - val_loss: 162.0360 - val_mean_squared_error: 162.0360\n",
      "Epoch 857/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 108.7345 - mean_squared_error: 108.7345 - val_loss: 163.0423 - val_mean_squared_error: 163.0423\n",
      "Epoch 858/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 109.1354 - mean_squared_error: 109.1353 - val_loss: 159.4648 - val_mean_squared_error: 159.4649\n",
      "Epoch 859/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 108.8730 - mean_squared_error: 108.8730 - val_loss: 161.8483 - val_mean_squared_error: 161.8483\n",
      "Epoch 860/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 108.5974 - mean_squared_error: 108.5974 - val_loss: 161.7266 - val_mean_squared_error: 161.7266\n",
      "Epoch 861/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.8639 - mean_squared_error: 108.8639 - val_loss: 161.9407 - val_mean_squared_error: 161.9408\n",
      "Epoch 862/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.6704 - mean_squared_error: 108.6704 - val_loss: 162.5699 - val_mean_squared_error: 162.5700\n",
      "Epoch 863/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 108.5561 - mean_squared_error: 108.5560 - val_loss: 162.0639 - val_mean_squared_error: 162.0639\n",
      "Epoch 864/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.6010 - mean_squared_error: 108.6010 - val_loss: 161.3088 - val_mean_squared_error: 161.3088\n",
      "Epoch 865/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.8200 - mean_squared_error: 108.8200 - val_loss: 160.3829 - val_mean_squared_error: 160.3829\n",
      "Epoch 866/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.4940 - mean_squared_error: 108.4940 - val_loss: 161.5924 - val_mean_squared_error: 161.5924\n",
      "Epoch 867/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.7665 - mean_squared_error: 108.7665 - val_loss: 162.2300 - val_mean_squared_error: 162.2300\n",
      "Epoch 868/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.7430 - mean_squared_error: 108.7430 - val_loss: 162.7965 - val_mean_squared_error: 162.7965\n",
      "Epoch 869/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.7352 - mean_squared_error: 108.7352 - val_loss: 162.1374 - val_mean_squared_error: 162.1375\n",
      "Epoch 870/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 108.4794 - mean_squared_error: 108.4794 - val_loss: 161.8335 - val_mean_squared_error: 161.8335\n",
      "Epoch 871/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.4768 - mean_squared_error: 108.4769 - val_loss: 161.2233 - val_mean_squared_error: 161.2233\n",
      "Epoch 872/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.5181 - mean_squared_error: 108.5181 - val_loss: 161.9402 - val_mean_squared_error: 161.9402\n",
      "Epoch 873/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.3534 - mean_squared_error: 108.3534 - val_loss: 162.2816 - val_mean_squared_error: 162.2816\n",
      "Epoch 874/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 108.5063 - mean_squared_error: 108.5063 - val_loss: 161.7587 - val_mean_squared_error: 161.7587\n",
      "Epoch 875/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.0517 - mean_squared_error: 108.0518 - val_loss: 161.7797 - val_mean_squared_error: 161.7796\n",
      "Epoch 876/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.5833 - mean_squared_error: 108.5833 - val_loss: 162.1973 - val_mean_squared_error: 162.1973\n",
      "Epoch 877/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.5597 - mean_squared_error: 108.5596 - val_loss: 162.7705 - val_mean_squared_error: 162.7705\n",
      "Epoch 878/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.4664 - mean_squared_error: 108.4665 - val_loss: 163.8069 - val_mean_squared_error: 163.8070\n",
      "Epoch 879/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.4206 - mean_squared_error: 108.4206 - val_loss: 162.7243 - val_mean_squared_error: 162.7243\n",
      "Epoch 880/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.5313 - mean_squared_error: 108.5313 - val_loss: 160.6873 - val_mean_squared_error: 160.6873\n",
      "Epoch 881/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.5372 - mean_squared_error: 108.5372 - val_loss: 161.7460 - val_mean_squared_error: 161.7460\n",
      "Epoch 882/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.3479 - mean_squared_error: 108.3479 - val_loss: 160.0204 - val_mean_squared_error: 160.0204\n",
      "Epoch 883/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.5094 - mean_squared_error: 108.5094 - val_loss: 160.4857 - val_mean_squared_error: 160.4857\n",
      "Epoch 884/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 108.2350 - mean_squared_error: 108.2350 - val_loss: 162.1950 - val_mean_squared_error: 162.1950\n",
      "Epoch 885/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.1786 - mean_squared_error: 108.1785 - val_loss: 161.5094 - val_mean_squared_error: 161.5094\n",
      "Epoch 886/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 108.1023 - mean_squared_error: 108.1023 - val_loss: 163.2933 - val_mean_squared_error: 163.2933\n",
      "Epoch 887/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.4782 - mean_squared_error: 108.4782 - val_loss: 162.4567 - val_mean_squared_error: 162.4567\n",
      "Epoch 888/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.4187 - mean_squared_error: 108.4187 - val_loss: 161.6919 - val_mean_squared_error: 161.6919\n",
      "Epoch 889/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 108.0972 - mean_squared_error: 108.0972 - val_loss: 160.1056 - val_mean_squared_error: 160.1056\n",
      "Epoch 890/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.1049 - mean_squared_error: 108.1049 - val_loss: 162.8143 - val_mean_squared_error: 162.8143\n",
      "Epoch 891/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.3276 - mean_squared_error: 108.3276 - val_loss: 162.8498 - val_mean_squared_error: 162.8499\n",
      "Epoch 892/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 107.7293 - mean_squared_error: 107.7293 - val_loss: 162.7974 - val_mean_squared_error: 162.7974\n",
      "Epoch 893/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 107.8028 - mean_squared_error: 107.8028 - val_loss: 161.6262 - val_mean_squared_error: 161.6262\n",
      "Epoch 894/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.1784 - mean_squared_error: 108.1785 - val_loss: 160.6935 - val_mean_squared_error: 160.6935\n",
      "Epoch 895/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 107.9526 - mean_squared_error: 107.9525 - val_loss: 162.3533 - val_mean_squared_error: 162.3533\n",
      "Epoch 896/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.2043 - mean_squared_error: 108.2042 - val_loss: 163.3262 - val_mean_squared_error: 163.3262\n",
      "Epoch 897/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.2185 - mean_squared_error: 108.2185 - val_loss: 165.3814 - val_mean_squared_error: 165.3814\n",
      "Epoch 898/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.1070 - mean_squared_error: 108.1070 - val_loss: 164.8892 - val_mean_squared_error: 164.8892\n",
      "Epoch 899/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.4586 - mean_squared_error: 108.4586 - val_loss: 163.2681 - val_mean_squared_error: 163.2682\n",
      "Epoch 900/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 26us/sample - loss: 107.8454 - mean_squared_error: 107.8453 - val_loss: 162.5667 - val_mean_squared_error: 162.5666\n",
      "Epoch 901/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 107.6933 - mean_squared_error: 107.6933 - val_loss: 163.5745 - val_mean_squared_error: 163.5746\n",
      "Epoch 902/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.1160 - mean_squared_error: 108.1160 - val_loss: 165.0274 - val_mean_squared_error: 165.0275\n",
      "Epoch 903/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.0837 - mean_squared_error: 108.0837 - val_loss: 161.9187 - val_mean_squared_error: 161.9187\n",
      "Epoch 904/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 107.7342 - mean_squared_error: 107.7342 - val_loss: 162.2512 - val_mean_squared_error: 162.2512\n",
      "Epoch 905/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 108.1244 - mean_squared_error: 108.1244 - val_loss: 161.7526 - val_mean_squared_error: 161.7527\n",
      "Epoch 906/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 107.9441 - mean_squared_error: 107.9441 - val_loss: 162.6899 - val_mean_squared_error: 162.6900\n",
      "Epoch 907/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 107.6869 - mean_squared_error: 107.6869 - val_loss: 163.7712 - val_mean_squared_error: 163.7713\n",
      "Epoch 908/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 107.7384 - mean_squared_error: 107.7384 - val_loss: 163.3275 - val_mean_squared_error: 163.3275\n",
      "Epoch 909/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 107.6100 - mean_squared_error: 107.6100 - val_loss: 164.6260 - val_mean_squared_error: 164.6260\n",
      "Epoch 910/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 107.3601 - mean_squared_error: 107.3601 - val_loss: 163.8241 - val_mean_squared_error: 163.8241\n",
      "Epoch 911/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 107.9043 - mean_squared_error: 107.9043 - val_loss: 163.3620 - val_mean_squared_error: 163.3620\n",
      "Epoch 912/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 107.3850 - mean_squared_error: 107.3850 - val_loss: 163.0431 - val_mean_squared_error: 163.0431\n",
      "Epoch 913/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 107.7161 - mean_squared_error: 107.7161 - val_loss: 164.5653 - val_mean_squared_error: 164.5653\n",
      "Epoch 914/1000\n",
      "49590/49590 [==============================] - 2s 44us/sample - loss: 108.1467 - mean_squared_error: 108.1467 - val_loss: 164.6124 - val_mean_squared_error: 164.6124\n",
      "Epoch 915/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 107.6102 - mean_squared_error: 107.6102 - val_loss: 162.9435 - val_mean_squared_error: 162.9435\n",
      "Epoch 916/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 107.4617 - mean_squared_error: 107.4617 - val_loss: 163.7873 - val_mean_squared_error: 163.7873\n",
      "Epoch 917/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 107.4798 - mean_squared_error: 107.4798 - val_loss: 162.6903 - val_mean_squared_error: 162.6903\n",
      "Epoch 918/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 107.3847 - mean_squared_error: 107.3847 - val_loss: 161.2185 - val_mean_squared_error: 161.2185\n",
      "Epoch 919/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 107.6785 - mean_squared_error: 107.6784 - val_loss: 162.9356 - val_mean_squared_error: 162.9356\n",
      "Epoch 920/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 107.9839 - mean_squared_error: 107.9838 - val_loss: 166.8813 - val_mean_squared_error: 166.8813\n",
      "Epoch 921/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 107.0959 - mean_squared_error: 107.0960 - val_loss: 163.6449 - val_mean_squared_error: 163.6449\n",
      "Epoch 922/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 107.2168 - mean_squared_error: 107.2168 - val_loss: 162.1449 - val_mean_squared_error: 162.1449\n",
      "Epoch 923/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 107.0992 - mean_squared_error: 107.0992 - val_loss: 162.3394 - val_mean_squared_error: 162.3395\n",
      "Epoch 924/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 107.5425 - mean_squared_error: 107.5424 - val_loss: 163.5945 - val_mean_squared_error: 163.5946\n",
      "Epoch 925/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 107.0430 - mean_squared_error: 107.0430 - val_loss: 162.2874 - val_mean_squared_error: 162.2874\n",
      "Epoch 926/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 107.3890 - mean_squared_error: 107.3890 - val_loss: 161.4595 - val_mean_squared_error: 161.4595\n",
      "Epoch 927/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 107.0388 - mean_squared_error: 107.0388 - val_loss: 163.1555 - val_mean_squared_error: 163.1555\n",
      "Epoch 928/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 107.2827 - mean_squared_error: 107.2827 - val_loss: 162.9323 - val_mean_squared_error: 162.9323\n",
      "Epoch 929/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 107.3328 - mean_squared_error: 107.3329 - val_loss: 163.9694 - val_mean_squared_error: 163.9694\n",
      "Epoch 930/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 107.2535 - mean_squared_error: 107.2535 - val_loss: 164.6224 - val_mean_squared_error: 164.6224\n",
      "Epoch 931/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 107.4812 - mean_squared_error: 107.4812 - val_loss: 161.8350 - val_mean_squared_error: 161.8350\n",
      "Epoch 932/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 107.0902 - mean_squared_error: 107.0901 - val_loss: 163.2588 - val_mean_squared_error: 163.2588\n",
      "Epoch 933/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 106.8972 - mean_squared_error: 106.8973 - val_loss: 160.3509 - val_mean_squared_error: 160.3508\n",
      "Epoch 934/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 107.5736 - mean_squared_error: 107.5735 - val_loss: 162.5494 - val_mean_squared_error: 162.5493\n",
      "Epoch 935/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 107.2370 - mean_squared_error: 107.2370 - val_loss: 164.2601 - val_mean_squared_error: 164.2602\n",
      "Epoch 936/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 107.4976 - mean_squared_error: 107.4976 - val_loss: 165.4718 - val_mean_squared_error: 165.4718\n",
      "Epoch 937/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 106.9642 - mean_squared_error: 106.9641 - val_loss: 162.9806 - val_mean_squared_error: 162.9807\n",
      "Epoch 938/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 107.3001 - mean_squared_error: 107.3001 - val_loss: 164.3558 - val_mean_squared_error: 164.3559\n",
      "Epoch 939/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 106.9110 - mean_squared_error: 106.9110 - val_loss: 164.5577 - val_mean_squared_error: 164.5577\n",
      "Epoch 940/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 107.0966 - mean_squared_error: 107.0966 - val_loss: 162.4870 - val_mean_squared_error: 162.4870\n",
      "Epoch 941/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 107.2383 - mean_squared_error: 107.2383 - val_loss: 165.0167 - val_mean_squared_error: 165.0167\n",
      "Epoch 942/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 107.2888 - mean_squared_error: 107.2889 - val_loss: 163.6921 - val_mean_squared_error: 163.6921\n",
      "Epoch 943/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 107.0530 - mean_squared_error: 107.0530 - val_loss: 163.3207 - val_mean_squared_error: 163.3207\n",
      "Epoch 944/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 106.8062 - mean_squared_error: 106.8063 - val_loss: 164.5272 - val_mean_squared_error: 164.5271\n",
      "Epoch 945/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 107.5829 - mean_squared_error: 107.5829 - val_loss: 165.7880 - val_mean_squared_error: 165.7880\n",
      "Epoch 946/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 107.0123 - mean_squared_error: 107.0123 - val_loss: 163.6818 - val_mean_squared_error: 163.6817\n",
      "Epoch 947/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 107.0121 - mean_squared_error: 107.0121 - val_loss: 164.1579 - val_mean_squared_error: 164.1580\n",
      "Epoch 948/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 106.7984 - mean_squared_error: 106.7984 - val_loss: 164.0660 - val_mean_squared_error: 164.0660\n",
      "Epoch 949/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 106.9723 - mean_squared_error: 106.9723 - val_loss: 162.4717 - val_mean_squared_error: 162.4717\n",
      "Epoch 950/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 106.7391 - mean_squared_error: 106.7391 - val_loss: 163.9191 - val_mean_squared_error: 163.9192\n",
      "Epoch 951/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 106.6959 - mean_squared_error: 106.6958 - val_loss: 163.5505 - val_mean_squared_error: 163.5505\n",
      "Epoch 952/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 106.9712 - mean_squared_error: 106.9713 - val_loss: 163.8328 - val_mean_squared_error: 163.8328\n",
      "Epoch 953/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 106.5743 - mean_squared_error: 106.5743 - val_loss: 163.4389 - val_mean_squared_error: 163.4389\n",
      "Epoch 954/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 107.0497 - mean_squared_error: 107.0498 - val_loss: 165.3708 - val_mean_squared_error: 165.3708\n",
      "Epoch 955/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 106.6689 - mean_squared_error: 106.6689 - val_loss: 164.7889 - val_mean_squared_error: 164.7889\n",
      "Epoch 956/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 106.7225 - mean_squared_error: 106.7225 - val_loss: 164.3350 - val_mean_squared_error: 164.3351\n",
      "Epoch 957/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 106.5861 - mean_squared_error: 106.5860 - val_loss: 167.5299 - val_mean_squared_error: 167.5300\n",
      "Epoch 958/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 106.8176 - mean_squared_error: 106.8176 - val_loss: 163.6408 - val_mean_squared_error: 163.6408\n",
      "Epoch 959/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 106.6974 - mean_squared_error: 106.6974 - val_loss: 164.1237 - val_mean_squared_error: 164.1236\n",
      "Epoch 960/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 106.6540 - mean_squared_error: 106.6541 - val_loss: 163.7860 - val_mean_squared_error: 163.7861\n",
      "Epoch 961/1000\n",
      "49590/49590 [==============================] - 2s 43us/sample - loss: 106.6655 - mean_squared_error: 106.6655 - val_loss: 164.6220 - val_mean_squared_error: 164.6219\n",
      "Epoch 962/1000\n",
      "49590/49590 [==============================] - 2s 44us/sample - loss: 106.7157 - mean_squared_error: 106.7157 - val_loss: 165.0719 - val_mean_squared_error: 165.0719\n",
      "Epoch 963/1000\n",
      "49590/49590 [==============================] - 3s 67us/sample - loss: 106.8639 - mean_squared_error: 106.8639 - val_loss: 165.4190 - val_mean_squared_error: 165.4190\n",
      "Epoch 964/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 106.7468 - mean_squared_error: 106.7468 - val_loss: 165.5316 - val_mean_squared_error: 165.5316\n",
      "Epoch 965/1000\n",
      "49590/49590 [==============================] - 3s 58us/sample - loss: 106.3685 - mean_squared_error: 106.3685 - val_loss: 165.9568 - val_mean_squared_error: 165.9569\n",
      "Epoch 966/1000\n",
      "49590/49590 [==============================] - 3s 58us/sample - loss: 106.5676 - mean_squared_error: 106.5676 - val_loss: 165.8105 - val_mean_squared_error: 165.8105\n",
      "Epoch 967/1000\n",
      "49590/49590 [==============================] - 2s 49us/sample - loss: 106.8015 - mean_squared_error: 106.8015 - val_loss: 165.0631 - val_mean_squared_error: 165.0631\n",
      "Epoch 968/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 106.4206 - mean_squared_error: 106.4206 - val_loss: 164.5555 - val_mean_squared_error: 164.5555\n",
      "Epoch 969/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 106.6325 - mean_squared_error: 106.6325 - val_loss: 163.9510 - val_mean_squared_error: 163.9509\n",
      "Epoch 970/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 106.4227 - mean_squared_error: 106.4227 - val_loss: 164.2531 - val_mean_squared_error: 164.2531\n",
      "Epoch 971/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 106.5026 - mean_squared_error: 106.5026 - val_loss: 164.9726 - val_mean_squared_error: 164.9726\n",
      "Epoch 972/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 106.2084 - mean_squared_error: 106.2084 - val_loss: 163.0663 - val_mean_squared_error: 163.0663\n",
      "Epoch 973/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 106.2759 - mean_squared_error: 106.2759 - val_loss: 162.8993 - val_mean_squared_error: 162.8993\n",
      "Epoch 974/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 106.5565 - mean_squared_error: 106.5565 - val_loss: 165.6712 - val_mean_squared_error: 165.6712\n",
      "Epoch 975/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 106.7096 - mean_squared_error: 106.7096 - val_loss: 167.4337 - val_mean_squared_error: 167.4337\n",
      "Epoch 976/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 106.4730 - mean_squared_error: 106.4730 - val_loss: 164.9977 - val_mean_squared_error: 164.9977\n",
      "Epoch 977/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 106.1701 - mean_squared_error: 106.1702 - val_loss: 164.1909 - val_mean_squared_error: 164.1909\n",
      "Epoch 978/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 106.4379 - mean_squared_error: 106.4380 - val_loss: 164.7223 - val_mean_squared_error: 164.7223\n",
      "Epoch 979/1000\n",
      "49590/49590 [==============================] - 3s 52us/sample - loss: 106.2690 - mean_squared_error: 106.2690 - val_loss: 164.7063 - val_mean_squared_error: 164.7063\n",
      "Epoch 980/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 106.1720 - mean_squared_error: 106.1721 - val_loss: 167.4217 - val_mean_squared_error: 167.4216\n",
      "Epoch 981/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 106.3912 - mean_squared_error: 106.3912 - val_loss: 164.3207 - val_mean_squared_error: 164.3207\n",
      "Epoch 982/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 106.6595 - mean_squared_error: 106.6595 - val_loss: 163.2207 - val_mean_squared_error: 163.2207\n",
      "Epoch 983/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 106.2765 - mean_squared_error: 106.2766 - val_loss: 167.6551 - val_mean_squared_error: 167.6551\n",
      "Epoch 984/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 106.3939 - mean_squared_error: 106.3939 - val_loss: 167.4423 - val_mean_squared_error: 167.4422\n",
      "Epoch 985/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 106.0118 - mean_squared_error: 106.0118 - val_loss: 165.0925 - val_mean_squared_error: 165.0925\n",
      "Epoch 986/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 106.2801 - mean_squared_error: 106.2801 - val_loss: 166.3278 - val_mean_squared_error: 166.3278\n",
      "Epoch 987/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 106.2868 - mean_squared_error: 106.2868 - val_loss: 163.4756 - val_mean_squared_error: 163.4756\n",
      "Epoch 988/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 106.1490 - mean_squared_error: 106.1490 - val_loss: 165.1042 - val_mean_squared_error: 165.1042\n",
      "Epoch 989/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 106.1419 - mean_squared_error: 106.1419 - val_loss: 165.9989 - val_mean_squared_error: 165.9988\n",
      "Epoch 990/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 2s 36us/sample - loss: 106.2853 - mean_squared_error: 106.2852 - val_loss: 165.3404 - val_mean_squared_error: 165.3403\n",
      "Epoch 991/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 105.8487 - mean_squared_error: 105.8487 - val_loss: 163.2117 - val_mean_squared_error: 163.2117\n",
      "Epoch 992/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 106.0548 - mean_squared_error: 106.0548 - val_loss: 167.3422 - val_mean_squared_error: 167.3421\n",
      "Epoch 993/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 106.4812 - mean_squared_error: 106.4812 - val_loss: 166.2791 - val_mean_squared_error: 166.2791\n",
      "Epoch 994/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 105.8399 - mean_squared_error: 105.8399 - val_loss: 165.7945 - val_mean_squared_error: 165.7945\n",
      "Epoch 995/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 106.5316 - mean_squared_error: 106.5316 - val_loss: 166.1457 - val_mean_squared_error: 166.1457\n",
      "Epoch 996/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 105.9715 - mean_squared_error: 105.9715 - val_loss: 163.7784 - val_mean_squared_error: 163.7784\n",
      "Epoch 997/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 106.3721 - mean_squared_error: 106.3722 - val_loss: 164.9937 - val_mean_squared_error: 164.9937\n",
      "Epoch 998/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 106.1582 - mean_squared_error: 106.1582 - val_loss: 166.2472 - val_mean_squared_error: 166.2472\n",
      "Epoch 999/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 105.9446 - mean_squared_error: 105.9446 - val_loss: 164.5755 - val_mean_squared_error: 164.5754\n",
      "Epoch 1000/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 106.0560 - mean_squared_error: 106.0560 - val_loss: 165.7815 - val_mean_squared_error: 165.7815\n"
     ]
    }
   ],
   "source": [
    "# quantitative: ANN\n",
    "# specify network layers\n",
    "quant_ann = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation = 'sigmoid', input_shape = (13, )),\n",
    "    tf.keras.layers.Dense(100, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(100, activation = 'relu'),\n",
    "     tf.keras.layers.Dense(100, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation = 'linear')\n",
    "])\n",
    "\n",
    "# compile and fit network\n",
    "quant_ann.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['mean_squared_error']) \n",
    "history = quant_ann.fit(X_train, y_train, epochs = 1000, batch_size = 128, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training and validation accuracy\n",
    "plt.plot(history.history['mean_squared_error'])\n",
    "plt.plot(history.history['val_mean_squared_error'])\n",
    "plt.title('Model MSE vs. Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Training', 'Validation'], loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "0.0862026946720178\n"
     ]
    }
   ],
   "source": [
    "scores = quant_ann.predict(X_test)\n",
    "accuracy = r2_score(y_test, scores)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 49590 samples, validate on 21253 samples\n",
      "Epoch 1/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 390.1971 - mean_squared_error: 390.1010 - val_loss: 172.8463 - val_mean_squared_error: 172.7507\n",
      "Epoch 2/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 170.4170 - mean_squared_error: 170.3210 - val_loss: 168.8234 - val_mean_squared_error: 168.7268\n",
      "Epoch 3/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 167.4288 - mean_squared_error: 167.3316 - val_loss: 166.7804 - val_mean_squared_error: 166.6817\n",
      "Epoch 4/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 165.3487 - mean_squared_error: 165.2495 - val_loss: 164.8314 - val_mean_squared_error: 164.7315\n",
      "Epoch 5/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 163.7816 - mean_squared_error: 163.6806 - val_loss: 164.2961 - val_mean_squared_error: 164.1937\n",
      "Epoch 6/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 162.7397 - mean_squared_error: 162.6371 - val_loss: 162.5049 - val_mean_squared_error: 162.4019\n",
      "Epoch 7/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 162.2333 - mean_squared_error: 162.1299 - val_loss: 162.3261 - val_mean_squared_error: 162.2222\n",
      "Epoch 8/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 161.5558 - mean_squared_error: 161.4519 - val_loss: 162.4446 - val_mean_squared_error: 162.3419\n",
      "Epoch 9/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 161.2781 - mean_squared_error: 161.1747 - val_loss: 161.6280 - val_mean_squared_error: 161.5248\n",
      "Epoch 10/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 161.2000 - mean_squared_error: 161.0975 - val_loss: 162.4687 - val_mean_squared_error: 162.3669\n",
      "Epoch 11/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 160.9694 - mean_squared_error: 160.8676 - val_loss: 161.4476 - val_mean_squared_error: 161.3472\n",
      "Epoch 12/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 160.8416 - mean_squared_error: 160.7411 - val_loss: 161.4092 - val_mean_squared_error: 161.3093\n",
      "Epoch 13/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 161.0175 - mean_squared_error: 160.9182 - val_loss: 161.6238 - val_mean_squared_error: 161.5249\n",
      "Epoch 14/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 160.7594 - mean_squared_error: 160.6616 - val_loss: 162.2823 - val_mean_squared_error: 162.1859\n",
      "Epoch 15/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 160.6257 - mean_squared_error: 160.5291 - val_loss: 161.5089 - val_mean_squared_error: 161.4123\n",
      "Epoch 16/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 160.4479 - mean_squared_error: 160.3530 - val_loss: 160.9532 - val_mean_squared_error: 160.8582\n",
      "Epoch 17/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 160.3497 - mean_squared_error: 160.2557 - val_loss: 160.8983 - val_mean_squared_error: 160.8051\n",
      "Epoch 18/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 160.3600 - mean_squared_error: 160.2679 - val_loss: 161.0481 - val_mean_squared_error: 160.9566\n",
      "Epoch 19/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 160.1446 - mean_squared_error: 160.0536 - val_loss: 161.9817 - val_mean_squared_error: 161.8905\n",
      "Epoch 20/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 160.2921 - mean_squared_error: 160.2026 - val_loss: 160.5812 - val_mean_squared_error: 160.4922\n",
      "Epoch 21/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 160.4908 - mean_squared_error: 160.4024 - val_loss: 161.3110 - val_mean_squared_error: 161.2225\n",
      "Epoch 22/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 159.9753 - mean_squared_error: 159.8882 - val_loss: 165.0913 - val_mean_squared_error: 165.0031\n",
      "Epoch 23/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 159.8343 - mean_squared_error: 159.7483 - val_loss: 160.4270 - val_mean_squared_error: 160.3412\n",
      "Epoch 24/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 159.8861 - mean_squared_error: 159.8010 - val_loss: 160.6062 - val_mean_squared_error: 160.5222\n",
      "Epoch 25/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 159.8142 - mean_squared_error: 159.7301 - val_loss: 160.5792 - val_mean_squared_error: 160.4948\n",
      "Epoch 26/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 159.6143 - mean_squared_error: 159.5309 - val_loss: 160.2763 - val_mean_squared_error: 160.1938\n",
      "Epoch 27/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 159.7055 - mean_squared_error: 159.6227 - val_loss: 159.8876 - val_mean_squared_error: 159.8051\n",
      "Epoch 28/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 159.2965 - mean_squared_error: 159.2141 - val_loss: 160.1419 - val_mean_squared_error: 160.0602\n",
      "Epoch 29/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 159.1109 - mean_squared_error: 159.0291 - val_loss: 160.1445 - val_mean_squared_error: 160.0630\n",
      "Epoch 30/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 159.3564 - mean_squared_error: 159.2745 - val_loss: 159.7768 - val_mean_squared_error: 159.6946\n",
      "Epoch 31/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 158.8713 - mean_squared_error: 158.7894 - val_loss: 159.3912 - val_mean_squared_error: 159.3096\n",
      "Epoch 32/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 158.8191 - mean_squared_error: 158.7372 - val_loss: 159.2004 - val_mean_squared_error: 159.1185\n",
      "Epoch 33/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 158.7201 - mean_squared_error: 158.6378 - val_loss: 161.2774 - val_mean_squared_error: 161.1938\n",
      "Epoch 34/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 158.6176 - mean_squared_error: 158.5350 - val_loss: 158.9630 - val_mean_squared_error: 158.8803\n",
      "Epoch 35/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 158.4389 - mean_squared_error: 158.3559 - val_loss: 158.8929 - val_mean_squared_error: 158.8093\n",
      "Epoch 36/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 158.1267 - mean_squared_error: 158.0429 - val_loss: 159.0515 - val_mean_squared_error: 158.9670\n",
      "Epoch 37/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 157.9210 - mean_squared_error: 157.8367 - val_loss: 158.9159 - val_mean_squared_error: 158.8316\n",
      "Epoch 38/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 157.7249 - mean_squared_error: 157.6398 - val_loss: 159.4429 - val_mean_squared_error: 159.3582\n",
      "Epoch 39/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 157.5618 - mean_squared_error: 157.4758 - val_loss: 158.2622 - val_mean_squared_error: 158.1751\n",
      "Epoch 40/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 157.5798 - mean_squared_error: 157.4925 - val_loss: 158.5205 - val_mean_squared_error: 158.4332\n",
      "Epoch 41/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 157.1292 - mean_squared_error: 157.0406 - val_loss: 157.5780 - val_mean_squared_error: 157.4887\n",
      "Epoch 42/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 157.0220 - mean_squared_error: 156.9319 - val_loss: 157.5288 - val_mean_squared_error: 157.4382\n",
      "Epoch 43/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 156.7731 - mean_squared_error: 156.6815 - val_loss: 157.3373 - val_mean_squared_error: 157.2449\n",
      "Epoch 44/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 156.5638 - mean_squared_error: 156.4700 - val_loss: 157.5462 - val_mean_squared_error: 157.4520\n",
      "Epoch 45/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 156.2508 - mean_squared_error: 156.1550 - val_loss: 156.8190 - val_mean_squared_error: 156.7224\n",
      "Epoch 46/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 156.3048 - mean_squared_error: 156.2069 - val_loss: 156.8339 - val_mean_squared_error: 156.7346\n",
      "Epoch 47/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 155.7435 - mean_squared_error: 155.6434 - val_loss: 157.2110 - val_mean_squared_error: 157.1102\n",
      "Epoch 48/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 155.7985 - mean_squared_error: 155.6960 - val_loss: 156.5280 - val_mean_squared_error: 156.4248\n",
      "Epoch 49/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 155.3966 - mean_squared_error: 155.2914 - val_loss: 157.6318 - val_mean_squared_error: 157.5246\n",
      "Epoch 50/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 155.3519 - mean_squared_error: 155.2441 - val_loss: 155.8696 - val_mean_squared_error: 155.7605\n",
      "Epoch 51/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 155.0866 - mean_squared_error: 154.9762 - val_loss: 158.0092 - val_mean_squared_error: 157.8966\n",
      "Epoch 52/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 155.0180 - mean_squared_error: 154.9052 - val_loss: 156.1666 - val_mean_squared_error: 156.0532\n",
      "Epoch 53/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 154.6927 - mean_squared_error: 154.5773 - val_loss: 155.2933 - val_mean_squared_error: 155.1765\n",
      "Epoch 54/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 154.5482 - mean_squared_error: 154.4302 - val_loss: 156.1537 - val_mean_squared_error: 156.0334\n",
      "Epoch 55/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 154.3472 - mean_squared_error: 154.2263 - val_loss: 155.0969 - val_mean_squared_error: 154.9748\n",
      "Epoch 56/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 154.7803 - mean_squared_error: 154.6575 - val_loss: 155.3436 - val_mean_squared_error: 155.2189\n",
      "Epoch 57/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 154.2926 - mean_squared_error: 154.1673 - val_loss: 154.9344 - val_mean_squared_error: 154.8083\n",
      "Epoch 58/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 154.1114 - mean_squared_error: 153.9841 - val_loss: 154.7740 - val_mean_squared_error: 154.6456\n",
      "Epoch 59/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 153.8474 - mean_squared_error: 153.7178 - val_loss: 156.3030 - val_mean_squared_error: 156.1730\n",
      "Epoch 60/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 153.9440 - mean_squared_error: 153.8120 - val_loss: 154.4344 - val_mean_squared_error: 154.3014\n",
      "Epoch 61/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 153.7560 - mean_squared_error: 153.6222 - val_loss: 156.7747 - val_mean_squared_error: 156.6390\n",
      "Epoch 62/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 153.6891 - mean_squared_error: 153.5535 - val_loss: 154.3448 - val_mean_squared_error: 154.2082\n",
      "Epoch 63/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 153.5146 - mean_squared_error: 153.3767 - val_loss: 154.1309 - val_mean_squared_error: 153.9919\n",
      "Epoch 64/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 153.3788 - mean_squared_error: 153.2390 - val_loss: 154.8434 - val_mean_squared_error: 154.7023\n",
      "Epoch 65/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 153.3850 - mean_squared_error: 153.2433 - val_loss: 154.3650 - val_mean_squared_error: 154.2221\n",
      "Epoch 66/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 153.1341 - mean_squared_error: 152.9906 - val_loss: 153.9004 - val_mean_squared_error: 153.7555\n",
      "Epoch 67/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 153.2758 - mean_squared_error: 153.1300 - val_loss: 154.1455 - val_mean_squared_error: 153.9986\n",
      "Epoch 68/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 152.9260 - mean_squared_error: 152.7787 - val_loss: 153.6880 - val_mean_squared_error: 153.5393\n",
      "Epoch 69/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 152.8910 - mean_squared_error: 152.7412 - val_loss: 153.8201 - val_mean_squared_error: 153.6695\n",
      "Epoch 70/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 152.7542 - mean_squared_error: 152.6023 - val_loss: 155.7201 - val_mean_squared_error: 155.5679\n",
      "Epoch 71/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 152.7174 - mean_squared_error: 152.5631 - val_loss: 154.8572 - val_mean_squared_error: 154.7022\n",
      "Epoch 72/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 152.4955 - mean_squared_error: 152.3393 - val_loss: 156.2669 - val_mean_squared_error: 156.1085\n",
      "Epoch 73/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 152.3886 - mean_squared_error: 152.2301 - val_loss: 153.1752 - val_mean_squared_error: 153.0154\n",
      "Epoch 74/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 152.2826 - mean_squared_error: 152.1210 - val_loss: 153.4743 - val_mean_squared_error: 153.3114\n",
      "Epoch 75/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 152.2557 - mean_squared_error: 152.0916 - val_loss: 153.0691 - val_mean_squared_error: 152.9038\n",
      "Epoch 76/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 152.0307 - mean_squared_error: 151.8641 - val_loss: 153.7581 - val_mean_squared_error: 153.5904\n",
      "Epoch 77/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 152.2654 - mean_squared_error: 152.0959 - val_loss: 152.8769 - val_mean_squared_error: 152.7065\n",
      "Epoch 78/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 151.8784 - mean_squared_error: 151.7069 - val_loss: 152.7316 - val_mean_squared_error: 152.5581\n",
      "Epoch 79/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 152.0381 - mean_squared_error: 151.8636 - val_loss: 153.0224 - val_mean_squared_error: 152.8462\n",
      "Epoch 80/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 151.7698 - mean_squared_error: 151.5925 - val_loss: 153.0297 - val_mean_squared_error: 152.8512\n",
      "Epoch 81/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 151.9292 - mean_squared_error: 151.7495 - val_loss: 152.8191 - val_mean_squared_error: 152.6388\n",
      "Epoch 82/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 151.5568 - mean_squared_error: 151.3744 - val_loss: 152.4091 - val_mean_squared_error: 152.2253\n",
      "Epoch 83/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 151.4637 - mean_squared_error: 151.2788 - val_loss: 152.6234 - val_mean_squared_error: 152.4361\n",
      "Epoch 84/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 151.6124 - mean_squared_error: 151.4240 - val_loss: 152.7293 - val_mean_squared_error: 152.5400\n",
      "Epoch 85/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 151.4477 - mean_squared_error: 151.2573 - val_loss: 153.1141 - val_mean_squared_error: 152.9221\n",
      "Epoch 86/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 151.2529 - mean_squared_error: 151.0598 - val_loss: 152.2315 - val_mean_squared_error: 152.0376\n",
      "Epoch 87/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 151.2648 - mean_squared_error: 151.0689 - val_loss: 152.2805 - val_mean_squared_error: 152.0827\n",
      "Epoch 88/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 151.1022 - mean_squared_error: 150.9030 - val_loss: 152.4219 - val_mean_squared_error: 152.2212\n",
      "Epoch 89/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 150.9949 - mean_squared_error: 150.7925 - val_loss: 152.1364 - val_mean_squared_error: 151.9330\n",
      "Epoch 90/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 21us/sample - loss: 151.1740 - mean_squared_error: 150.9695 - val_loss: 152.1652 - val_mean_squared_error: 151.9585\n",
      "Epoch 91/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 150.8619 - mean_squared_error: 150.6541 - val_loss: 151.8693 - val_mean_squared_error: 151.6597\n",
      "Epoch 92/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 150.8623 - mean_squared_error: 150.6512 - val_loss: 152.3916 - val_mean_squared_error: 152.1794\n",
      "Epoch 93/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 150.7115 - mean_squared_error: 150.4977 - val_loss: 152.0321 - val_mean_squared_error: 151.8157\n",
      "Epoch 94/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 150.4783 - mean_squared_error: 150.2610 - val_loss: 151.7154 - val_mean_squared_error: 151.4967\n",
      "Epoch 95/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 150.6644 - mean_squared_error: 150.4441 - val_loss: 151.7488 - val_mean_squared_error: 151.5267\n",
      "Epoch 96/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 150.4727 - mean_squared_error: 150.2493 - val_loss: 151.5330 - val_mean_squared_error: 151.3078\n",
      "Epoch 97/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 150.3495 - mean_squared_error: 150.1233 - val_loss: 151.8761 - val_mean_squared_error: 151.6471\n",
      "Epoch 98/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 150.3306 - mean_squared_error: 150.1006 - val_loss: 152.3951 - val_mean_squared_error: 152.1638\n",
      "Epoch 99/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 150.3983 - mean_squared_error: 150.1659 - val_loss: 151.5564 - val_mean_squared_error: 151.3223\n",
      "Epoch 100/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 150.1864 - mean_squared_error: 149.9510 - val_loss: 151.9477 - val_mean_squared_error: 151.7100\n",
      "Epoch 101/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 150.0906 - mean_squared_error: 149.8515 - val_loss: 151.3491 - val_mean_squared_error: 151.1088\n",
      "Epoch 102/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 149.9672 - mean_squared_error: 149.7244 - val_loss: 151.1744 - val_mean_squared_error: 150.9309\n",
      "Epoch 103/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 150.0062 - mean_squared_error: 149.7608 - val_loss: 152.3547 - val_mean_squared_error: 152.1090\n",
      "Epoch 104/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 150.0508 - mean_squared_error: 149.8029 - val_loss: 152.4503 - val_mean_squared_error: 152.2013\n",
      "Epoch 105/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 149.7583 - mean_squared_error: 149.5070 - val_loss: 151.3444 - val_mean_squared_error: 151.0903\n",
      "Epoch 106/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 149.9144 - mean_squared_error: 149.6598 - val_loss: 151.3689 - val_mean_squared_error: 151.1131\n",
      "Epoch 107/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 149.5046 - mean_squared_error: 149.2475 - val_loss: 151.3041 - val_mean_squared_error: 151.0446\n",
      "Epoch 108/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 149.6262 - mean_squared_error: 149.3656 - val_loss: 151.9718 - val_mean_squared_error: 151.7093\n",
      "Epoch 109/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 149.4857 - mean_squared_error: 149.2211 - val_loss: 151.0843 - val_mean_squared_error: 150.8195\n",
      "Epoch 110/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 149.2290 - mean_squared_error: 148.9628 - val_loss: 151.1549 - val_mean_squared_error: 150.8845\n",
      "Epoch 111/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 149.1452 - mean_squared_error: 148.8744 - val_loss: 152.3666 - val_mean_squared_error: 152.0938\n",
      "Epoch 112/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 149.1297 - mean_squared_error: 148.8556 - val_loss: 151.4448 - val_mean_squared_error: 151.1693\n",
      "Epoch 113/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 149.2374 - mean_squared_error: 148.9609 - val_loss: 150.4744 - val_mean_squared_error: 150.1954\n",
      "Epoch 114/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 149.3630 - mean_squared_error: 149.0833 - val_loss: 152.2721 - val_mean_squared_error: 151.9908\n",
      "Epoch 115/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 148.8370 - mean_squared_error: 148.5546 - val_loss: 150.9451 - val_mean_squared_error: 150.6597\n",
      "Epoch 116/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 149.0436 - mean_squared_error: 148.7577 - val_loss: 152.9711 - val_mean_squared_error: 152.6833\n",
      "Epoch 117/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 148.8656 - mean_squared_error: 148.5770 - val_loss: 150.3696 - val_mean_squared_error: 150.0791\n",
      "Epoch 118/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 148.8065 - mean_squared_error: 148.5153 - val_loss: 150.2372 - val_mean_squared_error: 149.9440\n",
      "Epoch 119/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 148.3886 - mean_squared_error: 148.0942 - val_loss: 150.0604 - val_mean_squared_error: 149.7653\n",
      "Epoch 120/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 148.7356 - mean_squared_error: 148.4377 - val_loss: 150.2197 - val_mean_squared_error: 149.9211\n",
      "Epoch 121/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 148.4622 - mean_squared_error: 148.1624 - val_loss: 150.1799 - val_mean_squared_error: 149.8779\n",
      "Epoch 122/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 148.5600 - mean_squared_error: 148.2571 - val_loss: 150.3155 - val_mean_squared_error: 150.0114\n",
      "Epoch 123/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 148.4455 - mean_squared_error: 148.1397 - val_loss: 150.3155 - val_mean_squared_error: 150.0098\n",
      "Epoch 124/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 148.3293 - mean_squared_error: 148.0218 - val_loss: 151.3415 - val_mean_squared_error: 151.0318\n",
      "Epoch 125/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 148.2399 - mean_squared_error: 147.9298 - val_loss: 149.8149 - val_mean_squared_error: 149.5023\n",
      "Epoch 126/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 148.2196 - mean_squared_error: 147.9061 - val_loss: 150.0186 - val_mean_squared_error: 149.7039\n",
      "Epoch 127/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 148.3090 - mean_squared_error: 147.9928 - val_loss: 150.0062 - val_mean_squared_error: 149.6900\n",
      "Epoch 128/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 147.9110 - mean_squared_error: 147.5924 - val_loss: 149.7041 - val_mean_squared_error: 149.3858\n",
      "Epoch 129/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 147.9748 - mean_squared_error: 147.6540 - val_loss: 149.5693 - val_mean_squared_error: 149.2476\n",
      "Epoch 130/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 148.0193 - mean_squared_error: 147.6958 - val_loss: 150.3676 - val_mean_squared_error: 150.0458\n",
      "Epoch 131/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 147.7253 - mean_squared_error: 147.4006 - val_loss: 149.6468 - val_mean_squared_error: 149.3199\n",
      "Epoch 132/1000\n",
      "49590/49590 [==============================] - 1s 18us/sample - loss: 148.0016 - mean_squared_error: 147.6750 - val_loss: 150.3879 - val_mean_squared_error: 150.0602\n",
      "Epoch 133/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 147.8227 - mean_squared_error: 147.4937 - val_loss: 149.5924 - val_mean_squared_error: 149.2626\n",
      "Epoch 134/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 147.8119 - mean_squared_error: 147.4806 - val_loss: 149.4449 - val_mean_squared_error: 149.1150\n",
      "Epoch 135/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 147.6422 - mean_squared_error: 147.3097 - val_loss: 149.2367 - val_mean_squared_error: 148.9038\n",
      "Epoch 136/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 147.7156 - mean_squared_error: 147.3812 - val_loss: 151.0475 - val_mean_squared_error: 150.7116\n",
      "Epoch 137/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 147.1903 - mean_squared_error: 146.8527 - val_loss: 149.4525 - val_mean_squared_error: 149.1148\n",
      "Epoch 138/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 147.4636 - mean_squared_error: 147.1256 - val_loss: 149.2251 - val_mean_squared_error: 148.8843\n",
      "Epoch 139/1000\n",
      "49590/49590 [==============================] - 1s 18us/sample - loss: 147.5150 - mean_squared_error: 147.1740 - val_loss: 149.6208 - val_mean_squared_error: 149.2796\n",
      "Epoch 140/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 147.2912 - mean_squared_error: 146.9487 - val_loss: 158.2386 - val_mean_squared_error: 157.8945\n",
      "Epoch 141/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 147.3056 - mean_squared_error: 146.9612 - val_loss: 149.9019 - val_mean_squared_error: 149.5571\n",
      "Epoch 142/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 147.0728 - mean_squared_error: 146.7258 - val_loss: 149.5207 - val_mean_squared_error: 149.1733\n",
      "Epoch 143/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 147.0569 - mean_squared_error: 146.7079 - val_loss: 150.0563 - val_mean_squared_error: 149.7078\n",
      "Epoch 144/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 147.1018 - mean_squared_error: 146.7523 - val_loss: 149.1473 - val_mean_squared_error: 148.7956\n",
      "Epoch 145/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 147.2643 - mean_squared_error: 146.9122 - val_loss: 149.5857 - val_mean_squared_error: 149.2345\n",
      "Epoch 146/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 146.9014 - mean_squared_error: 146.5488 - val_loss: 149.0834 - val_mean_squared_error: 148.7299\n",
      "Epoch 147/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 146.9133 - mean_squared_error: 146.5592 - val_loss: 149.5854 - val_mean_squared_error: 149.2287\n",
      "Epoch 148/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 146.8043 - mean_squared_error: 146.4476 - val_loss: 148.8495 - val_mean_squared_error: 148.4921\n",
      "Epoch 149/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 146.7352 - mean_squared_error: 146.3769 - val_loss: 148.9719 - val_mean_squared_error: 148.6122\n",
      "Epoch 150/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 146.7022 - mean_squared_error: 146.3421 - val_loss: 148.8553 - val_mean_squared_error: 148.4937\n",
      "Epoch 151/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 146.6151 - mean_squared_error: 146.2537 - val_loss: 151.0644 - val_mean_squared_error: 150.7027\n",
      "Epoch 152/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 146.7555 - mean_squared_error: 146.3927 - val_loss: 148.9884 - val_mean_squared_error: 148.6252\n",
      "Epoch 153/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 146.4306 - mean_squared_error: 146.0666 - val_loss: 148.7550 - val_mean_squared_error: 148.3914\n",
      "Epoch 154/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 146.5847 - mean_squared_error: 146.2194 - val_loss: 150.7048 - val_mean_squared_error: 150.3378\n",
      "Epoch 155/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 146.3358 - mean_squared_error: 145.9693 - val_loss: 150.5165 - val_mean_squared_error: 150.1477\n",
      "Epoch 156/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 146.3173 - mean_squared_error: 145.9483 - val_loss: 148.6674 - val_mean_squared_error: 148.2980\n",
      "Epoch 157/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 146.7523 - mean_squared_error: 146.3829 - val_loss: 149.1219 - val_mean_squared_error: 148.7507\n",
      "Epoch 158/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 146.3571 - mean_squared_error: 145.9863 - val_loss: 148.5273 - val_mean_squared_error: 148.1562\n",
      "Epoch 159/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 146.1590 - mean_squared_error: 145.7878 - val_loss: 149.0102 - val_mean_squared_error: 148.6371\n",
      "Epoch 160/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 146.3865 - mean_squared_error: 146.0124 - val_loss: 148.3054 - val_mean_squared_error: 147.9314\n",
      "Epoch 161/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 145.9306 - mean_squared_error: 145.5553 - val_loss: 149.5260 - val_mean_squared_error: 149.1501\n",
      "Epoch 162/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 146.0370 - mean_squared_error: 145.6606 - val_loss: 148.2645 - val_mean_squared_error: 147.8876\n",
      "Epoch 163/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 145.9817 - mean_squared_error: 145.6039 - val_loss: 150.0367 - val_mean_squared_error: 149.6579\n",
      "Epoch 164/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 146.1137 - mean_squared_error: 145.7343 - val_loss: 148.2235 - val_mean_squared_error: 147.8471\n",
      "Epoch 165/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 146.0836 - mean_squared_error: 145.7045 - val_loss: 148.2616 - val_mean_squared_error: 147.8819\n",
      "Epoch 166/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 146.0328 - mean_squared_error: 145.6521 - val_loss: 148.1355 - val_mean_squared_error: 147.7563\n",
      "Epoch 167/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 145.9084 - mean_squared_error: 145.5276 - val_loss: 148.3390 - val_mean_squared_error: 147.9556\n",
      "Epoch 168/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 145.8660 - mean_squared_error: 145.4832 - val_loss: 148.9569 - val_mean_squared_error: 148.5729\n",
      "Epoch 169/1000\n",
      "49590/49590 [==============================] - 1s 18us/sample - loss: 145.7913 - mean_squared_error: 145.4074 - val_loss: 148.0212 - val_mean_squared_error: 147.6362\n",
      "Epoch 170/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 145.8028 - mean_squared_error: 145.4174 - val_loss: 148.8863 - val_mean_squared_error: 148.5006\n",
      "Epoch 171/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 145.7251 - mean_squared_error: 145.3387 - val_loss: 147.8907 - val_mean_squared_error: 147.5029\n",
      "Epoch 172/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 145.6169 - mean_squared_error: 145.2292 - val_loss: 149.0219 - val_mean_squared_error: 148.6339\n",
      "Epoch 173/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 145.6661 - mean_squared_error: 145.2773 - val_loss: 149.6925 - val_mean_squared_error: 149.3022\n",
      "Epoch 174/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 145.4326 - mean_squared_error: 145.0430 - val_loss: 148.2486 - val_mean_squared_error: 147.8588\n",
      "Epoch 175/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 145.4413 - mean_squared_error: 145.0497 - val_loss: 148.7734 - val_mean_squared_error: 148.3811\n",
      "Epoch 176/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 145.3345 - mean_squared_error: 144.9419 - val_loss: 147.9420 - val_mean_squared_error: 147.5493\n",
      "Epoch 177/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 145.5640 - mean_squared_error: 145.1709 - val_loss: 148.6251 - val_mean_squared_error: 148.2317\n",
      "Epoch 178/1000\n",
      "49590/49590 [==============================] - 1s 18us/sample - loss: 145.4344 - mean_squared_error: 145.0405 - val_loss: 150.0072 - val_mean_squared_error: 149.6121\n",
      "Epoch 179/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 145.3713 - mean_squared_error: 144.9764 - val_loss: 147.9603 - val_mean_squared_error: 147.5628\n",
      "Epoch 180/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 19us/sample - loss: 145.1452 - mean_squared_error: 144.7484 - val_loss: 147.7131 - val_mean_squared_error: 147.3156\n",
      "Epoch 181/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 145.2570 - mean_squared_error: 144.8590 - val_loss: 148.6815 - val_mean_squared_error: 148.2836\n",
      "Epoch 182/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 145.2212 - mean_squared_error: 144.8220 - val_loss: 148.1326 - val_mean_squared_error: 147.7348\n",
      "Epoch 183/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 145.1040 - mean_squared_error: 144.7036 - val_loss: 147.7145 - val_mean_squared_error: 147.3159\n",
      "Epoch 184/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 145.1943 - mean_squared_error: 144.7952 - val_loss: 147.5855 - val_mean_squared_error: 147.1853\n",
      "Epoch 185/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 145.0292 - mean_squared_error: 144.6284 - val_loss: 148.4228 - val_mean_squared_error: 148.0204\n",
      "Epoch 186/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 144.9434 - mean_squared_error: 144.5414 - val_loss: 147.8278 - val_mean_squared_error: 147.4256\n",
      "Epoch 187/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 145.0442 - mean_squared_error: 144.6412 - val_loss: 148.1151 - val_mean_squared_error: 147.7117\n",
      "Epoch 188/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 144.9990 - mean_squared_error: 144.5959 - val_loss: 148.2033 - val_mean_squared_error: 147.7990\n",
      "Epoch 189/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 145.0006 - mean_squared_error: 144.5947 - val_loss: 147.4052 - val_mean_squared_error: 147.0005\n",
      "Epoch 190/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 144.7975 - mean_squared_error: 144.3915 - val_loss: 148.0671 - val_mean_squared_error: 147.6607\n",
      "Epoch 191/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 144.9133 - mean_squared_error: 144.5059 - val_loss: 147.5073 - val_mean_squared_error: 147.1006\n",
      "Epoch 192/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 144.8504 - mean_squared_error: 144.4420 - val_loss: 147.7469 - val_mean_squared_error: 147.3398\n",
      "Epoch 193/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 144.9205 - mean_squared_error: 144.5120 - val_loss: 147.4484 - val_mean_squared_error: 147.0389\n",
      "Epoch 194/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 144.7302 - mean_squared_error: 144.3210 - val_loss: 147.3677 - val_mean_squared_error: 146.9587\n",
      "Epoch 195/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 144.5480 - mean_squared_error: 144.1379 - val_loss: 148.7427 - val_mean_squared_error: 148.3307\n",
      "Epoch 196/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 144.6627 - mean_squared_error: 144.2499 - val_loss: 148.3234 - val_mean_squared_error: 147.9128\n",
      "Epoch 197/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 144.6370 - mean_squared_error: 144.2240 - val_loss: 148.4646 - val_mean_squared_error: 148.0508\n",
      "Epoch 198/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 144.6280 - mean_squared_error: 144.2153 - val_loss: 151.0260 - val_mean_squared_error: 150.6102\n",
      "Epoch 199/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 144.4079 - mean_squared_error: 143.9930 - val_loss: 147.2328 - val_mean_squared_error: 146.8169\n",
      "Epoch 200/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 144.4348 - mean_squared_error: 144.0183 - val_loss: 147.2636 - val_mean_squared_error: 146.8480\n",
      "Epoch 201/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 144.7427 - mean_squared_error: 144.3263 - val_loss: 147.9409 - val_mean_squared_error: 147.5247\n",
      "Epoch 202/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 144.5184 - mean_squared_error: 144.1014 - val_loss: 147.2145 - val_mean_squared_error: 146.7973\n",
      "Epoch 203/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 144.2863 - mean_squared_error: 143.8675 - val_loss: 147.6121 - val_mean_squared_error: 147.1925\n",
      "Epoch 204/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 144.2763 - mean_squared_error: 143.8557 - val_loss: 147.8724 - val_mean_squared_error: 147.4515\n",
      "Epoch 205/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 144.3084 - mean_squared_error: 143.8874 - val_loss: 147.5962 - val_mean_squared_error: 147.1739\n",
      "Epoch 206/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 144.2225 - mean_squared_error: 143.7988 - val_loss: 147.2769 - val_mean_squared_error: 146.8564\n",
      "Epoch 207/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 144.1298 - mean_squared_error: 143.7074 - val_loss: 147.0769 - val_mean_squared_error: 146.6546\n",
      "Epoch 208/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 144.2281 - mean_squared_error: 143.8048 - val_loss: 147.0824 - val_mean_squared_error: 146.6587\n",
      "Epoch 209/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 144.2180 - mean_squared_error: 143.7944 - val_loss: 146.9269 - val_mean_squared_error: 146.5019\n",
      "Epoch 210/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 144.1178 - mean_squared_error: 143.6924 - val_loss: 147.8418 - val_mean_squared_error: 147.4156\n",
      "Epoch 211/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 144.0821 - mean_squared_error: 143.6550 - val_loss: 147.9392 - val_mean_squared_error: 147.5115\n",
      "Epoch 212/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 143.9331 - mean_squared_error: 143.5052 - val_loss: 147.2199 - val_mean_squared_error: 146.7917\n",
      "Epoch 213/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 144.0088 - mean_squared_error: 143.5796 - val_loss: 147.2197 - val_mean_squared_error: 146.7909\n",
      "Epoch 214/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 143.9413 - mean_squared_error: 143.5115 - val_loss: 146.8109 - val_mean_squared_error: 146.3809\n",
      "Epoch 215/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 143.8939 - mean_squared_error: 143.4622 - val_loss: 147.7074 - val_mean_squared_error: 147.2773\n",
      "Epoch 216/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 143.9511 - mean_squared_error: 143.5199 - val_loss: 146.8043 - val_mean_squared_error: 146.3716\n",
      "Epoch 217/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 143.8303 - mean_squared_error: 143.3969 - val_loss: 148.3157 - val_mean_squared_error: 147.8832\n",
      "Epoch 218/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 143.7827 - mean_squared_error: 143.3490 - val_loss: 146.9265 - val_mean_squared_error: 146.4923\n",
      "Epoch 219/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 143.8418 - mean_squared_error: 143.4084 - val_loss: 147.2402 - val_mean_squared_error: 146.8039\n",
      "Epoch 220/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 143.7446 - mean_squared_error: 143.3086 - val_loss: 147.8811 - val_mean_squared_error: 147.4447\n",
      "Epoch 221/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 143.8396 - mean_squared_error: 143.4035 - val_loss: 146.8988 - val_mean_squared_error: 146.4617\n",
      "Epoch 222/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 143.6005 - mean_squared_error: 143.1641 - val_loss: 146.8421 - val_mean_squared_error: 146.4036\n",
      "Epoch 223/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 143.5577 - mean_squared_error: 143.1196 - val_loss: 146.8574 - val_mean_squared_error: 146.4200\n",
      "Epoch 224/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 143.6362 - mean_squared_error: 143.1978 - val_loss: 146.7367 - val_mean_squared_error: 146.2968\n",
      "Epoch 225/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 143.5930 - mean_squared_error: 143.1526 - val_loss: 147.1976 - val_mean_squared_error: 146.7576\n",
      "Epoch 226/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 143.5322 - mean_squared_error: 143.0914 - val_loss: 147.2390 - val_mean_squared_error: 146.7978\n",
      "Epoch 227/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 143.6606 - mean_squared_error: 143.2192 - val_loss: 148.0509 - val_mean_squared_error: 147.6107\n",
      "Epoch 228/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 143.5238 - mean_squared_error: 143.0831 - val_loss: 146.6833 - val_mean_squared_error: 146.2395\n",
      "Epoch 229/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 143.5075 - mean_squared_error: 143.0649 - val_loss: 146.9300 - val_mean_squared_error: 146.4858\n",
      "Epoch 230/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 143.4619 - mean_squared_error: 143.0165 - val_loss: 146.7990 - val_mean_squared_error: 146.3549\n",
      "Epoch 231/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 143.5184 - mean_squared_error: 143.0740 - val_loss: 146.6164 - val_mean_squared_error: 146.1739\n",
      "Epoch 232/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 143.2918 - mean_squared_error: 142.8479 - val_loss: 146.5484 - val_mean_squared_error: 146.1005\n",
      "Epoch 233/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 143.2463 - mean_squared_error: 142.7994 - val_loss: 146.6912 - val_mean_squared_error: 146.2433\n",
      "Epoch 234/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 143.4003 - mean_squared_error: 142.9538 - val_loss: 146.3776 - val_mean_squared_error: 145.9289\n",
      "Epoch 235/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 143.1097 - mean_squared_error: 142.6610 - val_loss: 148.5587 - val_mean_squared_error: 148.1096\n",
      "Epoch 236/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 143.3756 - mean_squared_error: 142.9266 - val_loss: 146.7634 - val_mean_squared_error: 146.3132\n",
      "Epoch 237/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 143.3381 - mean_squared_error: 142.8884 - val_loss: 146.5365 - val_mean_squared_error: 146.0872\n",
      "Epoch 238/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 143.1759 - mean_squared_error: 142.7246 - val_loss: 146.7599 - val_mean_squared_error: 146.3092\n",
      "Epoch 239/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 143.3119 - mean_squared_error: 142.8612 - val_loss: 147.5042 - val_mean_squared_error: 147.0521\n",
      "Epoch 240/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 142.9568 - mean_squared_error: 142.5034 - val_loss: 146.5078 - val_mean_squared_error: 146.0558\n",
      "Epoch 241/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 143.2973 - mean_squared_error: 142.8433 - val_loss: 146.4451 - val_mean_squared_error: 145.9924\n",
      "Epoch 242/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 143.1981 - mean_squared_error: 142.7431 - val_loss: 148.4093 - val_mean_squared_error: 147.9552\n",
      "Epoch 243/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 142.9902 - mean_squared_error: 142.5343 - val_loss: 146.6070 - val_mean_squared_error: 146.1533\n",
      "Epoch 244/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 142.9054 - mean_squared_error: 142.4499 - val_loss: 146.5563 - val_mean_squared_error: 146.0992\n",
      "Epoch 245/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 143.3759 - mean_squared_error: 142.9184 - val_loss: 146.1816 - val_mean_squared_error: 145.7257\n",
      "Epoch 246/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 143.0887 - mean_squared_error: 142.6323 - val_loss: 146.3777 - val_mean_squared_error: 145.9197\n",
      "Epoch 247/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 142.8299 - mean_squared_error: 142.3713 - val_loss: 146.8848 - val_mean_squared_error: 146.4257\n",
      "Epoch 248/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 142.9035 - mean_squared_error: 142.4444 - val_loss: 146.6835 - val_mean_squared_error: 146.2253\n",
      "Epoch 249/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 143.0980 - mean_squared_error: 142.6383 - val_loss: 149.9575 - val_mean_squared_error: 149.4981\n",
      "Epoch 250/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 142.8975 - mean_squared_error: 142.4367 - val_loss: 147.1671 - val_mean_squared_error: 146.7064\n",
      "Epoch 251/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 142.8529 - mean_squared_error: 142.3917 - val_loss: 148.4914 - val_mean_squared_error: 148.0301\n",
      "Epoch 252/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 142.8025 - mean_squared_error: 142.3403 - val_loss: 146.6504 - val_mean_squared_error: 146.1882\n",
      "Epoch 253/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 143.1157 - mean_squared_error: 142.6545 - val_loss: 146.7633 - val_mean_squared_error: 146.3001\n",
      "Epoch 254/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 142.7859 - mean_squared_error: 142.3228 - val_loss: 147.3171 - val_mean_squared_error: 146.8530\n",
      "Epoch 255/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 142.8072 - mean_squared_error: 142.3418 - val_loss: 146.6121 - val_mean_squared_error: 146.1485\n",
      "Epoch 256/1000\n",
      "49590/49590 [==============================] - 3s 52us/sample - loss: 142.6479 - mean_squared_error: 142.1832 - val_loss: 146.0330 - val_mean_squared_error: 145.5681\n",
      "Epoch 257/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 142.6067 - mean_squared_error: 142.1402 - val_loss: 146.1682 - val_mean_squared_error: 145.7012\n",
      "Epoch 258/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 142.8362 - mean_squared_error: 142.3702 - val_loss: 145.9759 - val_mean_squared_error: 145.5076\n",
      "Epoch 259/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 142.5101 - mean_squared_error: 142.0421 - val_loss: 146.3161 - val_mean_squared_error: 145.8472\n",
      "Epoch 260/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 142.7378 - mean_squared_error: 142.2692 - val_loss: 147.4060 - val_mean_squared_error: 146.9376\n",
      "Epoch 261/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 142.4269 - mean_squared_error: 141.9581 - val_loss: 146.5623 - val_mean_squared_error: 146.0940\n",
      "Epoch 262/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 142.7964 - mean_squared_error: 142.3263 - val_loss: 146.6298 - val_mean_squared_error: 146.1603\n",
      "Epoch 263/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 142.6462 - mean_squared_error: 142.1756 - val_loss: 145.9246 - val_mean_squared_error: 145.4529\n",
      "Epoch 264/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 142.5341 - mean_squared_error: 142.0623 - val_loss: 145.8478 - val_mean_squared_error: 145.3768\n",
      "Epoch 265/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 142.4757 - mean_squared_error: 142.0033 - val_loss: 147.2158 - val_mean_squared_error: 146.7440\n",
      "Epoch 266/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 142.4758 - mean_squared_error: 142.0030 - val_loss: 146.3077 - val_mean_squared_error: 145.8342\n",
      "Epoch 267/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 142.4055 - mean_squared_error: 141.9314 - val_loss: 146.0650 - val_mean_squared_error: 145.5907\n",
      "Epoch 268/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 142.2124 - mean_squared_error: 141.7375 - val_loss: 145.7090 - val_mean_squared_error: 145.2320\n",
      "Epoch 269/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 142.4471 - mean_squared_error: 141.9712 - val_loss: 147.0192 - val_mean_squared_error: 146.5428\n",
      "Epoch 270/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 19us/sample - loss: 142.4402 - mean_squared_error: 141.9631 - val_loss: 146.7618 - val_mean_squared_error: 146.2859\n",
      "Epoch 271/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 142.4606 - mean_squared_error: 141.9839 - val_loss: 145.6525 - val_mean_squared_error: 145.1755\n",
      "Epoch 272/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 142.1351 - mean_squared_error: 141.6585 - val_loss: 146.1459 - val_mean_squared_error: 145.6672\n",
      "Epoch 273/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 142.1717 - mean_squared_error: 141.6930 - val_loss: 145.7996 - val_mean_squared_error: 145.3223\n",
      "Epoch 274/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 142.3207 - mean_squared_error: 141.8422 - val_loss: 147.5208 - val_mean_squared_error: 147.0422\n",
      "Epoch 275/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 142.2447 - mean_squared_error: 141.7665 - val_loss: 145.8736 - val_mean_squared_error: 145.3938\n",
      "Epoch 276/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 142.3092 - mean_squared_error: 141.8288 - val_loss: 145.6366 - val_mean_squared_error: 145.1578\n",
      "Epoch 277/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 142.1491 - mean_squared_error: 141.6685 - val_loss: 146.2156 - val_mean_squared_error: 145.7354\n",
      "Epoch 278/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 142.1583 - mean_squared_error: 141.6777 - val_loss: 146.3017 - val_mean_squared_error: 145.8213\n",
      "Epoch 279/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 142.0441 - mean_squared_error: 141.5630 - val_loss: 145.6547 - val_mean_squared_error: 145.1716\n",
      "Epoch 280/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 142.1310 - mean_squared_error: 141.6478 - val_loss: 145.5639 - val_mean_squared_error: 145.0804\n",
      "Epoch 281/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 141.9595 - mean_squared_error: 141.4767 - val_loss: 145.8490 - val_mean_squared_error: 145.3644\n",
      "Epoch 282/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 141.9714 - mean_squared_error: 141.4871 - val_loss: 146.8172 - val_mean_squared_error: 146.3325\n",
      "Epoch 283/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 142.1457 - mean_squared_error: 141.6612 - val_loss: 145.7307 - val_mean_squared_error: 145.2460\n",
      "Epoch 284/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 141.9158 - mean_squared_error: 141.4310 - val_loss: 145.8784 - val_mean_squared_error: 145.3934\n",
      "Epoch 285/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 142.0641 - mean_squared_error: 141.5784 - val_loss: 145.4845 - val_mean_squared_error: 144.9989\n",
      "Epoch 286/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 141.8332 - mean_squared_error: 141.3478 - val_loss: 145.5751 - val_mean_squared_error: 145.0879\n",
      "Epoch 287/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 142.0637 - mean_squared_error: 141.5771 - val_loss: 148.0860 - val_mean_squared_error: 147.5986\n",
      "Epoch 288/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 142.1379 - mean_squared_error: 141.6508 - val_loss: 145.8554 - val_mean_squared_error: 145.3685\n",
      "Epoch 289/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 141.9684 - mean_squared_error: 141.4813 - val_loss: 146.9308 - val_mean_squared_error: 146.4436\n",
      "Epoch 290/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 141.8208 - mean_squared_error: 141.3334 - val_loss: 145.5543 - val_mean_squared_error: 145.0667\n",
      "Epoch 291/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 141.6007 - mean_squared_error: 141.1125 - val_loss: 147.1199 - val_mean_squared_error: 146.6316\n",
      "Epoch 292/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 141.6908 - mean_squared_error: 141.2021 - val_loss: 146.2230 - val_mean_squared_error: 145.7337\n",
      "Epoch 293/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 141.6879 - mean_squared_error: 141.1981 - val_loss: 147.1823 - val_mean_squared_error: 146.6931\n",
      "Epoch 294/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 141.8373 - mean_squared_error: 141.3483 - val_loss: 145.3366 - val_mean_squared_error: 144.8469\n",
      "Epoch 295/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 141.8939 - mean_squared_error: 141.4050 - val_loss: 145.2775 - val_mean_squared_error: 144.7860\n",
      "Epoch 296/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 141.8831 - mean_squared_error: 141.3911 - val_loss: 145.5884 - val_mean_squared_error: 145.0980\n",
      "Epoch 297/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 141.5946 - mean_squared_error: 141.1031 - val_loss: 145.5278 - val_mean_squared_error: 145.0360\n",
      "Epoch 298/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 141.6919 - mean_squared_error: 141.2002 - val_loss: 145.5340 - val_mean_squared_error: 145.0418\n",
      "Epoch 299/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 141.8602 - mean_squared_error: 141.3675 - val_loss: 145.4401 - val_mean_squared_error: 144.9478\n",
      "Epoch 300/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 141.8325 - mean_squared_error: 141.3398 - val_loss: 146.0165 - val_mean_squared_error: 145.5238\n",
      "Epoch 301/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 141.4060 - mean_squared_error: 140.9139 - val_loss: 145.8848 - val_mean_squared_error: 145.3910\n",
      "Epoch 302/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 141.6837 - mean_squared_error: 141.1890 - val_loss: 147.5870 - val_mean_squared_error: 147.0931\n",
      "Epoch 303/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 141.5464 - mean_squared_error: 141.0520 - val_loss: 145.3552 - val_mean_squared_error: 144.8611\n",
      "Epoch 304/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 141.5677 - mean_squared_error: 141.0729 - val_loss: 146.1481 - val_mean_squared_error: 145.6532\n",
      "Epoch 305/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 141.5209 - mean_squared_error: 141.0266 - val_loss: 145.0469 - val_mean_squared_error: 144.5503\n",
      "Epoch 306/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 141.4752 - mean_squared_error: 140.9789 - val_loss: 145.4340 - val_mean_squared_error: 144.9382\n",
      "Epoch 307/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 141.4152 - mean_squared_error: 140.9190 - val_loss: 145.2527 - val_mean_squared_error: 144.7573\n",
      "Epoch 308/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 141.4579 - mean_squared_error: 140.9611 - val_loss: 145.1134 - val_mean_squared_error: 144.6167\n",
      "Epoch 309/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 141.4758 - mean_squared_error: 140.9790 - val_loss: 145.1906 - val_mean_squared_error: 144.6935\n",
      "Epoch 310/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 141.3597 - mean_squared_error: 140.8616 - val_loss: 145.2244 - val_mean_squared_error: 144.7263\n",
      "Epoch 311/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 141.3222 - mean_squared_error: 140.8246 - val_loss: 145.1199 - val_mean_squared_error: 144.6210\n",
      "Epoch 312/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 141.2599 - mean_squared_error: 140.7605 - val_loss: 148.2465 - val_mean_squared_error: 147.7488\n",
      "Epoch 313/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 141.5694 - mean_squared_error: 141.0714 - val_loss: 146.7380 - val_mean_squared_error: 146.2404\n",
      "Epoch 314/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 141.3070 - mean_squared_error: 140.8096 - val_loss: 144.9969 - val_mean_squared_error: 144.4974\n",
      "Epoch 315/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 141.2941 - mean_squared_error: 140.7944 - val_loss: 145.4032 - val_mean_squared_error: 144.9057\n",
      "Epoch 316/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 141.5434 - mean_squared_error: 141.0448 - val_loss: 144.9761 - val_mean_squared_error: 144.4772\n",
      "Epoch 317/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 141.3807 - mean_squared_error: 140.8804 - val_loss: 145.5278 - val_mean_squared_error: 145.0288\n",
      "Epoch 318/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 141.1385 - mean_squared_error: 140.6392 - val_loss: 144.8085 - val_mean_squared_error: 144.3077\n",
      "Epoch 319/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 141.2746 - mean_squared_error: 140.7723 - val_loss: 145.2581 - val_mean_squared_error: 144.7576\n",
      "Epoch 320/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 141.1565 - mean_squared_error: 140.6553 - val_loss: 144.9176 - val_mean_squared_error: 144.4145\n",
      "Epoch 321/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 141.0917 - mean_squared_error: 140.5884 - val_loss: 145.9478 - val_mean_squared_error: 145.4462\n",
      "Epoch 322/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 141.3391 - mean_squared_error: 140.8369 - val_loss: 145.1479 - val_mean_squared_error: 144.6443\n",
      "Epoch 323/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 140.9580 - mean_squared_error: 140.4550 - val_loss: 146.1271 - val_mean_squared_error: 145.6237\n",
      "Epoch 324/1000\n",
      "49590/49590 [==============================] - 2s 48us/sample - loss: 141.2469 - mean_squared_error: 140.7444 - val_loss: 145.1277 - val_mean_squared_error: 144.6227\n",
      "Epoch 325/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 141.0305 - mean_squared_error: 140.5260 - val_loss: 146.5819 - val_mean_squared_error: 146.0770\n",
      "Epoch 326/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 141.0193 - mean_squared_error: 140.5141 - val_loss: 144.7313 - val_mean_squared_error: 144.2272\n",
      "Epoch 327/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 140.9989 - mean_squared_error: 140.4946 - val_loss: 144.9457 - val_mean_squared_error: 144.4399\n",
      "Epoch 328/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 141.1551 - mean_squared_error: 140.6499 - val_loss: 145.2232 - val_mean_squared_error: 144.7175\n",
      "Epoch 329/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 141.1007 - mean_squared_error: 140.5952 - val_loss: 144.9215 - val_mean_squared_error: 144.4158\n",
      "Epoch 330/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 140.9481 - mean_squared_error: 140.4424 - val_loss: 144.8657 - val_mean_squared_error: 144.3612\n",
      "Epoch 331/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 141.1623 - mean_squared_error: 140.6567 - val_loss: 145.0916 - val_mean_squared_error: 144.5871\n",
      "Epoch 332/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 140.8257 - mean_squared_error: 140.3196 - val_loss: 144.9335 - val_mean_squared_error: 144.4274\n",
      "Epoch 333/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 140.9353 - mean_squared_error: 140.4299 - val_loss: 144.6092 - val_mean_squared_error: 144.1018\n",
      "Epoch 334/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 141.0348 - mean_squared_error: 140.5280 - val_loss: 144.6317 - val_mean_squared_error: 144.1242s - loss: 141.6634 - mean_squared\n",
      "Epoch 335/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 140.9829 - mean_squared_error: 140.4753 - val_loss: 145.2828 - val_mean_squared_error: 144.7759\n",
      "Epoch 336/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 141.0801 - mean_squared_error: 140.5719 - val_loss: 147.2288 - val_mean_squared_error: 146.7207\n",
      "Epoch 337/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 140.8252 - mean_squared_error: 140.3174 - val_loss: 145.2295 - val_mean_squared_error: 144.7210\n",
      "Epoch 338/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 140.7663 - mean_squared_error: 140.2569 - val_loss: 144.9304 - val_mean_squared_error: 144.4230\n",
      "Epoch 339/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 140.7750 - mean_squared_error: 140.2657 - val_loss: 144.7870 - val_mean_squared_error: 144.2797\n",
      "Epoch 340/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 140.7667 - mean_squared_error: 140.2579 - val_loss: 144.6687 - val_mean_squared_error: 144.1609\n",
      "Epoch 341/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 140.8803 - mean_squared_error: 140.3710 - val_loss: 144.6618 - val_mean_squared_error: 144.1535\n",
      "Epoch 342/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 140.7994 - mean_squared_error: 140.2901 - val_loss: 144.8862 - val_mean_squared_error: 144.3759\n",
      "Epoch 343/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 140.8207 - mean_squared_error: 140.3113 - val_loss: 147.1938 - val_mean_squared_error: 146.6832\n",
      "Epoch 344/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 140.7198 - mean_squared_error: 140.2095 - val_loss: 144.4371 - val_mean_squared_error: 143.9272\n",
      "Epoch 345/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 140.8757 - mean_squared_error: 140.3652 - val_loss: 144.4758 - val_mean_squared_error: 143.9659\n",
      "Epoch 346/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 140.7417 - mean_squared_error: 140.2300 - val_loss: 146.0518 - val_mean_squared_error: 145.5411\n",
      "Epoch 347/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 140.7460 - mean_squared_error: 140.2355 - val_loss: 144.4117 - val_mean_squared_error: 143.9005\n",
      "Epoch 348/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 140.6303 - mean_squared_error: 140.1189 - val_loss: 144.8431 - val_mean_squared_error: 144.3295\n",
      "Epoch 349/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 140.6030 - mean_squared_error: 140.0902 - val_loss: 145.3204 - val_mean_squared_error: 144.8082\n",
      "Epoch 350/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 140.7897 - mean_squared_error: 140.2774 - val_loss: 144.8662 - val_mean_squared_error: 144.3541\n",
      "Epoch 351/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 140.6236 - mean_squared_error: 140.1115 - val_loss: 145.1263 - val_mean_squared_error: 144.6132\n",
      "Epoch 352/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 140.6904 - mean_squared_error: 140.1765 - val_loss: 144.4892 - val_mean_squared_error: 143.9756\n",
      "Epoch 353/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 140.4714 - mean_squared_error: 139.9578 - val_loss: 145.2891 - val_mean_squared_error: 144.7766\n",
      "Epoch 354/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 140.5992 - mean_squared_error: 140.0862 - val_loss: 144.2427 - val_mean_squared_error: 143.7280\n",
      "Epoch 355/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 140.4245 - mean_squared_error: 139.9100 - val_loss: 144.9462 - val_mean_squared_error: 144.4308\n",
      "Epoch 356/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 140.8872 - mean_squared_error: 140.3730 - val_loss: 145.8647 - val_mean_squared_error: 145.3495\n",
      "Epoch 357/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 140.5284 - mean_squared_error: 140.0138 - val_loss: 144.3427 - val_mean_squared_error: 143.8288\n",
      "Epoch 358/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 140.4160 - mean_squared_error: 139.9013 - val_loss: 144.8480 - val_mean_squared_error: 144.3326\n",
      "Epoch 359/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 140.6135 - mean_squared_error: 140.0983 - val_loss: 148.2155 - val_mean_squared_error: 147.7011\n",
      "Epoch 360/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 2s 33us/sample - loss: 140.4065 - mean_squared_error: 139.8913 - val_loss: 144.8226 - val_mean_squared_error: 144.3075\n",
      "Epoch 361/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 140.4284 - mean_squared_error: 139.9140 - val_loss: 144.2745 - val_mean_squared_error: 143.7588\n",
      "Epoch 362/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 140.3603 - mean_squared_error: 139.8438 - val_loss: 144.9376 - val_mean_squared_error: 144.4215\n",
      "Epoch 363/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 140.2687 - mean_squared_error: 139.7529 - val_loss: 144.1742 - val_mean_squared_error: 143.6573\n",
      "Epoch 364/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 140.3764 - mean_squared_error: 139.8592 - val_loss: 144.5480 - val_mean_squared_error: 144.0320\n",
      "Epoch 365/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 140.3626 - mean_squared_error: 139.8447 - val_loss: 144.5961 - val_mean_squared_error: 144.0816\n",
      "Epoch 366/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 140.3005 - mean_squared_error: 139.7842 - val_loss: 144.0505 - val_mean_squared_error: 143.5344\n",
      "Epoch 367/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 140.3286 - mean_squared_error: 139.8122 - val_loss: 144.1826 - val_mean_squared_error: 143.6662\n",
      "Epoch 368/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 140.2746 - mean_squared_error: 139.7587 - val_loss: 144.4294 - val_mean_squared_error: 143.9124\n",
      "Epoch 369/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 140.5878 - mean_squared_error: 140.0708 - val_loss: 145.8895 - val_mean_squared_error: 145.3741\n",
      "Epoch 370/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 140.3298 - mean_squared_error: 139.8140 - val_loss: 144.4405 - val_mean_squared_error: 143.9235\n",
      "Epoch 371/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 140.1743 - mean_squared_error: 139.6570 - val_loss: 144.0190 - val_mean_squared_error: 143.5031\n",
      "Epoch 372/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 140.1325 - mean_squared_error: 139.6159 - val_loss: 144.0655 - val_mean_squared_error: 143.5483\n",
      "Epoch 373/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 140.0749 - mean_squared_error: 139.5582 - val_loss: 144.8687 - val_mean_squared_error: 144.3509\n",
      "Epoch 374/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 140.2549 - mean_squared_error: 139.7377 - val_loss: 146.2671 - val_mean_squared_error: 145.7503\n",
      "Epoch 375/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 140.4182 - mean_squared_error: 139.9023 - val_loss: 144.2542 - val_mean_squared_error: 143.7377\n",
      "Epoch 376/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 140.3002 - mean_squared_error: 139.7831 - val_loss: 144.1517 - val_mean_squared_error: 143.6334\n",
      "Epoch 377/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 140.2454 - mean_squared_error: 139.7284 - val_loss: 145.3845 - val_mean_squared_error: 144.8680\n",
      "Epoch 378/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 140.3141 - mean_squared_error: 139.7973 - val_loss: 144.0274 - val_mean_squared_error: 143.5111\n",
      "Epoch 379/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 139.9731 - mean_squared_error: 139.4577 - val_loss: 144.2081 - val_mean_squared_error: 143.6896\n",
      "Epoch 380/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 140.2324 - mean_squared_error: 139.7144 - val_loss: 143.9313 - val_mean_squared_error: 143.4137\n",
      "Epoch 381/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 140.1546 - mean_squared_error: 139.6377 - val_loss: 143.9581 - val_mean_squared_error: 143.4397\n",
      "Epoch 382/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 140.3077 - mean_squared_error: 139.7894 - val_loss: 144.7176 - val_mean_squared_error: 144.2003\n",
      "Epoch 383/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 140.0713 - mean_squared_error: 139.5543 - val_loss: 143.8746 - val_mean_squared_error: 143.3575\n",
      "Epoch 384/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 140.0328 - mean_squared_error: 139.5153 - val_loss: 144.4197 - val_mean_squared_error: 143.9009\n",
      "Epoch 385/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 140.1755 - mean_squared_error: 139.6565 - val_loss: 144.2619 - val_mean_squared_error: 143.7444\n",
      "Epoch 386/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 139.9881 - mean_squared_error: 139.4707 - val_loss: 144.1733 - val_mean_squared_error: 143.6547\n",
      "Epoch 387/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 140.2212 - mean_squared_error: 139.7018 - val_loss: 144.0715 - val_mean_squared_error: 143.5537\n",
      "Epoch 388/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 140.1647 - mean_squared_error: 139.6471 - val_loss: 145.5394 - val_mean_squared_error: 145.0202\n",
      "Epoch 389/1000\n",
      "49590/49590 [==============================] - 2s 44us/sample - loss: 140.0277 - mean_squared_error: 139.5090 - val_loss: 144.7106 - val_mean_squared_error: 144.1920\n",
      "Epoch 390/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 139.8752 - mean_squared_error: 139.3575 - val_loss: 144.3407 - val_mean_squared_error: 143.8202\n",
      "Epoch 391/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 139.9053 - mean_squared_error: 139.3868 - val_loss: 144.9257 - val_mean_squared_error: 144.4043\n",
      "Epoch 392/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 139.8839 - mean_squared_error: 139.3640 - val_loss: 143.9893 - val_mean_squared_error: 143.4694\n",
      "Epoch 393/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 139.8905 - mean_squared_error: 139.3702 - val_loss: 144.0815 - val_mean_squared_error: 143.5630\n",
      "Epoch 394/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 139.9607 - mean_squared_error: 139.4420 - val_loss: 146.8891 - val_mean_squared_error: 146.3700\n",
      "Epoch 395/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 139.9191 - mean_squared_error: 139.3997 - val_loss: 144.2866 - val_mean_squared_error: 143.7683\n",
      "Epoch 396/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 139.9296 - mean_squared_error: 139.4099 - val_loss: 143.9802 - val_mean_squared_error: 143.4599\n",
      "Epoch 397/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 139.8640 - mean_squared_error: 139.3435 - val_loss: 144.7302 - val_mean_squared_error: 144.2110\n",
      "Epoch 398/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 139.7674 - mean_squared_error: 139.2474 - val_loss: 144.9880 - val_mean_squared_error: 144.4684\n",
      "Epoch 399/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 139.9284 - mean_squared_error: 139.4096 - val_loss: 143.7502 - val_mean_squared_error: 143.2327\n",
      "Epoch 400/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 139.9446 - mean_squared_error: 139.4255 - val_loss: 143.9783 - val_mean_squared_error: 143.4590\n",
      "Epoch 401/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 140.0243 - mean_squared_error: 139.5047 - val_loss: 144.3404 - val_mean_squared_error: 143.8208\n",
      "Epoch 402/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 140.0541 - mean_squared_error: 139.5344 - val_loss: 144.5815 - val_mean_squared_error: 144.0624\n",
      "Epoch 403/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 139.7552 - mean_squared_error: 139.2357 - val_loss: 144.2628 - val_mean_squared_error: 143.7438\n",
      "Epoch 404/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 139.7533 - mean_squared_error: 139.2348 - val_loss: 144.0550 - val_mean_squared_error: 143.5370\n",
      "Epoch 405/1000\n",
      "49590/49590 [==============================] - 2s 43us/sample - loss: 139.6484 - mean_squared_error: 139.1290 - val_loss: 144.4267 - val_mean_squared_error: 143.9073\n",
      "Epoch 406/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 139.8138 - mean_squared_error: 139.2947 - val_loss: 144.4717 - val_mean_squared_error: 143.9521\n",
      "Epoch 407/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 139.6254 - mean_squared_error: 139.1055 - val_loss: 144.2742 - val_mean_squared_error: 143.7554\n",
      "Epoch 408/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 139.9857 - mean_squared_error: 139.4664 - val_loss: 145.6905 - val_mean_squared_error: 145.1700\n",
      "Epoch 409/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 139.5983 - mean_squared_error: 139.0781 - val_loss: 143.9620 - val_mean_squared_error: 143.4431\n",
      "Epoch 410/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 139.5462 - mean_squared_error: 139.0261 - val_loss: 144.6349 - val_mean_squared_error: 144.1149\n",
      "Epoch 411/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 139.6908 - mean_squared_error: 139.1701 - val_loss: 144.3590 - val_mean_squared_error: 143.8376\n",
      "Epoch 412/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 139.6837 - mean_squared_error: 139.1636 - val_loss: 144.2934 - val_mean_squared_error: 143.7735\n",
      "Epoch 413/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 139.5888 - mean_squared_error: 139.0684 - val_loss: 143.7442 - val_mean_squared_error: 143.2231\n",
      "Epoch 414/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 139.5642 - mean_squared_error: 139.0436 - val_loss: 145.4515 - val_mean_squared_error: 144.9308\n",
      "Epoch 415/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 139.5197 - mean_squared_error: 138.9978 - val_loss: 144.1322 - val_mean_squared_error: 143.6121\n",
      "Epoch 416/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 139.6254 - mean_squared_error: 139.1048 - val_loss: 143.7785 - val_mean_squared_error: 143.2580\n",
      "Epoch 417/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 139.5250 - mean_squared_error: 139.0042 - val_loss: 145.4121 - val_mean_squared_error: 144.8905\n",
      "Epoch 418/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 139.6669 - mean_squared_error: 139.1447 - val_loss: 143.6999 - val_mean_squared_error: 143.1800\n",
      "Epoch 419/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 139.5740 - mean_squared_error: 139.0540 - val_loss: 143.8744 - val_mean_squared_error: 143.3558\n",
      "Epoch 420/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 139.5941 - mean_squared_error: 139.0749 - val_loss: 144.6566 - val_mean_squared_error: 144.1363\n",
      "Epoch 421/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 139.8491 - mean_squared_error: 139.3291 - val_loss: 144.7528 - val_mean_squared_error: 144.2322\n",
      "Epoch 422/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 139.4180 - mean_squared_error: 138.8978 - val_loss: 143.7670 - val_mean_squared_error: 143.2466\n",
      "Epoch 423/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 139.5156 - mean_squared_error: 138.9952 - val_loss: 144.4229 - val_mean_squared_error: 143.9019\n",
      "Epoch 424/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 139.4534 - mean_squared_error: 138.9330 - val_loss: 143.6501 - val_mean_squared_error: 143.1276\n",
      "Epoch 425/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 139.3518 - mean_squared_error: 138.8309 - val_loss: 143.9953 - val_mean_squared_error: 143.4746\n",
      "Epoch 426/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 139.4737 - mean_squared_error: 138.9532 - val_loss: 144.9862 - val_mean_squared_error: 144.4660\n",
      "Epoch 427/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 139.4779 - mean_squared_error: 138.9584 - val_loss: 145.0607 - val_mean_squared_error: 144.5391\n",
      "Epoch 428/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 139.3927 - mean_squared_error: 138.8717 - val_loss: 143.8103 - val_mean_squared_error: 143.2912\n",
      "Epoch 429/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 139.4931 - mean_squared_error: 138.9739 - val_loss: 143.7152 - val_mean_squared_error: 143.1939\n",
      "Epoch 430/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 139.5102 - mean_squared_error: 138.9893 - val_loss: 144.0324 - val_mean_squared_error: 143.5124\n",
      "Epoch 431/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 139.5400 - mean_squared_error: 139.0197 - val_loss: 144.7558 - val_mean_squared_error: 144.2352\n",
      "Epoch 432/1000\n",
      "49590/49590 [==============================] - 2s 44us/sample - loss: 139.4232 - mean_squared_error: 138.9027 - val_loss: 144.5076 - val_mean_squared_error: 143.9873\n",
      "Epoch 433/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 139.3615 - mean_squared_error: 138.8421 - val_loss: 144.0758 - val_mean_squared_error: 143.5551\n",
      "Epoch 434/1000\n",
      "49590/49590 [==============================] - 2s 44us/sample - loss: 139.4803 - mean_squared_error: 138.9596 - val_loss: 145.2476 - val_mean_squared_error: 144.7281\n",
      "Epoch 435/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 139.5379 - mean_squared_error: 139.0175 - val_loss: 143.3728 - val_mean_squared_error: 142.8533\n",
      "Epoch 436/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 139.2877 - mean_squared_error: 138.7675 - val_loss: 143.6225 - val_mean_squared_error: 143.1015\n",
      "Epoch 437/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 139.3875 - mean_squared_error: 138.8665 - val_loss: 143.7673 - val_mean_squared_error: 143.2480\n",
      "Epoch 438/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 139.1311 - mean_squared_error: 138.6113 - val_loss: 143.7550 - val_mean_squared_error: 143.2342\n",
      "Epoch 439/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 139.5291 - mean_squared_error: 139.0089 - val_loss: 146.1423 - val_mean_squared_error: 145.6202\n",
      "Epoch 440/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 139.2582 - mean_squared_error: 138.7373 - val_loss: 143.3656 - val_mean_squared_error: 142.8449\n",
      "Epoch 441/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 139.3476 - mean_squared_error: 138.8271 - val_loss: 145.5725 - val_mean_squared_error: 145.0501\n",
      "Epoch 442/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 139.1838 - mean_squared_error: 138.6630 - val_loss: 144.2924 - val_mean_squared_error: 143.7739\n",
      "Epoch 443/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 139.1387 - mean_squared_error: 138.6191 - val_loss: 143.5526 - val_mean_squared_error: 143.0321\n",
      "Epoch 444/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 139.1982 - mean_squared_error: 138.6781 - val_loss: 144.1552 - val_mean_squared_error: 143.6361\n",
      "Epoch 445/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 139.4458 - mean_squared_error: 138.9271 - val_loss: 144.0463 - val_mean_squared_error: 143.5271\n",
      "Epoch 446/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 139.2983 - mean_squared_error: 138.7782 - val_loss: 143.4581 - val_mean_squared_error: 142.9383\n",
      "Epoch 447/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 139.0162 - mean_squared_error: 138.4965 - val_loss: 144.1729 - val_mean_squared_error: 143.6513\n",
      "Epoch 448/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 139.3760 - mean_squared_error: 138.8551 - val_loss: 144.6839 - val_mean_squared_error: 144.1641\n",
      "Epoch 449/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 138.9912 - mean_squared_error: 138.4698 - val_loss: 143.6881 - val_mean_squared_error: 143.1664\n",
      "Epoch 450/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 23us/sample - loss: 139.2494 - mean_squared_error: 138.7294 - val_loss: 143.6235 - val_mean_squared_error: 143.1017\n",
      "Epoch 451/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 139.0859 - mean_squared_error: 138.5646 - val_loss: 143.5855 - val_mean_squared_error: 143.0642\n",
      "Epoch 452/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 139.0872 - mean_squared_error: 138.5658 - val_loss: 144.7865 - val_mean_squared_error: 144.2648\n",
      "Epoch 453/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 138.9549 - mean_squared_error: 138.4348 - val_loss: 143.8265 - val_mean_squared_error: 143.3042\n",
      "Epoch 454/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 139.0347 - mean_squared_error: 138.5137 - val_loss: 144.3162 - val_mean_squared_error: 143.7953\n",
      "Epoch 455/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 138.9395 - mean_squared_error: 138.4186 - val_loss: 144.9422 - val_mean_squared_error: 144.4207\n",
      "Epoch 456/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 139.2491 - mean_squared_error: 138.7281 - val_loss: 144.8673 - val_mean_squared_error: 144.3458\n",
      "Epoch 457/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 139.3953 - mean_squared_error: 138.8749 - val_loss: 143.3418 - val_mean_squared_error: 142.8204\n",
      "Epoch 458/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 139.1442 - mean_squared_error: 138.6237 - val_loss: 143.3837 - val_mean_squared_error: 142.8635\n",
      "Epoch 459/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 139.0144 - mean_squared_error: 138.4935 - val_loss: 143.7380 - val_mean_squared_error: 143.2180\n",
      "Epoch 460/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 139.0356 - mean_squared_error: 138.5155 - val_loss: 144.0805 - val_mean_squared_error: 143.5598\n",
      "Epoch 461/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 139.0944 - mean_squared_error: 138.5739 - val_loss: 143.2682 - val_mean_squared_error: 142.7466\n",
      "Epoch 462/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 139.0091 - mean_squared_error: 138.4881 - val_loss: 143.5344 - val_mean_squared_error: 143.0139\n",
      "Epoch 463/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 139.0688 - mean_squared_error: 138.5471 - val_loss: 143.5036 - val_mean_squared_error: 142.9822\n",
      "Epoch 464/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 139.3522 - mean_squared_error: 138.8309 - val_loss: 144.9487 - val_mean_squared_error: 144.4300\n",
      "Epoch 465/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 138.9267 - mean_squared_error: 138.4072 - val_loss: 144.2925 - val_mean_squared_error: 143.7716\n",
      "Epoch 466/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 138.9401 - mean_squared_error: 138.4197 - val_loss: 143.3635 - val_mean_squared_error: 142.8424\n",
      "Epoch 467/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 139.0613 - mean_squared_error: 138.5408 - val_loss: 143.9420 - val_mean_squared_error: 143.4226\n",
      "Epoch 468/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 139.0471 - mean_squared_error: 138.5265 - val_loss: 145.0193 - val_mean_squared_error: 144.4987\n",
      "Epoch 469/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 138.8782 - mean_squared_error: 138.3568 - val_loss: 143.7690 - val_mean_squared_error: 143.2486\n",
      "Epoch 470/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 138.8608 - mean_squared_error: 138.3405 - val_loss: 145.1167 - val_mean_squared_error: 144.5949\n",
      "Epoch 471/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 139.0929 - mean_squared_error: 138.5710 - val_loss: 143.3218 - val_mean_squared_error: 142.8012\n",
      "Epoch 472/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 138.9266 - mean_squared_error: 138.4049 - val_loss: 144.5321 - val_mean_squared_error: 144.0109\n",
      "Epoch 473/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 139.0752 - mean_squared_error: 138.5544 - val_loss: 143.5325 - val_mean_squared_error: 143.0116\n",
      "Epoch 474/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 139.1432 - mean_squared_error: 138.6225 - val_loss: 143.9918 - val_mean_squared_error: 143.4703\n",
      "Epoch 475/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 138.7608 - mean_squared_error: 138.2391 - val_loss: 144.8814 - val_mean_squared_error: 144.3607\n",
      "Epoch 476/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 138.8446 - mean_squared_error: 138.3227 - val_loss: 143.8829 - val_mean_squared_error: 143.3624\n",
      "Epoch 477/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 139.0305 - mean_squared_error: 138.5093 - val_loss: 143.8595 - val_mean_squared_error: 143.3377\n",
      "Epoch 478/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 138.7373 - mean_squared_error: 138.2163 - val_loss: 143.7983 - val_mean_squared_error: 143.2772\n",
      "Epoch 479/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 138.8846 - mean_squared_error: 138.3625 - val_loss: 146.6851 - val_mean_squared_error: 146.1630\n",
      "Epoch 480/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 139.1138 - mean_squared_error: 138.5921 - val_loss: 143.2631 - val_mean_squared_error: 142.7430\n",
      "Epoch 481/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 138.7961 - mean_squared_error: 138.2743 - val_loss: 143.5045 - val_mean_squared_error: 142.9822\n",
      "Epoch 482/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 138.9235 - mean_squared_error: 138.4013 - val_loss: 143.2553 - val_mean_squared_error: 142.7332\n",
      "Epoch 483/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 138.6180 - mean_squared_error: 138.0946 - val_loss: 145.1853 - val_mean_squared_error: 144.6631\n",
      "Epoch 484/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 138.7126 - mean_squared_error: 138.1904 - val_loss: 143.8457 - val_mean_squared_error: 143.3241\n",
      "Epoch 485/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 139.0057 - mean_squared_error: 138.4835 - val_loss: 143.9251 - val_mean_squared_error: 143.4028\n",
      "Epoch 486/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 138.5573 - mean_squared_error: 138.0338 - val_loss: 145.0762 - val_mean_squared_error: 144.5553\n",
      "Epoch 487/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 139.1754 - mean_squared_error: 138.6525 - val_loss: 143.8907 - val_mean_squared_error: 143.3684\n",
      "Epoch 488/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 138.6848 - mean_squared_error: 138.1618 - val_loss: 143.4777 - val_mean_squared_error: 142.9549\n",
      "Epoch 489/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 138.8270 - mean_squared_error: 138.3049 - val_loss: 143.5935 - val_mean_squared_error: 143.0708\n",
      "Epoch 490/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 138.4943 - mean_squared_error: 137.9709 - val_loss: 145.0883 - val_mean_squared_error: 144.5649\n",
      "Epoch 491/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 138.5701 - mean_squared_error: 138.0463 - val_loss: 143.1877 - val_mean_squared_error: 142.6642\n",
      "Epoch 492/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 138.9832 - mean_squared_error: 138.4595 - val_loss: 143.6958 - val_mean_squared_error: 143.1739\n",
      "Epoch 493/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 138.7438 - mean_squared_error: 138.2214 - val_loss: 143.3321 - val_mean_squared_error: 142.8088\n",
      "Epoch 494/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 138.7938 - mean_squared_error: 138.2704 - val_loss: 142.9912 - val_mean_squared_error: 142.4679\n",
      "Epoch 495/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 138.9250 - mean_squared_error: 138.4023 - val_loss: 146.4776 - val_mean_squared_error: 145.9519\n",
      "Epoch 496/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 138.5732 - mean_squared_error: 138.0485 - val_loss: 145.1513 - val_mean_squared_error: 144.6277\n",
      "Epoch 497/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 138.6070 - mean_squared_error: 138.0837 - val_loss: 143.6419 - val_mean_squared_error: 143.1176\n",
      "Epoch 498/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 138.5051 - mean_squared_error: 137.9809 - val_loss: 143.2942 - val_mean_squared_error: 142.7710\n",
      "Epoch 499/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 138.5407 - mean_squared_error: 138.0157 - val_loss: 143.0797 - val_mean_squared_error: 142.5554\n",
      "Epoch 500/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 138.7742 - mean_squared_error: 138.2499 - val_loss: 146.9294 - val_mean_squared_error: 146.4052\n",
      "Epoch 501/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 138.5535 - mean_squared_error: 138.0288 - val_loss: 143.0796 - val_mean_squared_error: 142.5553\n",
      "Epoch 502/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 138.5834 - mean_squared_error: 138.0597 - val_loss: 143.4298 - val_mean_squared_error: 142.9059\n",
      "Epoch 503/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 138.8288 - mean_squared_error: 138.3043 - val_loss: 143.7437 - val_mean_squared_error: 143.2197\n",
      "Epoch 504/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 138.4662 - mean_squared_error: 137.9420 - val_loss: 144.1178 - val_mean_squared_error: 143.5927\n",
      "Epoch 505/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 138.6879 - mean_squared_error: 138.1632 - val_loss: 143.3564 - val_mean_squared_error: 142.8325\n",
      "Epoch 506/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 138.5512 - mean_squared_error: 138.0263 - val_loss: 143.0871 - val_mean_squared_error: 142.5625\n",
      "Epoch 507/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 138.4433 - mean_squared_error: 137.9175 - val_loss: 143.4947 - val_mean_squared_error: 142.9684\n",
      "Epoch 508/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 138.4476 - mean_squared_error: 137.9217 - val_loss: 143.3359 - val_mean_squared_error: 142.8111\n",
      "Epoch 509/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 138.5614 - mean_squared_error: 138.0363 - val_loss: 143.2501 - val_mean_squared_error: 142.7265\n",
      "Epoch 510/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 138.6276 - mean_squared_error: 138.1036 - val_loss: 147.9541 - val_mean_squared_error: 147.4284\n",
      "Epoch 511/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 138.4927 - mean_squared_error: 137.9661 - val_loss: 143.0669 - val_mean_squared_error: 142.5419\n",
      "Epoch 512/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 138.3141 - mean_squared_error: 137.7878 - val_loss: 143.2734 - val_mean_squared_error: 142.7479\n",
      "Epoch 513/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 138.3784 - mean_squared_error: 137.8532 - val_loss: 143.1303 - val_mean_squared_error: 142.6047\n",
      "Epoch 514/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 138.5543 - mean_squared_error: 138.0286 - val_loss: 143.0270 - val_mean_squared_error: 142.5014\n",
      "Epoch 515/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 138.4176 - mean_squared_error: 137.8920 - val_loss: 144.0148 - val_mean_squared_error: 143.4889\n",
      "Epoch 516/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 138.3811 - mean_squared_error: 137.8553 - val_loss: 144.3920 - val_mean_squared_error: 143.8671\n",
      "Epoch 517/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 138.4350 - mean_squared_error: 137.9095 - val_loss: 143.2265 - val_mean_squared_error: 142.7009\n",
      "Epoch 518/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 138.4572 - mean_squared_error: 137.9320 - val_loss: 145.4128 - val_mean_squared_error: 144.8865\n",
      "Epoch 519/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 138.3432 - mean_squared_error: 137.8167 - val_loss: 143.1686 - val_mean_squared_error: 142.6432\n",
      "Epoch 520/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 138.3660 - mean_squared_error: 137.8409 - val_loss: 143.1347 - val_mean_squared_error: 142.6096\n",
      "Epoch 521/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 138.3237 - mean_squared_error: 137.7992 - val_loss: 142.9865 - val_mean_squared_error: 142.4609\n",
      "Epoch 522/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 138.4927 - mean_squared_error: 137.9684 - val_loss: 144.5240 - val_mean_squared_error: 143.9988\n",
      "Epoch 523/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 138.4165 - mean_squared_error: 137.8909 - val_loss: 143.0816 - val_mean_squared_error: 142.5561\n",
      "Epoch 524/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 138.2457 - mean_squared_error: 137.7208 - val_loss: 143.9479 - val_mean_squared_error: 143.4246\n",
      "Epoch 525/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 138.3011 - mean_squared_error: 137.7763 - val_loss: 144.8786 - val_mean_squared_error: 144.3541\n",
      "Epoch 526/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 138.4029 - mean_squared_error: 137.8779 - val_loss: 143.0739 - val_mean_squared_error: 142.5492\n",
      "Epoch 527/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 138.3675 - mean_squared_error: 137.8428 - val_loss: 143.1281 - val_mean_squared_error: 142.6020\n",
      "Epoch 528/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 138.4583 - mean_squared_error: 137.9323 - val_loss: 143.1558 - val_mean_squared_error: 142.6315\n",
      "Epoch 529/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 138.2845 - mean_squared_error: 137.7598 - val_loss: 143.5857 - val_mean_squared_error: 143.0605\n",
      "Epoch 530/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 138.2434 - mean_squared_error: 137.7185 - val_loss: 142.9660 - val_mean_squared_error: 142.4397\n",
      "Epoch 531/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 138.2556 - mean_squared_error: 137.7296 - val_loss: 143.1409 - val_mean_squared_error: 142.6154\n",
      "Epoch 532/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 138.4154 - mean_squared_error: 137.8887 - val_loss: 143.2834 - val_mean_squared_error: 142.7570\n",
      "Epoch 533/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 138.4121 - mean_squared_error: 137.8849 - val_loss: 143.1367 - val_mean_squared_error: 142.6119\n",
      "Epoch 534/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 138.2672 - mean_squared_error: 137.7422 - val_loss: 144.3157 - val_mean_squared_error: 143.7892\n",
      "Epoch 535/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 138.2582 - mean_squared_error: 137.7325 - val_loss: 143.2873 - val_mean_squared_error: 142.7616\n",
      "Epoch 536/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 138.3096 - mean_squared_error: 137.7842 - val_loss: 143.0718 - val_mean_squared_error: 142.5459\n",
      "Epoch 537/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 138.0578 - mean_squared_error: 137.5314 - val_loss: 145.2964 - val_mean_squared_error: 144.7709\n",
      "Epoch 538/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 138.2262 - mean_squared_error: 137.7015 - val_loss: 142.9807 - val_mean_squared_error: 142.4533\n",
      "Epoch 539/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 138.2435 - mean_squared_error: 137.7172 - val_loss: 143.7464 - val_mean_squared_error: 143.2185\n",
      "Epoch 540/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 20us/sample - loss: 138.1644 - mean_squared_error: 137.6361 - val_loss: 144.3446 - val_mean_squared_error: 143.8185\n",
      "Epoch 541/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 138.0576 - mean_squared_error: 137.5305 - val_loss: 143.6584 - val_mean_squared_error: 143.1318\n",
      "Epoch 542/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 138.2181 - mean_squared_error: 137.6922 - val_loss: 142.9577 - val_mean_squared_error: 142.4315\n",
      "Epoch 543/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 138.1188 - mean_squared_error: 137.5923 - val_loss: 143.0766 - val_mean_squared_error: 142.5494\n",
      "Epoch 544/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 138.1706 - mean_squared_error: 137.6433 - val_loss: 148.4618 - val_mean_squared_error: 147.9347\n",
      "Epoch 545/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 138.3124 - mean_squared_error: 137.7850 - val_loss: 143.2690 - val_mean_squared_error: 142.7425\n",
      "Epoch 546/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 138.1028 - mean_squared_error: 137.5763 - val_loss: 143.0250 - val_mean_squared_error: 142.4983\n",
      "Epoch 547/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 137.9769 - mean_squared_error: 137.4506 - val_loss: 142.9197 - val_mean_squared_error: 142.3920\n",
      "Epoch 548/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 138.0318 - mean_squared_error: 137.5035 - val_loss: 143.0440 - val_mean_squared_error: 142.5166\n",
      "Epoch 549/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 137.9688 - mean_squared_error: 137.4413 - val_loss: 143.7582 - val_mean_squared_error: 143.2319\n",
      "Epoch 550/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 138.1270 - mean_squared_error: 137.6000 - val_loss: 142.9480 - val_mean_squared_error: 142.4211\n",
      "Epoch 551/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 138.0211 - mean_squared_error: 137.4957 - val_loss: 143.1699 - val_mean_squared_error: 142.6411\n",
      "Epoch 552/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 137.9614 - mean_squared_error: 137.4330 - val_loss: 142.9205 - val_mean_squared_error: 142.3928\n",
      "Epoch 553/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 137.9971 - mean_squared_error: 137.4696 - val_loss: 143.5780 - val_mean_squared_error: 143.0503\n",
      "Epoch 554/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 137.9996 - mean_squared_error: 137.4722 - val_loss: 142.9809 - val_mean_squared_error: 142.4534\n",
      "Epoch 555/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 138.1035 - mean_squared_error: 137.5753 - val_loss: 144.9009 - val_mean_squared_error: 144.3735\n",
      "Epoch 556/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 138.1548 - mean_squared_error: 137.6275 - val_loss: 143.9647 - val_mean_squared_error: 143.4365\n",
      "Epoch 557/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 138.0741 - mean_squared_error: 137.5456 - val_loss: 143.3306 - val_mean_squared_error: 142.8035\n",
      "Epoch 558/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 137.8946 - mean_squared_error: 137.3669 - val_loss: 143.1313 - val_mean_squared_error: 142.6033\n",
      "Epoch 559/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 137.8923 - mean_squared_error: 137.3643 - val_loss: 145.8759 - val_mean_squared_error: 145.3466\n",
      "Epoch 560/1000\n",
      "49590/49590 [==============================] - 2s 42us/sample - loss: 138.0586 - mean_squared_error: 137.5307 - val_loss: 143.9950 - val_mean_squared_error: 143.4679\n",
      "Epoch 561/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 137.9089 - mean_squared_error: 137.3810 - val_loss: 142.8019 - val_mean_squared_error: 142.2743\n",
      "Epoch 562/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 138.2235 - mean_squared_error: 137.6965 - val_loss: 142.9992 - val_mean_squared_error: 142.4718\n",
      "Epoch 563/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 137.9207 - mean_squared_error: 137.3927 - val_loss: 143.4752 - val_mean_squared_error: 142.9479\n",
      "Epoch 564/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 138.1681 - mean_squared_error: 137.6397 - val_loss: 143.3421 - val_mean_squared_error: 142.8142\n",
      "Epoch 565/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 137.9425 - mean_squared_error: 137.4146 - val_loss: 143.1537 - val_mean_squared_error: 142.6253\n",
      "Epoch 566/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 137.8093 - mean_squared_error: 137.2813 - val_loss: 142.8531 - val_mean_squared_error: 142.3240\n",
      "Epoch 567/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 137.7439 - mean_squared_error: 137.2146 - val_loss: 143.0513 - val_mean_squared_error: 142.5215\n",
      "Epoch 568/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 137.9143 - mean_squared_error: 137.3859 - val_loss: 143.5617 - val_mean_squared_error: 143.0327\n",
      "Epoch 569/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 138.0149 - mean_squared_error: 137.4846 - val_loss: 143.5766 - val_mean_squared_error: 143.0463\n",
      "Epoch 570/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 137.8209 - mean_squared_error: 137.2912 - val_loss: 144.4569 - val_mean_squared_error: 143.9263\n",
      "Epoch 571/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 137.9357 - mean_squared_error: 137.4062 - val_loss: 146.0337 - val_mean_squared_error: 145.5039\n",
      "Epoch 572/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 137.9713 - mean_squared_error: 137.4422 - val_loss: 144.3853 - val_mean_squared_error: 143.8547\n",
      "Epoch 573/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 137.9898 - mean_squared_error: 137.4600 - val_loss: 142.9319 - val_mean_squared_error: 142.4023\n",
      "Epoch 574/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 137.9315 - mean_squared_error: 137.4018 - val_loss: 143.3172 - val_mean_squared_error: 142.7867\n",
      "Epoch 575/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 137.6632 - mean_squared_error: 137.1328 - val_loss: 142.8899 - val_mean_squared_error: 142.3585\n",
      "Epoch 576/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 137.8954 - mean_squared_error: 137.3649 - val_loss: 143.1334 - val_mean_squared_error: 142.6029\n",
      "Epoch 577/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 137.6448 - mean_squared_error: 137.1133 - val_loss: 144.0014 - val_mean_squared_error: 143.4710\n",
      "Epoch 578/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 137.7303 - mean_squared_error: 137.2002 - val_loss: 143.2963 - val_mean_squared_error: 142.7654\n",
      "Epoch 579/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 137.7984 - mean_squared_error: 137.2677 - val_loss: 143.2157 - val_mean_squared_error: 142.6836\n",
      "Epoch 580/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 137.9424 - mean_squared_error: 137.4115 - val_loss: 143.0338 - val_mean_squared_error: 142.5028\n",
      "Epoch 581/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 137.6455 - mean_squared_error: 137.1136 - val_loss: 142.9522 - val_mean_squared_error: 142.4215\n",
      "Epoch 582/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 137.7999 - mean_squared_error: 137.2690 - val_loss: 142.7660 - val_mean_squared_error: 142.2358\n",
      "Epoch 583/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 137.9716 - mean_squared_error: 137.4399 - val_loss: 143.0410 - val_mean_squared_error: 142.5116\n",
      "Epoch 584/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 137.8381 - mean_squared_error: 137.3074 - val_loss: 143.6186 - val_mean_squared_error: 143.0873\n",
      "Epoch 585/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 138.0028 - mean_squared_error: 137.4724 - val_loss: 143.0412 - val_mean_squared_error: 142.5102\n",
      "Epoch 586/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 137.6925 - mean_squared_error: 137.1613 - val_loss: 143.1162 - val_mean_squared_error: 142.5845\n",
      "Epoch 587/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 137.7849 - mean_squared_error: 137.2536 - val_loss: 142.8007 - val_mean_squared_error: 142.2691\n",
      "Epoch 588/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 137.8294 - mean_squared_error: 137.2985 - val_loss: 143.2282 - val_mean_squared_error: 142.6978\n",
      "Epoch 589/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 137.6479 - mean_squared_error: 137.1165 - val_loss: 143.2094 - val_mean_squared_error: 142.6772\n",
      "Epoch 590/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.5132 - mean_squared_error: 136.9815 - val_loss: 144.1436 - val_mean_squared_error: 143.6111\n",
      "Epoch 591/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 137.6258 - mean_squared_error: 137.0923 - val_loss: 142.7981 - val_mean_squared_error: 142.2669\n",
      "Epoch 592/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 137.6233 - mean_squared_error: 137.0928 - val_loss: 144.6209 - val_mean_squared_error: 144.0874\n",
      "Epoch 593/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 137.5699 - mean_squared_error: 137.0370 - val_loss: 145.2092 - val_mean_squared_error: 144.6772\n",
      "Epoch 594/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 137.6529 - mean_squared_error: 137.1209 - val_loss: 143.1505 - val_mean_squared_error: 142.6171\n",
      "Epoch 595/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 137.5645 - mean_squared_error: 137.0308 - val_loss: 143.0487 - val_mean_squared_error: 142.5159\n",
      "Epoch 596/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 137.6284 - mean_squared_error: 137.0949 - val_loss: 143.3060 - val_mean_squared_error: 142.7733\n",
      "Epoch 597/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 137.5479 - mean_squared_error: 137.0156 - val_loss: 143.0830 - val_mean_squared_error: 142.5494\n",
      "Epoch 598/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 137.3584 - mean_squared_error: 136.8246 - val_loss: 142.8906 - val_mean_squared_error: 142.3584\n",
      "Epoch 599/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 137.6901 - mean_squared_error: 137.1580 - val_loss: 143.0917 - val_mean_squared_error: 142.5589\n",
      "Epoch 600/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 137.5388 - mean_squared_error: 137.0064 - val_loss: 143.2046 - val_mean_squared_error: 142.6725\n",
      "Epoch 601/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 137.4259 - mean_squared_error: 136.8929 - val_loss: 142.7215 - val_mean_squared_error: 142.1894\n",
      "Epoch 602/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 137.5200 - mean_squared_error: 136.9878 - val_loss: 142.7525 - val_mean_squared_error: 142.2190\n",
      "Epoch 603/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 137.6890 - mean_squared_error: 137.1555 - val_loss: 144.3970 - val_mean_squared_error: 143.8645\n",
      "Epoch 604/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 137.4754 - mean_squared_error: 136.9426 - val_loss: 143.7481 - val_mean_squared_error: 143.2156\n",
      "Epoch 605/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 137.3697 - mean_squared_error: 136.8379 - val_loss: 144.1629 - val_mean_squared_error: 143.6303\n",
      "Epoch 606/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 137.5877 - mean_squared_error: 137.0553 - val_loss: 144.3023 - val_mean_squared_error: 143.7685\n",
      "Epoch 607/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 137.8895 - mean_squared_error: 137.3565 - val_loss: 142.8383 - val_mean_squared_error: 142.3058\n",
      "Epoch 608/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 137.3844 - mean_squared_error: 136.8532 - val_loss: 142.6262 - val_mean_squared_error: 142.0936\n",
      "Epoch 609/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.6501 - mean_squared_error: 137.1172 - val_loss: 142.9964 - val_mean_squared_error: 142.4644\n",
      "Epoch 610/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 137.7235 - mean_squared_error: 137.1911 - val_loss: 142.7132 - val_mean_squared_error: 142.1814\n",
      "Epoch 611/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.6061 - mean_squared_error: 137.0742 - val_loss: 146.5413 - val_mean_squared_error: 146.0088\n",
      "Epoch 612/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 137.5478 - mean_squared_error: 137.0149 - val_loss: 143.5650 - val_mean_squared_error: 143.0332\n",
      "Epoch 613/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 137.3260 - mean_squared_error: 136.7929 - val_loss: 142.9008 - val_mean_squared_error: 142.3686\n",
      "Epoch 614/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 137.3430 - mean_squared_error: 136.8103 - val_loss: 143.7755 - val_mean_squared_error: 143.2438\n",
      "Epoch 615/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 137.4041 - mean_squared_error: 136.8707 - val_loss: 143.3687 - val_mean_squared_error: 142.8381\n",
      "Epoch 616/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 137.4088 - mean_squared_error: 136.8768 - val_loss: 142.7841 - val_mean_squared_error: 142.2523\n",
      "Epoch 617/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 137.4305 - mean_squared_error: 136.8994 - val_loss: 143.6402 - val_mean_squared_error: 143.1082\n",
      "Epoch 618/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 137.5185 - mean_squared_error: 136.9864 - val_loss: 143.1442 - val_mean_squared_error: 142.6134\n",
      "Epoch 619/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.2308 - mean_squared_error: 136.6985 - val_loss: 143.2107 - val_mean_squared_error: 142.6788\n",
      "Epoch 620/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.3925 - mean_squared_error: 136.8601 - val_loss: 142.9307 - val_mean_squared_error: 142.3985\n",
      "Epoch 621/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 137.5764 - mean_squared_error: 137.0436 - val_loss: 145.3342 - val_mean_squared_error: 144.8017\n",
      "Epoch 622/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 137.3124 - mean_squared_error: 136.7792 - val_loss: 143.6056 - val_mean_squared_error: 143.0726\n",
      "Epoch 623/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 137.4686 - mean_squared_error: 136.9360 - val_loss: 142.8551 - val_mean_squared_error: 142.3236\n",
      "Epoch 624/1000\n",
      "49590/49590 [==============================] - 2s 30us/sample - loss: 137.3559 - mean_squared_error: 136.8235 - val_loss: 143.0894 - val_mean_squared_error: 142.5574\n",
      "Epoch 625/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 137.6590 - mean_squared_error: 137.1274 - val_loss: 143.2765 - val_mean_squared_error: 142.7438\n",
      "Epoch 626/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 137.4393 - mean_squared_error: 136.9073 - val_loss: 142.7242 - val_mean_squared_error: 142.1918\n",
      "Epoch 627/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 137.3109 - mean_squared_error: 136.7772 - val_loss: 143.9703 - val_mean_squared_error: 143.4391\n",
      "Epoch 628/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 137.2754 - mean_squared_error: 136.7441 - val_loss: 143.6701 - val_mean_squared_error: 143.1364\n",
      "Epoch 629/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 137.3049 - mean_squared_error: 136.7718 - val_loss: 145.0440 - val_mean_squared_error: 144.5112\n",
      "Epoch 630/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 20us/sample - loss: 137.4503 - mean_squared_error: 136.9177 - val_loss: 142.9508 - val_mean_squared_error: 142.4185\n",
      "Epoch 631/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.5736 - mean_squared_error: 137.0403 - val_loss: 142.9761 - val_mean_squared_error: 142.4437\n",
      "Epoch 632/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.2444 - mean_squared_error: 136.7113 - val_loss: 143.5671 - val_mean_squared_error: 143.0341\n",
      "Epoch 633/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 137.5336 - mean_squared_error: 137.0020 - val_loss: 143.0699 - val_mean_squared_error: 142.5378\n",
      "Epoch 634/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.0952 - mean_squared_error: 136.5627 - val_loss: 142.6910 - val_mean_squared_error: 142.1583\n",
      "Epoch 635/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.5006 - mean_squared_error: 136.9685 - val_loss: 144.4753 - val_mean_squared_error: 143.9424\n",
      "Epoch 636/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.3139 - mean_squared_error: 136.7808 - val_loss: 142.5963 - val_mean_squared_error: 142.0633\n",
      "Epoch 637/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 137.1060 - mean_squared_error: 136.5743 - val_loss: 142.9968 - val_mean_squared_error: 142.4643\n",
      "Epoch 638/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.5201 - mean_squared_error: 136.9880 - val_loss: 143.0898 - val_mean_squared_error: 142.5578\n",
      "Epoch 639/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.1930 - mean_squared_error: 136.6610 - val_loss: 142.6129 - val_mean_squared_error: 142.0811\n",
      "Epoch 640/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.1342 - mean_squared_error: 136.6021 - val_loss: 142.6810 - val_mean_squared_error: 142.1479\n",
      "Epoch 641/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.3839 - mean_squared_error: 136.8510 - val_loss: 143.6018 - val_mean_squared_error: 143.0691\n",
      "Epoch 642/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.4758 - mean_squared_error: 136.9435 - val_loss: 145.4536 - val_mean_squared_error: 144.9209\n",
      "Epoch 643/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 137.2116 - mean_squared_error: 136.6792 - val_loss: 143.8285 - val_mean_squared_error: 143.2957\n",
      "Epoch 644/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.3044 - mean_squared_error: 136.7710 - val_loss: 144.5616 - val_mean_squared_error: 144.0288\n",
      "Epoch 645/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.2688 - mean_squared_error: 136.7366 - val_loss: 143.0064 - val_mean_squared_error: 142.4730\n",
      "Epoch 646/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.1721 - mean_squared_error: 136.6388 - val_loss: 142.9896 - val_mean_squared_error: 142.4574\n",
      "Epoch 647/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.1228 - mean_squared_error: 136.5895 - val_loss: 143.3550 - val_mean_squared_error: 142.8221\n",
      "Epoch 648/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 137.3282 - mean_squared_error: 136.7950 - val_loss: 143.0705 - val_mean_squared_error: 142.5371\n",
      "Epoch 649/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 137.3430 - mean_squared_error: 136.8095 - val_loss: 142.6404 - val_mean_squared_error: 142.1076\n",
      "Epoch 650/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.1274 - mean_squared_error: 136.5949 - val_loss: 142.9472 - val_mean_squared_error: 142.4138\n",
      "Epoch 651/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.1170 - mean_squared_error: 136.5848 - val_loss: 142.9085 - val_mean_squared_error: 142.3743\n",
      "Epoch 652/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.0923 - mean_squared_error: 136.5576 - val_loss: 142.8863 - val_mean_squared_error: 142.3522\n",
      "Epoch 653/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 137.2269 - mean_squared_error: 136.6939 - val_loss: 142.6968 - val_mean_squared_error: 142.1638\n",
      "Epoch 654/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 136.9958 - mean_squared_error: 136.4629 - val_loss: 142.6800 - val_mean_squared_error: 142.1471\n",
      "Epoch 655/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.1411 - mean_squared_error: 136.6077 - val_loss: 143.6438 - val_mean_squared_error: 143.1108\n",
      "Epoch 656/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.1210 - mean_squared_error: 136.5881 - val_loss: 142.7949 - val_mean_squared_error: 142.2615\n",
      "Epoch 657/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 137.1696 - mean_squared_error: 136.6363 - val_loss: 143.9837 - val_mean_squared_error: 143.4510\n",
      "Epoch 658/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 137.1634 - mean_squared_error: 136.6312 - val_loss: 143.5245 - val_mean_squared_error: 142.9913\n",
      "Epoch 659/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 137.1686 - mean_squared_error: 136.6363 - val_loss: 143.8354 - val_mean_squared_error: 143.3027\n",
      "Epoch 660/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 137.0079 - mean_squared_error: 136.4755 - val_loss: 142.5744 - val_mean_squared_error: 142.0413\n",
      "Epoch 661/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 137.1355 - mean_squared_error: 136.6024 - val_loss: 142.6628 - val_mean_squared_error: 142.1287\n",
      "Epoch 662/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 137.1330 - mean_squared_error: 136.6007 - val_loss: 144.8313 - val_mean_squared_error: 144.2985\n",
      "Epoch 663/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 137.1101 - mean_squared_error: 136.5775 - val_loss: 142.5105 - val_mean_squared_error: 141.9772\n",
      "Epoch 664/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 137.0087 - mean_squared_error: 136.4751 - val_loss: 142.6178 - val_mean_squared_error: 142.0846\n",
      "Epoch 665/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 137.1462 - mean_squared_error: 136.6134 - val_loss: 143.5295 - val_mean_squared_error: 142.9963\n",
      "Epoch 666/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 137.0835 - mean_squared_error: 136.5509 - val_loss: 142.5885 - val_mean_squared_error: 142.0551\n",
      "Epoch 667/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 137.3660 - mean_squared_error: 136.8328 - val_loss: 143.7736 - val_mean_squared_error: 143.2413\n",
      "Epoch 668/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 137.0947 - mean_squared_error: 136.5633 - val_loss: 143.6961 - val_mean_squared_error: 143.1626\n",
      "Epoch 669/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 136.9949 - mean_squared_error: 136.4617 - val_loss: 143.1503 - val_mean_squared_error: 142.6166\n",
      "Epoch 670/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 137.2577 - mean_squared_error: 136.7245 - val_loss: 142.6805 - val_mean_squared_error: 142.1486\n",
      "Epoch 671/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 136.8750 - mean_squared_error: 136.3416 - val_loss: 143.0076 - val_mean_squared_error: 142.4742\n",
      "Epoch 672/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 137.0428 - mean_squared_error: 136.5098 - val_loss: 143.3753 - val_mean_squared_error: 142.8418\n",
      "Epoch 673/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 136.9252 - mean_squared_error: 136.3923 - val_loss: 142.7446 - val_mean_squared_error: 142.2108\n",
      "Epoch 674/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 136.9294 - mean_squared_error: 136.3955 - val_loss: 142.5114 - val_mean_squared_error: 141.9781\n",
      "Epoch 675/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 136.8923 - mean_squared_error: 136.3584 - val_loss: 142.9471 - val_mean_squared_error: 142.4125\n",
      "Epoch 676/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 137.0689 - mean_squared_error: 136.5348 - val_loss: 142.7789 - val_mean_squared_error: 142.2447\n",
      "Epoch 677/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 136.9776 - mean_squared_error: 136.4433 - val_loss: 142.8751 - val_mean_squared_error: 142.3413\n",
      "Epoch 678/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 136.9826 - mean_squared_error: 136.4482 - val_loss: 142.6298 - val_mean_squared_error: 142.0965\n",
      "Epoch 679/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 137.0457 - mean_squared_error: 136.5123 - val_loss: 143.3553 - val_mean_squared_error: 142.8211\n",
      "Epoch 680/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 136.9147 - mean_squared_error: 136.3811 - val_loss: 143.1696 - val_mean_squared_error: 142.6353\n",
      "Epoch 681/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 136.9470 - mean_squared_error: 136.4135 - val_loss: 142.7675 - val_mean_squared_error: 142.2332\n",
      "Epoch 682/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 136.7991 - mean_squared_error: 136.2640 - val_loss: 142.6849 - val_mean_squared_error: 142.1522\n",
      "Epoch 683/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 136.9504 - mean_squared_error: 136.4168 - val_loss: 142.5512 - val_mean_squared_error: 142.0182\n",
      "Epoch 684/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 136.7364 - mean_squared_error: 136.2029 - val_loss: 143.3613 - val_mean_squared_error: 142.8262\n",
      "Epoch 685/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 136.7589 - mean_squared_error: 136.2254 - val_loss: 144.5732 - val_mean_squared_error: 144.0370\n",
      "Epoch 686/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 137.1345 - mean_squared_error: 136.6005 - val_loss: 143.2159 - val_mean_squared_error: 142.6807\n",
      "Epoch 687/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 137.0403 - mean_squared_error: 136.5057 - val_loss: 143.9027 - val_mean_squared_error: 143.3680\n",
      "Epoch 688/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 136.8288 - mean_squared_error: 136.2937 - val_loss: 142.6360 - val_mean_squared_error: 142.1019\n",
      "Epoch 689/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 136.8555 - mean_squared_error: 136.3209 - val_loss: 143.9910 - val_mean_squared_error: 143.4549\n",
      "Epoch 690/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 136.9055 - mean_squared_error: 136.3704 - val_loss: 143.5488 - val_mean_squared_error: 143.0132\n",
      "Epoch 691/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 136.6337 - mean_squared_error: 136.0981 - val_loss: 142.5473 - val_mean_squared_error: 142.0115\n",
      "Epoch 692/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 137.1539 - mean_squared_error: 136.6188 - val_loss: 145.0214 - val_mean_squared_error: 144.4869\n",
      "Epoch 693/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 136.8770 - mean_squared_error: 136.3425 - val_loss: 143.0159 - val_mean_squared_error: 142.4812\n",
      "Epoch 694/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 136.8326 - mean_squared_error: 136.2969 - val_loss: 143.5237 - val_mean_squared_error: 142.9891\n",
      "Epoch 695/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 136.9575 - mean_squared_error: 136.4241 - val_loss: 142.8709 - val_mean_squared_error: 142.3369\n",
      "Epoch 696/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 136.7785 - mean_squared_error: 136.2453 - val_loss: 142.8045 - val_mean_squared_error: 142.2701\n",
      "Epoch 697/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 136.6725 - mean_squared_error: 136.1388 - val_loss: 142.5749 - val_mean_squared_error: 142.0412\n",
      "Epoch 698/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 137.0030 - mean_squared_error: 136.4684 - val_loss: 142.7595 - val_mean_squared_error: 142.2261\n",
      "Epoch 699/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 136.8854 - mean_squared_error: 136.3520 - val_loss: 143.0354 - val_mean_squared_error: 142.5024\n",
      "Epoch 700/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 136.7915 - mean_squared_error: 136.2575 - val_loss: 142.3822 - val_mean_squared_error: 141.8495\n",
      "Epoch 701/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 136.9819 - mean_squared_error: 136.4491 - val_loss: 142.9995 - val_mean_squared_error: 142.4661\n",
      "Epoch 702/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 136.8912 - mean_squared_error: 136.3590 - val_loss: 142.9317 - val_mean_squared_error: 142.3977\n",
      "Epoch 703/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 136.8584 - mean_squared_error: 136.3230 - val_loss: 144.5456 - val_mean_squared_error: 144.0123\n",
      "Epoch 704/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 136.5973 - mean_squared_error: 136.0635 - val_loss: 143.3568 - val_mean_squared_error: 142.8238\n",
      "Epoch 705/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 136.9189 - mean_squared_error: 136.3862 - val_loss: 142.5829 - val_mean_squared_error: 142.0489\n",
      "Epoch 706/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 136.5328 - mean_squared_error: 135.9986 - val_loss: 142.7400 - val_mean_squared_error: 142.2054\n",
      "Epoch 707/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 136.6298 - mean_squared_error: 136.0957 - val_loss: 144.7119 - val_mean_squared_error: 144.1787\n",
      "Epoch 708/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 136.8067 - mean_squared_error: 136.2719 - val_loss: 142.4509 - val_mean_squared_error: 141.9178\n",
      "Epoch 709/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 136.7485 - mean_squared_error: 136.2149 - val_loss: 142.4063 - val_mean_squared_error: 141.8724\n",
      "Epoch 710/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 136.7531 - mean_squared_error: 136.2190 - val_loss: 142.8620 - val_mean_squared_error: 142.3270\n",
      "Epoch 711/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 136.7721 - mean_squared_error: 136.2366 - val_loss: 142.8786 - val_mean_squared_error: 142.3440\n",
      "Epoch 712/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 136.5714 - mean_squared_error: 136.0366 - val_loss: 142.8388 - val_mean_squared_error: 142.3038\n",
      "Epoch 713/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 136.5149 - mean_squared_error: 135.9803 - val_loss: 142.5433 - val_mean_squared_error: 142.0085\n",
      "Epoch 714/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 136.5760 - mean_squared_error: 136.0411 - val_loss: 143.4282 - val_mean_squared_error: 142.8936\n",
      "Epoch 715/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 136.7723 - mean_squared_error: 136.2382 - val_loss: 142.5870 - val_mean_squared_error: 142.0518\n",
      "Epoch 716/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 136.6502 - mean_squared_error: 136.1154 - val_loss: 142.4591 - val_mean_squared_error: 141.9238\n",
      "Epoch 717/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 136.7363 - mean_squared_error: 136.2018 - val_loss: 142.5784 - val_mean_squared_error: 142.0433\n",
      "Epoch 718/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 136.5403 - mean_squared_error: 136.0057 - val_loss: 143.1239 - val_mean_squared_error: 142.5887\n",
      "Epoch 719/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 136.6794 - mean_squared_error: 136.1447 - val_loss: 142.5327 - val_mean_squared_error: 141.9972\n",
      "Epoch 720/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 30us/sample - loss: 136.6879 - mean_squared_error: 136.1525 - val_loss: 142.9806 - val_mean_squared_error: 142.4466\n",
      "Epoch 721/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 136.6133 - mean_squared_error: 136.0779 - val_loss: 142.5359 - val_mean_squared_error: 142.0016\n",
      "Epoch 722/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 136.6608 - mean_squared_error: 136.1265 - val_loss: 143.0602 - val_mean_squared_error: 142.5273\n",
      "Epoch 723/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 136.5510 - mean_squared_error: 136.0167 - val_loss: 143.1618 - val_mean_squared_error: 142.6270\n",
      "Epoch 724/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 136.7528 - mean_squared_error: 136.2176 - val_loss: 144.2431 - val_mean_squared_error: 143.7100\n",
      "Epoch 725/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 136.6491 - mean_squared_error: 136.1161 - val_loss: 142.9766 - val_mean_squared_error: 142.4422\n",
      "Epoch 726/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 136.4353 - mean_squared_error: 135.9007 - val_loss: 142.6085 - val_mean_squared_error: 142.0739\n",
      "Epoch 727/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 136.5185 - mean_squared_error: 135.9836 - val_loss: 143.1612 - val_mean_squared_error: 142.6273\n",
      "Epoch 728/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 136.5212 - mean_squared_error: 135.9871 - val_loss: 144.3426 - val_mean_squared_error: 143.8081\n",
      "Epoch 729/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 136.6241 - mean_squared_error: 136.0907 - val_loss: 142.6514 - val_mean_squared_error: 142.1166\n",
      "Epoch 730/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 136.5326 - mean_squared_error: 135.9979 - val_loss: 143.0079 - val_mean_squared_error: 142.4731\n",
      "Epoch 731/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 136.6379 - mean_squared_error: 136.1032 - val_loss: 143.5767 - val_mean_squared_error: 143.0425\n",
      "Epoch 732/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 136.7538 - mean_squared_error: 136.2197 - val_loss: 142.5513 - val_mean_squared_error: 142.0169\n",
      "Epoch 733/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 136.4272 - mean_squared_error: 135.8931 - val_loss: 142.4573 - val_mean_squared_error: 141.9232\n",
      "Epoch 734/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 136.2996 - mean_squared_error: 135.7657 - val_loss: 142.4501 - val_mean_squared_error: 141.9151\n",
      "Epoch 735/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 136.5359 - mean_squared_error: 136.0005 - val_loss: 143.0630 - val_mean_squared_error: 142.5291\n",
      "Epoch 736/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 136.4142 - mean_squared_error: 135.8801 - val_loss: 142.2998 - val_mean_squared_error: 141.7659\n",
      "Epoch 737/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 136.5980 - mean_squared_error: 136.0638 - val_loss: 142.6243 - val_mean_squared_error: 142.0895\n",
      "Epoch 738/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 136.4586 - mean_squared_error: 135.9246 - val_loss: 143.2829 - val_mean_squared_error: 142.7489\n",
      "Epoch 739/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 136.7107 - mean_squared_error: 136.1761 - val_loss: 142.7245 - val_mean_squared_error: 142.1915\n",
      "Epoch 740/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 136.6557 - mean_squared_error: 136.1224 - val_loss: 142.4016 - val_mean_squared_error: 141.8680\n",
      "Epoch 741/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 136.5227 - mean_squared_error: 135.9891 - val_loss: 142.7796 - val_mean_squared_error: 142.2452\n",
      "Epoch 742/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 136.6376 - mean_squared_error: 136.1037 - val_loss: 143.5380 - val_mean_squared_error: 143.0042\n",
      "Epoch 743/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 136.4830 - mean_squared_error: 135.9488 - val_loss: 142.8080 - val_mean_squared_error: 142.2731\n",
      "Epoch 744/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 136.3435 - mean_squared_error: 135.8073 - val_loss: 142.6612 - val_mean_squared_error: 142.1273\n",
      "Epoch 745/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 136.4879 - mean_squared_error: 135.9548 - val_loss: 142.5071 - val_mean_squared_error: 141.9733\n",
      "Epoch 746/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 136.4467 - mean_squared_error: 135.9128 - val_loss: 142.6006 - val_mean_squared_error: 142.0662\n",
      "Epoch 747/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 136.4740 - mean_squared_error: 135.9399 - val_loss: 143.5801 - val_mean_squared_error: 143.0458\n",
      "Epoch 748/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 136.3936 - mean_squared_error: 135.8590 - val_loss: 142.9246 - val_mean_squared_error: 142.3912\n",
      "Epoch 749/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 136.5890 - mean_squared_error: 136.0549 - val_loss: 142.2928 - val_mean_squared_error: 141.7599\n",
      "Epoch 750/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 136.4753 - mean_squared_error: 135.9413 - val_loss: 142.5975 - val_mean_squared_error: 142.0628\n",
      "Epoch 751/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 136.2051 - mean_squared_error: 135.6709 - val_loss: 143.5299 - val_mean_squared_error: 142.9943\n",
      "Epoch 752/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 136.5580 - mean_squared_error: 136.0235 - val_loss: 142.2129 - val_mean_squared_error: 141.6793\n",
      "Epoch 753/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 136.2961 - mean_squared_error: 135.7622 - val_loss: 143.2836 - val_mean_squared_error: 142.7492\n",
      "Epoch 754/1000\n",
      "49590/49590 [==============================] - 2s 47us/sample - loss: 136.3111 - mean_squared_error: 135.7773 - val_loss: 142.8265 - val_mean_squared_error: 142.2928\n",
      "Epoch 755/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 136.4738 - mean_squared_error: 135.9407 - val_loss: 142.4533 - val_mean_squared_error: 141.9194\n",
      "Epoch 756/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 136.3487 - mean_squared_error: 135.8146 - val_loss: 142.3755 - val_mean_squared_error: 141.8415\n",
      "Epoch 757/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 136.6890 - mean_squared_error: 136.1553 - val_loss: 143.4136 - val_mean_squared_error: 142.8796\n",
      "Epoch 758/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 136.3161 - mean_squared_error: 135.7816 - val_loss: 142.7237 - val_mean_squared_error: 142.1896\n",
      "Epoch 759/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 136.4325 - mean_squared_error: 135.8983 - val_loss: 143.0909 - val_mean_squared_error: 142.5567\n",
      "Epoch 760/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 136.2387 - mean_squared_error: 135.7041 - val_loss: 142.3905 - val_mean_squared_error: 141.8565\n",
      "Epoch 761/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 136.3587 - mean_squared_error: 135.8243 - val_loss: 142.4240 - val_mean_squared_error: 141.8907\n",
      "Epoch 762/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 136.4387 - mean_squared_error: 135.9048 - val_loss: 142.5679 - val_mean_squared_error: 142.0338\n",
      "Epoch 763/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 136.6024 - mean_squared_error: 136.0686 - val_loss: 142.3878 - val_mean_squared_error: 141.8533\n",
      "Epoch 764/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 136.4448 - mean_squared_error: 135.9099 - val_loss: 142.6862 - val_mean_squared_error: 142.1514\n",
      "Epoch 765/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 136.3811 - mean_squared_error: 135.8468 - val_loss: 142.6236 - val_mean_squared_error: 142.0885\n",
      "Epoch 766/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 136.4425 - mean_squared_error: 135.9081 - val_loss: 142.4932 - val_mean_squared_error: 141.9583\n",
      "Epoch 767/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 136.1447 - mean_squared_error: 135.6091 - val_loss: 142.5648 - val_mean_squared_error: 142.0303\n",
      "Epoch 768/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 136.1109 - mean_squared_error: 135.5764 - val_loss: 142.9043 - val_mean_squared_error: 142.3691\n",
      "Epoch 769/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 136.4183 - mean_squared_error: 135.8842 - val_loss: 142.3889 - val_mean_squared_error: 141.8536\n",
      "Epoch 770/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 136.2321 - mean_squared_error: 135.6970 - val_loss: 144.0607 - val_mean_squared_error: 143.5266\n",
      "Epoch 771/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 136.1632 - mean_squared_error: 135.6288 - val_loss: 143.0474 - val_mean_squared_error: 142.5133\n",
      "Epoch 772/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 136.4038 - mean_squared_error: 135.8700 - val_loss: 142.3314 - val_mean_squared_error: 141.7971\n",
      "Epoch 773/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 136.2586 - mean_squared_error: 135.7239 - val_loss: 142.3207 - val_mean_squared_error: 141.7874\n",
      "Epoch 774/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 136.1893 - mean_squared_error: 135.6556 - val_loss: 143.5059 - val_mean_squared_error: 142.9709\n",
      "Epoch 775/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 136.1832 - mean_squared_error: 135.6487 - val_loss: 142.9741 - val_mean_squared_error: 142.4384\n",
      "Epoch 776/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 136.1974 - mean_squared_error: 135.6623 - val_loss: 142.5198 - val_mean_squared_error: 141.9854\n",
      "Epoch 777/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 136.1459 - mean_squared_error: 135.6126 - val_loss: 142.8871 - val_mean_squared_error: 142.3534\n",
      "Epoch 778/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 136.1119 - mean_squared_error: 135.5768 - val_loss: 142.4021 - val_mean_squared_error: 141.8681\n",
      "Epoch 779/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 136.2803 - mean_squared_error: 135.7464 - val_loss: 142.6945 - val_mean_squared_error: 142.1611\n",
      "Epoch 780/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 136.4675 - mean_squared_error: 135.9348 - val_loss: 144.4049 - val_mean_squared_error: 143.8712\n",
      "Epoch 781/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 136.3738 - mean_squared_error: 135.8393 - val_loss: 142.4755 - val_mean_squared_error: 141.9416\n",
      "Epoch 782/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 136.1333 - mean_squared_error: 135.6001 - val_loss: 144.0137 - val_mean_squared_error: 143.4803\n",
      "Epoch 783/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 136.4819 - mean_squared_error: 135.9487 - val_loss: 142.3699 - val_mean_squared_error: 141.8365\n",
      "Epoch 784/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 136.0385 - mean_squared_error: 135.5052 - val_loss: 142.8951 - val_mean_squared_error: 142.3607\n",
      "Epoch 785/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 136.1080 - mean_squared_error: 135.5731 - val_loss: 142.5743 - val_mean_squared_error: 142.0408\n",
      "Epoch 786/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 136.2415 - mean_squared_error: 135.7073 - val_loss: 142.6370 - val_mean_squared_error: 142.1039\n",
      "Epoch 787/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 136.1844 - mean_squared_error: 135.6507 - val_loss: 142.9094 - val_mean_squared_error: 142.3752\n",
      "Epoch 788/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 136.1168 - mean_squared_error: 135.5835 - val_loss: 143.4570 - val_mean_squared_error: 142.9225\n",
      "Epoch 789/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 136.1462 - mean_squared_error: 135.6129 - val_loss: 143.2529 - val_mean_squared_error: 142.7199\n",
      "Epoch 790/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 136.2109 - mean_squared_error: 135.6784 - val_loss: 142.6498 - val_mean_squared_error: 142.1153\n",
      "Epoch 791/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 136.0415 - mean_squared_error: 135.5075 - val_loss: 142.6665 - val_mean_squared_error: 142.1313\n",
      "Epoch 792/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 136.3895 - mean_squared_error: 135.8550 - val_loss: 142.5013 - val_mean_squared_error: 141.9677\n",
      "Epoch 793/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 136.1730 - mean_squared_error: 135.6392 - val_loss: 142.2953 - val_mean_squared_error: 141.7622\n",
      "Epoch 794/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 136.1353 - mean_squared_error: 135.6015 - val_loss: 142.8860 - val_mean_squared_error: 142.3526\n",
      "Epoch 795/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 136.0197 - mean_squared_error: 135.4859 - val_loss: 142.3413 - val_mean_squared_error: 141.8067\n",
      "Epoch 796/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 136.0417 - mean_squared_error: 135.5085 - val_loss: 142.8517 - val_mean_squared_error: 142.3178\n",
      "Epoch 797/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 136.3281 - mean_squared_error: 135.7931 - val_loss: 142.9190 - val_mean_squared_error: 142.3852\n",
      "Epoch 798/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 135.9166 - mean_squared_error: 135.3820 - val_loss: 142.4727 - val_mean_squared_error: 141.9391\n",
      "Epoch 799/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 135.9900 - mean_squared_error: 135.4553 - val_loss: 144.7156 - val_mean_squared_error: 144.1831\n",
      "Epoch 800/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 136.1749 - mean_squared_error: 135.6417 - val_loss: 142.5283 - val_mean_squared_error: 141.9943\n",
      "Epoch 801/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 136.1509 - mean_squared_error: 135.6170 - val_loss: 144.0133 - val_mean_squared_error: 143.4800\n",
      "Epoch 802/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 136.0410 - mean_squared_error: 135.5074 - val_loss: 143.6446 - val_mean_squared_error: 143.1118\n",
      "Epoch 803/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 135.9488 - mean_squared_error: 135.4157 - val_loss: 142.5501 - val_mean_squared_error: 142.0164\n",
      "Epoch 804/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 136.1074 - mean_squared_error: 135.5740 - val_loss: 144.2752 - val_mean_squared_error: 143.7408\n",
      "Epoch 805/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 136.2288 - mean_squared_error: 135.6949 - val_loss: 142.8579 - val_mean_squared_error: 142.3246\n",
      "Epoch 806/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 135.9320 - mean_squared_error: 135.3980 - val_loss: 142.3994 - val_mean_squared_error: 141.8669\n",
      "Epoch 807/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 135.8608 - mean_squared_error: 135.3278 - val_loss: 142.9053 - val_mean_squared_error: 142.3715\n",
      "Epoch 808/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 136.1005 - mean_squared_error: 135.5663 - val_loss: 143.7288 - val_mean_squared_error: 143.1964\n",
      "Epoch 809/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 135.9660 - mean_squared_error: 135.4311 - val_loss: 142.2936 - val_mean_squared_error: 141.7610\n",
      "Epoch 810/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 25us/sample - loss: 136.0970 - mean_squared_error: 135.5640 - val_loss: 143.1919 - val_mean_squared_error: 142.6597\n",
      "Epoch 811/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 135.8869 - mean_squared_error: 135.3536 - val_loss: 142.5320 - val_mean_squared_error: 141.9991\n",
      "Epoch 812/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 136.1675 - mean_squared_error: 135.6350 - val_loss: 142.8629 - val_mean_squared_error: 142.3293\n",
      "Epoch 813/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 135.9333 - mean_squared_error: 135.4007 - val_loss: 142.8223 - val_mean_squared_error: 142.2881\n",
      "Epoch 814/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 136.1132 - mean_squared_error: 135.5788 - val_loss: 143.3900 - val_mean_squared_error: 142.8568\n",
      "Epoch 815/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 136.0054 - mean_squared_error: 135.4721 - val_loss: 143.0728 - val_mean_squared_error: 142.5391\n",
      "Epoch 816/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 135.7963 - mean_squared_error: 135.2620 - val_loss: 142.4240 - val_mean_squared_error: 141.8913\n",
      "Epoch 817/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 135.9832 - mean_squared_error: 135.4503 - val_loss: 142.2627 - val_mean_squared_error: 141.7293\n",
      "Epoch 818/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 136.0591 - mean_squared_error: 135.5254 - val_loss: 142.7623 - val_mean_squared_error: 142.2296\n",
      "Epoch 819/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 135.9666 - mean_squared_error: 135.4344 - val_loss: 142.4298 - val_mean_squared_error: 141.8970\n",
      "Epoch 820/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 135.9220 - mean_squared_error: 135.3878 - val_loss: 142.5102 - val_mean_squared_error: 141.9777\n",
      "Epoch 821/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 136.0953 - mean_squared_error: 135.5630 - val_loss: 142.4712 - val_mean_squared_error: 141.9377\n",
      "Epoch 822/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 136.0526 - mean_squared_error: 135.5187 - val_loss: 142.2523 - val_mean_squared_error: 141.7194\n",
      "Epoch 823/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 136.0916 - mean_squared_error: 135.5587 - val_loss: 142.6878 - val_mean_squared_error: 142.1552\n",
      "Epoch 824/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 135.9080 - mean_squared_error: 135.3755 - val_loss: 143.8700 - val_mean_squared_error: 143.3368\n",
      "Epoch 825/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 136.0426 - mean_squared_error: 135.5107 - val_loss: 142.4172 - val_mean_squared_error: 141.8836\n",
      "Epoch 826/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 135.6812 - mean_squared_error: 135.1477 - val_loss: 142.5139 - val_mean_squared_error: 141.9802\n",
      "Epoch 827/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 135.7295 - mean_squared_error: 135.1960 - val_loss: 142.9641 - val_mean_squared_error: 142.4315\n",
      "Epoch 828/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 135.9222 - mean_squared_error: 135.3896 - val_loss: 143.0922 - val_mean_squared_error: 142.5599\n",
      "Epoch 829/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 136.0378 - mean_squared_error: 135.5058 - val_loss: 142.2356 - val_mean_squared_error: 141.7028\n",
      "Epoch 830/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 135.9899 - mean_squared_error: 135.4576 - val_loss: 142.3216 - val_mean_squared_error: 141.7882\n",
      "Epoch 831/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 136.2810 - mean_squared_error: 135.7478 - val_loss: 142.1942 - val_mean_squared_error: 141.6608\n",
      "Epoch 832/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 135.7803 - mean_squared_error: 135.2471 - val_loss: 144.0129 - val_mean_squared_error: 143.4791\n",
      "Epoch 833/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 135.8816 - mean_squared_error: 135.3479 - val_loss: 142.3927 - val_mean_squared_error: 141.8605\n",
      "Epoch 834/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 136.0334 - mean_squared_error: 135.5014 - val_loss: 142.1726 - val_mean_squared_error: 141.6408\n",
      "Epoch 835/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 135.8352 - mean_squared_error: 135.3035 - val_loss: 142.3895 - val_mean_squared_error: 141.8573\n",
      "Epoch 836/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 135.7584 - mean_squared_error: 135.2257 - val_loss: 142.9327 - val_mean_squared_error: 142.4017\n",
      "Epoch 837/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 135.8668 - mean_squared_error: 135.3351 - val_loss: 143.5753 - val_mean_squared_error: 143.0427\n",
      "Epoch 838/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 135.7975 - mean_squared_error: 135.2655 - val_loss: 142.2746 - val_mean_squared_error: 141.7421\n",
      "Epoch 839/1000\n",
      "49590/49590 [==============================] - 2s 41us/sample - loss: 135.8898 - mean_squared_error: 135.3575 - val_loss: 142.2023 - val_mean_squared_error: 141.6711\n",
      "Epoch 840/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 135.8580 - mean_squared_error: 135.3260 - val_loss: 142.9652 - val_mean_squared_error: 142.4334\n",
      "Epoch 841/1000\n",
      "49590/49590 [==============================] - 2s 40us/sample - loss: 135.8356 - mean_squared_error: 135.3038 - val_loss: 142.3777 - val_mean_squared_error: 141.8451\n",
      "Epoch 842/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 135.8983 - mean_squared_error: 135.3664 - val_loss: 142.3594 - val_mean_squared_error: 141.8268\n",
      "Epoch 843/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 135.6846 - mean_squared_error: 135.1521 - val_loss: 142.2397 - val_mean_squared_error: 141.7083\n",
      "Epoch 844/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 135.7991 - mean_squared_error: 135.2667 - val_loss: 142.7927 - val_mean_squared_error: 142.2615\n",
      "Epoch 845/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 135.8277 - mean_squared_error: 135.2957 - val_loss: 142.7340 - val_mean_squared_error: 142.2014\n",
      "Epoch 846/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 135.6856 - mean_squared_error: 135.1534 - val_loss: 142.2969 - val_mean_squared_error: 141.7660\n",
      "Epoch 847/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 135.8157 - mean_squared_error: 135.2840 - val_loss: 142.9377 - val_mean_squared_error: 142.4069\n",
      "Epoch 848/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 135.7615 - mean_squared_error: 135.2298 - val_loss: 142.3411 - val_mean_squared_error: 141.8091\n",
      "Epoch 849/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 135.7827 - mean_squared_error: 135.2509 - val_loss: 142.6673 - val_mean_squared_error: 142.1358\n",
      "Epoch 850/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 135.8979 - mean_squared_error: 135.3668 - val_loss: 142.3196 - val_mean_squared_error: 141.7890\n",
      "Epoch 851/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 136.1163 - mean_squared_error: 135.5858 - val_loss: 142.8421 - val_mean_squared_error: 142.3101\n",
      "Epoch 852/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 135.5466 - mean_squared_error: 135.0146 - val_loss: 142.3894 - val_mean_squared_error: 141.8583\n",
      "Epoch 853/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 135.8536 - mean_squared_error: 135.3217 - val_loss: 143.0165 - val_mean_squared_error: 142.4861\n",
      "Epoch 854/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 135.6617 - mean_squared_error: 135.1312 - val_loss: 142.8987 - val_mean_squared_error: 142.3675\n",
      "Epoch 855/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 135.6493 - mean_squared_error: 135.1182 - val_loss: 142.3561 - val_mean_squared_error: 141.8242\n",
      "Epoch 856/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 135.7592 - mean_squared_error: 135.2286 - val_loss: 143.7296 - val_mean_squared_error: 143.1974\n",
      "Epoch 857/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 135.6948 - mean_squared_error: 135.1626 - val_loss: 142.7484 - val_mean_squared_error: 142.2164\n",
      "Epoch 858/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 135.7528 - mean_squared_error: 135.2225 - val_loss: 143.1456 - val_mean_squared_error: 142.6140\n",
      "Epoch 859/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 135.6847 - mean_squared_error: 135.1527 - val_loss: 142.3801 - val_mean_squared_error: 141.8483\n",
      "Epoch 860/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 135.7039 - mean_squared_error: 135.1730 - val_loss: 142.3501 - val_mean_squared_error: 141.8196\n",
      "Epoch 861/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 135.7845 - mean_squared_error: 135.2542 - val_loss: 143.6735 - val_mean_squared_error: 143.1419\n",
      "Epoch 862/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 135.7946 - mean_squared_error: 135.2645 - val_loss: 143.4185 - val_mean_squared_error: 142.8876\n",
      "Epoch 863/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 136.0025 - mean_squared_error: 135.4713 - val_loss: 142.4975 - val_mean_squared_error: 141.9665\n",
      "Epoch 864/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 135.9958 - mean_squared_error: 135.4651 - val_loss: 142.4070 - val_mean_squared_error: 141.8750\n",
      "Epoch 865/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 135.7179 - mean_squared_error: 135.1876 - val_loss: 142.4539 - val_mean_squared_error: 141.9223\n",
      "Epoch 866/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 135.8231 - mean_squared_error: 135.2910 - val_loss: 142.0921 - val_mean_squared_error: 141.5615\n",
      "Epoch 867/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 135.6130 - mean_squared_error: 135.0820 - val_loss: 143.2098 - val_mean_squared_error: 142.6782\n",
      "Epoch 868/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 135.5894 - mean_squared_error: 135.0580 - val_loss: 142.4918 - val_mean_squared_error: 141.9609\n",
      "Epoch 869/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 135.6457 - mean_squared_error: 135.1134 - val_loss: 143.0819 - val_mean_squared_error: 142.5508\n",
      "Epoch 870/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 135.4847 - mean_squared_error: 134.9538 - val_loss: 142.9294 - val_mean_squared_error: 142.3978\n",
      "Epoch 871/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 135.7446 - mean_squared_error: 135.2139 - val_loss: 142.4417 - val_mean_squared_error: 141.9104\n",
      "Epoch 872/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 135.5546 - mean_squared_error: 135.0239 - val_loss: 142.3873 - val_mean_squared_error: 141.8563\n",
      "Epoch 873/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 135.5594 - mean_squared_error: 135.0283 - val_loss: 142.8151 - val_mean_squared_error: 142.2846\n",
      "Epoch 874/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 135.6552 - mean_squared_error: 135.1238 - val_loss: 142.2175 - val_mean_squared_error: 141.6878\n",
      "Epoch 875/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 135.8006 - mean_squared_error: 135.2694 - val_loss: 143.1236 - val_mean_squared_error: 142.5938\n",
      "Epoch 876/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 135.8394 - mean_squared_error: 135.3102 - val_loss: 142.3332 - val_mean_squared_error: 141.8034\n",
      "Epoch 877/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 135.4866 - mean_squared_error: 134.9556 - val_loss: 142.7462 - val_mean_squared_error: 142.2150\n",
      "Epoch 878/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 135.7040 - mean_squared_error: 135.1734 - val_loss: 143.1381 - val_mean_squared_error: 142.6065\n",
      "Epoch 879/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 135.6482 - mean_squared_error: 135.1176 - val_loss: 142.5422 - val_mean_squared_error: 142.0107\n",
      "Epoch 880/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 135.6776 - mean_squared_error: 135.1472 - val_loss: 142.1653 - val_mean_squared_error: 141.6342\n",
      "Epoch 881/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 135.5477 - mean_squared_error: 135.0173 - val_loss: 142.1574 - val_mean_squared_error: 141.6257\n",
      "Epoch 882/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 135.5787 - mean_squared_error: 135.0472 - val_loss: 142.1158 - val_mean_squared_error: 141.5854\n",
      "Epoch 883/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 135.5110 - mean_squared_error: 134.9798 - val_loss: 142.2042 - val_mean_squared_error: 141.6731\n",
      "Epoch 884/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 135.6643 - mean_squared_error: 135.1335 - val_loss: 143.0038 - val_mean_squared_error: 142.4730\n",
      "Epoch 885/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 135.5793 - mean_squared_error: 135.0484 - val_loss: 142.3497 - val_mean_squared_error: 141.8202\n",
      "Epoch 886/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 135.8327 - mean_squared_error: 135.3016 - val_loss: 143.3320 - val_mean_squared_error: 142.8027\n",
      "Epoch 887/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 135.5925 - mean_squared_error: 135.0623 - val_loss: 142.2751 - val_mean_squared_error: 141.7447\n",
      "Epoch 888/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 135.6301 - mean_squared_error: 135.0997 - val_loss: 144.0976 - val_mean_squared_error: 143.5666\n",
      "Epoch 889/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 135.3902 - mean_squared_error: 134.8584 - val_loss: 142.2513 - val_mean_squared_error: 141.7198\n",
      "Epoch 890/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 135.4278 - mean_squared_error: 134.8962 - val_loss: 142.6109 - val_mean_squared_error: 142.0804\n",
      "Epoch 891/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 135.5070 - mean_squared_error: 134.9760 - val_loss: 142.8486 - val_mean_squared_error: 142.3171\n",
      "Epoch 892/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 135.5021 - mean_squared_error: 134.9709 - val_loss: 142.3995 - val_mean_squared_error: 141.8681\n",
      "Epoch 893/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 135.4785 - mean_squared_error: 134.9466 - val_loss: 142.6961 - val_mean_squared_error: 142.1672\n",
      "Epoch 894/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 135.7136 - mean_squared_error: 135.1827 - val_loss: 142.4503 - val_mean_squared_error: 141.9200\n",
      "Epoch 895/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 135.3907 - mean_squared_error: 134.8601 - val_loss: 142.2935 - val_mean_squared_error: 141.7633\n",
      "Epoch 896/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 135.5853 - mean_squared_error: 135.0553 - val_loss: 142.8480 - val_mean_squared_error: 142.3169\n",
      "Epoch 897/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 135.6710 - mean_squared_error: 135.1399 - val_loss: 143.7354 - val_mean_squared_error: 143.2044\n",
      "Epoch 898/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 135.5347 - mean_squared_error: 135.0036 - val_loss: 142.4617 - val_mean_squared_error: 141.9319\n",
      "Epoch 899/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 135.2819 - mean_squared_error: 134.7518 - val_loss: 142.4391 - val_mean_squared_error: 141.9076\n",
      "Epoch 900/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 24us/sample - loss: 135.5250 - mean_squared_error: 134.9938 - val_loss: 142.7989 - val_mean_squared_error: 142.2672\n",
      "Epoch 901/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 135.5819 - mean_squared_error: 135.0507 - val_loss: 142.5050 - val_mean_squared_error: 141.9742\n",
      "Epoch 902/1000\n",
      "49590/49590 [==============================] - 2s 34us/sample - loss: 135.4234 - mean_squared_error: 134.8925 - val_loss: 142.2314 - val_mean_squared_error: 141.7016\n",
      "Epoch 903/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 135.4216 - mean_squared_error: 134.8901 - val_loss: 142.9416 - val_mean_squared_error: 142.4113\n",
      "Epoch 904/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 135.3582 - mean_squared_error: 134.8279 - val_loss: 142.3344 - val_mean_squared_error: 141.8034\n",
      "Epoch 905/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 135.6388 - mean_squared_error: 135.1075 - val_loss: 142.4296 - val_mean_squared_error: 141.8983\n",
      "Epoch 906/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 135.6167 - mean_squared_error: 135.0871 - val_loss: 142.3569 - val_mean_squared_error: 141.8267\n",
      "Epoch 907/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 135.4749 - mean_squared_error: 134.9450 - val_loss: 142.5365 - val_mean_squared_error: 142.0050\n",
      "Epoch 908/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 135.3921 - mean_squared_error: 134.8615 - val_loss: 142.3667 - val_mean_squared_error: 141.8363\n",
      "Epoch 909/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 135.5338 - mean_squared_error: 135.0039 - val_loss: 142.5559 - val_mean_squared_error: 142.0254\n",
      "Epoch 910/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 135.5602 - mean_squared_error: 135.0293 - val_loss: 142.3614 - val_mean_squared_error: 141.8314\n",
      "Epoch 911/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 135.4378 - mean_squared_error: 134.9080 - val_loss: 143.0924 - val_mean_squared_error: 142.5623\n",
      "Epoch 912/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 135.7753 - mean_squared_error: 135.2448 - val_loss: 145.1020 - val_mean_squared_error: 144.5723\n",
      "Epoch 913/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 135.6499 - mean_squared_error: 135.1199 - val_loss: 143.5549 - val_mean_squared_error: 143.0235\n",
      "Epoch 914/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 135.3130 - mean_squared_error: 134.7820 - val_loss: 143.2047 - val_mean_squared_error: 142.6756\n",
      "Epoch 915/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 135.3317 - mean_squared_error: 134.8009 - val_loss: 142.1841 - val_mean_squared_error: 141.6536\n",
      "Epoch 916/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 135.2636 - mean_squared_error: 134.7323 - val_loss: 142.4110 - val_mean_squared_error: 141.8795\n",
      "Epoch 917/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 135.4911 - mean_squared_error: 134.9592 - val_loss: 146.1447 - val_mean_squared_error: 145.6132\n",
      "Epoch 918/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 135.3132 - mean_squared_error: 134.7820 - val_loss: 142.1861 - val_mean_squared_error: 141.6553\n",
      "Epoch 919/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 135.3665 - mean_squared_error: 134.8353 - val_loss: 142.0134 - val_mean_squared_error: 141.4822\n",
      "Epoch 920/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 135.3103 - mean_squared_error: 134.7794 - val_loss: 142.4079 - val_mean_squared_error: 141.8759\n",
      "Epoch 921/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 135.3243 - mean_squared_error: 134.7932 - val_loss: 142.3637 - val_mean_squared_error: 141.8329\n",
      "Epoch 922/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 135.4110 - mean_squared_error: 134.8798 - val_loss: 142.3719 - val_mean_squared_error: 141.8406\n",
      "Epoch 923/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 135.3017 - mean_squared_error: 134.7698 - val_loss: 142.3249 - val_mean_squared_error: 141.7937\n",
      "Epoch 924/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 135.3276 - mean_squared_error: 134.7967 - val_loss: 142.1302 - val_mean_squared_error: 141.5996\n",
      "Epoch 925/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 135.4271 - mean_squared_error: 134.8969 - val_loss: 142.4789 - val_mean_squared_error: 141.9480\n",
      "Epoch 926/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 135.3232 - mean_squared_error: 134.7923 - val_loss: 143.7237 - val_mean_squared_error: 143.1927\n",
      "Epoch 927/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 135.4506 - mean_squared_error: 134.9192 - val_loss: 142.5348 - val_mean_squared_error: 142.0040\n",
      "Epoch 928/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 135.3572 - mean_squared_error: 134.8261 - val_loss: 142.7925 - val_mean_squared_error: 142.2615\n",
      "Epoch 929/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 135.4149 - mean_squared_error: 134.8831 - val_loss: 142.3855 - val_mean_squared_error: 141.8556\n",
      "Epoch 930/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 135.3096 - mean_squared_error: 134.7800 - val_loss: 142.4517 - val_mean_squared_error: 141.9202\n",
      "Epoch 931/1000\n",
      "49590/49590 [==============================] - 2s 38us/sample - loss: 135.8588 - mean_squared_error: 135.3279 - val_loss: 142.5635 - val_mean_squared_error: 142.0320\n",
      "Epoch 932/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 135.2991 - mean_squared_error: 134.7685 - val_loss: 143.4217 - val_mean_squared_error: 142.8911\n",
      "Epoch 933/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 135.4337 - mean_squared_error: 134.9021 - val_loss: 142.2776 - val_mean_squared_error: 141.7470\n",
      "Epoch 934/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 135.4634 - mean_squared_error: 134.9334 - val_loss: 142.7371 - val_mean_squared_error: 142.2054\n",
      "Epoch 935/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 135.3736 - mean_squared_error: 134.8419 - val_loss: 142.3142 - val_mean_squared_error: 141.7834\n",
      "Epoch 936/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 135.3552 - mean_squared_error: 134.8239 - val_loss: 142.4168 - val_mean_squared_error: 141.8868\n",
      "Epoch 937/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 135.2728 - mean_squared_error: 134.7420 - val_loss: 142.8144 - val_mean_squared_error: 142.2824\n",
      "Epoch 938/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 135.1071 - mean_squared_error: 134.5753 - val_loss: 142.5645 - val_mean_squared_error: 142.0324\n",
      "Epoch 939/1000\n",
      "49590/49590 [==============================] - 2s 39us/sample - loss: 135.3622 - mean_squared_error: 134.8306 - val_loss: 142.4034 - val_mean_squared_error: 141.8723\n",
      "Epoch 940/1000\n",
      "49590/49590 [==============================] - 2s 43us/sample - loss: 135.3484 - mean_squared_error: 134.8172 - val_loss: 142.0478 - val_mean_squared_error: 141.5169\n",
      "Epoch 941/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 135.5385 - mean_squared_error: 135.0071 - val_loss: 141.9892 - val_mean_squared_error: 141.4589\n",
      "Epoch 942/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 135.3352 - mean_squared_error: 134.8046 - val_loss: 142.3163 - val_mean_squared_error: 141.7852\n",
      "Epoch 943/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 135.3938 - mean_squared_error: 134.8621 - val_loss: 142.8634 - val_mean_squared_error: 142.3323\n",
      "Epoch 944/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 135.1340 - mean_squared_error: 134.6025 - val_loss: 143.0432 - val_mean_squared_error: 142.5108\n",
      "Epoch 945/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 135.1910 - mean_squared_error: 134.6589 - val_loss: 142.7803 - val_mean_squared_error: 142.2495\n",
      "Epoch 946/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 135.2196 - mean_squared_error: 134.6879 - val_loss: 147.3650 - val_mean_squared_error: 146.8331\n",
      "Epoch 947/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 135.2614 - mean_squared_error: 134.7294 - val_loss: 142.4499 - val_mean_squared_error: 141.9183\n",
      "Epoch 948/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 135.2553 - mean_squared_error: 134.7243 - val_loss: 142.5719 - val_mean_squared_error: 142.0400\n",
      "Epoch 949/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 135.4646 - mean_squared_error: 134.9325 - val_loss: 142.3610 - val_mean_squared_error: 141.8287\n",
      "Epoch 950/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 135.2167 - mean_squared_error: 134.6841 - val_loss: 143.4585 - val_mean_squared_error: 142.9273\n",
      "Epoch 951/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 134.9521 - mean_squared_error: 134.4201 - val_loss: 142.5648 - val_mean_squared_error: 142.0336\n",
      "Epoch 952/1000\n",
      "49590/49590 [==============================] - 2s 37us/sample - loss: 135.2106 - mean_squared_error: 134.6789 - val_loss: 143.5262 - val_mean_squared_error: 142.9940\n",
      "Epoch 953/1000\n",
      "49590/49590 [==============================] - 1s 19us/sample - loss: 135.2472 - mean_squared_error: 134.7152 - val_loss: 142.4950 - val_mean_squared_error: 141.9629\n",
      "Epoch 954/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 135.1409 - mean_squared_error: 134.6093 - val_loss: 142.7981 - val_mean_squared_error: 142.2664\n",
      "Epoch 955/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 135.1617 - mean_squared_error: 134.6298 - val_loss: 142.2680 - val_mean_squared_error: 141.7364\n",
      "Epoch 956/1000\n",
      "49590/49590 [==============================] - 2s 36us/sample - loss: 135.2835 - mean_squared_error: 134.7518 - val_loss: 142.2394 - val_mean_squared_error: 141.7083\n",
      "Epoch 957/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 135.3399 - mean_squared_error: 134.8089 - val_loss: 142.8947 - val_mean_squared_error: 142.3633\n",
      "Epoch 958/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 135.4370 - mean_squared_error: 134.9055 - val_loss: 142.4515 - val_mean_squared_error: 141.9193\n",
      "Epoch 959/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 135.0721 - mean_squared_error: 134.5400 - val_loss: 142.7203 - val_mean_squared_error: 142.1892\n",
      "Epoch 960/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 135.1848 - mean_squared_error: 134.6527 - val_loss: 142.1634 - val_mean_squared_error: 141.6317\n",
      "Epoch 961/1000\n",
      "49590/49590 [==============================] - 2s 35us/sample - loss: 135.2120 - mean_squared_error: 134.6802 - val_loss: 142.2837 - val_mean_squared_error: 141.7525\n",
      "Epoch 962/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 135.0787 - mean_squared_error: 134.5473 - val_loss: 143.0742 - val_mean_squared_error: 142.5419\n",
      "Epoch 963/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 135.5117 - mean_squared_error: 134.9795 - val_loss: 142.9711 - val_mean_squared_error: 142.4387\n",
      "Epoch 964/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 135.2039 - mean_squared_error: 134.6719 - val_loss: 142.2300 - val_mean_squared_error: 141.6981\n",
      "Epoch 965/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 135.3329 - mean_squared_error: 134.8006 - val_loss: 143.3983 - val_mean_squared_error: 142.8660\n",
      "Epoch 966/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 135.1288 - mean_squared_error: 134.5961 - val_loss: 142.3821 - val_mean_squared_error: 141.8497\n",
      "Epoch 967/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 135.2472 - mean_squared_error: 134.7147 - val_loss: 142.1493 - val_mean_squared_error: 141.6175\n",
      "Epoch 968/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 135.0924 - mean_squared_error: 134.5606 - val_loss: 142.0607 - val_mean_squared_error: 141.5285\n",
      "Epoch 969/1000\n",
      "49590/49590 [==============================] - 1s 20us/sample - loss: 135.2898 - mean_squared_error: 134.7577 - val_loss: 142.3422 - val_mean_squared_error: 141.8101\n",
      "Epoch 970/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 135.1030 - mean_squared_error: 134.5697 - val_loss: 142.2872 - val_mean_squared_error: 141.7553\n",
      "Epoch 971/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 135.1311 - mean_squared_error: 134.5980 - val_loss: 142.5176 - val_mean_squared_error: 141.9856\n",
      "Epoch 972/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 134.9341 - mean_squared_error: 134.4019 - val_loss: 142.7225 - val_mean_squared_error: 142.1893\n",
      "Epoch 973/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 135.1031 - mean_squared_error: 134.5705 - val_loss: 143.7965 - val_mean_squared_error: 143.2641\n",
      "Epoch 974/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 135.2634 - mean_squared_error: 134.7303 - val_loss: 142.3244 - val_mean_squared_error: 141.7924\n",
      "Epoch 975/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 134.8056 - mean_squared_error: 134.2729 - val_loss: 143.7951 - val_mean_squared_error: 143.2614\n",
      "Epoch 976/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 135.0762 - mean_squared_error: 134.5432 - val_loss: 142.1393 - val_mean_squared_error: 141.6060\n",
      "Epoch 977/1000\n",
      "49590/49590 [==============================] - 1s 27us/sample - loss: 134.9812 - mean_squared_error: 134.4478 - val_loss: 142.6345 - val_mean_squared_error: 142.1019\n",
      "Epoch 978/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 135.2091 - mean_squared_error: 134.6767 - val_loss: 142.2889 - val_mean_squared_error: 141.7568\n",
      "Epoch 979/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 134.9482 - mean_squared_error: 134.4159 - val_loss: 142.1993 - val_mean_squared_error: 141.6667\n",
      "Epoch 980/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 135.1614 - mean_squared_error: 134.6286 - val_loss: 142.1405 - val_mean_squared_error: 141.6084\n",
      "Epoch 981/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 135.2404 - mean_squared_error: 134.7084 - val_loss: 142.4995 - val_mean_squared_error: 141.9661\n",
      "Epoch 982/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 135.1083 - mean_squared_error: 134.5761 - val_loss: 142.1193 - val_mean_squared_error: 141.5863\n",
      "Epoch 983/1000\n",
      "49590/49590 [==============================] - 1s 26us/sample - loss: 135.0410 - mean_squared_error: 134.5086 - val_loss: 143.4563 - val_mean_squared_error: 142.9235\n",
      "Epoch 984/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 135.2305 - mean_squared_error: 134.6979 - val_loss: 142.4608 - val_mean_squared_error: 141.9282\n",
      "Epoch 985/1000\n",
      "49590/49590 [==============================] - 1s 23us/sample - loss: 135.1198 - mean_squared_error: 134.5861 - val_loss: 142.3775 - val_mean_squared_error: 141.8449\n",
      "Epoch 986/1000\n",
      "49590/49590 [==============================] - 1s 22us/sample - loss: 135.4556 - mean_squared_error: 134.9234 - val_loss: 142.1013 - val_mean_squared_error: 141.5684\n",
      "Epoch 987/1000\n",
      "49590/49590 [==============================] - 1s 24us/sample - loss: 135.0679 - mean_squared_error: 134.5343 - val_loss: 142.8148 - val_mean_squared_error: 142.2822\n",
      "Epoch 988/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 135.0110 - mean_squared_error: 134.4789 - val_loss: 142.8559 - val_mean_squared_error: 142.3218\n",
      "Epoch 989/1000\n",
      "49590/49590 [==============================] - 1s 30us/sample - loss: 135.2248 - mean_squared_error: 134.6904 - val_loss: 142.9426 - val_mean_squared_error: 142.4082\n",
      "Epoch 990/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49590/49590 [==============================] - 1s 27us/sample - loss: 134.9406 - mean_squared_error: 134.4068 - val_loss: 142.1848 - val_mean_squared_error: 141.6510\n",
      "Epoch 991/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 135.1471 - mean_squared_error: 134.6134 - val_loss: 143.9145 - val_mean_squared_error: 143.3801\n",
      "Epoch 992/1000\n",
      "49590/49590 [==============================] - 2s 32us/sample - loss: 134.9861 - mean_squared_error: 134.4531 - val_loss: 143.0095 - val_mean_squared_error: 142.4748\n",
      "Epoch 993/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 135.0379 - mean_squared_error: 134.5041 - val_loss: 142.2115 - val_mean_squared_error: 141.6775\n",
      "Epoch 994/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 135.0702 - mean_squared_error: 134.5367 - val_loss: 143.0097 - val_mean_squared_error: 142.4754\n",
      "Epoch 995/1000\n",
      "49590/49590 [==============================] - 2s 33us/sample - loss: 134.7591 - mean_squared_error: 134.2249 - val_loss: 142.1079 - val_mean_squared_error: 141.5729\n",
      "Epoch 996/1000\n",
      "49590/49590 [==============================] - 1s 28us/sample - loss: 134.9306 - mean_squared_error: 134.3956 - val_loss: 142.3860 - val_mean_squared_error: 141.8527\n",
      "Epoch 997/1000\n",
      "49590/49590 [==============================] - 2s 31us/sample - loss: 134.9002 - mean_squared_error: 134.3675 - val_loss: 141.9472 - val_mean_squared_error: 141.4132\n",
      "Epoch 998/1000\n",
      "49590/49590 [==============================] - 1s 25us/sample - loss: 135.1586 - mean_squared_error: 134.6246 - val_loss: 141.9665 - val_mean_squared_error: 141.4328\n",
      "Epoch 999/1000\n",
      "49590/49590 [==============================] - 1s 21us/sample - loss: 134.9259 - mean_squared_error: 134.3911 - val_loss: 142.1443 - val_mean_squared_error: 141.6096\n",
      "Epoch 1000/1000\n",
      "49590/49590 [==============================] - 1s 29us/sample - loss: 134.9037 - mean_squared_error: 134.3692 - val_loss: 142.3821 - val_mean_squared_error: 141.8479\n"
     ]
    }
   ],
   "source": [
    "# quantitative: ANN\n",
    "# specify network layers\n",
    "quant_ann = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation = 'sigmoid', input_shape = (13, )),\n",
    "    tf.keras.layers.Dense(100, activation = 'relu', \n",
    "                       kernel_regularizer = tf.keras.regularizers.l2(l = 0.001)),\n",
    "    tf.keras.layers.Dense(1, activation = 'linear')\n",
    "])\n",
    "\n",
    "# compile and fit network\n",
    "quant_ann.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['mean_squared_error']) \n",
    "history = quant_ann.fit(X_train, y_train, epochs = 1000, batch_size = 128, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmcHGW59//PNT1rZs1kIxskQFhDliEEEJRVFARRRCGKrIILiv5wA47nAbcjPnoQ8XBUFAEVQQ7IcvghiIgLAsEEQlgCJEBCJutkmcy+dM/1/HFXJ51JdzozmZ5J0t/369Wvqbrrrqq7upK66l6q2twdERGR3gqGugAiIrJrUoAQEZG0FCBERCQtBQgREUlLAUJERNJSgBARkbQUIGS3YGaTzMzNrHAH8l5oZk8NRrnyTXQO9h/qcsjgUICQAWdmS82sy8xG9kpfEF1gJg1NybYKNM/3Sh8ZlXlpStqxZva0mW0ysw1m9k8zOyJadqGZJcyspddn3CAey1Iza++1//8arP3Lnk8BQnLlbWBOcsbMDgPKhq442yg3s6kp8x8nlBkAM6sCHgZ+AtQC44FvAp0p6zzj7hW9PisHoeypzui1/88P8v5lD6YAIbnyG+D8lPkLgF+nZjCzajP7tZk1mNkyM/uGmRVEy2Jm9kMzW2dmbwEfSLPurWa2ysxWmNl3zCzWx/JdkDJ/fq/yHQDg7ne5e8Ld2939T+6+sA/7SJb1Z2b2w15pD5rZldH016NjaDaz183spL7uI80+L4xqPD+JakCvpW7XzMaZ2UNRzWiJmV2asixmZteY2ZtRmeab2cSUzZ9sZovNbKOZ3WxmFq23v5n9LdrfOjP7/c4ehwwtBQjJlWeBKjM7OLpwnwP8tleenwDVwL7AcYSL9EXRskuB04GZwCzg7F7r3gHEgf2jPKcAn+pD+X4LnBtdDA8GKoG5KcvfABJmdoeZnWpmw/uw7d5+B5yTciEdHpX3bjM7EPg8cIS7VwLvA5buxL5SHQm8BYwErgX+YGa10bK7gHpgHOG7/Y+UAHIlofZ3GlAFXAy0pWz3dOAIYDrwsajMAN8G/gQMByYQzq/sxhQgJJeStYj3Aq8BK5ILUoLG1e7e7O5Lgf8EPhll+Rhwo7svd/cNwPdS1h0DnAp8yd1b3X0t8CPg3D6UrR54HTiZNLUbd28CjgUc+AXQEN1xj0nJdpSZNaZ83sywr39E23l3NH82oXlqJZAASoBDzKzI3Ze6e6btpPNArzJcmrJsLeE77Hb330fH+4GoNnAs8HV373D3BcAv2fLdfwr4hru/7sGL7r4+ZbvXu3uju78DPAnMiNK7gX2AcdF2NVBgN6cAIbn0G0Lb/oX0ugAT7mqLgWUpacsIbf0Q7myX91qWtA9QBKxKXhiBnwOj+1i+X0dlm8O2tRvcfZG7X+juE4CpUZluTMnyrLvXpHz2S7cTD2/EvJstfTIfB+6Mli0BvgRcB6w1s7v72NH9oV5l+EXKshW+9ds4l0XHMA7Y4O7NvZYlv/uJwPaC1OqU6TagIpr+GmDAc2b2ipld3IfjkF2QAoTkjLsvI3T8ngb8odfidWy540zamy21jFWEC1XqsqTlhM7ikSkXxip3P7SPRbyP0LfxVlTW7R3La8DthEDRH3cBZ5vZPoSmn/tStv07dz+W8F048P1+7qO38clmrcjewMroU2tmlb2WJb/75UDaYLc97r7a3S9193HAp4H/1pDY3ZsChOTaJcCJ7t6amujuCeAe4LtmVhldOK9ky538PcAVZjYharO/KmXdVYS27v80syozKzCz/czsuL4ULCrTiaTpuzCzg8zsy2Y2IZqfSKgBPNuXfaTs6wWggdCU85i7N0bbPdDMTjSzEqADaCc0Ow2E0YTvsMjMPgocDDzi7suBp4HvmVmpmU0jnKc7o/V+CXzbzKZYMM3MRmTbmZl9NPl9ARsJwW6gjkWGgAKE5JS7v+nu8zIs/gLQSuhIfYrQmfuraNkvgMeAF4Hn2bYGcj6hiepVwsXoXmBsP8o3L0ObfzPhTn+umbUSAsPLwJdT8hxt2z4HccR2dncXoc/jdylpJcD1hBrVasJF/RoAM/uEmb2S5RD+t9f+709ZNheYEm37u8DZKX0Jc4BJhNrE/cC17v54tOwGQoD+E9AE3MqODVE+gvB9tQAPAV9097ezrCO7MNMPBonseczsQuBTUdOVSL+oBiEiImkpQIiISFpqYhIRkbRyXoOInlR9wcwejuYnm9nc6FH935tZcZReEs0viZZPynXZREQks6yvTh4AXwQWER7ZhzDG+0fufreZ/YwwvO6n0d+N7r6/mZ0b5TtnexseOXKkT5o0KWcFFxHZE82fP3+du4/Kli+nTUzRmOg7CEPsrgTOIIwF38vd42Z2NHCdu7/PzB6Lpp+x8M7/1cAo304BZ82a5fPmZRpBKSIi6ZjZfHeflS1frpuYbiQ8ft8TzY8AGt09Hs3Xs+Xx/vFEr1aIlm+K8ouIyBDIWYAws9OBte4+PzU5TVbfgWWp273MzOaZ2byGhoYBKKmIiKSTyxrEMcAHLfxC192EVxrcCNTYlp+NnEB4khNCbWIiQLS8GtjQe6Pufou7z3L3WaNGZW1CExGRfspZJ7W7Xw1cDWBmxwNfcfdPmNn/EF53fDfhNcsPRqs8FM0/Ey3/y/b6H0Rkz9Ld3U19fT0dHR1DXZQ9RmlpKRMmTKCoqKhf6w/GKKbevk74oZTvAC8Q3vNC9Pc3ZraEUHPoy7v9RWQ3V19fT2VlJZMmTWLrl9BKf7g769evp76+nsmTJ/drG4MSINz9r8Bfo+m3gNlp8nQAHx2M8ojIrqejo0PBYQCZGSNGjGBn+mr1qg0R2WUoOAysnf0+8zJAvLGmmRv+9DrrWjqHuigiIrusvAwQi9e0cNNflrChtWuoiyIiu4j169czY8YMZsyYwV577cX48eM3z3d17di14qKLLuL111/fbp6bb76ZO++8c7t5dhVD0Um9y9AYKRFJGjFiBAsWLADguuuuo6Kigq985Stb5XF33J2CgvT31rfddlvW/Vx++eU7X9hBkpc1CDVzisiOWrJkCVOnTuUzn/kMdXV1rFq1issuu4xZs2Zx6KGH8q1vfWtz3mOPPZYFCxYQj8epqanhqquuYvr06Rx99NGsXbsWgG984xvceOONm/NfddVVzJ49mwMPPJCnn34agNbWVj7ykY8wffp05syZw6xZszYHr8GU3zWIbR/UFpFdwDf/9xVeXdk0oNs8ZFwV155xaL/WffXVV7ntttv42c9+BsD1119PbW0t8XicE044gbPPPptDDjlkq3U2bdrEcccdx/XXX8+VV17Jr371K6666qpttu3uPPfcczz00EN861vf4tFHH+UnP/kJe+21F/fddx8vvvgidXV1/Sr3zsrPGsRQF0BEdiv77bcfRxyx5efG77rrLurq6qirq2PRokW8+uqr26xTVlbGqaeeCsDhhx/O0qVL0277rLPO2ibPU089xbnnhkfBpk+fzqGH9i+w7ay8rkGIyK6pv3f6uVJeXr55evHixfz4xz/mueeeo6amhvPOOy/t09/FxcWbp2OxGPF4fJs8ACUlJdvk2VVeIpGXNYikXeQciMhupKmpicrKSqqqqli1ahWPPfbYgO/j2GOP5Z577gHgpZdeSltDGQx5WYNQJ7WI9FddXR2HHHIIU6dOZd999+WYY44Z8H184Qtf4Pzzz2fatGnU1dUxdepUqqurB3w/2ezWv0nd3x8MevTlVXzmt8/zyBXv5pBxVdlXEJGcW7RoEQcffPBQF2OXEI/HicfjlJaWsnjxYk455RQWL15MYWHf7+nTfa87+oNBeVmDUDe1iOzKWlpaOOmkk4jH47g7P//5z/sVHHZWngaIQMNcRWRXVFNTw/z587NnzLG87KRWH4SISHZ5GSCSduPuFxGRnMvLAKEKhIhIdnkZIEREJLu8DBD6URIR6e3444/f5qG3G2+8kc997nMZ16moqABg5cqVnH322Rm3m204/o033khbW9vm+dNOO43GxsYdLXrO5GWASFIfhIgkzZkzh7vvvnurtLvvvps5c+ZkXXfcuHHce++9/d537wDxyCOPUFNT0+/tDZS8DBCqP4hIb2effTYPP/wwnZ3hlyaXLl3KypUrmTFjBieddBJ1dXUcdthhPPjgg9usu3TpUqZOnQpAe3s75557LtOmTeOcc86hvb19c77Pfvazm18Tfu211wJw0003sXLlSk444QROOOEEACZNmsS6desAuOGGG5g6dSpTp07d/JrwpUuXcvDBB3PppZdy6KGHcsopp2y1n4GS189BiMgu6o9XweqXBnabex0Gp16fcfGIESOYPXs2jz76KGeeeSZ3330355xzDmVlZdx///1UVVWxbt06jjrqKD74wQ9mbKr+6U9/yrBhw1i4cCELFy7c6lXd3/3ud6mtrSWRSHDSSSexcOFCrrjiCm644QaefPJJRo4cudW25s+fz2233cbcuXNxd4488kiOO+44hg8fzuLFi7nrrrv4xS9+wcc+9jHuu+8+zjvvvIH5riJ5WYNI0oNyIpIqtZkp2bzk7lxzzTVMmzaNk08+mRUrVrBmzZqM2/j73/+++UI9bdo0pk2btnnZPffcQ11dHTNnzuSVV17J+hK+p556ig9/+MOUl5dTUVHBWWedxT/+8Q8AJk+ezIwZM4Dtv058Z+RlDUJ91CK7uO3c6efShz70Ia688kqef/552tvbqaur4/bbb6ehoYH58+dTVFTEpEmT0r7eO1W62sXbb7/ND3/4Q/71r38xfPhwLrzwwqzb2d678pKvCYfwqvBcNDHldw1CFQgRSVFRUcHxxx/PxRdfvLlzetOmTYwePZqioiKefPJJli1btt1tvOc97+HOO+8E4OWXX2bhwoVAeE14eXk51dXVrFmzhj/+8Y+b16msrKS5uTntth544AHa2tpobW3l/vvv593vfvdAHW5WqkGIiKSYM2cOZ5111uampk984hOcccYZzJo1ixkzZnDQQQdtd/3PfvazXHTRRUybNo0ZM2Ywe/ZsIPwy3MyZMzn00EO3eU34ZZddxqmnnsrYsWN58sknN6fX1dVx4YUXbt7Gpz71KWbOnJmT5qR08vJ13395bQ0X3z6PBy4/hhkTh34omYjodd+5sjOv+87LJibTQFcRkazyMkAk7c61JxGRXMvPAKEKhMguSTdtA2tnv8/8DBAR/VMU2XWUlpayfv16BYkB4u6sX7+e0tLSfm8jZ6OYzKwU+DtQEu3nXne/1sxuB44DNkVZL3T3BRYGDv8YOA1oi9Kfz0nZcrFREdkpEyZMoL6+noaGhqEuyh6jtLSUCRMm9Hv9XA5z7QROdPcWMysCnjKz5MDfr7p77zdbnQpMiT5HAj+N/opIHigqKmLy5MlDXQxJkbMmJg9aotmi6LO9uuOZwK+j9Z4FasxsbK7KF8qYy62LiOzectoHYWYxM1sArAUed/e50aLvmtlCM/uRmSWfFx8PLE9ZvT5K673Ny8xsnpnN629VVL8HISKSXU4DhLsn3H0GMAGYbWZTgauBg4AjgFrg61H2dFftbe7x3f0Wd5/l7rNGjRq1syXcyfVFRPZcgzKKyd0bgb8C73f3VVEzUidwGzA7ylYPTExZbQKwMhflUf1BRCS7nAUIMxtlZjXRdBlwMvBasl8hGrX0IeDlaJWHgPMtOArY5O6rclU+UB+EiMj25HIU01jgDjOLEQLRPe7+sJn9xcxGEW7kFwCfifI/QhjiuoQwzPWiXBVMXRAiItnlLEC4+0JgZpr0EzPkd+DyXJUn7T4Hc2ciIruZvHySWi/rExHJLi8DRJL6IEREMsvLAKE+CBGR7PIyQIiISHZ5HSD01kgRkczyMkCohUlEJLu8DBBJqj+IiGSWnwFCVQgRkazyM0BE1AUhIpJZXgYIPSgnIpJdXgaIJFcvhIhIRnkZIPSgnIhIdnkZIDZTBUJEJKO8DBCqQIiIZJeXASJJFQgRkczyMkCYOiFERLLKywAhIiLZ5XWA0INyIiKZ5WWAUAuTiEh2eRkgkvSgnIhIZnkZIFSBEBHJLi8DRJL6IEREMsvLAKE+CBGR7PIyQCSpAiEiklmeBghVIUREssnTABG4OiFERDLKywChPggRkezyMkCIiEh2eR0g1MAkIpJZXgYItTCJiGSXswBhZqVm9pyZvWhmr5jZN6P0yWY218wWm9nvzaw4Si+J5pdEyyflqmybqQohIpJRLmsQncCJ7j4dmAG838yOAr4P/MjdpwAbgUui/JcAG919f+BHUb6c0O9BiIhkl7MA4UFLNFsUfRw4Ebg3Sr8D+FA0fWY0T7T8JMvxlVwv6xMRySynfRBmFjOzBcBa4HHgTaDR3eNRlnpgfDQ9HlgOEC3fBIxIs83LzGyemc1raGjoX7n6tZaISH7JaYBw94S7zwAmALOBg9Nli/6mu25vc4vv7re4+yx3nzVq1KidLN9OrS4iskcblFFM7t4I/BU4Cqgxs8Jo0QRgZTRdD0wEiJZXAxtyUR51QYiIZJfLUUyjzKwmmi4DTgYWAU8CZ0fZLgAejKYfiuaJlv/Fc/wuDNUgREQyK8yepd/GAneYWYwQiO5x94fN7FXgbjP7DvACcGuU/1bgN2a2hFBzODdXBTP1QoiIZJWzAOHuC4GZadLfIvRH9E7vAD6aq/KkowqEiEhmefkktYiIZJeXAUKd1CIi2eVlgEjS70GIiGSW1wFCREQyy+sAofqDiEhmeRkg1AchIpJdXgaIJHVBiIhklpcBQg/KiYhkl5cBYgtVIUREMsnLAKE+CBGR7PIyQCSpD0JEJLO8DBCqQYiIZJeXAUJERLLL6wChFiYRkczyMkBomKuISHbbDRBmdl7K9DG9ln0+V4UaLOqkFhHJLFsN4sqU6Z/0WnbxAJdl0KiTWkQku2wBwjJMp5vf7bh6IUREMsoWIDzDdLr53cZuH9lERAZBtt+kPsjMFhKuqftF00Tz++a0ZINAfRAiIpllCxAHD0opBpn6IEREsttugHD3ZanzZjYCeA/wjrvPz2XBBoMqECIimWUb5vqwmU2NpscCLxNGL/3GzL40COXLEVUhRESyydZJPdndX46mLwIed/czgCPZjYe5iohIdtkCRHfK9EnAIwDu3gz05KpQg8XVSy0iklG2TurlZvYFoB6oAx4FMLMyoCjHZcsZdVKLiGSXrQZxCXAocCFwjrs3RulHAbflsFwiIjLEso1iWgt8Jk36k8CTuSpUrqkCISKS3XYDhJk9tL3l7v7BgS3O4FIXhIhIZtn6II4GlgN3AXPpw823mU0Efg3sRejQvsXdf2xm1wGXAg1R1mvc/ZFonasJzVoJ4Ap3f2zHD2XHmTohRESyyhYg9gLeC8wBPg78/8Bd7v7KDmw7DnzZ3Z83s0pgvpk9Hi37kbv/MDWzmR0CnEvo8xgH/NnMDnD3xI4fTt/oZX0iIpltt5Pa3RPu/qi7X0DomF4C/DUa2bRd7r7K3Z+PppuBRcD47axyJnC3u3e6+9vRvmbv4HH0ieoPIiLZZf1FOTMrMbOzgN8ClwM3AX/oy07MbBIwk9BMBfB5M1toZr8ys+FR2nhCc1ZSPWkCipldZmbzzGxeQ0ND78V9oj4IEZHMsr1q4w7gacIzEN909yPc/dvuvmJHd2BmFcB9wJfcvQn4KbAfMANYBfxnMmua1be5hLv7Le4+y91njRo1akeL0atM/VpNRCSvZOuD+CTQChwAXJHSuWuAu3vV9lY2syJCcLjT3f9AWGlNyvJfAA9Hs/XAxJTVJwArd+ww+kc1CBGRzLL1QRS4e2X0qUr5VO5AcDDgVmCRu9+Qkj42JduHCS8ABHgIODdq0poMTAGe689BZWPqhRARySpbDWJnHEOogbxkZguitGuAOWY2g9B8tBT4NIC7v2Jm9wCvEkZAXZ7LEUwiIrJ9OQsQ7v4U6fsVHtnOOt8FvpurMm2zv8HakYjIbijrKKY9kTqpRUSyy8sAkaTXfYuIZJbXAUJERDLL6wCh+oOISGZ5GSDUByEikl1eBojNVIUQEckoLwOEXvctIpJdXgaIJL3uW0Qks7wMEKo/iIhkl5cBQkREssvrAKHn5EREMsvLAKE+ahGR7PIyQCSpAiEiklleBgj9HoSISHZ5GSCS1AchIpJZXgYI9UGIiGSXlwEiSQ/KiYhklpcBQhUIEZHs8jJAJKkPQkQks/wMEKpCiIhklZ8BQkREssrrAKEWJhGRzPIyQOhBORGR7PIyQGymXmoRkYzyMkDoQTkRkezyMkAkqf4gIpJZXgYIVSBERLLLywCRpC4IEZHM8jJAmDohRESyyssAkeSqQoiIZJSzAGFmE83sSTNbZGavmNkXo/RaM3vczBZHf4dH6WZmN5nZEjNbaGZ1OStbrjYsIrIHyWUNIg582d0PBo4CLjezQ4CrgCfcfQrwRDQPcCowJfpcBvw0h2UDNIpJRGR7chYg3H2Vuz8fTTcDi4DxwJnAHVG2O4APRdNnAr/24FmgxszG5qJs6oIQEcluUPogzGwSMBOYC4xx91UQgggwOso2Hlieslp9lNZ7W5eZ2Twzm9fQ0JDLYouI5LWcBwgzqwDuA77k7k3by5ombZtWIHe/xd1nufusUaNG7VTZ1EctIpJZTgOEmRURgsOd7v6HKHlNsuko+rs2Sq8HJqasPgFYmZNyqZtaRCSrXI5iMuBWYJG735Cy6CHggmj6AuDBlPTzo9FMRwGbkk1RuaIKhIhIZoU53PYxwCeBl8xsQZR2DXA9cI+ZXQK8A3w0WvYIcBqwBGgDLspZyVSBEBHJKmcBwt2fIvOl+KQ0+R24PFflSUcPyomIZJaXT1JrmKuISHZ5GSBERCS7vAwQqkCIiGSXlwEiSV0QIiKZ5WWA0Ou+RUSyy8sAISIi2eV1gHA9KiciklFeBgg1MImIZJeXASJJndQiIpnlZYBQH7WISHZ5GSCSVIEQEcksLwOEXvctIpJdXgaIJPVBiIhklpcBQn0QIiLZ5WeAWPk81xfeQknXhqEuiojILis/A0TLGs4t/CuVHTn9wToRkd1aXgYIrxgDwLDOdUNcEhGRXVdeBoii6rFhokU1CBGRTPIyQBRU7kU3hbBx6VAXRURkl5WXAYJYIatKJjO65fWhLomIyC4rPwMEsKnmUKYkltDeGd96wQt3wuqXh6ZQIiK7kLwNELFJ76LGWlnyz3u3JPb0wIOfg58dM3QFExHZRRQOdQGGyr4nnE/bs//OYX//NBSvgjFTYfikoS6WiMguI28DRGlpGfNHvY/D1z0Ef75u2wzusHwurHoRjvz0oJdPRGSo5W0TE8Bhn7mD+0dcylqv2WZZz7dGwK/eB3/8GjS8AYnuISihiMjQMd+N31g3a9Ysnzdv3k5vZ11LJ88uXs3rr73E+jfmMrl7CR+IPcs4S3kVx/DJcMUL4UVO3R1QWDI4L3VKxKEgphdIiciAMbP57j4raz4FiG11J3q4+7l3WPb0vRzX9L+82xYA0FWzH8WNb4ZMp/0QZl8KnS1QNAwKclQZu64ajvgUfOA/c7N9Eck7Oxog8rqJKZOiWAGfPHoS3/jyVzjwK4/xf6c/yiOJ2VuCA8AjX4E/fxO+Nx7+/oMwAuqPX4fnfjFwBYl3hb//+uXAbVNEZAflbSf1jhpdWcrXPnw0a0/6X25+7C+896WvcEDBirDwqRvC37/+B3Q2wdyfhfnZlw7MzrtaBmY7IiL9oBrEDhpdVcrlHz2N1k/9k28fcB/P9+y/dYZn/mvL9M1HwsoF0LQSWtZm33hPIn16V2v/CywispNyVoMws18BpwNr3X1qlHYdcCnQEGW7xt0fiZZdDVwCJIAr3P2xXJVtZ8zcezgzP34ya5r+yZ2L1rBk0QLK3v4zZ/iTNHgN74m9BA2vwS3HbVlp9KGwz9FQVgtNK8IQ2n3eFQLI/NuheSV87lkYffDWO+tuG9RjExFJlbNOajN7D9AC/LpXgGhx9x/2ynsIcBcwGxgH/Bk4wN0z3FoHueqk7quO7gTPvLWeF9/ZyNMLXmb/xn+yt63hzNjTjLAmioln38jpN8L6JTD6EJjxcYh3wv2fhlcfCMuv2xRqJasXwr4nQM3EHS9gvBNevg+mz9FoKBHZNUYxmdkk4OEdCBBXA7j796L5x4Dr3P2Z7W1/VwkQvW1q7+YfixtYuq6Vl1Zs4oXXlrBPzwqmFbzFKbF5jIy1MZxman3jjm/0gFPhjT9umb/8X6Gj/LivwaRj4fVHw3DYNx6F938fYimVwz/9Ozx9E3z8HjjgfX0/oEUPh2G9U97b93VFZJezowFiKDqpP29m5wPzgC+7+0ZgPPBsSp76KG0bZnYZcBnA3nvvneOi9k91WRGnTxuXkjKL11c38/KKTfwjChp/e6MBcOpsMcOtmTNKX2Rm0TtUF3RQ0/7OthtNDQ4ANx8R/r79t23zrnkFDj4DaveDsdNDcABo3xj6O6wgNF/FO2H9mzBhVmj26miEYbUw/w7Y/yTYVA9V4+H3nwjrX7MSisuzfwHtjVC27cOHAHQ2h+V9qQElbVy6Z78OZcV8qNgLqtP+0xcZdINdgxgDrAMc+DYw1t0vNrObgWfc/bdRvluBR9z9vu1tf1etQeyI7kQPS9e18shLq1lY38gTr62lZlgRjW3dGD2MpImDCt6hZ9hI3jV5OO9beysjy4sY1rGK4g1v7NzOYyWQ6NwyX1IFNXvDmpfhY7+Bez65ZVlxJXQ1h2mLwaVPwCv3w8QjQ7AorQ7DcI/7OgwbEZrBbj8NJr8HDjodZl8Grz4Y+mWOvwpuPx2W/gP+z4ZQ40mV6IaF98D0c+G1h2H/90LxsLBs0cMhUH3iPphycpYvtz18htXu3PfUX+7QuCwEs5UvwC3Hw6f/AWOnbX+966rDMzX/ph+y2qO1rIVFD4Xnm4bILlmDcPc1yWkz+wXwcDRbD6TeUk4AVg5i0QZdUayAKWMq+eKYyq3Sl65rZe7b66nf2M7jr06kK9HDD15q5Qd8fqt8MRIcMqqYWbUdTC9rYPjw4YyvKmZ412pqNy7A1r0Bq1+CeEe4UK96ETYth8LSkJaqsykEB9jaDG5vAAAThklEQVQ6OMCW4ADgiXCxS+eF3249//bfwwfC60oAJr07BIfk8s7msL8xU+Gz/wzDhP/0DXjn6S3bu2YlFJbB4/8e5le+APudGPpm4p2h7Ml3ZfX0hFrQ78+DZf8M/TbJ9LWvwphDQxAqLM58DKXVofa1I37zYWhaBZenVH4fvRqW/BnWvQEXPwZvRGMt3nh0+wEieaOWOjAh3hW2deCpoe+ofj60b9jxpr6X7oW/fg8uf27bYJxKT+sPnK62MPz93V+GorL0ee69OPw/2PcEGLHf4JavjwY1QJjZWHdP3h59GEj+8MJDwO/M7AZCJ/UU4LnBLNuuYtLIciaNDM04Xz7lQADcndVNHby2upkXlm1k0epm/vZ6A2s7C3mioZo7NhbRs7kiOB4YT235hxk+rIjhw4qZQBkjppRgwPEHjGK0bWT4iFGMbHoVqxgTnrdIdIWmn7WvhN/DGLFfuKh2tYWaQd358PRPwgsMOxp3/ICSwQFCzSLpNx/aMr3mZfjBFGiNhgSnBpv/SG2qA578TmhWSwYaCB3wex8dOvlfe3hL+l1z4ID3hxrO6oWAESqvwNGfh544NC6Hjk1h3ZbVYdlH74C2deEp+dcehroLwnb+9A14/ZEQlA6/CN78S8h/XXWoUZUND4EgafVLW/aX6A75xs0M/Uk1E8NghE318N9HwxGXbH2cy/8Fvz4Tulvh3LvgoNPglyeGZf9n49ZP7nc2h2M9/EI47GzY8HY4n/d/Ohxj82pY/iw88Dn46hJ47N9g2jkQKwoj5743ASYfBxc8tHUZ5t8O4w+HvQ5jG+/MheH7wMt/CDW16edCR1NoJtvwJsw8f+tA3L4xBKKiUiip3HZ7O2L9m1A1busLb08C5t8GUz8CBYX93/ZA+PsPw01OawOU1sC7Pp8+36b68Hc3eM4pl6OY7gKOB0YCa4Bro/kZhP81S4FPJwOGmf0bcDEQB77k7n/cZqO97M5NTAOpM55gydoWlm9oY01TJ6s2dbCmqYPGti4a27tpaO5kRWM7vU91gcHwYcVUlBayz4hyEj09TBldSW15MY1t3XQlEgwrLmTK6ArGVJVSUljAQXtVUVFaiCfiFPZ0htpIYWm4oLY3gvdArBjwEGji7aGp5flfhzv+8lGw7GlYv3jrwlRPDMN+IfRftK0fjK9uaPUeeJBUu1+4yG5mcPTlWz9rc9jHQt9Rw2sw71db0j9yK9zXK9hsT/noLYH5xG/AtHPhtlNDbTOpOgpm+58cglFnE/zPhVtv5/Pz4J4Lwg0GRE2OI0MZOxpDbSvpvPvCv5nGd0JQaQ39cSS6Q9Cp3Q/2OyE8B3TjNBhfF25Qfn9eWP/8B6Hh9RAQ59++9U3IhCPgXV8I/WwHnQ4LfgeLH4NZF4cyH34RVIwJ6xYUhqbW7g742/XQui408R15WQhGk94dbhq620Ngf/2PocZ75n+H/fz1e3DGj0Ptq2gYfDOl3+2Eb8DeR8IrD4TRg52bQo2hIAbfGhECd0k1HPdVOOLSUDt/47HQ3DtuBvxgP5jyPphzF8z9eQiAf/+/4f/YGTfudCDcJUYx5ZoCxI5r7uimpTPO2+taaWrvpn5jO41t3Wxo62LZ+laa2uMkepxl61tp7dru6GIAhhXHGFNVSmlRjAnDyygvjjGqsoSCAqPAjAPHVFJeUkh7d4LqsiImjyhneHkR5cUhrawoRkFBryaNnsSWppDO5tBWWz0xdE53NYcO3OXPhmad2skhoHgPrF0UmnQmHQt7TQvNad1toR9g/OHhQrV+Scj/5hOAhTvayr1g7AyoHLP1RTbVyAPCttNJ11wnA6NiDLSsyZ5vsJQND/9mMi6vDc1/2YydHv59bk9q0M5k8nEhaB52dvZ9prFL9kHI0KksLaKytIix1RnaRSM9Pc761i7KS2IsXtPC+tbQmd3Y1s3Sda28vb6NhuYORleWsqapg+aOOItWNdEV72FDaxfxnu3fcJhtaW4fWVHCupZOjpxcS1eih6KCAmrLi9ln5DBwKCgwasqW0+MxVm0qYfZk44Axp8AoWLGxnbrDhrOmqYO9ppeGYywppMchdvDpff+CTv9R5mXuIXjFCsN0alu9e/gUFISmqg1vQ+2+IajV7hsuGhYLd+QjD4B1i0PTTkFhqCVVjQvrlVSFWlhPAppXhbvpfY8P0x1NIUDue3wYoda2PtTKVi0EPNTYympD+dYtCcFx8rtDk+C+x4e76cpx4W555QvhIc2WtbDw92GU2oGnQfnI0GRmMWhYFO6e/3VruPOdcV64WLesCfkKikJQtRjU/ytc9FYuCOWfeCS8+hBMPCI0N3V3hLvw938/bLe7I/SrtK0LTVfVE8N3s/ql8H0WloVyjpgSahLvPB1qna0NW77zfY+HcXXw7E9DDbWwNNzhN60ItZJ9jg135O88EwJNZ/OWvh0rCDcVvRUUhrv6ijHhu2/fEI6zJ3rNf+/X/Y+YEm5AEtH70mr23jIacMnj4bspGhbd2ETBrrgyHOfYGWF7ydpWb7GibdN634yseB4OOTP9+gNINQgZMJ3xBIkepyvew2urmymKGS2dCRavaSbR45jB+pYu3mxooaQwxsa2LuYv28jetcNobO/G3Yn3OE3t3ZgZiSzBJp1hxTH2rh1GoscpLYqxvqWT/UZXsKm9m/1HV1BRUkhTezdrmjqZuXcN5SWFFMWMzu4elm1oY/qEaipKC3mroZUjJ4+gorSQ1ZvamTSynKXr2jh0XBVtXQl63BlXXUZTRzejKktY09TBuJoy3KG4UG+wyWvuIQilGxgQ7wzPFO2MeGe4kUiO8OsHNTHJbsvd6fHwd0NrF2uaOmnu6Ka5M057VwIzWLWpg7auBCPKi1mytoVYgdHjTltXgk3t3RQYNLXHKYwZ9RvbeXtdKyMrSmjtDGnNHTvwdHs/VZUWUhQrYH1rF9MmVFNgxj4jhtHZ3UNhLJSztChGYYFhGGXFMarKwl1jUYFRU15MdVkRHd0h4L62qolj9h9JgRkefT/Dy4vZ1NZNcWEBk0eWM6qyhOJYAT3uJNxp6YjT0hlndGUpZcVbLlTujmm0Ut5TE5PstsyMmAEYo6tKGV1VOuD76IlqNN0J31zzeW11M5WlhWxs7ebVVZsYPqyYWIFRGCvA3anf2E5teTFVpUUsXd/Kysb2zbWll1ZsYvrEGqrLiqgsKaQ70cMrK5uAMCJj3tKNDCuO0d4d+nfiCaetKwSpph0IVnc8s6xfx1lYYIyuLGF1U8fmkW6TRgxj6frQ5FIcK2BCbRmVJYXEe5yx1WVUlhZSWGAUFRawqa2bdza0UWBw+D61dMZD/1FRYQEtHXFeXdVE3d41m2tOxYUFjKwooaSwgL2qS2nuiFMcKyDe00PNsGK64j2UFBYQ73FaOuOMrCimZljx5sC1qrGDfUYMY2NbF+NqQlncobQoRlNHN93xHmrLizEzOroTlES1tR0JegqOfacAIXkp2UFeXGibm4SO2nfE5uXHThk5aGXp6E4Q73EKDFo648QTTnNHqOmsa+5kWHEha5s7cIfK0kKef6eR2vIiyooLaeuM09wRpzOeoKO7h6XrWxldWcryjW1UlhQyprqUNZs66Ez00NGV2FzT6oz30NDcSVeih+JYuLD3dPfw1roW4gmnO9FDd6IHMDq7EzR3xnl5ZROlhQXbDGKYv6wPr4zpp+JYAV2J0HcQKzAMiPc4w6LaUW15Md2JHoYVF7J8QxsHjKmkx52O7gTlJYXEE87ra5o5fJ/hjKkqoaeHzbW5R15azQenj2NkRQkNLZ2sberg8H2GYwYtHXHWNHVy8NgqNrZ1YQbjqstY3dRBSWEBVWVFlBQWUFhgrGjsoKIkxsFjq+iM91Bg0N6d4B9vrGNC7TCOmDScxqjWV1YUI9HjTKwtY9WmDmIFxpsNrUwaMYza8mIqSgopLYrR2hmnvTvBO+vb2H90BaOrSjffaFSVpumrGGBqYhKRrJLXCTOjOxEGJIysKGHFxnZGVhbT3pWgtCjG2+taQ9NfRTErNrZTVhyjwKArHoKOA8vWt1IUC01jHd0JGtu6WdvcwdvrWqksLaK0KMY+tcN4fU0zTe3dVJYWEisoIFYAT77WwEF7VVJcWED9xnbau0PQqyotoqE51JI6uhMUxgqoLiukpqyYN9Y2E084Kxrb2W9UOd0JpyhmxBNOa1cIABAGOVSVFdGVCMFzV2YGXzhxCle+94B+rq8mJhEZIKlNM0WxAsZEzX57jwgdpcOKw6Vk6vjqzfn2G1WRYWuj+l2Or77voH6vm0lPj28z5Lo9qiWVFhXQGe/ZPHCtK95De1eolWxo7aI70UOPh3xlRTHWt3bR0Z2guLCArngP7tAZ72FYcYwVje2UFsXo6E5QUVLIOxvacIeaYUW0dMZpau+muqyIpo44i9c0YwZ7VZVRW160uR+upChGe1eCrngPMyZW9z6UAacAISJ5bZvncWCrjv3Soi3TJYUxKqOmnfKSbS+fIyoyj1BKDZ4Ax/S5pINP4/FERCQtBQgREUlLAUJERNJSgBARkbQUIEREJC0FCBERSUsBQkRE0lKAEBGRtHbrV22YWQPQv7eYhV+6WzeAxdkd6Jjzg445P+zMMe/j7lkfad+tA8TOMLN5O/Iukj2Jjjk/6Jjzw2Acs5qYREQkLQUIERFJK58DxC1DXYAhoGPODzrm/JDzY87bPggREdm+fK5BiIjIdihAiIhIWnkZIMzs/Wb2upktMbOrhro8A8XMJprZk2a2yMxeMbMvRum1Zva4mS2O/g6P0s3Mboq+h4VmVje0R9A/ZhYzsxfM7OFofrKZzY2O9/dmVhyll0TzS6Llk4ay3DvDzGrM7F4zey0630fvyefZzP6/6N/0y2Z2l5mV7onn2cx+ZWZrzezllLQ+n1czuyDKv9jMLuhvefIuQJhZDLgZOBU4BJhjZocMbakGTBz4srsfDBwFXB4d21XAE+4+BXgimofwHUyJPpcBPx38Ig+ILwKLUua/D/woOt6NwCVR+iXARnffH/hRlG939WPgUXc/CJhOOP498jyb2XjgCmCWu08FYsC57Jnn+Xbg/b3S+nRezawWuBY4EpgNXJsMKn3m7nn1AY4GHkuZvxq4eqjLlaNjfRB4L/A6MDZKGwu8Hk3/HJiTkn9zvt3lA0yI/tOcCDwMGOHp0sLe5xt4DDg6mi6M8tlQH0M/jrkKeLt32ffU8wyMB5YDtdF5exh43556noFJwMv9Pa/AHODnKelb5evLJ+9qEGz5x5ZUH6XtUaJq9UxgLjDG3VcBRH9HR9n2hO/iRuBrQE80PwJodPd4NJ96TJuPN1q+Kcq/u9kXaABui5rWfmlm5eyh59ndVwA/BN4BVhHO23z2/POc1NfzOmDnOx8DxLa/UA571FhfM6sA7gO+5O5N28uaJm23+S7M7HRgrbvPT01Ok9V3YNnupBCoA37q7jOBVrY0O6SzWx931DxyJjAZGAeUE5pXetvTznM2mY5zwI4/HwNEPTAxZX4CsHKIyjLgzKyIEBzudPc/RMlrzGxstHwssDZK392/i2OAD5rZUuBuQjPTjUCNmRVGeVKPafPxRsurgQ2DWeABUg/Uu/vcaP5eQsDYU8/zycDb7t7g7t3AH4B3seef56S+ntcBO9/5GCD+BUyJRkAUEzq7HhriMg0IMzPgVmCRu9+QsughIDmS4QJC30Qy/fxoNMRRwKZkVXZ34O5Xu/sEd59EOI9/cfdPAE8CZ0fZeh9v8ns4O8q/291ZuvtqYLmZHRglnQS8yh56nglNS0eZ2bDo33jyePfo85yir+f1MeAUMxse1b5OidL6bqg7ZIaoE+g04A3gTeDfhro8A3hcxxKqkguBBdHnNEL76xPA4uhvbZTfCCO63gReIowSGfLj6OexHw88HE3vCzwHLAH+ByiJ0kuj+SXR8n2Hutw7cbwzgHnRuX4AGL4nn2fgm8BrwMvAb4CSPfE8A3cR+lm6CTWBS/pzXoGLo+NfAlzU3/LoVRsiIpJWPjYxiYjIDlCAEBGRtBQgREQkLQUIERFJSwFCRETSUoAQScPMEma2IOUzYG/9NbNJqW/rFNlVFWbPIpKX2t19xlAXQmQoqQYh0gdmttTMvm9mz0Wf/aP0fczsiei9/E+Y2d5R+hgzu9/MXow+74o2FTOzX0S/cfAnMyuL8l9hZq9G27l7iA5TBFCAEMmkrFcT0zkpy5rcfTbwX4R3PxFN/9rdpwF3AjdF6TcBf3P36YT3Jb0SpU8Bbnb3Q4FG4CNR+lXAzGg7n8nVwYnsCD1JLZKGmbW4e0Wa9KXAie7+VvRixNXuPsLM1hHe2d8dpa9y95Fm1gBMcPfOlG1MAh738AMwmNnXgSJ3/46ZPQq0EF6f8YC7t+T4UEUyUg1CpO88w3SmPOl0pkwn2NIf+AHC+3UOB+anvK1UZNApQIj03Tkpf5+Jpp8mvFEW4BPAU9H0E8BnYfNvZ1dl2qiZFQAT3f1Jwo8g1QDb1GJEBovuTkTSKzOzBSnzj7p7cqhriZnNJdxgzYnSrgB+ZWZfJfza20VR+heBW8zsEkJN4bOEt3WmEwN+a2bVhDd1/sjdGwfsiET6SH0QIn0Q9UHMcvd1Q10WkVxTE5OIiKSlGoSIiKSlGoSIiKSlACEiImkpQIiISFoKECIikpYChIiIpPX/AJj04NLFM7PEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training and validation accuracy\n",
    "plt.plot(history.history['mean_squared_error'])\n",
    "plt.plot(history.history['val_mean_squared_error'])\n",
    "plt.title('Model MSE vs. Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Training', 'Validation'], loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "0.22432744545591743\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "scores = quant_ann.predict(X_train)\n",
    "accuracy = r2_score(y_train, scores)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldies = pd.read_csv(\"data/oldies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Track ID</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Duration_ms</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Key</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time Signature</th>\n",
       "      <th>Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elton John</td>\n",
       "      <td>Rocket Man (I Think It's Going To Be A Long, L...</td>\n",
       "      <td>3gdewACMIVMEWVbyb8O9sY</td>\n",
       "      <td>83</td>\n",
       "      <td>0.43200</td>\n",
       "      <td>0.601</td>\n",
       "      <td>281613</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0925</td>\n",
       "      <td>-9.119</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>136.571</td>\n",
       "      <td>4</td>\n",
       "      <td>0.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stevie Wonder</td>\n",
       "      <td>Isn't She Lovely</td>\n",
       "      <td>3vqlZUIT3rEmLaYKDBfb4Q</td>\n",
       "      <td>18</td>\n",
       "      <td>0.18000</td>\n",
       "      <td>0.485</td>\n",
       "      <td>394267</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3280</td>\n",
       "      <td>-6.887</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0953</td>\n",
       "      <td>118.643</td>\n",
       "      <td>4</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Doobie Brothers</td>\n",
       "      <td>Listen to the Music</td>\n",
       "      <td>7Ar4G7Ci11gpt6sfH9Cgz5</td>\n",
       "      <td>76</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.645</td>\n",
       "      <td>227267</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>-13.180</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>105.929</td>\n",
       "      <td>4</td>\n",
       "      <td>0.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Van Morrison</td>\n",
       "      <td>Moondance - 2013 Remaster</td>\n",
       "      <td>683b4ikwa62JevCjwrmfg6</td>\n",
       "      <td>69</td>\n",
       "      <td>0.50100</td>\n",
       "      <td>0.606</td>\n",
       "      <td>274040</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>-12.207</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>67.409</td>\n",
       "      <td>4</td>\n",
       "      <td>0.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Bellamy Brothers</td>\n",
       "      <td>Let Your Love Flow</td>\n",
       "      <td>064SVQsmWl5EF0zahmzkQk</td>\n",
       "      <td>69</td>\n",
       "      <td>0.06110</td>\n",
       "      <td>0.679</td>\n",
       "      <td>198760</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>-14.687</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>109.071</td>\n",
       "      <td>4</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Elton John</td>\n",
       "      <td>Don't Go Breaking My Heart</td>\n",
       "      <td>7HW5WIw7ZgZORCzUxv5gW5</td>\n",
       "      <td>77</td>\n",
       "      <td>0.14900</td>\n",
       "      <td>0.729</td>\n",
       "      <td>275440</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>-8.824</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>131.459</td>\n",
       "      <td>4</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Carly Simon</td>\n",
       "      <td>You're so Vain</td>\n",
       "      <td>2DnJjbjNTV9Nd5NOa1KGba</td>\n",
       "      <td>76</td>\n",
       "      <td>0.15700</td>\n",
       "      <td>0.659</td>\n",
       "      <td>258411</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>-8.180</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>106.186</td>\n",
       "      <td>4</td>\n",
       "      <td>0.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Commodores</td>\n",
       "      <td>Easy</td>\n",
       "      <td>1JQ6Xm1JrvHfvAqhl5pwaA</td>\n",
       "      <td>77</td>\n",
       "      <td>0.11200</td>\n",
       "      <td>0.589</td>\n",
       "      <td>256427</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>-15.075</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>132.909</td>\n",
       "      <td>4</td>\n",
       "      <td>0.354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Don McLean</td>\n",
       "      <td>American Pie</td>\n",
       "      <td>1fDsrQ23eTAVFElUMaf38X</td>\n",
       "      <td>75</td>\n",
       "      <td>0.69900</td>\n",
       "      <td>0.531</td>\n",
       "      <td>516893</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>-11.709</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>138.450</td>\n",
       "      <td>4</td>\n",
       "      <td>0.491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Electric Light Orchestra</td>\n",
       "      <td>Livin' Thing</td>\n",
       "      <td>2hdNya0b6Cc2YJ8IyaQIWp</td>\n",
       "      <td>71</td>\n",
       "      <td>0.58300</td>\n",
       "      <td>0.549</td>\n",
       "      <td>212307</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>-7.097</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>122.818</td>\n",
       "      <td>4</td>\n",
       "      <td>0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Elton John</td>\n",
       "      <td>Your Song</td>\n",
       "      <td>38zsOOcu31XbbYj9BIPUF1</td>\n",
       "      <td>78</td>\n",
       "      <td>0.82800</td>\n",
       "      <td>0.554</td>\n",
       "      <td>241787</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>-11.028</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>128.157</td>\n",
       "      <td>4</td>\n",
       "      <td>0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Eagles</td>\n",
       "      <td>Take It Easy - 2013 Remaster</td>\n",
       "      <td>4yugZvBYaoREkJKtbG08Qr</td>\n",
       "      <td>76</td>\n",
       "      <td>0.34300</td>\n",
       "      <td>0.575</td>\n",
       "      <td>211578</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1290</td>\n",
       "      <td>-10.390</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>139.191</td>\n",
       "      <td>4</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Yusuf / Cat Stevens</td>\n",
       "      <td>Wild World</td>\n",
       "      <td>6Xz7FeyE8HTP90HecgHV57</td>\n",
       "      <td>78</td>\n",
       "      <td>0.37600</td>\n",
       "      <td>0.484</td>\n",
       "      <td>200173</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>-9.308</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>151.867</td>\n",
       "      <td>4</td>\n",
       "      <td>0.554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bread</td>\n",
       "      <td>Everything I Own</td>\n",
       "      <td>52VIdyKqp1pJRSyUQaxKUA</td>\n",
       "      <td>70</td>\n",
       "      <td>0.73500</td>\n",
       "      <td>0.365</td>\n",
       "      <td>187000</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>-13.406</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>79.241</td>\n",
       "      <td>4</td>\n",
       "      <td>0.446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Frankie Valli &amp; The Four Seasons</td>\n",
       "      <td>December, 1963 (Oh, What a Night)</td>\n",
       "      <td>4nuPrKithHbRJXuA9spwu4</td>\n",
       "      <td>43</td>\n",
       "      <td>0.06630</td>\n",
       "      <td>0.729</td>\n",
       "      <td>201093</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>-9.527</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>104.414</td>\n",
       "      <td>4</td>\n",
       "      <td>0.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Elton John</td>\n",
       "      <td>Tiny Dancer</td>\n",
       "      <td>2TVxnKdb3tqe1nhQWwwZCO</td>\n",
       "      <td>80</td>\n",
       "      <td>0.38200</td>\n",
       "      <td>0.414</td>\n",
       "      <td>377093</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1480</td>\n",
       "      <td>-11.097</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>145.075</td>\n",
       "      <td>4</td>\n",
       "      <td>0.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stevie Wonder</td>\n",
       "      <td>You Are The Sunshine Of My Life</td>\n",
       "      <td>0n2pjCIMKwHSXoYfEbYMfX</td>\n",
       "      <td>71</td>\n",
       "      <td>0.82300</td>\n",
       "      <td>0.519</td>\n",
       "      <td>178200</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>11</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>-14.530</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0688</td>\n",
       "      <td>132.082</td>\n",
       "      <td>4</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>John Denver</td>\n",
       "      <td>Annie's Song</td>\n",
       "      <td>5qxFudz7A6PGptviHsz4Yd</td>\n",
       "      <td>21</td>\n",
       "      <td>0.92000</td>\n",
       "      <td>0.325</td>\n",
       "      <td>178267</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.006030</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4410</td>\n",
       "      <td>-11.503</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0297</td>\n",
       "      <td>147.117</td>\n",
       "      <td>3</td>\n",
       "      <td>0.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Simon &amp; Garfunkel</td>\n",
       "      <td>Cecilia</td>\n",
       "      <td>6QhXQOpyYvbpdbyjgAqKdY</td>\n",
       "      <td>74</td>\n",
       "      <td>0.35700</td>\n",
       "      <td>0.755</td>\n",
       "      <td>174827</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>-8.867</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>102.762</td>\n",
       "      <td>4</td>\n",
       "      <td>0.954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Fleetwood Mac</td>\n",
       "      <td>Dreams - 2004 Remaster</td>\n",
       "      <td>0ofHAoxe9vBkTCp2UQIavz</td>\n",
       "      <td>80</td>\n",
       "      <td>0.06440</td>\n",
       "      <td>0.828</td>\n",
       "      <td>257800</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.004280</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>-9.744</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>120.151</td>\n",
       "      <td>4</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Elton John</td>\n",
       "      <td>Goodbye Yellow Brick Road - Remastered 2014</td>\n",
       "      <td>6Rvlwah55rEmg1ufhBz022</td>\n",
       "      <td>69</td>\n",
       "      <td>0.44600</td>\n",
       "      <td>0.559</td>\n",
       "      <td>192827</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1540</td>\n",
       "      <td>-7.712</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>121.227</td>\n",
       "      <td>4</td>\n",
       "      <td>0.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Knowing Me, Knowing You</td>\n",
       "      <td>46ou4l4zvrZMada0TgoVH9</td>\n",
       "      <td>54</td>\n",
       "      <td>0.04260</td>\n",
       "      <td>0.550</td>\n",
       "      <td>243893</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>-7.109</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>107.327</td>\n",
       "      <td>4</td>\n",
       "      <td>0.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>The Doobie Brothers</td>\n",
       "      <td>What a Fool Believes</td>\n",
       "      <td>2yBVeksU2EtrPJbTu4ZslK</td>\n",
       "      <td>70</td>\n",
       "      <td>0.28400</td>\n",
       "      <td>0.758</td>\n",
       "      <td>223867</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>-15.308</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>120.736</td>\n",
       "      <td>4</td>\n",
       "      <td>0.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Paul Simon</td>\n",
       "      <td>50 Ways to Leave Your Lover</td>\n",
       "      <td>6Qb7gtV6Q4MnUjSbkFcopl</td>\n",
       "      <td>70</td>\n",
       "      <td>0.16600</td>\n",
       "      <td>0.815</td>\n",
       "      <td>217347</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>-12.814</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0752</td>\n",
       "      <td>101.684</td>\n",
       "      <td>4</td>\n",
       "      <td>0.293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Paul McCartney</td>\n",
       "      <td>Band On The Run - Remastered 2010</td>\n",
       "      <td>1H4idkmruFoJBg1DvUv2tY</td>\n",
       "      <td>72</td>\n",
       "      <td>0.08320</td>\n",
       "      <td>0.479</td>\n",
       "      <td>313027</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>-8.806</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>124.966</td>\n",
       "      <td>4</td>\n",
       "      <td>0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Elton John</td>\n",
       "      <td>Bennie And The Jets - Remastered 2014</td>\n",
       "      <td>0dBatXn1vVUl0jLgXRClwD</td>\n",
       "      <td>72</td>\n",
       "      <td>0.25900</td>\n",
       "      <td>0.665</td>\n",
       "      <td>322549</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4970</td>\n",
       "      <td>-7.950</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0493</td>\n",
       "      <td>132.642</td>\n",
       "      <td>4</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Joni Mitchell</td>\n",
       "      <td>Big Yellow Taxi</td>\n",
       "      <td>6UkMcAA19lTdjs22jtB7o2</td>\n",
       "      <td>70</td>\n",
       "      <td>0.57900</td>\n",
       "      <td>0.611</td>\n",
       "      <td>134800</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5810</td>\n",
       "      <td>-9.135</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>85.527</td>\n",
       "      <td>4</td>\n",
       "      <td>0.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Johnny Nash</td>\n",
       "      <td>I Can See Clearly Now</td>\n",
       "      <td>0oCT5rVvMdPPUm0bxG7yzT</td>\n",
       "      <td>53</td>\n",
       "      <td>0.41000</td>\n",
       "      <td>0.683</td>\n",
       "      <td>162653</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>-8.542</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0601</td>\n",
       "      <td>124.392</td>\n",
       "      <td>4</td>\n",
       "      <td>0.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Stevie Wonder</td>\n",
       "      <td>Sir Duke</td>\n",
       "      <td>4RQgqR09VmHn345vRhKQ6T</td>\n",
       "      <td>23</td>\n",
       "      <td>0.16000</td>\n",
       "      <td>0.576</td>\n",
       "      <td>234093</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0777</td>\n",
       "      <td>-9.628</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>106.978</td>\n",
       "      <td>4</td>\n",
       "      <td>0.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>James Taylor</td>\n",
       "      <td>Fire and Rain</td>\n",
       "      <td>3LcYYV9ozePfgYYmXv0P3r</td>\n",
       "      <td>74</td>\n",
       "      <td>0.49900</td>\n",
       "      <td>0.611</td>\n",
       "      <td>200579</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0844</td>\n",
       "      <td>-14.480</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>76.064</td>\n",
       "      <td>4</td>\n",
       "      <td>0.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>INXS</td>\n",
       "      <td>Need You Tonight</td>\n",
       "      <td>1sR4aKaHpLrc9u7g4ii90U</td>\n",
       "      <td>62</td>\n",
       "      <td>0.04190</td>\n",
       "      <td>0.795</td>\n",
       "      <td>181107</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0894</td>\n",
       "      <td>-7.217</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0841</td>\n",
       "      <td>108.701</td>\n",
       "      <td>4</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>John Parr</td>\n",
       "      <td>St. Elmos Fire (Man in Motion)</td>\n",
       "      <td>1A2PWRltFrX8iB8IP3CUgo</td>\n",
       "      <td>69</td>\n",
       "      <td>0.15000</td>\n",
       "      <td>0.612</td>\n",
       "      <td>251800</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2220</td>\n",
       "      <td>-10.945</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0327</td>\n",
       "      <td>111.203</td>\n",
       "      <td>4</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Van Halen</td>\n",
       "      <td>Jump - 2015 Remaster</td>\n",
       "      <td>7N3PAbqfTjSEU1edb2tY8j</td>\n",
       "      <td>79</td>\n",
       "      <td>0.17100</td>\n",
       "      <td>0.572</td>\n",
       "      <td>241600</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0702</td>\n",
       "      <td>-6.219</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>129.994</td>\n",
       "      <td>4</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Spandau Ballet</td>\n",
       "      <td>Gold</td>\n",
       "      <td>2X9fsxb6O6bYEopJYmUbNC</td>\n",
       "      <td>67</td>\n",
       "      <td>0.26100</td>\n",
       "      <td>0.711</td>\n",
       "      <td>231480</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>-7.776</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>143.047</td>\n",
       "      <td>4</td>\n",
       "      <td>0.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>The Buggles</td>\n",
       "      <td>Video Killed The Radio Star</td>\n",
       "      <td>7o7E1nrHWncYY7PY94gCiX</td>\n",
       "      <td>71</td>\n",
       "      <td>0.10300</td>\n",
       "      <td>0.680</td>\n",
       "      <td>252773</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.008280</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>-11.548</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0754</td>\n",
       "      <td>131.165</td>\n",
       "      <td>4</td>\n",
       "      <td>0.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Joan Jett &amp; The Blackhearts</td>\n",
       "      <td>I Love Rock 'N Roll</td>\n",
       "      <td>2Cdvbe2G4hZsnhNMKyGrie</td>\n",
       "      <td>73</td>\n",
       "      <td>0.32600</td>\n",
       "      <td>0.535</td>\n",
       "      <td>175173</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6590</td>\n",
       "      <td>-5.025</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0431</td>\n",
       "      <td>94.379</td>\n",
       "      <td>4</td>\n",
       "      <td>0.901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Madonna</td>\n",
       "      <td>Material Girl</td>\n",
       "      <td>22sLuJYcvZOSoLLRYev1s5</td>\n",
       "      <td>74</td>\n",
       "      <td>0.33300</td>\n",
       "      <td>0.742</td>\n",
       "      <td>240280</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0964</td>\n",
       "      <td>-3.419</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>136.506</td>\n",
       "      <td>4</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Elton John</td>\n",
       "      <td>Nikita</td>\n",
       "      <td>5lBI9isMBEHRn5Wxde058W</td>\n",
       "      <td>24</td>\n",
       "      <td>0.12300</td>\n",
       "      <td>0.632</td>\n",
       "      <td>343240</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0735</td>\n",
       "      <td>-9.290</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>86.605</td>\n",
       "      <td>4</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Pet Shop Boys</td>\n",
       "      <td>Always on My Mind</td>\n",
       "      <td>07ABETRdek3ACMpRPvQuaT</td>\n",
       "      <td>71</td>\n",
       "      <td>0.01160</td>\n",
       "      <td>0.533</td>\n",
       "      <td>234907</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.056500</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>-10.610</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>124.874</td>\n",
       "      <td>4</td>\n",
       "      <td>0.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Bonnie Tyler</td>\n",
       "      <td>Total Eclipse of the Heart</td>\n",
       "      <td>5prTs2HAw2G4idHZyeFp8o</td>\n",
       "      <td>76</td>\n",
       "      <td>0.19500</td>\n",
       "      <td>0.435</td>\n",
       "      <td>269787</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>-8.179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0661</td>\n",
       "      <td>130.276</td>\n",
       "      <td>4</td>\n",
       "      <td>0.184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>UB40</td>\n",
       "      <td>I Got You Babe</td>\n",
       "      <td>07itbZUgkAmBi4CEH5NniJ</td>\n",
       "      <td>66</td>\n",
       "      <td>0.08060</td>\n",
       "      <td>0.756</td>\n",
       "      <td>189093</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>-13.002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0709</td>\n",
       "      <td>173.818</td>\n",
       "      <td>4</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Roxette</td>\n",
       "      <td>The Look</td>\n",
       "      <td>0ZfM5XfJTtFPhOxAERRnNY</td>\n",
       "      <td>71</td>\n",
       "      <td>0.05310</td>\n",
       "      <td>0.634</td>\n",
       "      <td>237320</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0522</td>\n",
       "      <td>-5.363</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0413</td>\n",
       "      <td>95.011</td>\n",
       "      <td>4</td>\n",
       "      <td>0.541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Daryl Hall &amp; John Oates</td>\n",
       "      <td>Maneater - Radio Edit</td>\n",
       "      <td>028r3igL3M00VdRCe2Ga7Q</td>\n",
       "      <td>55</td>\n",
       "      <td>0.01530</td>\n",
       "      <td>0.728</td>\n",
       "      <td>270947</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>11</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>-11.114</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>88.708</td>\n",
       "      <td>4</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Soft Cell</td>\n",
       "      <td>Tainted Love</td>\n",
       "      <td>0cGG2EouYCEEC3xfa0tDFV</td>\n",
       "      <td>75</td>\n",
       "      <td>0.46200</td>\n",
       "      <td>0.500</td>\n",
       "      <td>153800</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>-8.284</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>144.438</td>\n",
       "      <td>4</td>\n",
       "      <td>0.623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Alannah Myles</td>\n",
       "      <td>Black Velvet</td>\n",
       "      <td>1KU5EHSz04JhGg3rReGJ0N</td>\n",
       "      <td>72</td>\n",
       "      <td>0.27300</td>\n",
       "      <td>0.754</td>\n",
       "      <td>287440</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>-10.070</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>91.147</td>\n",
       "      <td>4</td>\n",
       "      <td>0.469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>George Michael</td>\n",
       "      <td>I Knew You Were Waiting (For Me)</td>\n",
       "      <td>58lTbZKr7XkkR4zEpoLhYH</td>\n",
       "      <td>61</td>\n",
       "      <td>0.27400</td>\n",
       "      <td>0.727</td>\n",
       "      <td>241920</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>-11.297</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>107.775</td>\n",
       "      <td>4</td>\n",
       "      <td>0.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Laura Branigan</td>\n",
       "      <td>Gloria</td>\n",
       "      <td>15ob9SMGLWrexuPuyuMjKl</td>\n",
       "      <td>68</td>\n",
       "      <td>0.13500</td>\n",
       "      <td>0.775</td>\n",
       "      <td>295067</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>-3.598</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>131.340</td>\n",
       "      <td>4</td>\n",
       "      <td>0.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Bruce Springsteen</td>\n",
       "      <td>Born In The U.S.A.</td>\n",
       "      <td>310epXrlbXmfGcD1qSdgVV</td>\n",
       "      <td>21</td>\n",
       "      <td>0.00201</td>\n",
       "      <td>0.397</td>\n",
       "      <td>278827</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>-12.156</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0569</td>\n",
       "      <td>121.856</td>\n",
       "      <td>4</td>\n",
       "      <td>0.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Guns N' Roses</td>\n",
       "      <td>Sweet Child O' Mine</td>\n",
       "      <td>7o2CTH4ctstm8TNelqjb51</td>\n",
       "      <td>83</td>\n",
       "      <td>0.08520</td>\n",
       "      <td>0.454</td>\n",
       "      <td>354520</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.098800</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1160</td>\n",
       "      <td>-7.766</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0446</td>\n",
       "      <td>125.116</td>\n",
       "      <td>4</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>The Cars</td>\n",
       "      <td>Drive</td>\n",
       "      <td>2lFFiNm0XtgJ6wkdncTB4k</td>\n",
       "      <td>69</td>\n",
       "      <td>0.11500</td>\n",
       "      <td>0.261</td>\n",
       "      <td>234332</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>-7.871</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0414</td>\n",
       "      <td>83.495</td>\n",
       "      <td>4</td>\n",
       "      <td>0.405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>The B-52's</td>\n",
       "      <td>Love Shack</td>\n",
       "      <td>4W4wYHtsrgDiivRASVOINL</td>\n",
       "      <td>70</td>\n",
       "      <td>0.03250</td>\n",
       "      <td>0.715</td>\n",
       "      <td>321573</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8510</td>\n",
       "      <td>-6.227</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0532</td>\n",
       "      <td>133.858</td>\n",
       "      <td>4</td>\n",
       "      <td>0.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>INXS</td>\n",
       "      <td>New Sensation</td>\n",
       "      <td>2xcrseImDFEf8Urommws03</td>\n",
       "      <td>65</td>\n",
       "      <td>0.00712</td>\n",
       "      <td>0.682</td>\n",
       "      <td>220160</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0520</td>\n",
       "      <td>-4.951</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>115.473</td>\n",
       "      <td>4</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Nena</td>\n",
       "      <td>99 Red Balloons</td>\n",
       "      <td>5mYtpXrZZ1bbGJYDGC8I0Y</td>\n",
       "      <td>19</td>\n",
       "      <td>0.08530</td>\n",
       "      <td>0.543</td>\n",
       "      <td>284773</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>-12.789</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>193.513</td>\n",
       "      <td>4</td>\n",
       "      <td>0.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Billy Idol</td>\n",
       "      <td>Dancing With Myself</td>\n",
       "      <td>1BY1Vd2Bt6JPOhMvsIwtVv</td>\n",
       "      <td>70</td>\n",
       "      <td>0.01570</td>\n",
       "      <td>0.510</td>\n",
       "      <td>359733</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2970</td>\n",
       "      <td>-10.830</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>176.567</td>\n",
       "      <td>4</td>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Billy Ocean</td>\n",
       "      <td>Get Outta My Dreams, Get Into My Car</td>\n",
       "      <td>2D4D3hiOf5U0W6SvJoCQph</td>\n",
       "      <td>60</td>\n",
       "      <td>0.08790</td>\n",
       "      <td>0.666</td>\n",
       "      <td>284373</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3350</td>\n",
       "      <td>-6.457</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0399</td>\n",
       "      <td>117.141</td>\n",
       "      <td>4</td>\n",
       "      <td>0.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Heart</td>\n",
       "      <td>Alone</td>\n",
       "      <td>54b8qPFqYqIndfdxiLApea</td>\n",
       "      <td>74</td>\n",
       "      <td>0.63800</td>\n",
       "      <td>0.418</td>\n",
       "      <td>218733</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0959</td>\n",
       "      <td>-13.099</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>175.088</td>\n",
       "      <td>4</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Yazoo</td>\n",
       "      <td>Only You</td>\n",
       "      <td>15Mh8m2BGTUptR8yy7fNAS</td>\n",
       "      <td>67</td>\n",
       "      <td>0.33200</td>\n",
       "      <td>0.752</td>\n",
       "      <td>194173</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>-17.063</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>106.158</td>\n",
       "      <td>4</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Tina Turner</td>\n",
       "      <td>What's Love Got to Do with It</td>\n",
       "      <td>4kOfxxnW1ukZdsNbCKY9br</td>\n",
       "      <td>70</td>\n",
       "      <td>0.21900</td>\n",
       "      <td>0.851</td>\n",
       "      <td>226880</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0853</td>\n",
       "      <td>-11.631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0661</td>\n",
       "      <td>97.840</td>\n",
       "      <td>4</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>The Bangles</td>\n",
       "      <td>Eternal Flame</td>\n",
       "      <td>5MoDQWMDMaAGDEiWsJfeCi</td>\n",
       "      <td>71</td>\n",
       "      <td>0.52500</td>\n",
       "      <td>0.526</td>\n",
       "      <td>238027</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0942</td>\n",
       "      <td>-7.239</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>78.988</td>\n",
       "      <td>3</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Depeche Mode</td>\n",
       "      <td>Just Can't Get Enough</td>\n",
       "      <td>0qi4b1l0eT3jpzeNHeFXDT</td>\n",
       "      <td>72</td>\n",
       "      <td>0.40300</td>\n",
       "      <td>0.766</td>\n",
       "      <td>220893</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1830</td>\n",
       "      <td>-9.362</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>128.166</td>\n",
       "      <td>4</td>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Artist                                         Track Name                Track ID  Popularity  Acousticness  Danceability  Duration_ms  Energy  Instrumentalness  Key  Liveness  Loudness  Mode  Speechiness    Tempo  Time Signature  Valence\n",
       "0                          Elton John  Rocket Man (I Think It's Going To Be A Long, L...  3gdewACMIVMEWVbyb8O9sY          83       0.43200         0.601       281613   0.532          0.000006   10    0.0925    -9.119     1       0.0286  136.571               4    0.341\n",
       "1                       Stevie Wonder                                   Isn't She Lovely  3vqlZUIT3rEmLaYKDBfb4Q          18       0.18000         0.485       394267   0.820          0.004110    1    0.3280    -6.887     0       0.0953  118.643               4    0.817\n",
       "2                 The Doobie Brothers                                Listen to the Music  7Ar4G7Ci11gpt6sfH9Cgz5          76       0.22100         0.645       227267   0.598          0.000004    1    0.0721   -13.180     0       0.0335  105.929               4    0.913\n",
       "3                        Van Morrison                          Moondance - 2013 Remaster  683b4ikwa62JevCjwrmfg6          69       0.50100         0.606       274040   0.282          0.000008    9    0.1520   -12.207     0       0.0339   67.409               4    0.563\n",
       "4                The Bellamy Brothers                                 Let Your Love Flow  064SVQsmWl5EF0zahmzkQk          69       0.06110         0.679       198760   0.553          0.000007    3    0.1390   -14.687     1       0.0316  109.071               4    0.946\n",
       "5                          Elton John                         Don't Go Breaking My Heart  7HW5WIw7ZgZORCzUxv5gW5          77       0.14900         0.729       275440   0.844          0.000003    5    0.0604    -8.824     1       0.0344  131.459               4    0.777\n",
       "6                         Carly Simon                                     You're so Vain  2DnJjbjNTV9Nd5NOa1KGba          76       0.15700         0.659       258411   0.678          0.000007    0    0.0784    -8.180     1       0.0313  106.186               4    0.647\n",
       "7                          Commodores                                               Easy  1JQ6Xm1JrvHfvAqhl5pwaA          77       0.11200         0.589       256427   0.384          0.000028   10    0.0596   -15.075     0       0.0332  132.909               4    0.354\n",
       "8                          Don McLean                                       American Pie  1fDsrQ23eTAVFElUMaf38X          75       0.69900         0.531       516893   0.481          0.000000    4    0.0842   -11.709     0       0.0600  138.450               4    0.491\n",
       "9            Electric Light Orchestra                                       Livin' Thing  2hdNya0b6Cc2YJ8IyaQIWp          71       0.58300         0.549       212307   0.651          0.000000    0    0.1210    -7.097     1       0.0323  122.818               4    0.368\n",
       "10                         Elton John                                          Your Song  38zsOOcu31XbbYj9BIPUF1          78       0.82800         0.554       241787   0.315          0.000006    3    0.1010   -11.028     1       0.0298  128.157               4    0.325\n",
       "11                             Eagles                       Take It Easy - 2013 Remaster  4yugZvBYaoREkJKtbG08Qr          76       0.34300         0.575       211578   0.670          0.000005    7    0.1290   -10.390     1       0.0318  139.191               4    0.740\n",
       "12                Yusuf / Cat Stevens                                         Wild World  6Xz7FeyE8HTP90HecgHV57          78       0.37600         0.484       200173   0.508          0.000791    0    0.0961    -9.308     1       0.0364  151.867               4    0.554\n",
       "13                              Bread                                   Everything I Own  52VIdyKqp1pJRSyUQaxKUA          70       0.73500         0.365       187000   0.338          0.000000    2    0.1040   -13.406     1       0.0322   79.241               4    0.446\n",
       "14   Frankie Valli & The Four Seasons                  December, 1963 (Oh, What a Night)  4nuPrKithHbRJXuA9spwu4          43       0.06630         0.729       201093   0.600          0.000008    1    0.0382    -9.527     1       0.0255  104.414               4    0.964\n",
       "15                         Elton John                                        Tiny Dancer  2TVxnKdb3tqe1nhQWwwZCO          80       0.38200         0.414       377093   0.428          0.000243    0    0.1480   -11.097     1       0.0278  145.075               4    0.282\n",
       "16                      Stevie Wonder                    You Are The Sunshine Of My Life  0n2pjCIMKwHSXoYfEbYMfX          71       0.82300         0.519       178200   0.460          0.000060   11    0.2430   -14.530     1       0.0688  132.082               4    0.675\n",
       "17                        John Denver                                       Annie's Song  5qxFudz7A6PGptviHsz4Yd          21       0.92000         0.325       178267   0.308          0.006030    2    0.4410   -11.503     1       0.0297  147.117               3    0.447\n",
       "18                  Simon & Garfunkel                                            Cecilia  6QhXQOpyYvbpdbyjgAqKdY          74       0.35700         0.755       174827   0.876          0.000005    0    0.2200    -8.867     1       0.0362  102.762               4    0.954\n",
       "19                      Fleetwood Mac                             Dreams - 2004 Remaster  0ofHAoxe9vBkTCp2UQIavz          80       0.06440         0.828       257800   0.492          0.004280    0    0.1280    -9.744     1       0.0276  120.151               4    0.789\n",
       "20                         Elton John        Goodbye Yellow Brick Road - Remastered 2014  6Rvlwah55rEmg1ufhBz022          69       0.44600         0.559       192827   0.473          0.001410    5    0.1540    -7.712     1       0.0279  121.227               4    0.397\n",
       "21                               ABBA                            Knowing Me, Knowing You  46ou4l4zvrZMada0TgoVH9          54       0.04260         0.550       243893   0.741          0.000004    2    0.2350    -7.109     1       0.0299  107.327               4    0.903\n",
       "22                The Doobie Brothers                               What a Fool Believes  2yBVeksU2EtrPJbTu4ZslK          70       0.28400         0.758       223867   0.378          0.000000    8    0.0490   -15.308     0       0.0449  120.736               4    0.985\n",
       "23                         Paul Simon                        50 Ways to Leave Your Lover  6Qb7gtV6Q4MnUjSbkFcopl          70       0.16600         0.815       217347   0.372          0.000116    7    0.0767   -12.814     1       0.0752  101.684               4    0.293\n",
       "24                     Paul McCartney                  Band On The Run - Remastered 2010  1H4idkmruFoJBg1DvUv2tY          72       0.08320         0.479       313027   0.601          0.001420    7    0.1100    -8.806     1       0.0318  124.966               4    0.669\n",
       "25                         Elton John              Bennie And The Jets - Remastered 2014  0dBatXn1vVUl0jLgXRClwD          72       0.25900         0.665       322549   0.673          0.000008    0    0.4970    -7.950     1       0.0493  132.642               4    0.779\n",
       "26                      Joni Mitchell                                    Big Yellow Taxi  6UkMcAA19lTdjs22jtB7o2          70       0.57900         0.611       134800   0.470          0.000000    4    0.5810    -9.135     1       0.0356   85.527               4    0.970\n",
       "27                        Johnny Nash                              I Can See Clearly Now  0oCT5rVvMdPPUm0bxG7yzT          53       0.41000         0.683       162653   0.530          0.000074    2    0.0600    -8.542     1       0.0601  124.392               4    0.579\n",
       "28                      Stevie Wonder                                           Sir Duke  4RQgqR09VmHn345vRhKQ6T          23       0.16000         0.576       234093   0.579          0.000000    6    0.0777    -9.628     1       0.0769  106.978               4    0.947\n",
       "29                       James Taylor                                      Fire and Rain  3LcYYV9ozePfgYYmXv0P3r          74       0.49900         0.611       200579   0.350          0.000008    5    0.0844   -14.480     1       0.0356   76.064               4    0.360\n",
       "..                                ...                                                ...                     ...         ...           ...           ...          ...     ...               ...  ...       ...       ...   ...          ...      ...             ...      ...\n",
       "179                              INXS                                   Need You Tonight  1sR4aKaHpLrc9u7g4ii90U          62       0.04190         0.795       181107   0.630          0.575000   10    0.0894    -7.217     0       0.0841  108.701               4    0.785\n",
       "180                         John Parr                     St. Elmos Fire (Man in Motion)  1A2PWRltFrX8iB8IP3CUgo          69       0.15000         0.612       251800   0.600          0.000003    9    0.2220   -10.945     1       0.0327  111.203               4    0.471\n",
       "181                         Van Halen                               Jump - 2015 Remaster  7N3PAbqfTjSEU1edb2tY8j          79       0.17100         0.572       241600   0.835          0.000376    0    0.0702    -6.219     1       0.0317  129.994               4    0.796\n",
       "182                    Spandau Ballet                                               Gold  2X9fsxb6O6bYEopJYmUbNC          67       0.26100         0.711       231480   0.740          0.011400   10    0.1040    -7.776     0       0.0360  143.047               4    0.638\n",
       "183                       The Buggles                        Video Killed The Radio Star  7o7E1nrHWncYY7PY94gCiX          71       0.10300         0.680       252773   0.678          0.008280    1    0.2040   -11.548     1       0.0754  131.165               4    0.251\n",
       "184       Joan Jett & The Blackhearts                                I Love Rock 'N Roll  2Cdvbe2G4hZsnhNMKyGrie          73       0.32600         0.535       175173   0.716          0.000000    4    0.6590    -5.025     1       0.0431   94.379               4    0.901\n",
       "185                           Madonna                                      Material Girl  22sLuJYcvZOSoLLRYev1s5          74       0.33300         0.742       240280   0.883          0.000008    0    0.0964    -3.419     1       0.0329  136.506               4    0.978\n",
       "186                        Elton John                                             Nikita  5lBI9isMBEHRn5Wxde058W          24       0.12300         0.632       343240   0.656          0.000264    7    0.0735    -9.290     1       0.0277   86.605               4    0.752\n",
       "187                     Pet Shop Boys                                  Always on My Mind  07ABETRdek3ACMpRPvQuaT          71       0.01160         0.533       234907   0.783          0.056500    7    0.1860   -10.610     1       0.0366  124.874               4    0.726\n",
       "188                      Bonnie Tyler                         Total Eclipse of the Heart  5prTs2HAw2G4idHZyeFp8o          76       0.19500         0.435       269787   0.658          0.000000    8    0.1020    -8.179     1       0.0661  130.276               4    0.184\n",
       "189                              UB40                                     I Got You Babe  07itbZUgkAmBi4CEH5NniJ          66       0.08060         0.756       189093   0.610          0.000079    5    0.1140   -13.002     1       0.0709  173.818               4    0.863\n",
       "190                           Roxette                                           The Look  0ZfM5XfJTtFPhOxAERRnNY          71       0.05310         0.634       237320   0.838          0.000008    2    0.0522    -5.363     1       0.0413   95.011               4    0.541\n",
       "191           Daryl Hall & John Oates                              Maneater - Radio Edit  028r3igL3M00VdRCe2Ga7Q          55       0.01530         0.728       270947   0.518          0.000042   11    0.1030   -11.114     0       0.0380   88.708               4    0.833\n",
       "192                         Soft Cell                                       Tainted Love  0cGG2EouYCEEC3xfa0tDFV          75       0.46200         0.500       153800   0.501          0.000000    0    0.2600    -8.284     0       0.0376  144.438               4    0.623\n",
       "193                     Alannah Myles                                       Black Velvet  1KU5EHSz04JhGg3rReGJ0N          72       0.27300         0.754       287440   0.366          0.000090    8    0.1060   -10.070     1       0.0312   91.147               4    0.469\n",
       "194                    George Michael                   I Knew You Were Waiting (For Me)  58lTbZKr7XkkR4zEpoLhYH          61       0.27400         0.727       241920   0.680          0.000000    4    0.3100   -11.297     1       0.0445  107.775               4    0.683\n",
       "195                    Laura Branigan                                             Gloria  15ob9SMGLWrexuPuyuMjKl          68       0.13500         0.775       295067   0.866          0.037600    9    0.1520    -3.598     1       0.0295  131.340               4    0.876\n",
       "196                 Bruce Springsteen                                 Born In The U.S.A.  310epXrlbXmfGcD1qSdgVV          21       0.00201         0.397       278827   0.861          0.000025    4    0.3500   -12.156     1       0.0569  121.856               4    0.512\n",
       "197                     Guns N' Roses                                Sweet Child O' Mine  7o2CTH4ctstm8TNelqjb51          83       0.08520         0.454       354520   0.910          0.098800    6    0.1160    -7.766     1       0.0446  125.116               4    0.630\n",
       "198                          The Cars                                              Drive  2lFFiNm0XtgJ6wkdncTB4k          69       0.11500         0.261       234332   0.703          0.000780    6    0.1020    -7.871     1       0.0414   83.495               4    0.405\n",
       "199                        The B-52's                                         Love Shack  4W4wYHtsrgDiivRASVOINL          70       0.03250         0.715       321573   0.817          0.000002    5    0.8510    -6.227     0       0.0532  133.858               4    0.871\n",
       "200                              INXS                                      New Sensation  2xcrseImDFEf8Urommws03          65       0.00712         0.682       220160   0.954          0.000040    9    0.0520    -4.951     1       0.0625  115.473               4    0.928\n",
       "201                              Nena                                    99 Red Balloons  5mYtpXrZZ1bbGJYDGC8I0Y          19       0.08530         0.543       284773   0.482          0.000092    4    0.1110   -12.789     1       0.1940  193.513               4    0.415\n",
       "202                        Billy Idol                                Dancing With Myself  1BY1Vd2Bt6JPOhMvsIwtVv          70       0.01570         0.510       359733   0.696          0.000104    4    0.2970   -10.830     1       0.0802  176.567               4    0.905\n",
       "203                       Billy Ocean               Get Outta My Dreams, Get Into My Car  2D4D3hiOf5U0W6SvJoCQph          60       0.08790         0.666       284373   0.910          0.000008    4    0.3350    -6.457     1       0.0399  117.141               4    0.919\n",
       "204                             Heart                                              Alone  54b8qPFqYqIndfdxiLApea          74       0.63800         0.418       218733   0.452          0.000260    1    0.0959   -13.099     1       0.0356  175.088               4    0.168\n",
       "205                             Yazoo                                           Only You  15Mh8m2BGTUptR8yy7fNAS          67       0.33200         0.752       194173   0.307          0.000135    9    0.0829   -17.063     1       0.0398  106.158               4    0.854\n",
       "206                       Tina Turner                      What's Love Got to Do with It  4kOfxxnW1ukZdsNbCKY9br          70       0.21900         0.851       226880   0.406          0.000006    1    0.0853   -11.631     1       0.0661   97.840               4    0.792\n",
       "207                       The Bangles                                      Eternal Flame  5MoDQWMDMaAGDEiWsJfeCi          71       0.52500         0.526       238027   0.358          0.000000    4    0.0942    -7.239     0       0.0243   78.988               3    0.400\n",
       "208                      Depeche Mode                              Just Can't Get Enough  0qi4b1l0eT3jpzeNHeFXDT          72       0.40300         0.766       220893   0.772          0.058400    0    0.1830    -9.362     1       0.0353  128.166               4    0.920\n",
       "\n",
       "[209 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oldies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_reg = BaggingRegressor(n_estimators=10, random_state=0).fit(X_train_2, y_train_2)\n",
    "\n",
    "bag_reg_train_score = bag_reg.score(X_train_2, y_train_2)\n",
    "print('R^2 on training set:', bag_reg_train_score)\n",
    "\n",
    "bag_reg_test_score = bag_reg.score(X_test_2, y_test_2)\n",
    "print('R^2 on test set:', bag_reg_test_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
