{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(112358)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from random import randint \n",
    "\n",
    "from sklearn import tree\n",
    "%matplotlib inline\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "pd.set_option('display.width', 1500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Track ID</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Duration_ms</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Key</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time Signature</th>\n",
       "      <th>Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>Sunflower - Spider-Man: Into the Spider-Verse</td>\n",
       "      <td>3KkXRkHbMCARz0aVfEt68P</td>\n",
       "      <td>90</td>\n",
       "      <td>0.55600</td>\n",
       "      <td>0.760</td>\n",
       "      <td>158040</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0703</td>\n",
       "      <td>-5.574</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0466</td>\n",
       "      <td>89.911</td>\n",
       "      <td>4</td>\n",
       "      <td>0.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Lil Baby</td>\n",
       "      <td>Drip Too Hard (Lil Baby &amp; Gunna)</td>\n",
       "      <td>78QR3Wp35dqAhFEc2qAGjE</td>\n",
       "      <td>86</td>\n",
       "      <td>0.08520</td>\n",
       "      <td>0.897</td>\n",
       "      <td>145543</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5340</td>\n",
       "      <td>-6.903</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2920</td>\n",
       "      <td>112.511</td>\n",
       "      <td>4</td>\n",
       "      <td>0.389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Travis Scott</td>\n",
       "      <td>SICKO MODE</td>\n",
       "      <td>2xLMifQCjDGFmkHkpNLD9h</td>\n",
       "      <td>89</td>\n",
       "      <td>0.00513</td>\n",
       "      <td>0.834</td>\n",
       "      <td>312820</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>-3.714</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2220</td>\n",
       "      <td>155.008</td>\n",
       "      <td>4</td>\n",
       "      <td>0.446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Juice WRLD</td>\n",
       "      <td>Lucid Dreams</td>\n",
       "      <td>285pBltuF7vW8TeWk8hdRR</td>\n",
       "      <td>88</td>\n",
       "      <td>0.34900</td>\n",
       "      <td>0.511</td>\n",
       "      <td>239836</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>-7.230</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>83.903</td>\n",
       "      <td>4</td>\n",
       "      <td>0.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>YNW Melly</td>\n",
       "      <td>Murder On My Mind</td>\n",
       "      <td>7eBqSVxrzQZtK2mmgRG6lC</td>\n",
       "      <td>86</td>\n",
       "      <td>0.14500</td>\n",
       "      <td>0.759</td>\n",
       "      <td>268434</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>-7.985</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>115.007</td>\n",
       "      <td>4</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Artist                                     Track Name                Track ID  Popularity  Acousticness  Danceability  Duration_ms  Energy  Instrumentalness  Key  Liveness  Loudness  Mode  Speechiness    Tempo  Time Signature  Valence\n",
       "0           0   Post Malone  Sunflower - Spider-Man: Into the Spider-Verse  3KkXRkHbMCARz0aVfEt68P          90       0.55600         0.760       158040   0.479          0.000000    2    0.0703    -5.574     1       0.0466   89.911               4    0.913\n",
       "1           1      Lil Baby               Drip Too Hard (Lil Baby & Gunna)  78QR3Wp35dqAhFEc2qAGjE          86       0.08520         0.897       145543   0.662          0.000000    1    0.5340    -6.903     0       0.2920  112.511               4    0.389\n",
       "2           2  Travis Scott                                     SICKO MODE  2xLMifQCjDGFmkHkpNLD9h          89       0.00513         0.834       312820   0.730          0.000000    8    0.1240    -3.714     1       0.2220  155.008               4    0.446\n",
       "3           3    Juice WRLD                                   Lucid Dreams  285pBltuF7vW8TeWk8hdRR          88       0.34900         0.511       239836   0.566          0.000000    6    0.3400    -7.230     0       0.2000   83.903               4    0.218\n",
       "4           4     YNW Melly                              Murder On My Mind  7eBqSVxrzQZtK2mmgRG6lC          86       0.14500         0.759       268434   0.730          0.000003    0    0.1100    -7.985     0       0.0516  115.007               4    0.740"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in 2018 songs\n",
    "songs_df = pd.read_csv('data/songs_10000.csv')\n",
    "songs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Duration_ms</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Key</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time Signature</th>\n",
       "      <th>Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>58.874600</td>\n",
       "      <td>0.303989</td>\n",
       "      <td>0.634328</td>\n",
       "      <td>200119.502900</td>\n",
       "      <td>0.573902</td>\n",
       "      <td>0.120668</td>\n",
       "      <td>5.307600</td>\n",
       "      <td>0.176829</td>\n",
       "      <td>-8.25150</td>\n",
       "      <td>0.612700</td>\n",
       "      <td>0.120497</td>\n",
       "      <td>119.849287</td>\n",
       "      <td>3.907800</td>\n",
       "      <td>0.440162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.808775</td>\n",
       "      <td>0.307698</td>\n",
       "      <td>0.172954</td>\n",
       "      <td>58370.598685</td>\n",
       "      <td>0.223470</td>\n",
       "      <td>0.287823</td>\n",
       "      <td>3.614732</td>\n",
       "      <td>0.136660</td>\n",
       "      <td>5.49679</td>\n",
       "      <td>0.487158</td>\n",
       "      <td>0.119886</td>\n",
       "      <td>30.873220</td>\n",
       "      <td>0.433495</td>\n",
       "      <td>0.234605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31200.000000</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>-44.56900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>0.041775</td>\n",
       "      <td>0.529000</td>\n",
       "      <td>169272.000000</td>\n",
       "      <td>0.438000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.099000</td>\n",
       "      <td>-9.35150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040300</td>\n",
       "      <td>94.973750</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.253000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.183000</td>\n",
       "      <td>0.657000</td>\n",
       "      <td>198643.000000</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>-6.79250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>119.986000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.424500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.761000</td>\n",
       "      <td>228000.000000</td>\n",
       "      <td>0.739000</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.205000</td>\n",
       "      <td>-5.10200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161000</td>\n",
       "      <td>141.987000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.611250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>688742.000000</td>\n",
       "      <td>0.998000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.979000</td>\n",
       "      <td>0.17500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966000</td>\n",
       "      <td>220.099000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.981000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Popularity  Acousticness  Danceability    Duration_ms        Energy  Instrumentalness           Key      Liveness     Loudness          Mode   Speechiness         Tempo  Time Signature       Valence\n",
       "count  10000.000000  10000.000000  10000.000000   10000.000000  10000.000000      10000.000000  10000.000000  10000.000000  10000.00000  10000.000000  10000.000000  10000.000000    10000.000000  10000.000000\n",
       "mean      58.874600      0.303989      0.634328  200119.502900      0.573902          0.120668      5.307600      0.176829     -8.25150      0.612700      0.120497    119.849287        3.907800      0.440162\n",
       "std        7.808775      0.307698      0.172954   58370.598685      0.223470          0.287823      3.614732      0.136660      5.49679      0.487158      0.119886     30.873220        0.433495      0.234605\n",
       "min       46.000000      0.000002      0.000000   31200.000000      0.000020          0.000000      0.000000      0.019600    -44.56900      0.000000      0.000000      0.000000        0.000000      0.000000\n",
       "25%       53.000000      0.041775      0.529000  169272.000000      0.438000          0.000000      2.000000      0.099000     -9.35150      0.000000      0.040300     94.973750        4.000000      0.253000\n",
       "50%       57.000000      0.183000      0.657000  198643.000000      0.593000          0.000002      5.000000      0.120000     -6.79250      1.000000      0.064200    119.986000        4.000000      0.424500\n",
       "75%       63.000000      0.512000      0.761000  228000.000000      0.739000          0.002010      8.000000      0.205000     -5.10200      1.000000      0.161000    141.987000        4.000000      0.611250\n",
       "max       90.000000      0.996000      0.985000  688742.000000      0.998000          1.000000     11.000000      0.979000      0.17500      1.000000      0.966000    220.099000        5.000000      0.981000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist               object\n",
      "Track Name           object\n",
      "Track ID             object\n",
      "Popularity            int64\n",
      "Acousticness        float64\n",
      "Danceability        float64\n",
      "Duration_ms           int64\n",
      "Energy              float64\n",
      "Instrumentalness    float64\n",
      "Key                   int64\n",
      "Liveness            float64\n",
      "Loudness            float64\n",
      "Mode                  int64\n",
      "Speechiness         float64\n",
      "Tempo               float64\n",
      "Time Signature        int64\n",
      "Valence             float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# drop additional index column\n",
    "songs_df = songs_df.drop(columns = 'Unnamed: 0')\n",
    "\n",
    "# calculate summary statistics\n",
    "display(songs_df.describe())\n",
    "\n",
    "# print out variable types\n",
    "print(songs_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix of pairwise scatterplots\n",
    "scatter_matrix(songs_df, alpha = 0.8, figsize = (30, 20), diagonal = 'kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new binary response variable 'tophit'\n",
    "# classify as top hit if popularity > 60 (about halfway split)\n",
    "songs_df['tophit'] = np.where(songs_df['Popularity'] > 60, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for modeling\n",
    "songs_df_clean = songs_df.drop(columns = ['Artist', 'Track Name', 'Track ID', 'Popularity'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(songs_df_clean.loc[:, songs_df_clean.columns != 'tophit'], \n",
    "                                                    songs_df_clean.tophit, test_size = 0.2, \n",
    "                                                    random_state = 100, stratify = songs_df_clean.tophit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit cross-validated single decision tree\n",
    "depths = list(range(1, 21))\n",
    "\n",
    "def calc_meanstd(X_train, y_train, depths):\n",
    "    cvmeans = {}\n",
    "    cvstds = {}\n",
    "    train_scores = {}\n",
    "    for i in depths:\n",
    "        model = DecisionTreeClassifier(max_depth = i)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_train)\n",
    "        # get training set scores\n",
    "        train_scores[i] = accuracy_score(y_train, y_pred)\n",
    "        # get cross-validation scores\n",
    "        score = cross_val_score(estimator = model, X = X_train, y = y_train, cv = 5, n_jobs = -1)\n",
    "        cvmeans[i] = score.mean()\n",
    "        cvstds[i] = score.std()\n",
    "    return cvmeans, cvstds, train_scores\n",
    "\n",
    "cvmeans, cvstds, train_scores = calc_meanstd(X_train, y_train, depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best depth: 3\n",
      "Classification accuracy on training set: 0.645\n",
      "Classification accuracy on test set: 0.6395\n"
     ]
    }
   ],
   "source": [
    "# report best tree depth from cross-validation\n",
    "best_depth = sorted(cvmeans, key = cvmeans.get, reverse = True)[0]\n",
    "print('Best depth:', best_depth)\n",
    "\n",
    "# refit on best tree depth, then report classification accuracies\n",
    "best_model = DecisionTreeClassifier(max_depth = best_depth)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "best_cv_tree_train_score = accuracy_score(y_train, y_train_pred)\n",
    "print('Classification accuracy on training set:', best_cv_tree_train_score)\n",
    "\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "best_cv_tree_test_score = accuracy_score(y_test, y_test_pred)\n",
    "print('Classification accuracy on test set:', best_cv_tree_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "cat_cols = ['Key', 'Time Signature']\n",
    "X_train_num = X_train.drop(cat_cols, axis = 1)\n",
    "X_test_num = X_test.drop(cat_cols, axis = 1)\n",
    "num_features = X_train_num.columns.tolist()\n",
    "num_index_train = X_train.index.tolist()\n",
    "num_index_test = X_test.index.tolist()\n",
    "\n",
    "X_train_dum = pd.get_dummies(X_train[cat_cols], columns = cat_cols)\n",
    "X_test_dum = pd.get_dummies(X_test[cat_cols], columns = cat_cols)\n",
    "\n",
    "scaler = MinMaxScaler().fit(X_train_num)\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(X_train_num), index = num_index_train, columns = num_features)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test_num), index = num_index_test, columns = num_features)\n",
    "\n",
    "X_train = pd.concat([X_train_dum, X_train_scaled], axis = 1)\n",
    "X_test = pd.concat([X_test_dum, X_test_scaled], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key_0</th>\n",
       "      <th>Key_1</th>\n",
       "      <th>Key_2</th>\n",
       "      <th>Key_3</th>\n",
       "      <th>Key_4</th>\n",
       "      <th>Key_5</th>\n",
       "      <th>Key_6</th>\n",
       "      <th>Key_7</th>\n",
       "      <th>Key_8</th>\n",
       "      <th>Key_9</th>\n",
       "      <th>Key_10</th>\n",
       "      <th>Key_11</th>\n",
       "      <th>Time Signature_0</th>\n",
       "      <th>Time Signature_1</th>\n",
       "      <th>Time Signature_3</th>\n",
       "      <th>Time Signature_4</th>\n",
       "      <th>Time Signature_5</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Duration_ms</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5760</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.299492</td>\n",
       "      <td>0.256368</td>\n",
       "      <td>0.716427</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.231333</td>\n",
       "      <td>0.850080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.073395</td>\n",
       "      <td>0.394990</td>\n",
       "      <td>0.246939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5683</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.832329</td>\n",
       "      <td>0.492386</td>\n",
       "      <td>0.225507</td>\n",
       "      <td>0.619231</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.155933</td>\n",
       "      <td>0.813003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.065942</td>\n",
       "      <td>0.591706</td>\n",
       "      <td>0.465306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7125</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.210842</td>\n",
       "      <td>0.576650</td>\n",
       "      <td>0.267664</td>\n",
       "      <td>0.302591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086815</td>\n",
       "      <td>0.821384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.029089</td>\n",
       "      <td>0.378979</td>\n",
       "      <td>0.218367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8092</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527107</td>\n",
       "      <td>0.390863</td>\n",
       "      <td>0.346355</td>\n",
       "      <td>0.362713</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.076553</td>\n",
       "      <td>0.794274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.036128</td>\n",
       "      <td>0.538967</td>\n",
       "      <td>0.188776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5228</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.262047</td>\n",
       "      <td>0.748223</td>\n",
       "      <td>0.348043</td>\n",
       "      <td>0.724443</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.066918</td>\n",
       "      <td>0.864429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.051760</td>\n",
       "      <td>0.524237</td>\n",
       "      <td>0.666327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4715</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.616244</td>\n",
       "      <td>0.250428</td>\n",
       "      <td>0.744484</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.188397</td>\n",
       "      <td>0.884700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.038923</td>\n",
       "      <td>0.581293</td>\n",
       "      <td>0.767347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051303</td>\n",
       "      <td>0.982741</td>\n",
       "      <td>0.351473</td>\n",
       "      <td>0.590172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054456</td>\n",
       "      <td>0.821585</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.263975</td>\n",
       "      <td>0.590611</td>\n",
       "      <td>0.273469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.052307</td>\n",
       "      <td>0.627411</td>\n",
       "      <td>0.200290</td>\n",
       "      <td>0.561113</td>\n",
       "      <td>0.938000</td>\n",
       "      <td>0.195727</td>\n",
       "      <td>0.712118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025466</td>\n",
       "      <td>0.454586</td>\n",
       "      <td>0.121429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6146</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.795180</td>\n",
       "      <td>0.356345</td>\n",
       "      <td>0.378925</td>\n",
       "      <td>0.290567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304639</td>\n",
       "      <td>0.809695</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030642</td>\n",
       "      <td>0.653706</td>\n",
       "      <td>0.343878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7682</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.237563</td>\n",
       "      <td>0.253184</td>\n",
       "      <td>0.928856</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.097288</td>\n",
       "      <td>0.864920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448240</td>\n",
       "      <td>0.595200</td>\n",
       "      <td>0.283673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3434</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.559236</td>\n",
       "      <td>0.873096</td>\n",
       "      <td>0.226852</td>\n",
       "      <td>0.688371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209341</td>\n",
       "      <td>0.835710</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.072567</td>\n",
       "      <td>0.511415</td>\n",
       "      <td>0.763265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4881</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040058</td>\n",
       "      <td>0.852792</td>\n",
       "      <td>0.213696</td>\n",
       "      <td>0.544079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100429</td>\n",
       "      <td>0.823149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.492754</td>\n",
       "      <td>0.772684</td>\n",
       "      <td>0.164286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9798</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014255</td>\n",
       "      <td>0.560406</td>\n",
       "      <td>0.168713</td>\n",
       "      <td>0.567126</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>0.428212</td>\n",
       "      <td>0.829452</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.029296</td>\n",
       "      <td>0.467871</td>\n",
       "      <td>0.123469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.072689</td>\n",
       "      <td>0.638579</td>\n",
       "      <td>0.290009</td>\n",
       "      <td>0.609211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069431</td>\n",
       "      <td>0.834123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>0.468067</td>\n",
       "      <td>0.421429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.348392</td>\n",
       "      <td>0.968528</td>\n",
       "      <td>0.205972</td>\n",
       "      <td>0.581154</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.118232</td>\n",
       "      <td>0.796643</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.379917</td>\n",
       "      <td>0.581570</td>\n",
       "      <td>0.489796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8222</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.965863</td>\n",
       "      <td>0.615228</td>\n",
       "      <td>0.229943</td>\n",
       "      <td>0.218421</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.094146</td>\n",
       "      <td>0.681142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070083</td>\n",
       "      <td>0.363673</td>\n",
       "      <td>0.538776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9466</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004626</td>\n",
       "      <td>0.225381</td>\n",
       "      <td>0.052391</td>\n",
       "      <td>0.312611</td>\n",
       "      <td>0.847000</td>\n",
       "      <td>0.417740</td>\n",
       "      <td>0.165162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066563</td>\n",
       "      <td>0.449593</td>\n",
       "      <td>0.037143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033130</td>\n",
       "      <td>0.786802</td>\n",
       "      <td>0.243781</td>\n",
       "      <td>0.873745</td>\n",
       "      <td>0.057900</td>\n",
       "      <td>0.289978</td>\n",
       "      <td>0.902356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.048551</td>\n",
       "      <td>0.558812</td>\n",
       "      <td>0.386735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>0.726904</td>\n",
       "      <td>0.328276</td>\n",
       "      <td>0.542075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098335</td>\n",
       "      <td>0.819328</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.154244</td>\n",
       "      <td>0.635977</td>\n",
       "      <td>0.394898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6710</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.351404</td>\n",
       "      <td>0.396954</td>\n",
       "      <td>0.303313</td>\n",
       "      <td>0.650294</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.841096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040890</td>\n",
       "      <td>0.787141</td>\n",
       "      <td>0.205102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.588352</td>\n",
       "      <td>0.769543</td>\n",
       "      <td>0.221996</td>\n",
       "      <td>0.621235</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.173735</td>\n",
       "      <td>0.837878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087578</td>\n",
       "      <td>0.708849</td>\n",
       "      <td>0.412245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.618473</td>\n",
       "      <td>0.967513</td>\n",
       "      <td>0.212773</td>\n",
       "      <td>0.555101</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.088910</td>\n",
       "      <td>0.881660</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.078675</td>\n",
       "      <td>0.458934</td>\n",
       "      <td>0.466327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6979</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.513051</td>\n",
       "      <td>0.716751</td>\n",
       "      <td>0.247447</td>\n",
       "      <td>0.380749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234475</td>\n",
       "      <td>0.845365</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.338509</td>\n",
       "      <td>0.294681</td>\n",
       "      <td>0.388776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.151605</td>\n",
       "      <td>0.769543</td>\n",
       "      <td>0.233786</td>\n",
       "      <td>0.491974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094146</td>\n",
       "      <td>0.829474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078364</td>\n",
       "      <td>0.590462</td>\n",
       "      <td>0.268367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727911</td>\n",
       "      <td>0.667005</td>\n",
       "      <td>0.219042</td>\n",
       "      <td>0.159302</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.270081</td>\n",
       "      <td>0.647036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040890</td>\n",
       "      <td>0.454423</td>\n",
       "      <td>0.085000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.676142</td>\n",
       "      <td>0.264132</td>\n",
       "      <td>0.729453</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.022830</td>\n",
       "      <td>0.866284</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.043375</td>\n",
       "      <td>0.558821</td>\n",
       "      <td>0.520408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6771</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032026</td>\n",
       "      <td>0.564467</td>\n",
       "      <td>0.322924</td>\n",
       "      <td>0.672338</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.094146</td>\n",
       "      <td>0.853813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066977</td>\n",
       "      <td>0.477317</td>\n",
       "      <td>0.257143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007458</td>\n",
       "      <td>0.539086</td>\n",
       "      <td>0.268392</td>\n",
       "      <td>0.848694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073830</td>\n",
       "      <td>0.908770</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.054762</td>\n",
       "      <td>0.477194</td>\n",
       "      <td>0.387755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5767</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.958835</td>\n",
       "      <td>0.707614</td>\n",
       "      <td>0.099799</td>\n",
       "      <td>0.359707</td>\n",
       "      <td>0.899000</td>\n",
       "      <td>0.073725</td>\n",
       "      <td>0.779099</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.305383</td>\n",
       "      <td>0.382578</td>\n",
       "      <td>0.848980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6017</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.065159</td>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.205877</td>\n",
       "      <td>0.581154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092052</td>\n",
       "      <td>0.854237</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.365424</td>\n",
       "      <td>0.680530</td>\n",
       "      <td>0.723469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7371</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.794176</td>\n",
       "      <td>0.521827</td>\n",
       "      <td>0.251391</td>\n",
       "      <td>0.362713</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.084721</td>\n",
       "      <td>0.746178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045756</td>\n",
       "      <td>0.345163</td>\n",
       "      <td>0.076837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9581</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273091</td>\n",
       "      <td>0.867005</td>\n",
       "      <td>0.303535</td>\n",
       "      <td>0.508006</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>0.058435</td>\n",
       "      <td>0.867602</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052588</td>\n",
       "      <td>0.464718</td>\n",
       "      <td>0.690816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.683734</td>\n",
       "      <td>0.574619</td>\n",
       "      <td>0.242194</td>\n",
       "      <td>0.412814</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.055503</td>\n",
       "      <td>0.839777</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.027640</td>\n",
       "      <td>0.372010</td>\n",
       "      <td>0.479592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6906</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117468</td>\n",
       "      <td>0.458883</td>\n",
       "      <td>0.288229</td>\n",
       "      <td>0.758512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127657</td>\n",
       "      <td>0.899473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.485868</td>\n",
       "      <td>0.304082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.237950</td>\n",
       "      <td>0.665990</td>\n",
       "      <td>0.195294</td>\n",
       "      <td>0.380749</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.084721</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052070</td>\n",
       "      <td>0.622452</td>\n",
       "      <td>0.954082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.703815</td>\n",
       "      <td>0.567513</td>\n",
       "      <td>0.388915</td>\n",
       "      <td>0.422834</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.067232</td>\n",
       "      <td>0.730355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.201863</td>\n",
       "      <td>0.336221</td>\n",
       "      <td>0.194898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9326</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.633533</td>\n",
       "      <td>0.168528</td>\n",
       "      <td>0.246161</td>\n",
       "      <td>0.319626</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.414598</td>\n",
       "      <td>0.645383</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.035611</td>\n",
       "      <td>0.507781</td>\n",
       "      <td>0.034796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.255018</td>\n",
       "      <td>0.565482</td>\n",
       "      <td>0.303818</td>\n",
       "      <td>0.512014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081579</td>\n",
       "      <td>0.844381</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030124</td>\n",
       "      <td>0.708963</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4448</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222890</td>\n",
       "      <td>0.676142</td>\n",
       "      <td>0.221952</td>\n",
       "      <td>0.856711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.503613</td>\n",
       "      <td>0.877235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244306</td>\n",
       "      <td>0.572211</td>\n",
       "      <td>0.784694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4822</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.618473</td>\n",
       "      <td>0.392893</td>\n",
       "      <td>0.247304</td>\n",
       "      <td>0.621235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064509</td>\n",
       "      <td>0.902132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.083954</td>\n",
       "      <td>0.442537</td>\n",
       "      <td>0.413265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9559</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.072387</td>\n",
       "      <td>0.734010</td>\n",
       "      <td>0.381846</td>\n",
       "      <td>0.608209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359095</td>\n",
       "      <td>0.863557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158385</td>\n",
       "      <td>0.599680</td>\n",
       "      <td>0.531633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4724</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.146584</td>\n",
       "      <td>0.534010</td>\n",
       "      <td>0.240864</td>\n",
       "      <td>0.412814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087863</td>\n",
       "      <td>0.778808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.046480</td>\n",
       "      <td>0.753615</td>\n",
       "      <td>0.270408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021685</td>\n",
       "      <td>0.560406</td>\n",
       "      <td>0.433420</td>\n",
       "      <td>0.563117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294167</td>\n",
       "      <td>0.842728</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.169772</td>\n",
       "      <td>0.613424</td>\n",
       "      <td>0.447959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4855</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.370481</td>\n",
       "      <td>0.758376</td>\n",
       "      <td>0.249414</td>\n",
       "      <td>0.558107</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.085768</td>\n",
       "      <td>0.795593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.681352</td>\n",
       "      <td>0.563265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458834</td>\n",
       "      <td>0.773604</td>\n",
       "      <td>0.206872</td>\n",
       "      <td>0.739474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098335</td>\n",
       "      <td>0.867245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107660</td>\n",
       "      <td>0.704192</td>\n",
       "      <td>0.813265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045179</td>\n",
       "      <td>0.641624</td>\n",
       "      <td>0.177856</td>\n",
       "      <td>0.728451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100429</td>\n",
       "      <td>0.831754</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.077536</td>\n",
       "      <td>0.734701</td>\n",
       "      <td>0.415306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099998</td>\n",
       "      <td>0.725888</td>\n",
       "      <td>0.151669</td>\n",
       "      <td>0.618229</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.172688</td>\n",
       "      <td>0.871871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.248447</td>\n",
       "      <td>0.800172</td>\n",
       "      <td>0.288776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7665</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007558</td>\n",
       "      <td>0.883249</td>\n",
       "      <td>0.304406</td>\n",
       "      <td>0.665324</td>\n",
       "      <td>0.341000</td>\n",
       "      <td>0.031731</td>\n",
       "      <td>0.820021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.064182</td>\n",
       "      <td>0.568058</td>\n",
       "      <td>0.871429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4581</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035440</td>\n",
       "      <td>0.939086</td>\n",
       "      <td>0.260079</td>\n",
       "      <td>0.737470</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.079066</td>\n",
       "      <td>0.856115</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.136646</td>\n",
       "      <td>0.667940</td>\n",
       "      <td>0.503061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220882</td>\n",
       "      <td>0.752284</td>\n",
       "      <td>0.190576</td>\n",
       "      <td>0.557105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080637</td>\n",
       "      <td>0.847533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098033</td>\n",
       "      <td>0.636332</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.300199</td>\n",
       "      <td>0.326904</td>\n",
       "      <td>0.432783</td>\n",
       "      <td>0.755506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120327</td>\n",
       "      <td>0.852695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.285503</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3523</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.689758</td>\n",
       "      <td>0.712690</td>\n",
       "      <td>0.043799</td>\n",
       "      <td>0.499990</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.144413</td>\n",
       "      <td>0.843487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156315</td>\n",
       "      <td>0.759108</td>\n",
       "      <td>0.231633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7591</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.296183</td>\n",
       "      <td>0.656853</td>\n",
       "      <td>0.238091</td>\n",
       "      <td>0.646285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095193</td>\n",
       "      <td>0.916525</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.032195</td>\n",
       "      <td>0.608867</td>\n",
       "      <td>0.439796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5373</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.161645</td>\n",
       "      <td>0.792893</td>\n",
       "      <td>0.306218</td>\n",
       "      <td>0.629251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073934</td>\n",
       "      <td>0.876743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.069151</td>\n",
       "      <td>0.536086</td>\n",
       "      <td>0.293878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7228</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.488955</td>\n",
       "      <td>0.670051</td>\n",
       "      <td>0.387787</td>\n",
       "      <td>0.313613</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>0.087863</td>\n",
       "      <td>0.699133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.027226</td>\n",
       "      <td>0.654124</td>\n",
       "      <td>0.230612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4915</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.869036</td>\n",
       "      <td>0.152085</td>\n",
       "      <td>0.546083</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.131846</td>\n",
       "      <td>0.752749</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.731489</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2563</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.366464</td>\n",
       "      <td>0.868020</td>\n",
       "      <td>0.179658</td>\n",
       "      <td>0.307601</td>\n",
       "      <td>0.854000</td>\n",
       "      <td>0.087863</td>\n",
       "      <td>0.759208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075776</td>\n",
       "      <td>0.408875</td>\n",
       "      <td>0.177551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046986</td>\n",
       "      <td>0.613198</td>\n",
       "      <td>0.269306</td>\n",
       "      <td>0.880759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073097</td>\n",
       "      <td>0.920369</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.626913</td>\n",
       "      <td>0.772449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.684738</td>\n",
       "      <td>0.411168</td>\n",
       "      <td>0.453074</td>\n",
       "      <td>0.420830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053304</td>\n",
       "      <td>0.835308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.035197</td>\n",
       "      <td>0.641184</td>\n",
       "      <td>0.353061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.791164</td>\n",
       "      <td>0.525888</td>\n",
       "      <td>0.132431</td>\n",
       "      <td>0.442875</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.167452</td>\n",
       "      <td>0.785089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259834</td>\n",
       "      <td>0.372501</td>\n",
       "      <td>0.531633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows  28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Key_0  Key_1  Key_2  Key_3  Key_4  Key_5  Key_6  Key_7  Key_8  Key_9  Key_10  Key_11  Time Signature_0  Time Signature_1  Time Signature_3  Time Signature_4  Time Signature_5  Acousticness  Danceability  Duration_ms    Energy  Instrumentalness  Liveness  Loudness  Mode  Speechiness     Tempo   Valence\n",
       "5760      0      0      1      0      0      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.002126      0.299492     0.256368  0.716427          0.000002  0.231333  0.850080   1.0     0.073395  0.394990  0.246939\n",
       "5683      0      0      1      0      0      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.832329      0.492386     0.225507  0.619231          0.000004  0.155933  0.813003   1.0     0.065942  0.591706  0.465306\n",
       "7125      0      0      0      0      0      0      1      0      0      0       0       0                 0                 1                 0                 0                 0      0.210842      0.576650     0.267664  0.302591          0.000000  0.086815  0.821384   1.0     0.029089  0.378979  0.218367\n",
       "8092      0      0      1      0      0      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.527107      0.390863     0.346355  0.362713          0.000120  0.076553  0.794274   1.0     0.036128  0.538967  0.188776\n",
       "5228      0      0      0      0      0      0      0      0      1      0       0       0                 0                 0                 0                 1                 0      0.262047      0.748223     0.348043  0.724443          0.000097  0.066918  0.864429   1.0     0.051760  0.524237  0.666327\n",
       "4715      0      0      1      0      0      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.000569      0.616244     0.250428  0.744484          0.000010  0.188397  0.884700   1.0     0.038923  0.581293  0.767347\n",
       "645       0      0      0      0      0      0      0      0      0      0       0       1                 0                 0                 0                 1                 0      0.051303      0.982741     0.351473  0.590172          0.000000  0.054456  0.821585   1.0     0.263975  0.590611  0.273469\n",
       "4600      0      0      0      0      1      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.052307      0.627411     0.200290  0.561113          0.938000  0.195727  0.712118   0.0     0.025466  0.454586  0.121429\n",
       "6146      1      0      0      0      0      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.795180      0.356345     0.378925  0.290567          0.000000  0.304639  0.809695   1.0     0.030642  0.653706  0.343878\n",
       "7682      0      0      0      0      0      1      0      0      0      0       0       0                 0                 0                 1                 0                 0      0.000010      0.237563     0.253184  0.928856          0.000039  0.097288  0.864920   0.0     0.448240  0.595200  0.283673\n",
       "3434      0      0      0      0      0      1      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.559236      0.873096     0.226852  0.688371          0.000000  0.209341  0.835710   1.0     0.072567  0.511415  0.763265\n",
       "4881      0      1      0      0      0      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.040058      0.852792     0.213696  0.544079          0.000000  0.100429  0.823149   1.0     0.492754  0.772684  0.164286\n",
       "9798      1      0      0      0      0      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.014255      0.560406     0.168713  0.567126          0.958000  0.428212  0.829452   1.0     0.029296  0.467871  0.123469\n",
       "2733      0      0      1      0      0      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.072689      0.638579     0.290009  0.609211          0.000000  0.069431  0.834123   0.0     0.079814  0.468067  0.421429\n",
       "1072      0      0      0      0      0      0      0      1      0      0       0       0                 0                 0                 0                 1                 0      0.348392      0.968528     0.205972  0.581154          0.000002  0.118232  0.796643   1.0     0.379917  0.581570  0.489796\n",
       "8222      0      0      0      0      1      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.965863      0.615228     0.229943  0.218421          0.860000  0.094146  0.681142   1.0     0.070083  0.363673  0.538776\n",
       "9466      0      0      0      0      1      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.004626      0.225381     0.052391  0.312611          0.847000  0.417740  0.165162   0.0     0.066563  0.449593  0.037143\n",
       "1437      0      0      0      0      0      0      1      0      0      0       0       0                 0                 0                 0                 1                 0      0.033130      0.786802     0.243781  0.873745          0.057900  0.289978  0.902356   1.0     0.048551  0.558812  0.386735\n",
       "201       0      1      0      0      0      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.002106      0.726904     0.328276  0.542075          0.000000  0.098335  0.819328   1.0     0.154244  0.635977  0.394898\n",
       "6710      0      0      0      1      0      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.351404      0.396954     0.303313  0.650294          0.000100  0.227144  0.841096   0.0     0.040890  0.787141  0.205102\n",
       "1868      0      0      0      0      0      1      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.588352      0.769543     0.221996  0.621235          0.000078  0.173735  0.837878   0.0     0.087578  0.708849  0.412245\n",
       "2018      1      0      0      0      0      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.618473      0.967513     0.212773  0.555101          0.000869  0.088910  0.881660   1.0     0.078675  0.458934  0.466327\n",
       "6979      0      0      1      0      0      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.513051      0.716751     0.247447  0.380749          0.000000  0.234475  0.845365   1.0     0.338509  0.294681  0.388776\n",
       "6392      0      0      0      0      0      0      0      1      0      0       0       0                 0                 0                 0                 1                 0      0.151605      0.769543     0.233786  0.491974          0.000000  0.094146  0.829474   0.0     0.078364  0.590462  0.268367\n",
       "2611      0      0      0      0      1      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.727911      0.667005     0.219042  0.159302          0.730000  0.270081  0.647036   0.0     0.040890  0.454423  0.085000\n",
       "260       0      0      0      0      0      0      0      1      0      0       0       0                 0                 0                 0                 1                 0      0.001755      0.676142     0.264132  0.729453          0.000004  0.022830  0.866284   1.0     0.043375  0.558821  0.520408\n",
       "6771      0      0      0      0      0      0      0      0      0      0       0       1                 0                 0                 0                 1                 0      0.032026      0.564467     0.322924  0.672338          0.000377  0.094146  0.853813   0.0     0.066977  0.477317  0.257143\n",
       "3105      0      1      0      0      0      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.007458      0.539086     0.268392  0.848694          0.000000  0.073830  0.908770   1.0     0.054762  0.477194  0.387755\n",
       "5767      0      1      0      0      0      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.958835      0.707614     0.099799  0.359707          0.899000  0.073725  0.779099   1.0     0.305383  0.382578  0.848980\n",
       "6017      0      1      0      0      0      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.065159      0.857868     0.205877  0.581154          0.000000  0.092052  0.854237   1.0     0.365424  0.680530  0.723469\n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...     ...     ...               ...               ...               ...               ...               ...           ...           ...          ...       ...               ...       ...       ...   ...          ...       ...       ...\n",
       "7371      0      0      0      0      0      0      0      0      0      1       0       0                 0                 0                 0                 1                 0      0.794176      0.521827     0.251391  0.362713          0.013900  0.084721  0.746178   0.0     0.045756  0.345163  0.076837\n",
       "9581      0      0      1      0      0      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.273091      0.867005     0.303535  0.508006          0.001970  0.058435  0.867602   1.0     0.052588  0.464718  0.690816\n",
       "1485      0      0      0      0      0      1      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.683734      0.574619     0.242194  0.412814          0.017000  0.055503  0.839777   1.0     0.027640  0.372010  0.479592\n",
       "6906      0      0      0      0      0      0      0      0      1      0       0       0                 0                 0                 1                 0                 0      0.117468      0.458883     0.288229  0.758512          0.000000  0.127657  0.899473   0.0     0.261905  0.485868  0.304082\n",
       "1690      0      0      0      0      0      0      0      0      1      0       0       0                 0                 0                 0                 1                 0      0.237950      0.665990     0.195294  0.380749          0.000456  0.084721  0.867424   1.0     0.052070  0.622452  0.954082\n",
       "409       0      0      0      0      0      0      0      0      0      0       0       1                 0                 0                 0                 1                 0      0.703815      0.567513     0.388915  0.422834          0.000002  0.067232  0.730355   1.0     0.201863  0.336221  0.194898\n",
       "9326      1      0      0      0      0      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.633533      0.168528     0.246161  0.319626          0.842000  0.414598  0.645383   1.0     0.035611  0.507781  0.034796\n",
       "321       0      0      0      0      0      0      0      0      1      0       0       0                 0                 0                 0                 1                 0      0.255018      0.565482     0.303818  0.512014          0.000000  0.081579  0.844381   1.0     0.030124  0.708963  0.614286\n",
       "4448      0      0      0      0      0      0      0      0      0      0       0       1                 0                 0                 0                 1                 0      0.222890      0.676142     0.221952  0.856711          0.000000  0.503613  0.877235   0.0     0.244306  0.572211  0.784694\n",
       "4822      0      0      0      0      0      0      1      0      0      0       0       0                 0                 0                 1                 0                 0      0.618473      0.392893     0.247304  0.621235          0.000000  0.064509  0.902132   1.0     0.083954  0.442537  0.413265\n",
       "9559      0      0      0      0      0      0      0      1      0      0       0       0                 0                 0                 0                 1                 0      0.072387      0.734010     0.381846  0.608209          0.000000  0.359095  0.863557   0.0     0.158385  0.599680  0.531633\n",
       "4724      0      0      0      0      0      0      0      0      0      1       0       0                 0                 0                 0                 1                 0      0.146584      0.534010     0.240864  0.412814          0.000000  0.087863  0.778808   1.0     0.046480  0.753615  0.270408\n",
       "1191      0      0      0      0      0      0      0      0      0      0       0       1                 0                 0                 0                 1                 0      0.021685      0.560406     0.433420  0.563117          0.000000  0.294167  0.842728   1.0     0.169772  0.613424  0.447959\n",
       "4855      0      1      0      0      0      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.370481      0.758376     0.249414  0.558107          0.000035  0.085768  0.795593   0.0     0.071429  0.681352  0.563265\n",
       "2364      0      0      0      0      0      1      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.458834      0.773604     0.206872  0.739474          0.000000  0.098335  0.867245   0.0     0.107660  0.704192  0.813265\n",
       "637       1      0      0      0      0      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.045179      0.641624     0.177856  0.728451          0.000000  0.100429  0.831754   1.0     0.077536  0.734701  0.415306\n",
       "1094      0      0      0      0      0      0      0      0      0      0       0       1                 0                 0                 0                 1                 0      0.099998      0.725888     0.151669  0.618229          0.000003  0.172688  0.871871   0.0     0.248447  0.800172  0.288776\n",
       "7665      0      0      0      0      0      0      0      0      0      1       0       0                 0                 0                 0                 1                 0      0.007558      0.883249     0.304406  0.665324          0.341000  0.031731  0.820021   1.0     0.064182  0.568058  0.871429\n",
       "4581      0      1      0      0      0      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.035440      0.939086     0.260079  0.737470          0.000156  0.079066  0.856115   1.0     0.136646  0.667940  0.503061\n",
       "504       0      0      0      0      0      0      0      1      0      0       0       0                 0                 0                 0                 1                 0      0.220882      0.752284     0.190576  0.557105          0.000000  0.080637  0.847533   0.0     0.098033  0.636332  0.628571\n",
       "1126      0      0      0      0      0      0      0      0      0      0       1       0                 0                 0                 0                 1                 0      0.300199      0.326904     0.432783  0.755506          0.000000  0.120327  0.852695   0.0     0.284679  0.285503  0.400000\n",
       "3523      0      0      0      0      1      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.689758      0.712690     0.043799  0.499990          0.000002  0.144413  0.843487   0.0     0.156315  0.759108  0.231633\n",
       "7591      0      0      0      0      0      0      0      1      0      0       0       0                 0                 0                 1                 0                 0      0.296183      0.656853     0.238091  0.646285          0.000000  0.095193  0.916525   1.0     0.032195  0.608867  0.439796\n",
       "5373      0      1      0      0      0      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.161645      0.792893     0.306218  0.629251          0.000000  0.073934  0.876743   1.0     0.069151  0.536086  0.293878\n",
       "7228      0      0      0      0      0      1      0      0      0      0       0       0                 0                 0                 1                 0                 0      0.488955      0.670051     0.387787  0.313613          0.003490  0.087863  0.699133   1.0     0.027226  0.654124  0.230612\n",
       "4915      0      1      0      0      0      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.000601      0.869036     0.152085  0.546083          0.000973  0.131846  0.752749   1.0     0.261905  0.731489  0.050000\n",
       "2563      0      1      0      0      0      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.366464      0.868020     0.179658  0.307601          0.854000  0.087863  0.759208   0.0     0.075776  0.408875  0.177551\n",
       "223       0      0      0      0      1      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.046986      0.613198     0.269306  0.880759          0.000000  0.073097  0.920369   1.0     0.033333  0.626913  0.772449\n",
       "7161      0      0      0      0      0      0      0      0      0      1       0       0                 0                 0                 1                 0                 0      0.684738      0.411168     0.453074  0.420830          0.000000  0.053304  0.835308   1.0     0.035197  0.641184  0.353061\n",
       "3638      1      0      0      0      0      0      0      0      0      0       0       0                 0                 0                 0                 1                 0      0.791164      0.525888     0.132431  0.442875          0.904000  0.167452  0.785089   0.0     0.259834  0.372501  0.531633\n",
       "\n",
       "[2000 rows x 28 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 5600 samples, validate on 2400 samples\n",
      "Epoch 1/1000\n",
      "5600/5600 [==============================] - 0s 77us/sample - loss: 0.6560 - accuracy: 0.6371 - val_loss: 0.6458 - val_accuracy: 0.6454\n",
      "Epoch 2/1000\n",
      "5600/5600 [==============================] - 0s 43us/sample - loss: 0.6463 - accuracy: 0.6416 - val_loss: 0.6395 - val_accuracy: 0.6454\n",
      "Epoch 3/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.6422 - accuracy: 0.6416 - val_loss: 0.6369 - val_accuracy: 0.6454\n",
      "Epoch 4/1000\n",
      "5600/5600 [==============================] - 0s 42us/sample - loss: 0.6412 - accuracy: 0.6416 - val_loss: 0.6440 - val_accuracy: 0.6454\n",
      "Epoch 5/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.6368 - accuracy: 0.6416 - val_loss: 0.6380 - val_accuracy: 0.6429\n",
      "Epoch 6/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.6313 - accuracy: 0.6439 - val_loss: 0.6367 - val_accuracy: 0.6438\n",
      "Epoch 7/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.6317 - accuracy: 0.6470 - val_loss: 0.6411 - val_accuracy: 0.6383\n",
      "Epoch 8/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.6277 - accuracy: 0.6479 - val_loss: 0.6397 - val_accuracy: 0.6408\n",
      "Epoch 9/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.6229 - accuracy: 0.6514 - val_loss: 0.6423 - val_accuracy: 0.6354\n",
      "Epoch 10/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.6180 - accuracy: 0.6495 - val_loss: 0.6461 - val_accuracy: 0.6242\n",
      "Epoch 11/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.6121 - accuracy: 0.6566 - val_loss: 0.6616 - val_accuracy: 0.6350\n",
      "Epoch 12/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.6131 - accuracy: 0.6555 - val_loss: 0.6544 - val_accuracy: 0.6296\n",
      "Epoch 13/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.6092 - accuracy: 0.6598 - val_loss: 0.6582 - val_accuracy: 0.6375\n",
      "Epoch 14/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.6028 - accuracy: 0.6605 - val_loss: 0.6626 - val_accuracy: 0.6267\n",
      "Epoch 15/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.5967 - accuracy: 0.6673 - val_loss: 0.6666 - val_accuracy: 0.6275\n",
      "Epoch 16/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.5954 - accuracy: 0.6704 - val_loss: 0.6752 - val_accuracy: 0.6263\n",
      "Epoch 17/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.5915 - accuracy: 0.6723 - val_loss: 0.6677 - val_accuracy: 0.6187\n",
      "Epoch 18/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.5846 - accuracy: 0.6748 - val_loss: 0.6861 - val_accuracy: 0.6300\n",
      "Epoch 19/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.5820 - accuracy: 0.6743 - val_loss: 0.6868 - val_accuracy: 0.6204\n",
      "Epoch 20/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.5815 - accuracy: 0.6759 - val_loss: 0.6853 - val_accuracy: 0.6196\n",
      "Epoch 21/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.5747 - accuracy: 0.6800 - val_loss: 0.6905 - val_accuracy: 0.6229\n",
      "Epoch 22/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.5680 - accuracy: 0.6889 - val_loss: 0.6958 - val_accuracy: 0.6204\n",
      "Epoch 23/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.5651 - accuracy: 0.6845 - val_loss: 0.7251 - val_accuracy: 0.6033\n",
      "Epoch 24/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.5585 - accuracy: 0.6913 - val_loss: 0.7269 - val_accuracy: 0.6283\n",
      "Epoch 25/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.5527 - accuracy: 0.6946 - val_loss: 0.7474 - val_accuracy: 0.6208\n",
      "Epoch 26/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.5566 - accuracy: 0.6932 - val_loss: 0.7320 - val_accuracy: 0.6104\n",
      "Epoch 27/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.5453 - accuracy: 0.7014 - val_loss: 0.7466 - val_accuracy: 0.5892\n",
      "Epoch 28/1000\n",
      "5600/5600 [==============================] - 0s 44us/sample - loss: 0.5410 - accuracy: 0.7063 - val_loss: 0.7537 - val_accuracy: 0.6000\n",
      "Epoch 29/1000\n",
      "5600/5600 [==============================] - 0s 43us/sample - loss: 0.5346 - accuracy: 0.7073 - val_loss: 0.7642 - val_accuracy: 0.6004\n",
      "Epoch 30/1000\n",
      "5600/5600 [==============================] - 0s 47us/sample - loss: 0.5277 - accuracy: 0.7180 - val_loss: 0.7732 - val_accuracy: 0.6017\n",
      "Epoch 31/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.5215 - accuracy: 0.7139 - val_loss: 0.7737 - val_accuracy: 0.6008\n",
      "Epoch 32/1000\n",
      "5600/5600 [==============================] - 0s 43us/sample - loss: 0.5117 - accuracy: 0.7193 - val_loss: 0.7971 - val_accuracy: 0.5962\n",
      "Epoch 33/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.5044 - accuracy: 0.7264 - val_loss: 0.8063 - val_accuracy: 0.5983\n",
      "Epoch 34/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.5143 - accuracy: 0.7234 - val_loss: 0.8201 - val_accuracy: 0.6067\n",
      "Epoch 35/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.5016 - accuracy: 0.7350 - val_loss: 0.8414 - val_accuracy: 0.5854\n",
      "Epoch 36/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.4951 - accuracy: 0.7364 - val_loss: 0.8552 - val_accuracy: 0.6250\n",
      "Epoch 37/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.4879 - accuracy: 0.7411 - val_loss: 0.8975 - val_accuracy: 0.5875\n",
      "Epoch 38/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.4885 - accuracy: 0.7336 - val_loss: 0.8774 - val_accuracy: 0.5858\n",
      "Epoch 39/1000\n",
      "5600/5600 [==============================] - 0s 42us/sample - loss: 0.4690 - accuracy: 0.7539 - val_loss: 0.9451 - val_accuracy: 0.5792\n",
      "Epoch 40/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.4802 - accuracy: 0.7452 - val_loss: 0.8780 - val_accuracy: 0.5875\n",
      "Epoch 41/1000\n",
      "5600/5600 [==============================] - 0s 42us/sample - loss: 0.4708 - accuracy: 0.7498 - val_loss: 0.9306 - val_accuracy: 0.6083\n",
      "Epoch 42/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.4689 - accuracy: 0.7495 - val_loss: 0.9478 - val_accuracy: 0.6125\n",
      "Epoch 43/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.4543 - accuracy: 0.7596 - val_loss: 0.9246 - val_accuracy: 0.5933\n",
      "Epoch 44/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.4445 - accuracy: 0.7716 - val_loss: 0.9805 - val_accuracy: 0.5808\n",
      "Epoch 45/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.4391 - accuracy: 0.7664 - val_loss: 0.9699 - val_accuracy: 0.5838\n",
      "Epoch 46/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.4400 - accuracy: 0.7688 - val_loss: 1.0343 - val_accuracy: 0.5875\n",
      "Epoch 47/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.4385 - accuracy: 0.7736 - val_loss: 0.9492 - val_accuracy: 0.5813\n",
      "Epoch 48/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.4274 - accuracy: 0.7777 - val_loss: 1.0327 - val_accuracy: 0.5871\n",
      "Epoch 49/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.4172 - accuracy: 0.7845 - val_loss: 1.0250 - val_accuracy: 0.6046\n",
      "Epoch 50/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.4058 - accuracy: 0.7904 - val_loss: 1.1086 - val_accuracy: 0.5892\n",
      "Epoch 51/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.4173 - accuracy: 0.7843 - val_loss: 1.0871 - val_accuracy: 0.5833\n",
      "Epoch 52/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.4010 - accuracy: 0.7937 - val_loss: 1.0661 - val_accuracy: 0.5875\n",
      "Epoch 53/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.3998 - accuracy: 0.7989 - val_loss: 1.1438 - val_accuracy: 0.5996\n",
      "Epoch 54/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 0.3833 - accuracy: 0.8112 - val_loss: 1.1440 - val_accuracy: 0.6067\n",
      "Epoch 55/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.3899 - accuracy: 0.7971 - val_loss: 1.1525 - val_accuracy: 0.6042\n",
      "Epoch 56/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.3653 - accuracy: 0.8182 - val_loss: 1.1984 - val_accuracy: 0.5896\n",
      "Epoch 57/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.3682 - accuracy: 0.8155 - val_loss: 1.2671 - val_accuracy: 0.5908\n",
      "Epoch 58/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.3630 - accuracy: 0.8159 - val_loss: 1.1822 - val_accuracy: 0.5842\n",
      "Epoch 59/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.3518 - accuracy: 0.8239 - val_loss: 1.2170 - val_accuracy: 0.5913\n",
      "Epoch 60/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.3566 - accuracy: 0.8180 - val_loss: 1.2556 - val_accuracy: 0.5858\n",
      "Epoch 61/1000\n",
      "5600/5600 [==============================] - 0s 43us/sample - loss: 0.3382 - accuracy: 0.8314 - val_loss: 1.3050 - val_accuracy: 0.5904\n",
      "Epoch 62/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.3380 - accuracy: 0.8389 - val_loss: 1.2416 - val_accuracy: 0.6058\n",
      "Epoch 63/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.3378 - accuracy: 0.8368 - val_loss: 1.3252 - val_accuracy: 0.5967\n",
      "Epoch 64/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.3245 - accuracy: 0.8409 - val_loss: 1.3422 - val_accuracy: 0.5917\n",
      "Epoch 65/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.3450 - accuracy: 0.8271 - val_loss: 1.3259 - val_accuracy: 0.5987\n",
      "Epoch 66/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.3174 - accuracy: 0.8482 - val_loss: 1.4054 - val_accuracy: 0.5917\n",
      "Epoch 67/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.3209 - accuracy: 0.8459 - val_loss: 1.3585 - val_accuracy: 0.5892\n",
      "Epoch 68/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.3070 - accuracy: 0.8530 - val_loss: 1.4308 - val_accuracy: 0.5846\n",
      "Epoch 69/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.3177 - accuracy: 0.8504 - val_loss: 1.3922 - val_accuracy: 0.5863\n",
      "Epoch 70/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.2938 - accuracy: 0.8612 - val_loss: 1.4084 - val_accuracy: 0.5925\n",
      "Epoch 71/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.2877 - accuracy: 0.8671 - val_loss: 1.4365 - val_accuracy: 0.5921\n",
      "Epoch 72/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.2883 - accuracy: 0.8616 - val_loss: 1.4707 - val_accuracy: 0.5792\n",
      "Epoch 73/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.2798 - accuracy: 0.8714 - val_loss: 1.4667 - val_accuracy: 0.5792\n",
      "Epoch 74/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.2775 - accuracy: 0.8671 - val_loss: 1.5288 - val_accuracy: 0.5788\n",
      "Epoch 75/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.2680 - accuracy: 0.8725 - val_loss: 1.5441 - val_accuracy: 0.5846\n",
      "Epoch 76/1000\n",
      "5600/5600 [==============================] - 0s 43us/sample - loss: 0.2719 - accuracy: 0.8771 - val_loss: 1.6175 - val_accuracy: 0.5725\n",
      "Epoch 77/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.2725 - accuracy: 0.8763 - val_loss: 1.6151 - val_accuracy: 0.5550\n",
      "Epoch 78/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.2659 - accuracy: 0.8761 - val_loss: 1.5863 - val_accuracy: 0.5775\n",
      "Epoch 79/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.2533 - accuracy: 0.8854 - val_loss: 1.5753 - val_accuracy: 0.5863\n",
      "Epoch 80/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.2429 - accuracy: 0.8898 - val_loss: 1.5879 - val_accuracy: 0.5962\n",
      "Epoch 81/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.2348 - accuracy: 0.8950 - val_loss: 1.6102 - val_accuracy: 0.5817\n",
      "Epoch 82/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.2369 - accuracy: 0.8968 - val_loss: 1.6611 - val_accuracy: 0.5942\n",
      "Epoch 83/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.2437 - accuracy: 0.8909 - val_loss: 1.6707 - val_accuracy: 0.5850\n",
      "Epoch 84/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.2370 - accuracy: 0.8925 - val_loss: 1.6552 - val_accuracy: 0.5783\n",
      "Epoch 85/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.2344 - accuracy: 0.8918 - val_loss: 1.6911 - val_accuracy: 0.5996\n",
      "Epoch 86/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.2189 - accuracy: 0.9052 - val_loss: 1.8016 - val_accuracy: 0.5867\n",
      "Epoch 87/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.2209 - accuracy: 0.9011 - val_loss: 1.7177 - val_accuracy: 0.5958\n",
      "Epoch 88/1000\n",
      "5600/5600 [==============================] - 0s 43us/sample - loss: 0.2228 - accuracy: 0.9046 - val_loss: 1.7582 - val_accuracy: 0.5804\n",
      "Epoch 89/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.2270 - accuracy: 0.8975 - val_loss: 1.8293 - val_accuracy: 0.5858\n",
      "Epoch 90/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.2209 - accuracy: 0.9038 - val_loss: 1.7763 - val_accuracy: 0.5779\n",
      "Epoch 91/1000\n",
      "5600/5600 [==============================] - 0s 43us/sample - loss: 0.2079 - accuracy: 0.9075 - val_loss: 1.8148 - val_accuracy: 0.5850\n",
      "Epoch 92/1000\n",
      "5600/5600 [==============================] - 0s 44us/sample - loss: 0.1979 - accuracy: 0.9134 - val_loss: 1.8581 - val_accuracy: 0.5971\n",
      "Epoch 93/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.1936 - accuracy: 0.9186 - val_loss: 1.8840 - val_accuracy: 0.5829\n",
      "Epoch 94/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.1958 - accuracy: 0.9162 - val_loss: 1.8791 - val_accuracy: 0.5679\n",
      "Epoch 95/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.1963 - accuracy: 0.9200 - val_loss: 1.9284 - val_accuracy: 0.5858\n",
      "Epoch 96/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.2039 - accuracy: 0.9157 - val_loss: 1.9433 - val_accuracy: 0.5888\n",
      "Epoch 97/1000\n",
      "5600/5600 [==============================] - 0s 42us/sample - loss: 0.1843 - accuracy: 0.9202 - val_loss: 1.9577 - val_accuracy: 0.6029\n",
      "Epoch 98/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.2066 - accuracy: 0.9098 - val_loss: 1.9626 - val_accuracy: 0.5679\n",
      "Epoch 99/1000\n",
      "5600/5600 [==============================] - 0s 42us/sample - loss: 0.2088 - accuracy: 0.9114 - val_loss: 1.9558 - val_accuracy: 0.5804\n",
      "Epoch 100/1000\n",
      "5600/5600 [==============================] - 0s 43us/sample - loss: 0.2196 - accuracy: 0.9025 - val_loss: 1.9036 - val_accuracy: 0.5954\n",
      "Epoch 101/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.2045 - accuracy: 0.9107 - val_loss: 2.0133 - val_accuracy: 0.5738\n",
      "Epoch 102/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.1868 - accuracy: 0.9214 - val_loss: 1.9850 - val_accuracy: 0.5808\n",
      "Epoch 103/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.1771 - accuracy: 0.9246 - val_loss: 2.0031 - val_accuracy: 0.5804\n",
      "Epoch 104/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.1663 - accuracy: 0.9279 - val_loss: 2.1135 - val_accuracy: 0.5917\n",
      "Epoch 105/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 0.1517 - accuracy: 0.9380 - val_loss: 2.0354 - val_accuracy: 0.5908\n",
      "Epoch 106/1000\n",
      "5600/5600 [==============================] - 0s 43us/sample - loss: 0.1483 - accuracy: 0.9402 - val_loss: 2.0994 - val_accuracy: 0.5846\n",
      "Epoch 107/1000\n",
      "5600/5600 [==============================] - 0s 52us/sample - loss: 0.1447 - accuracy: 0.9436 - val_loss: 2.1310 - val_accuracy: 0.5775\n",
      "Epoch 108/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.1442 - accuracy: 0.9436 - val_loss: 2.1405 - val_accuracy: 0.5858\n",
      "Epoch 109/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.1408 - accuracy: 0.9459 - val_loss: 2.1783 - val_accuracy: 0.5754\n",
      "Epoch 110/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.1333 - accuracy: 0.9475 - val_loss: 2.1810 - val_accuracy: 0.5967\n",
      "Epoch 111/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.1374 - accuracy: 0.9463 - val_loss: 2.2914 - val_accuracy: 0.5775\n",
      "Epoch 112/1000\n",
      "5600/5600 [==============================] - 0s 43us/sample - loss: 0.1848 - accuracy: 0.9214 - val_loss: 2.1859 - val_accuracy: 0.5650\n",
      "Epoch 113/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.1849 - accuracy: 0.9259 - val_loss: 2.1745 - val_accuracy: 0.5858\n",
      "Epoch 114/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.1824 - accuracy: 0.9236 - val_loss: 2.2064 - val_accuracy: 0.5883\n",
      "Epoch 115/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.1799 - accuracy: 0.9236 - val_loss: 2.1873 - val_accuracy: 0.5654\n",
      "Epoch 116/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.1647 - accuracy: 0.9312 - val_loss: 2.1955 - val_accuracy: 0.5867\n",
      "Epoch 117/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.1583 - accuracy: 0.9346 - val_loss: 2.3033 - val_accuracy: 0.5871\n",
      "Epoch 118/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.1457 - accuracy: 0.9418 - val_loss: 2.2417 - val_accuracy: 0.5725\n",
      "Epoch 119/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.1578 - accuracy: 0.9404 - val_loss: 2.2472 - val_accuracy: 0.5942\n",
      "Epoch 120/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.1404 - accuracy: 0.9470 - val_loss: 2.3003 - val_accuracy: 0.5838\n",
      "Epoch 121/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.1458 - accuracy: 0.9413 - val_loss: 2.2811 - val_accuracy: 0.5783\n",
      "Epoch 122/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.1430 - accuracy: 0.9396 - val_loss: 2.2834 - val_accuracy: 0.5704\n",
      "Epoch 123/1000\n",
      "5600/5600 [==============================] - 0s 52us/sample - loss: 0.1304 - accuracy: 0.9502 - val_loss: 2.3018 - val_accuracy: 0.5925\n",
      "Epoch 124/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 0.1322 - accuracy: 0.9473 - val_loss: 2.3813 - val_accuracy: 0.5821\n",
      "Epoch 125/1000\n",
      "5600/5600 [==============================] - 0s 45us/sample - loss: 0.1324 - accuracy: 0.9507 - val_loss: 2.3362 - val_accuracy: 0.5833\n",
      "Epoch 126/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.1216 - accuracy: 0.9538 - val_loss: 2.4621 - val_accuracy: 0.5892\n",
      "Epoch 127/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.1197 - accuracy: 0.9523 - val_loss: 2.3699 - val_accuracy: 0.5871\n",
      "Epoch 128/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.1123 - accuracy: 0.9582 - val_loss: 2.4269 - val_accuracy: 0.5792\n",
      "Epoch 129/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.1102 - accuracy: 0.9582 - val_loss: 2.4411 - val_accuracy: 0.5892\n",
      "Epoch 130/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.1193 - accuracy: 0.9534 - val_loss: 2.3497 - val_accuracy: 0.5788\n",
      "Epoch 131/1000\n",
      "5600/5600 [==============================] - 0s 48us/sample - loss: 0.1044 - accuracy: 0.9604 - val_loss: 2.4467 - val_accuracy: 0.5775\n",
      "Epoch 132/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.0975 - accuracy: 0.9646 - val_loss: 2.4851 - val_accuracy: 0.5875\n",
      "Epoch 133/1000\n",
      "5600/5600 [==============================] - 0s 53us/sample - loss: 0.1061 - accuracy: 0.9629 - val_loss: 2.5022 - val_accuracy: 0.5612\n",
      "Epoch 134/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.1067 - accuracy: 0.9589 - val_loss: 2.5503 - val_accuracy: 0.5992\n",
      "Epoch 135/1000\n",
      "5600/5600 [==============================] - 0s 42us/sample - loss: 0.1119 - accuracy: 0.9568 - val_loss: 2.4516 - val_accuracy: 0.5838\n",
      "Epoch 136/1000\n",
      "5600/5600 [==============================] - 0s 48us/sample - loss: 0.0969 - accuracy: 0.9639 - val_loss: 2.4701 - val_accuracy: 0.5842\n",
      "Epoch 137/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.0947 - accuracy: 0.9659 - val_loss: 2.5598 - val_accuracy: 0.5838\n",
      "Epoch 138/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 0.0969 - accuracy: 0.9663 - val_loss: 2.5882 - val_accuracy: 0.5846\n",
      "Epoch 139/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.1100 - accuracy: 0.9596 - val_loss: 2.6042 - val_accuracy: 0.5788\n",
      "Epoch 140/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 0.1217 - accuracy: 0.9575 - val_loss: 2.5607 - val_accuracy: 0.5833\n",
      "Epoch 141/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.1389 - accuracy: 0.9420 - val_loss: 2.5652 - val_accuracy: 0.5896\n",
      "Epoch 142/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.1628 - accuracy: 0.9359 - val_loss: 2.5803 - val_accuracy: 0.5629\n",
      "Epoch 143/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.1889 - accuracy: 0.9300 - val_loss: 2.5308 - val_accuracy: 0.5900\n",
      "Epoch 144/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.2069 - accuracy: 0.9245 - val_loss: 2.4611 - val_accuracy: 0.5838\n",
      "Epoch 145/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.1533 - accuracy: 0.9439 - val_loss: 2.4559 - val_accuracy: 0.5775\n",
      "Epoch 146/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.1175 - accuracy: 0.9554 - val_loss: 2.4697 - val_accuracy: 0.5813\n",
      "Epoch 147/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0966 - accuracy: 0.9700 - val_loss: 2.5197 - val_accuracy: 0.5808\n",
      "Epoch 148/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0860 - accuracy: 0.9705 - val_loss: 2.5506 - val_accuracy: 0.5700\n",
      "Epoch 149/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0777 - accuracy: 0.9737 - val_loss: 2.5858 - val_accuracy: 0.5879\n",
      "Epoch 150/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0826 - accuracy: 0.9702 - val_loss: 2.6312 - val_accuracy: 0.5667\n",
      "Epoch 151/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0811 - accuracy: 0.9705 - val_loss: 2.6921 - val_accuracy: 0.5783\n",
      "Epoch 152/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0871 - accuracy: 0.9680 - val_loss: 2.6867 - val_accuracy: 0.5729\n",
      "Epoch 153/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0996 - accuracy: 0.9623 - val_loss: 2.7310 - val_accuracy: 0.5829\n",
      "Epoch 154/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.0947 - accuracy: 0.9661 - val_loss: 2.6502 - val_accuracy: 0.5925\n",
      "Epoch 155/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0843 - accuracy: 0.9689 - val_loss: 2.7038 - val_accuracy: 0.5754\n",
      "Epoch 156/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0855 - accuracy: 0.9714 - val_loss: 2.7356 - val_accuracy: 0.5646\n",
      "Epoch 157/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0750 - accuracy: 0.9748 - val_loss: 2.7215 - val_accuracy: 0.5846\n",
      "Epoch 158/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0752 - accuracy: 0.9761 - val_loss: 2.7485 - val_accuracy: 0.5742\n",
      "Epoch 159/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0759 - accuracy: 0.9746 - val_loss: 2.7397 - val_accuracy: 0.5779\n",
      "Epoch 160/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0788 - accuracy: 0.9709 - val_loss: 2.7996 - val_accuracy: 0.5767\n",
      "Epoch 161/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.0870 - accuracy: 0.9684 - val_loss: 2.8149 - val_accuracy: 0.5742\n",
      "Epoch 162/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0861 - accuracy: 0.9682 - val_loss: 2.7867 - val_accuracy: 0.5808\n",
      "Epoch 163/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0890 - accuracy: 0.9677 - val_loss: 2.7730 - val_accuracy: 0.5754\n",
      "Epoch 164/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.0969 - accuracy: 0.9661 - val_loss: 2.7860 - val_accuracy: 0.5717\n",
      "Epoch 165/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0891 - accuracy: 0.9696 - val_loss: 2.7726 - val_accuracy: 0.5763\n",
      "Epoch 166/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0882 - accuracy: 0.9693 - val_loss: 2.8220 - val_accuracy: 0.5792\n",
      "Epoch 167/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.1008 - accuracy: 0.9614 - val_loss: 2.7703 - val_accuracy: 0.5817\n",
      "Epoch 168/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0913 - accuracy: 0.9670 - val_loss: 2.7750 - val_accuracy: 0.5933\n",
      "Epoch 169/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0986 - accuracy: 0.9638 - val_loss: 2.8413 - val_accuracy: 0.5679\n",
      "Epoch 170/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.1120 - accuracy: 0.9598 - val_loss: 2.7825 - val_accuracy: 0.5708\n",
      "Epoch 171/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.1527 - accuracy: 0.9427 - val_loss: 2.7739 - val_accuracy: 0.5796\n",
      "Epoch 172/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.1931 - accuracy: 0.9282 - val_loss: 2.8163 - val_accuracy: 0.5596\n",
      "Epoch 173/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.1433 - accuracy: 0.9475 - val_loss: 2.6524 - val_accuracy: 0.5792\n",
      "Epoch 174/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.1225 - accuracy: 0.9543 - val_loss: 2.7528 - val_accuracy: 0.5783\n",
      "Epoch 175/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0906 - accuracy: 0.9663 - val_loss: 2.7328 - val_accuracy: 0.5692\n",
      "Epoch 176/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0820 - accuracy: 0.9718 - val_loss: 2.8243 - val_accuracy: 0.5775\n",
      "Epoch 177/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0662 - accuracy: 0.9773 - val_loss: 2.7731 - val_accuracy: 0.5654\n",
      "Epoch 178/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0600 - accuracy: 0.9825 - val_loss: 2.8438 - val_accuracy: 0.5738\n",
      "Epoch 179/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0622 - accuracy: 0.9796 - val_loss: 2.8592 - val_accuracy: 0.5696\n",
      "Epoch 180/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0588 - accuracy: 0.9809 - val_loss: 2.8064 - val_accuracy: 0.5725\n",
      "Epoch 181/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0518 - accuracy: 0.9850 - val_loss: 2.8976 - val_accuracy: 0.5717\n",
      "Epoch 182/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0511 - accuracy: 0.9841 - val_loss: 2.9195 - val_accuracy: 0.5829\n",
      "Epoch 183/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.0592 - accuracy: 0.9830 - val_loss: 2.8989 - val_accuracy: 0.5708\n",
      "Epoch 184/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.0644 - accuracy: 0.9782 - val_loss: 2.9105 - val_accuracy: 0.5729\n",
      "Epoch 185/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0679 - accuracy: 0.9771 - val_loss: 2.9169 - val_accuracy: 0.5871\n",
      "Epoch 186/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0740 - accuracy: 0.9721 - val_loss: 2.9317 - val_accuracy: 0.5742\n",
      "Epoch 187/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0650 - accuracy: 0.9779 - val_loss: 2.9447 - val_accuracy: 0.5758\n",
      "Epoch 188/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0561 - accuracy: 0.9809 - val_loss: 2.9456 - val_accuracy: 0.5846\n",
      "Epoch 189/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0560 - accuracy: 0.9812 - val_loss: 2.9357 - val_accuracy: 0.5883\n",
      "Epoch 190/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0566 - accuracy: 0.9821 - val_loss: 2.9825 - val_accuracy: 0.5738\n",
      "Epoch 191/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0576 - accuracy: 0.9805 - val_loss: 2.9565 - val_accuracy: 0.5754\n",
      "Epoch 192/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0708 - accuracy: 0.9734 - val_loss: 3.0203 - val_accuracy: 0.5733\n",
      "Epoch 193/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0858 - accuracy: 0.9682 - val_loss: 2.9204 - val_accuracy: 0.5825\n",
      "Epoch 194/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0859 - accuracy: 0.9714 - val_loss: 2.9247 - val_accuracy: 0.5825\n",
      "Epoch 195/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0828 - accuracy: 0.9720 - val_loss: 2.9697 - val_accuracy: 0.5754\n",
      "Epoch 196/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.1249 - accuracy: 0.9539 - val_loss: 2.9313 - val_accuracy: 0.5675\n",
      "Epoch 197/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.1265 - accuracy: 0.9546 - val_loss: 3.0650 - val_accuracy: 0.5471\n",
      "Epoch 198/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.1487 - accuracy: 0.9454 - val_loss: 2.8398 - val_accuracy: 0.5675\n",
      "Epoch 199/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.1346 - accuracy: 0.9493 - val_loss: 2.8145 - val_accuracy: 0.5621\n",
      "Epoch 200/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0920 - accuracy: 0.9670 - val_loss: 2.9522 - val_accuracy: 0.5612\n",
      "Epoch 201/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.1003 - accuracy: 0.9632 - val_loss: 2.8620 - val_accuracy: 0.5796\n",
      "Epoch 202/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0711 - accuracy: 0.9780 - val_loss: 2.8656 - val_accuracy: 0.5825\n",
      "Epoch 203/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0716 - accuracy: 0.9779 - val_loss: 2.9750 - val_accuracy: 0.5779\n",
      "Epoch 204/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0603 - accuracy: 0.9820 - val_loss: 2.8962 - val_accuracy: 0.5767\n",
      "Epoch 205/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0491 - accuracy: 0.9857 - val_loss: 2.9638 - val_accuracy: 0.5775\n",
      "Epoch 206/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0498 - accuracy: 0.9857 - val_loss: 2.9660 - val_accuracy: 0.5783\n",
      "Epoch 207/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0464 - accuracy: 0.9870 - val_loss: 3.0228 - val_accuracy: 0.5783\n",
      "Epoch 208/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0462 - accuracy: 0.9857 - val_loss: 2.9829 - val_accuracy: 0.5858\n",
      "Epoch 209/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0461 - accuracy: 0.9887 - val_loss: 2.9959 - val_accuracy: 0.5725\n",
      "Epoch 210/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0469 - accuracy: 0.9862 - val_loss: 3.0457 - val_accuracy: 0.5775\n",
      "Epoch 211/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0466 - accuracy: 0.9857 - val_loss: 3.0676 - val_accuracy: 0.5842\n",
      "Epoch 212/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0503 - accuracy: 0.9846 - val_loss: 3.0125 - val_accuracy: 0.5821\n",
      "Epoch 213/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0521 - accuracy: 0.9855 - val_loss: 3.0748 - val_accuracy: 0.5813\n",
      "Epoch 214/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.0599 - accuracy: 0.9812 - val_loss: 3.0171 - val_accuracy: 0.5813\n",
      "Epoch 215/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0570 - accuracy: 0.9814 - val_loss: 3.0180 - val_accuracy: 0.5800\n",
      "Epoch 216/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0758 - accuracy: 0.9741 - val_loss: 3.0430 - val_accuracy: 0.5738\n",
      "Epoch 217/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0830 - accuracy: 0.9711 - val_loss: 3.0178 - val_accuracy: 0.5654\n",
      "Epoch 218/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.1106 - accuracy: 0.9613 - val_loss: 3.0103 - val_accuracy: 0.5779\n",
      "Epoch 219/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.1064 - accuracy: 0.9607 - val_loss: 3.1044 - val_accuracy: 0.5750\n",
      "Epoch 220/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.1019 - accuracy: 0.9671 - val_loss: 3.0335 - val_accuracy: 0.5717\n",
      "Epoch 221/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.1104 - accuracy: 0.9625 - val_loss: 2.9757 - val_accuracy: 0.5679\n",
      "Epoch 222/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0993 - accuracy: 0.9648 - val_loss: 2.9482 - val_accuracy: 0.5817\n",
      "Epoch 223/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0792 - accuracy: 0.9730 - val_loss: 2.9684 - val_accuracy: 0.5758\n",
      "Epoch 224/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0619 - accuracy: 0.9816 - val_loss: 3.0130 - val_accuracy: 0.5833\n",
      "Epoch 225/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0569 - accuracy: 0.9821 - val_loss: 3.0435 - val_accuracy: 0.5775\n",
      "Epoch 226/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0501 - accuracy: 0.9846 - val_loss: 3.1073 - val_accuracy: 0.5800\n",
      "Epoch 227/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0642 - accuracy: 0.9779 - val_loss: 3.0565 - val_accuracy: 0.5867\n",
      "Epoch 228/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0540 - accuracy: 0.9804 - val_loss: 3.0665 - val_accuracy: 0.5942\n",
      "Epoch 229/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0578 - accuracy: 0.9823 - val_loss: 3.1362 - val_accuracy: 0.5854\n",
      "Epoch 230/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0482 - accuracy: 0.9852 - val_loss: 3.1047 - val_accuracy: 0.5779\n",
      "Epoch 231/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0546 - accuracy: 0.9814 - val_loss: 3.1079 - val_accuracy: 0.5717\n",
      "Epoch 232/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0592 - accuracy: 0.9807 - val_loss: 3.0665 - val_accuracy: 0.5813\n",
      "Epoch 233/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0585 - accuracy: 0.9818 - val_loss: 3.1386 - val_accuracy: 0.5850\n",
      "Epoch 234/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0531 - accuracy: 0.9827 - val_loss: 3.0719 - val_accuracy: 0.5875\n",
      "Epoch 235/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0402 - accuracy: 0.9870 - val_loss: 3.1695 - val_accuracy: 0.5788\n",
      "Epoch 236/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0491 - accuracy: 0.9846 - val_loss: 3.1921 - val_accuracy: 0.5813\n",
      "Epoch 237/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0552 - accuracy: 0.9829 - val_loss: 3.1514 - val_accuracy: 0.5704\n",
      "Epoch 238/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0530 - accuracy: 0.9814 - val_loss: 3.0945 - val_accuracy: 0.5838\n",
      "Epoch 239/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0515 - accuracy: 0.9812 - val_loss: 3.2078 - val_accuracy: 0.5742\n",
      "Epoch 240/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0560 - accuracy: 0.9805 - val_loss: 3.1333 - val_accuracy: 0.5854\n",
      "Epoch 241/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0734 - accuracy: 0.9755 - val_loss: 3.1483 - val_accuracy: 0.5779\n",
      "Epoch 242/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.0731 - accuracy: 0.9761 - val_loss: 3.1042 - val_accuracy: 0.5867\n",
      "Epoch 243/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.1119 - accuracy: 0.9589 - val_loss: 3.2245 - val_accuracy: 0.5621\n",
      "Epoch 244/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.1734 - accuracy: 0.9409 - val_loss: 3.2351 - val_accuracy: 0.5567\n",
      "Epoch 245/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.1447 - accuracy: 0.9477 - val_loss: 2.9547 - val_accuracy: 0.5792\n",
      "Epoch 246/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.1028 - accuracy: 0.9632 - val_loss: 2.8919 - val_accuracy: 0.5871\n",
      "Epoch 247/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0804 - accuracy: 0.9689 - val_loss: 3.0734 - val_accuracy: 0.5696\n",
      "Epoch 248/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0624 - accuracy: 0.9805 - val_loss: 3.0219 - val_accuracy: 0.5700\n",
      "Epoch 249/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0511 - accuracy: 0.9846 - val_loss: 3.0653 - val_accuracy: 0.5763\n",
      "Epoch 250/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0519 - accuracy: 0.9837 - val_loss: 3.0121 - val_accuracy: 0.5829\n",
      "Epoch 251/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0409 - accuracy: 0.9889 - val_loss: 3.1139 - val_accuracy: 0.5817\n",
      "Epoch 252/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.0364 - accuracy: 0.9887 - val_loss: 3.1201 - val_accuracy: 0.5783\n",
      "Epoch 253/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0403 - accuracy: 0.9884 - val_loss: 3.1136 - val_accuracy: 0.5938\n",
      "Epoch 254/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0413 - accuracy: 0.9875 - val_loss: 3.1780 - val_accuracy: 0.5738\n",
      "Epoch 255/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0445 - accuracy: 0.9861 - val_loss: 3.2152 - val_accuracy: 0.5779\n",
      "Epoch 256/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.0454 - accuracy: 0.9839 - val_loss: 3.2318 - val_accuracy: 0.5696\n",
      "Epoch 257/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0493 - accuracy: 0.9837 - val_loss: 3.1580 - val_accuracy: 0.5875\n",
      "Epoch 258/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0466 - accuracy: 0.9829 - val_loss: 3.1526 - val_accuracy: 0.5908\n",
      "Epoch 259/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0494 - accuracy: 0.9825 - val_loss: 3.1170 - val_accuracy: 0.5775\n",
      "Epoch 260/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0511 - accuracy: 0.9827 - val_loss: 3.1215 - val_accuracy: 0.5688\n",
      "Epoch 261/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0454 - accuracy: 0.9868 - val_loss: 3.1008 - val_accuracy: 0.5858\n",
      "Epoch 262/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0527 - accuracy: 0.9820 - val_loss: 3.1669 - val_accuracy: 0.5758\n",
      "Epoch 263/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0528 - accuracy: 0.9839 - val_loss: 3.1353 - val_accuracy: 0.5788\n",
      "Epoch 264/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0527 - accuracy: 0.9816 - val_loss: 3.1748 - val_accuracy: 0.5921\n",
      "Epoch 265/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0626 - accuracy: 0.9793 - val_loss: 3.2047 - val_accuracy: 0.5758\n",
      "Epoch 266/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0616 - accuracy: 0.9780 - val_loss: 3.1904 - val_accuracy: 0.5738\n",
      "Epoch 267/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0694 - accuracy: 0.9745 - val_loss: 3.2268 - val_accuracy: 0.5771\n",
      "Epoch 268/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0624 - accuracy: 0.9793 - val_loss: 3.2084 - val_accuracy: 0.5767\n",
      "Epoch 269/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0631 - accuracy: 0.9789 - val_loss: 3.2689 - val_accuracy: 0.5596\n",
      "Epoch 270/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0790 - accuracy: 0.9725 - val_loss: 3.2265 - val_accuracy: 0.5733\n",
      "Epoch 271/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0703 - accuracy: 0.9750 - val_loss: 3.1922 - val_accuracy: 0.5813\n",
      "Epoch 272/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0702 - accuracy: 0.9779 - val_loss: 3.2071 - val_accuracy: 0.5742\n",
      "Epoch 273/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0972 - accuracy: 0.9648 - val_loss: 3.1924 - val_accuracy: 0.5842\n",
      "Epoch 274/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0975 - accuracy: 0.9645 - val_loss: 3.0924 - val_accuracy: 0.5867\n",
      "Epoch 275/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0624 - accuracy: 0.9770 - val_loss: 3.2149 - val_accuracy: 0.5671\n",
      "Epoch 276/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0440 - accuracy: 0.9868 - val_loss: 3.1421 - val_accuracy: 0.5879\n",
      "Epoch 277/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0428 - accuracy: 0.9870 - val_loss: 3.2959 - val_accuracy: 0.5775\n",
      "Epoch 278/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0404 - accuracy: 0.9868 - val_loss: 3.2153 - val_accuracy: 0.5796\n",
      "Epoch 279/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0448 - accuracy: 0.9854 - val_loss: 3.3375 - val_accuracy: 0.5717\n",
      "Epoch 280/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0458 - accuracy: 0.9854 - val_loss: 3.2004 - val_accuracy: 0.5792\n",
      "Epoch 281/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0403 - accuracy: 0.9864 - val_loss: 3.2421 - val_accuracy: 0.5804\n",
      "Epoch 282/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0406 - accuracy: 0.9870 - val_loss: 3.2831 - val_accuracy: 0.5738\n",
      "Epoch 283/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0485 - accuracy: 0.9830 - val_loss: 3.2436 - val_accuracy: 0.5821\n",
      "Epoch 284/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0398 - accuracy: 0.9868 - val_loss: 3.2809 - val_accuracy: 0.5875\n",
      "Epoch 285/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0377 - accuracy: 0.9886 - val_loss: 3.3381 - val_accuracy: 0.5763\n",
      "Epoch 286/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0369 - accuracy: 0.9877 - val_loss: 3.3206 - val_accuracy: 0.5863\n",
      "Epoch 287/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0327 - accuracy: 0.9900 - val_loss: 3.3625 - val_accuracy: 0.5758\n",
      "Epoch 288/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0546 - accuracy: 0.9807 - val_loss: 3.2249 - val_accuracy: 0.5892\n",
      "Epoch 289/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0816 - accuracy: 0.9718 - val_loss: 3.2571 - val_accuracy: 0.5863\n",
      "Epoch 290/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.1042 - accuracy: 0.9625 - val_loss: 3.2788 - val_accuracy: 0.5738\n",
      "Epoch 291/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0940 - accuracy: 0.9684 - val_loss: 3.1390 - val_accuracy: 0.5863\n",
      "Epoch 292/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0981 - accuracy: 0.9663 - val_loss: 3.1353 - val_accuracy: 0.5813\n",
      "Epoch 293/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0827 - accuracy: 0.9698 - val_loss: 3.1742 - val_accuracy: 0.5783\n",
      "Epoch 294/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0988 - accuracy: 0.9684 - val_loss: 3.1351 - val_accuracy: 0.5796\n",
      "Epoch 295/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.1063 - accuracy: 0.9618 - val_loss: 3.1336 - val_accuracy: 0.5696\n",
      "Epoch 296/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0799 - accuracy: 0.9718 - val_loss: 3.1882 - val_accuracy: 0.5754\n",
      "Epoch 297/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0661 - accuracy: 0.9789 - val_loss: 3.1274 - val_accuracy: 0.5792\n",
      "Epoch 298/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0489 - accuracy: 0.9845 - val_loss: 3.1628 - val_accuracy: 0.5733\n",
      "Epoch 299/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0415 - accuracy: 0.9843 - val_loss: 3.1539 - val_accuracy: 0.5821\n",
      "Epoch 300/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0400 - accuracy: 0.9866 - val_loss: 3.1586 - val_accuracy: 0.5763\n",
      "Epoch 301/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0311 - accuracy: 0.9898 - val_loss: 3.1875 - val_accuracy: 0.5913\n",
      "Epoch 302/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0321 - accuracy: 0.9882 - val_loss: 3.1908 - val_accuracy: 0.5946\n",
      "Epoch 303/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0307 - accuracy: 0.9904 - val_loss: 3.2490 - val_accuracy: 0.5779\n",
      "Epoch 304/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0274 - accuracy: 0.9909 - val_loss: 3.2147 - val_accuracy: 0.5875\n",
      "Epoch 305/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0289 - accuracy: 0.9900 - val_loss: 3.2315 - val_accuracy: 0.5792\n",
      "Epoch 306/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0348 - accuracy: 0.9871 - val_loss: 3.2245 - val_accuracy: 0.5783\n",
      "Epoch 307/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0313 - accuracy: 0.9900 - val_loss: 3.2630 - val_accuracy: 0.5783\n",
      "Epoch 308/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0296 - accuracy: 0.9895 - val_loss: 3.3184 - val_accuracy: 0.5796\n",
      "Epoch 309/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0301 - accuracy: 0.9898 - val_loss: 3.2904 - val_accuracy: 0.5800\n",
      "Epoch 310/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0277 - accuracy: 0.9905 - val_loss: 3.3007 - val_accuracy: 0.5783\n",
      "Epoch 311/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0365 - accuracy: 0.9877 - val_loss: 3.2944 - val_accuracy: 0.5967\n",
      "Epoch 312/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0422 - accuracy: 0.9866 - val_loss: 3.1973 - val_accuracy: 0.5925\n",
      "Epoch 313/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0451 - accuracy: 0.9834 - val_loss: 3.1812 - val_accuracy: 0.5833\n",
      "Epoch 314/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0482 - accuracy: 0.9818 - val_loss: 3.2493 - val_accuracy: 0.5833\n",
      "Epoch 315/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0606 - accuracy: 0.9762 - val_loss: 3.3076 - val_accuracy: 0.5788\n",
      "Epoch 316/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0616 - accuracy: 0.9773 - val_loss: 3.3268 - val_accuracy: 0.5808\n",
      "Epoch 317/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0795 - accuracy: 0.9727 - val_loss: 3.2853 - val_accuracy: 0.5817\n",
      "Epoch 318/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.1016 - accuracy: 0.9614 - val_loss: 3.1445 - val_accuracy: 0.5950\n",
      "Epoch 319/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0904 - accuracy: 0.9652 - val_loss: 3.0796 - val_accuracy: 0.5954\n",
      "Epoch 320/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0687 - accuracy: 0.9725 - val_loss: 3.1994 - val_accuracy: 0.5700\n",
      "Epoch 321/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0519 - accuracy: 0.9823 - val_loss: 3.2268 - val_accuracy: 0.5775\n",
      "Epoch 322/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0449 - accuracy: 0.9848 - val_loss: 3.2404 - val_accuracy: 0.5808\n",
      "Epoch 323/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0303 - accuracy: 0.9909 - val_loss: 3.2855 - val_accuracy: 0.5754\n",
      "Epoch 324/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0268 - accuracy: 0.9904 - val_loss: 3.2368 - val_accuracy: 0.5788\n",
      "Epoch 325/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0250 - accuracy: 0.9909 - val_loss: 3.3072 - val_accuracy: 0.5829\n",
      "Epoch 326/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0295 - accuracy: 0.9902 - val_loss: 3.2444 - val_accuracy: 0.5875\n",
      "Epoch 327/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0289 - accuracy: 0.9902 - val_loss: 3.3325 - val_accuracy: 0.5733\n",
      "Epoch 328/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0303 - accuracy: 0.9898 - val_loss: 3.3086 - val_accuracy: 0.5775\n",
      "Epoch 329/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0282 - accuracy: 0.9900 - val_loss: 3.2989 - val_accuracy: 0.5888\n",
      "Epoch 330/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0254 - accuracy: 0.9912 - val_loss: 3.2722 - val_accuracy: 0.5896\n",
      "Epoch 331/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0335 - accuracy: 0.9877 - val_loss: 3.3469 - val_accuracy: 0.5758\n",
      "Epoch 332/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0295 - accuracy: 0.9880 - val_loss: 3.3521 - val_accuracy: 0.5858\n",
      "Epoch 333/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0305 - accuracy: 0.9893 - val_loss: 3.3401 - val_accuracy: 0.5842\n",
      "Epoch 334/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0300 - accuracy: 0.9889 - val_loss: 3.3691 - val_accuracy: 0.5813\n",
      "Epoch 335/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0340 - accuracy: 0.9880 - val_loss: 3.2764 - val_accuracy: 0.5825\n",
      "Epoch 336/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0328 - accuracy: 0.9889 - val_loss: 3.3487 - val_accuracy: 0.5754\n",
      "Epoch 337/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0349 - accuracy: 0.9879 - val_loss: 3.3341 - val_accuracy: 0.5863\n",
      "Epoch 338/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0450 - accuracy: 0.9829 - val_loss: 3.2876 - val_accuracy: 0.5863\n",
      "Epoch 339/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0860 - accuracy: 0.9711 - val_loss: 3.3077 - val_accuracy: 0.5796\n",
      "Epoch 340/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.0869 - accuracy: 0.9679 - val_loss: 3.3028 - val_accuracy: 0.5700\n",
      "Epoch 341/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.1264 - accuracy: 0.9595 - val_loss: 3.1607 - val_accuracy: 0.5867\n",
      "Epoch 342/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.1503 - accuracy: 0.9479 - val_loss: 2.9275 - val_accuracy: 0.5871\n",
      "Epoch 343/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.1064 - accuracy: 0.9600 - val_loss: 2.8925 - val_accuracy: 0.5729\n",
      "Epoch 344/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.1000 - accuracy: 0.9629 - val_loss: 2.9923 - val_accuracy: 0.5954\n",
      "Epoch 345/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0437 - accuracy: 0.9843 - val_loss: 3.0649 - val_accuracy: 0.5775\n",
      "Epoch 346/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0310 - accuracy: 0.9887 - val_loss: 3.1502 - val_accuracy: 0.5838\n",
      "Epoch 347/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0388 - accuracy: 0.9855 - val_loss: 3.1522 - val_accuracy: 0.5750\n",
      "Epoch 348/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0240 - accuracy: 0.9923 - val_loss: 3.2652 - val_accuracy: 0.5708\n",
      "Epoch 349/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0213 - accuracy: 0.9918 - val_loss: 3.1807 - val_accuracy: 0.5808\n",
      "Epoch 350/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0258 - accuracy: 0.9912 - val_loss: 3.2394 - val_accuracy: 0.5875\n",
      "Epoch 351/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0272 - accuracy: 0.9904 - val_loss: 3.1913 - val_accuracy: 0.5800\n",
      "Epoch 352/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0245 - accuracy: 0.9909 - val_loss: 3.2504 - val_accuracy: 0.5850\n",
      "Epoch 353/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0256 - accuracy: 0.9920 - val_loss: 3.2472 - val_accuracy: 0.5813\n",
      "Epoch 354/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0259 - accuracy: 0.9920 - val_loss: 3.3362 - val_accuracy: 0.5796\n",
      "Epoch 355/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0262 - accuracy: 0.9907 - val_loss: 3.3266 - val_accuracy: 0.5696\n",
      "Epoch 356/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0234 - accuracy: 0.9912 - val_loss: 3.3351 - val_accuracy: 0.5879\n",
      "Epoch 357/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0220 - accuracy: 0.9923 - val_loss: 3.2724 - val_accuracy: 0.5813\n",
      "Epoch 358/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0257 - accuracy: 0.9911 - val_loss: 3.2517 - val_accuracy: 0.5721\n",
      "Epoch 359/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0244 - accuracy: 0.9921 - val_loss: 3.2691 - val_accuracy: 0.5713\n",
      "Epoch 360/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0257 - accuracy: 0.9904 - val_loss: 3.3042 - val_accuracy: 0.5817\n",
      "Epoch 361/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0269 - accuracy: 0.9898 - val_loss: 3.2919 - val_accuracy: 0.5813\n",
      "Epoch 362/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0299 - accuracy: 0.9880 - val_loss: 3.3172 - val_accuracy: 0.5804\n",
      "Epoch 363/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0508 - accuracy: 0.9827 - val_loss: 3.3249 - val_accuracy: 0.5767\n",
      "Epoch 364/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0707 - accuracy: 0.9750 - val_loss: 3.2488 - val_accuracy: 0.5821\n",
      "Epoch 365/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0699 - accuracy: 0.9723 - val_loss: 3.3153 - val_accuracy: 0.6025\n",
      "Epoch 366/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0855 - accuracy: 0.9684 - val_loss: 3.2619 - val_accuracy: 0.5658\n",
      "Epoch 367/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0771 - accuracy: 0.9752 - val_loss: 3.1895 - val_accuracy: 0.5808\n",
      "Epoch 368/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0605 - accuracy: 0.9757 - val_loss: 3.2359 - val_accuracy: 0.5800\n",
      "Epoch 369/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0676 - accuracy: 0.9793 - val_loss: 3.2456 - val_accuracy: 0.5750\n",
      "Epoch 370/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0600 - accuracy: 0.9786 - val_loss: 3.2520 - val_accuracy: 0.5767\n",
      "Epoch 371/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0600 - accuracy: 0.9771 - val_loss: 3.2328 - val_accuracy: 0.5779\n",
      "Epoch 372/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0524 - accuracy: 0.9829 - val_loss: 3.2606 - val_accuracy: 0.5783\n",
      "Epoch 373/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0324 - accuracy: 0.9880 - val_loss: 3.2942 - val_accuracy: 0.5796\n",
      "Epoch 374/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0335 - accuracy: 0.9886 - val_loss: 3.2476 - val_accuracy: 0.5858\n",
      "Epoch 375/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0302 - accuracy: 0.9882 - val_loss: 3.2809 - val_accuracy: 0.5775\n",
      "Epoch 376/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0270 - accuracy: 0.9898 - val_loss: 3.2831 - val_accuracy: 0.5900\n",
      "Epoch 377/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0254 - accuracy: 0.9911 - val_loss: 3.3495 - val_accuracy: 0.5883\n",
      "Epoch 378/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0371 - accuracy: 0.9868 - val_loss: 3.2671 - val_accuracy: 0.5804\n",
      "Epoch 379/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0355 - accuracy: 0.9868 - val_loss: 3.2060 - val_accuracy: 0.5888\n",
      "Epoch 380/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0468 - accuracy: 0.9837 - val_loss: 3.3754 - val_accuracy: 0.5833\n",
      "Epoch 381/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0824 - accuracy: 0.9711 - val_loss: 3.2921 - val_accuracy: 0.5646\n",
      "Epoch 382/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0622 - accuracy: 0.9771 - val_loss: 3.3323 - val_accuracy: 0.5704\n",
      "Epoch 383/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0498 - accuracy: 0.9804 - val_loss: 3.3122 - val_accuracy: 0.5863\n",
      "Epoch 384/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0520 - accuracy: 0.9816 - val_loss: 3.2571 - val_accuracy: 0.5792\n",
      "Epoch 385/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0426 - accuracy: 0.9839 - val_loss: 3.3397 - val_accuracy: 0.5742\n",
      "Epoch 386/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0332 - accuracy: 0.9882 - val_loss: 3.2651 - val_accuracy: 0.5833\n",
      "Epoch 387/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0378 - accuracy: 0.9852 - val_loss: 3.3211 - val_accuracy: 0.5813\n",
      "Epoch 388/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0400 - accuracy: 0.9846 - val_loss: 3.3266 - val_accuracy: 0.5738\n",
      "Epoch 389/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0347 - accuracy: 0.9866 - val_loss: 3.3185 - val_accuracy: 0.5771\n",
      "Epoch 390/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0324 - accuracy: 0.9879 - val_loss: 3.3703 - val_accuracy: 0.5713\n",
      "Epoch 391/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0410 - accuracy: 0.9846 - val_loss: 3.3329 - val_accuracy: 0.5792\n",
      "Epoch 392/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0394 - accuracy: 0.9864 - val_loss: 3.2817 - val_accuracy: 0.5758\n",
      "Epoch 393/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0341 - accuracy: 0.9877 - val_loss: 3.3251 - val_accuracy: 0.5746\n",
      "Epoch 394/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0272 - accuracy: 0.9898 - val_loss: 3.3826 - val_accuracy: 0.5908\n",
      "Epoch 395/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0253 - accuracy: 0.9902 - val_loss: 3.3555 - val_accuracy: 0.5742\n",
      "Epoch 396/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0251 - accuracy: 0.9912 - val_loss: 3.4400 - val_accuracy: 0.5754\n",
      "Epoch 397/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0339 - accuracy: 0.9877 - val_loss: 3.3508 - val_accuracy: 0.5796\n",
      "Epoch 398/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0445 - accuracy: 0.9845 - val_loss: 3.3579 - val_accuracy: 0.5767\n",
      "Epoch 399/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0428 - accuracy: 0.9837 - val_loss: 3.3387 - val_accuracy: 0.5783\n",
      "Epoch 400/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0446 - accuracy: 0.9839 - val_loss: 3.3595 - val_accuracy: 0.5742\n",
      "Epoch 401/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0567 - accuracy: 0.9786 - val_loss: 3.2939 - val_accuracy: 0.5779\n",
      "Epoch 402/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0801 - accuracy: 0.9711 - val_loss: 3.3036 - val_accuracy: 0.5746\n",
      "Epoch 403/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0788 - accuracy: 0.9688 - val_loss: 3.2068 - val_accuracy: 0.5796\n",
      "Epoch 404/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0641 - accuracy: 0.9761 - val_loss: 3.3271 - val_accuracy: 0.5700\n",
      "Epoch 405/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0661 - accuracy: 0.9762 - val_loss: 3.2189 - val_accuracy: 0.5788\n",
      "Epoch 406/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0569 - accuracy: 0.9816 - val_loss: 3.1968 - val_accuracy: 0.5692\n",
      "Epoch 407/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0384 - accuracy: 0.9859 - val_loss: 3.3007 - val_accuracy: 0.5775\n",
      "Epoch 408/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0273 - accuracy: 0.9891 - val_loss: 3.3122 - val_accuracy: 0.5775\n",
      "Epoch 409/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0269 - accuracy: 0.9895 - val_loss: 3.3363 - val_accuracy: 0.5846\n",
      "Epoch 410/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0283 - accuracy: 0.9905 - val_loss: 3.3106 - val_accuracy: 0.5779\n",
      "Epoch 411/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0295 - accuracy: 0.9896 - val_loss: 3.4140 - val_accuracy: 0.5725\n",
      "Epoch 412/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0274 - accuracy: 0.9918 - val_loss: 3.4191 - val_accuracy: 0.5792\n",
      "Epoch 413/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0273 - accuracy: 0.9891 - val_loss: 3.4157 - val_accuracy: 0.5779\n",
      "Epoch 414/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.0359 - accuracy: 0.9875 - val_loss: 3.4217 - val_accuracy: 0.5733\n",
      "Epoch 415/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0394 - accuracy: 0.9870 - val_loss: 3.3776 - val_accuracy: 0.5892\n",
      "Epoch 416/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0471 - accuracy: 0.9820 - val_loss: 3.3863 - val_accuracy: 0.5813\n",
      "Epoch 417/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0458 - accuracy: 0.9814 - val_loss: 3.3851 - val_accuracy: 0.5788\n",
      "Epoch 418/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0319 - accuracy: 0.9891 - val_loss: 3.3959 - val_accuracy: 0.5800\n",
      "Epoch 419/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0235 - accuracy: 0.9909 - val_loss: 3.4235 - val_accuracy: 0.5775\n",
      "Epoch 420/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0246 - accuracy: 0.9914 - val_loss: 3.3704 - val_accuracy: 0.5800\n",
      "Epoch 421/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0333 - accuracy: 0.9884 - val_loss: 3.4756 - val_accuracy: 0.5658\n",
      "Epoch 422/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0383 - accuracy: 0.9868 - val_loss: 3.4020 - val_accuracy: 0.5850\n",
      "Epoch 423/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0339 - accuracy: 0.9864 - val_loss: 3.3847 - val_accuracy: 0.5758\n",
      "Epoch 424/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0404 - accuracy: 0.9868 - val_loss: 3.4881 - val_accuracy: 0.5592\n",
      "Epoch 425/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0250 - accuracy: 0.9889 - val_loss: 3.4078 - val_accuracy: 0.5813\n",
      "Epoch 426/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0239 - accuracy: 0.9920 - val_loss: 3.4805 - val_accuracy: 0.5692\n",
      "Epoch 427/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0242 - accuracy: 0.9907 - val_loss: 3.4374 - val_accuracy: 0.5654\n",
      "Epoch 428/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.0243 - accuracy: 0.9907 - val_loss: 3.4291 - val_accuracy: 0.5650\n",
      "Epoch 429/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0257 - accuracy: 0.9905 - val_loss: 3.4107 - val_accuracy: 0.5733\n",
      "Epoch 430/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.0257 - accuracy: 0.9905 - val_loss: 3.4328 - val_accuracy: 0.5758\n",
      "Epoch 431/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.0264 - accuracy: 0.9893 - val_loss: 3.4825 - val_accuracy: 0.5804\n",
      "Epoch 432/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0251 - accuracy: 0.9909 - val_loss: 3.4856 - val_accuracy: 0.5667\n",
      "Epoch 433/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0286 - accuracy: 0.9900 - val_loss: 3.4837 - val_accuracy: 0.5775\n",
      "Epoch 434/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0351 - accuracy: 0.9859 - val_loss: 3.4861 - val_accuracy: 0.5679\n",
      "Epoch 435/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0452 - accuracy: 0.9834 - val_loss: 3.4223 - val_accuracy: 0.5813\n",
      "Epoch 436/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0607 - accuracy: 0.9791 - val_loss: 3.3482 - val_accuracy: 0.5729\n",
      "Epoch 437/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.0652 - accuracy: 0.9750 - val_loss: 3.3953 - val_accuracy: 0.5742\n",
      "Epoch 438/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0910 - accuracy: 0.9671 - val_loss: 3.4068 - val_accuracy: 0.5750\n",
      "Epoch 439/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0885 - accuracy: 0.9668 - val_loss: 3.3098 - val_accuracy: 0.5692\n",
      "Epoch 440/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0676 - accuracy: 0.9739 - val_loss: 3.2474 - val_accuracy: 0.5846\n",
      "Epoch 441/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0477 - accuracy: 0.9836 - val_loss: 3.3251 - val_accuracy: 0.5767\n",
      "Epoch 442/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0403 - accuracy: 0.9841 - val_loss: 3.4161 - val_accuracy: 0.5746\n",
      "Epoch 443/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0372 - accuracy: 0.9852 - val_loss: 3.3671 - val_accuracy: 0.5658\n",
      "Epoch 444/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0289 - accuracy: 0.9886 - val_loss: 3.3843 - val_accuracy: 0.5808\n",
      "Epoch 445/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0348 - accuracy: 0.9873 - val_loss: 3.4119 - val_accuracy: 0.5775\n",
      "Epoch 446/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0354 - accuracy: 0.9861 - val_loss: 3.4126 - val_accuracy: 0.5579\n",
      "Epoch 447/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0422 - accuracy: 0.9870 - val_loss: 3.4150 - val_accuracy: 0.5750\n",
      "Epoch 448/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0288 - accuracy: 0.9864 - val_loss: 3.4302 - val_accuracy: 0.5842\n",
      "Epoch 449/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0309 - accuracy: 0.9891 - val_loss: 3.4105 - val_accuracy: 0.5746\n",
      "Epoch 450/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0328 - accuracy: 0.9895 - val_loss: 3.5636 - val_accuracy: 0.5567\n",
      "Epoch 451/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0319 - accuracy: 0.9871 - val_loss: 3.4395 - val_accuracy: 0.5779\n",
      "Epoch 452/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0332 - accuracy: 0.9880 - val_loss: 3.4107 - val_accuracy: 0.5850\n",
      "Epoch 453/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0370 - accuracy: 0.9855 - val_loss: 3.4148 - val_accuracy: 0.5750\n",
      "Epoch 454/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0297 - accuracy: 0.9887 - val_loss: 3.4085 - val_accuracy: 0.5800\n",
      "Epoch 455/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0315 - accuracy: 0.9880 - val_loss: 3.4418 - val_accuracy: 0.5733\n",
      "Epoch 456/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0266 - accuracy: 0.9905 - val_loss: 3.4246 - val_accuracy: 0.5833\n",
      "Epoch 457/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0213 - accuracy: 0.9921 - val_loss: 3.4699 - val_accuracy: 0.5892\n",
      "Epoch 458/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0271 - accuracy: 0.9898 - val_loss: 3.4365 - val_accuracy: 0.5817\n",
      "Epoch 459/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0230 - accuracy: 0.9907 - val_loss: 3.4564 - val_accuracy: 0.5854\n",
      "Epoch 460/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0295 - accuracy: 0.9896 - val_loss: 3.5136 - val_accuracy: 0.5537\n",
      "Epoch 461/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0356 - accuracy: 0.9868 - val_loss: 3.4006 - val_accuracy: 0.5800\n",
      "Epoch 462/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0330 - accuracy: 0.9879 - val_loss: 3.4626 - val_accuracy: 0.5596\n",
      "Epoch 463/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0360 - accuracy: 0.9861 - val_loss: 3.4674 - val_accuracy: 0.5729\n",
      "Epoch 464/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0386 - accuracy: 0.9862 - val_loss: 3.4912 - val_accuracy: 0.5738\n",
      "Epoch 465/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0511 - accuracy: 0.9804 - val_loss: 3.4422 - val_accuracy: 0.5692\n",
      "Epoch 466/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0485 - accuracy: 0.9800 - val_loss: 3.4670 - val_accuracy: 0.5813\n",
      "Epoch 467/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0513 - accuracy: 0.9814 - val_loss: 3.4147 - val_accuracy: 0.5763\n",
      "Epoch 468/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0511 - accuracy: 0.9820 - val_loss: 3.3211 - val_accuracy: 0.5779\n",
      "Epoch 469/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0468 - accuracy: 0.9843 - val_loss: 3.3480 - val_accuracy: 0.5813\n",
      "Epoch 470/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0541 - accuracy: 0.9807 - val_loss: 3.3295 - val_accuracy: 0.5771\n",
      "Epoch 471/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0337 - accuracy: 0.9875 - val_loss: 3.4797 - val_accuracy: 0.5733\n",
      "Epoch 472/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.0404 - accuracy: 0.9845 - val_loss: 3.4130 - val_accuracy: 0.5708\n",
      "Epoch 473/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0503 - accuracy: 0.9827 - val_loss: 3.3957 - val_accuracy: 0.5888\n",
      "Epoch 474/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0548 - accuracy: 0.9804 - val_loss: 3.4396 - val_accuracy: 0.5733\n",
      "Epoch 475/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0800 - accuracy: 0.9711 - val_loss: 3.2696 - val_accuracy: 0.5875\n",
      "Epoch 476/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0678 - accuracy: 0.9718 - val_loss: 3.3840 - val_accuracy: 0.5717\n",
      "Epoch 477/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0570 - accuracy: 0.9784 - val_loss: 3.3330 - val_accuracy: 0.5913\n",
      "Epoch 478/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0470 - accuracy: 0.9829 - val_loss: 3.4192 - val_accuracy: 0.5663\n",
      "Epoch 479/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0273 - accuracy: 0.9880 - val_loss: 3.3699 - val_accuracy: 0.5767\n",
      "Epoch 480/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0233 - accuracy: 0.9912 - val_loss: 3.3910 - val_accuracy: 0.5821\n",
      "Epoch 481/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0216 - accuracy: 0.9905 - val_loss: 3.4349 - val_accuracy: 0.5833\n",
      "Epoch 482/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0221 - accuracy: 0.9914 - val_loss: 3.4677 - val_accuracy: 0.5663\n",
      "Epoch 483/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0196 - accuracy: 0.9920 - val_loss: 3.4505 - val_accuracy: 0.5854\n",
      "Epoch 484/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0172 - accuracy: 0.9920 - val_loss: 3.4421 - val_accuracy: 0.5800\n",
      "Epoch 485/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0182 - accuracy: 0.9921 - val_loss: 3.4570 - val_accuracy: 0.5729\n",
      "Epoch 486/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0200 - accuracy: 0.9918 - val_loss: 3.4385 - val_accuracy: 0.5825\n",
      "Epoch 487/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0223 - accuracy: 0.9902 - val_loss: 3.4445 - val_accuracy: 0.5813\n",
      "Epoch 488/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0209 - accuracy: 0.9918 - val_loss: 3.4446 - val_accuracy: 0.5808\n",
      "Epoch 489/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0192 - accuracy: 0.9912 - val_loss: 3.4721 - val_accuracy: 0.5846\n",
      "Epoch 490/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0231 - accuracy: 0.9912 - val_loss: 3.5689 - val_accuracy: 0.5708\n",
      "Epoch 491/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0253 - accuracy: 0.9896 - val_loss: 3.4577 - val_accuracy: 0.5904\n",
      "Epoch 492/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0219 - accuracy: 0.9905 - val_loss: 3.4356 - val_accuracy: 0.5800\n",
      "Epoch 493/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0325 - accuracy: 0.9880 - val_loss: 3.4512 - val_accuracy: 0.5833\n",
      "Epoch 494/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0418 - accuracy: 0.9857 - val_loss: 3.4487 - val_accuracy: 0.5838\n",
      "Epoch 495/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0367 - accuracy: 0.9875 - val_loss: 3.4028 - val_accuracy: 0.5833\n",
      "Epoch 496/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0364 - accuracy: 0.9870 - val_loss: 3.4922 - val_accuracy: 0.5767\n",
      "Epoch 497/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0425 - accuracy: 0.9832 - val_loss: 3.4613 - val_accuracy: 0.5713\n",
      "Epoch 498/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0515 - accuracy: 0.9798 - val_loss: 3.4567 - val_accuracy: 0.5675\n",
      "Epoch 499/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0423 - accuracy: 0.9836 - val_loss: 3.4393 - val_accuracy: 0.5713\n",
      "Epoch 500/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0440 - accuracy: 0.9832 - val_loss: 3.3783 - val_accuracy: 0.5721\n",
      "Epoch 501/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0378 - accuracy: 0.9852 - val_loss: 3.4064 - val_accuracy: 0.5704\n",
      "Epoch 502/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0582 - accuracy: 0.9782 - val_loss: 3.3458 - val_accuracy: 0.5913\n",
      "Epoch 503/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0681 - accuracy: 0.9736 - val_loss: 3.3882 - val_accuracy: 0.5929\n",
      "Epoch 504/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0641 - accuracy: 0.9761 - val_loss: 3.2732 - val_accuracy: 0.5696\n",
      "Epoch 505/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0396 - accuracy: 0.9861 - val_loss: 3.3403 - val_accuracy: 0.5779\n",
      "Epoch 506/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0287 - accuracy: 0.9889 - val_loss: 3.3561 - val_accuracy: 0.5875\n",
      "Epoch 507/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0221 - accuracy: 0.9905 - val_loss: 3.4134 - val_accuracy: 0.5804\n",
      "Epoch 508/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0217 - accuracy: 0.9918 - val_loss: 3.4365 - val_accuracy: 0.5800\n",
      "Epoch 509/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0194 - accuracy: 0.9918 - val_loss: 3.4304 - val_accuracy: 0.5771\n",
      "Epoch 510/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0206 - accuracy: 0.9914 - val_loss: 3.4531 - val_accuracy: 0.5758\n",
      "Epoch 511/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0239 - accuracy: 0.9896 - val_loss: 3.5191 - val_accuracy: 0.5713\n",
      "Epoch 512/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0221 - accuracy: 0.9900 - val_loss: 3.4207 - val_accuracy: 0.5846\n",
      "Epoch 513/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0214 - accuracy: 0.9918 - val_loss: 3.4321 - val_accuracy: 0.5921\n",
      "Epoch 514/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0204 - accuracy: 0.9911 - val_loss: 3.3960 - val_accuracy: 0.5846\n",
      "Epoch 515/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0241 - accuracy: 0.9911 - val_loss: 3.4894 - val_accuracy: 0.5883\n",
      "Epoch 516/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0249 - accuracy: 0.9900 - val_loss: 3.4498 - val_accuracy: 0.5813\n",
      "Epoch 517/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0239 - accuracy: 0.9911 - val_loss: 3.4573 - val_accuracy: 0.5821\n",
      "Epoch 518/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0229 - accuracy: 0.9900 - val_loss: 3.5010 - val_accuracy: 0.5754\n",
      "Epoch 519/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0229 - accuracy: 0.9907 - val_loss: 3.4598 - val_accuracy: 0.5883\n",
      "Epoch 520/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0220 - accuracy: 0.9904 - val_loss: 3.4509 - val_accuracy: 0.5888\n",
      "Epoch 521/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0254 - accuracy: 0.9900 - val_loss: 3.4539 - val_accuracy: 0.5883\n",
      "Epoch 522/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0250 - accuracy: 0.9898 - val_loss: 3.4444 - val_accuracy: 0.5838\n",
      "Epoch 523/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0248 - accuracy: 0.9909 - val_loss: 3.4362 - val_accuracy: 0.5867\n",
      "Epoch 524/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0401 - accuracy: 0.9875 - val_loss: 3.2929 - val_accuracy: 0.5933\n",
      "Epoch 525/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0649 - accuracy: 0.9741 - val_loss: 3.3477 - val_accuracy: 0.5833\n",
      "Epoch 526/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0801 - accuracy: 0.9693 - val_loss: 3.4239 - val_accuracy: 0.5733\n",
      "Epoch 527/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.1159 - accuracy: 0.9591 - val_loss: 3.2506 - val_accuracy: 0.5717\n",
      "Epoch 528/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0877 - accuracy: 0.9721 - val_loss: 3.2023 - val_accuracy: 0.5771\n",
      "Epoch 529/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0489 - accuracy: 0.9796 - val_loss: 3.2517 - val_accuracy: 0.5771\n",
      "Epoch 530/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0289 - accuracy: 0.9877 - val_loss: 3.3207 - val_accuracy: 0.5854\n",
      "Epoch 531/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0190 - accuracy: 0.9925 - val_loss: 3.2784 - val_accuracy: 0.5863\n",
      "Epoch 532/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0164 - accuracy: 0.9936 - val_loss: 3.3909 - val_accuracy: 0.5758\n",
      "Epoch 533/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0163 - accuracy: 0.9929 - val_loss: 3.4506 - val_accuracy: 0.5771\n",
      "Epoch 534/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0211 - accuracy: 0.9912 - val_loss: 3.3847 - val_accuracy: 0.5883\n",
      "Epoch 535/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0175 - accuracy: 0.9927 - val_loss: 3.4128 - val_accuracy: 0.5850\n",
      "Epoch 536/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0170 - accuracy: 0.9918 - val_loss: 3.4531 - val_accuracy: 0.5829\n",
      "Epoch 537/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0171 - accuracy: 0.9932 - val_loss: 3.4281 - val_accuracy: 0.5858\n",
      "Epoch 538/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0172 - accuracy: 0.9923 - val_loss: 3.4284 - val_accuracy: 0.5808\n",
      "Epoch 539/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0172 - accuracy: 0.9930 - val_loss: 3.4680 - val_accuracy: 0.5808\n",
      "Epoch 540/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0225 - accuracy: 0.9905 - val_loss: 3.4530 - val_accuracy: 0.5713\n",
      "Epoch 541/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0216 - accuracy: 0.9909 - val_loss: 3.4542 - val_accuracy: 0.5721\n",
      "Epoch 542/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0177 - accuracy: 0.9921 - val_loss: 3.5215 - val_accuracy: 0.5758\n",
      "Epoch 543/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0202 - accuracy: 0.9909 - val_loss: 3.4380 - val_accuracy: 0.5796\n",
      "Epoch 544/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0214 - accuracy: 0.9902 - val_loss: 3.4778 - val_accuracy: 0.5763\n",
      "Epoch 545/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0173 - accuracy: 0.9927 - val_loss: 3.4311 - val_accuracy: 0.5821\n",
      "Epoch 546/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0197 - accuracy: 0.9912 - val_loss: 3.4672 - val_accuracy: 0.5875\n",
      "Epoch 547/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0185 - accuracy: 0.9912 - val_loss: 3.4461 - val_accuracy: 0.5729\n",
      "Epoch 548/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0182 - accuracy: 0.9925 - val_loss: 3.4733 - val_accuracy: 0.5813\n",
      "Epoch 549/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0223 - accuracy: 0.9904 - val_loss: 3.4519 - val_accuracy: 0.5817\n",
      "Epoch 550/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0194 - accuracy: 0.9909 - val_loss: 3.4961 - val_accuracy: 0.5738\n",
      "Epoch 551/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0260 - accuracy: 0.9907 - val_loss: 3.4788 - val_accuracy: 0.5808\n",
      "Epoch 552/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0201 - accuracy: 0.9916 - val_loss: 3.4806 - val_accuracy: 0.5829\n",
      "Epoch 553/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0287 - accuracy: 0.9893 - val_loss: 3.5110 - val_accuracy: 0.5833\n",
      "Epoch 554/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0865 - accuracy: 0.9721 - val_loss: 3.4882 - val_accuracy: 0.5517\n",
      "Epoch 555/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.1162 - accuracy: 0.9554 - val_loss: 3.2148 - val_accuracy: 0.5800\n",
      "Epoch 556/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.1088 - accuracy: 0.9591 - val_loss: 3.2531 - val_accuracy: 0.5608\n",
      "Epoch 557/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0951 - accuracy: 0.9646 - val_loss: 3.1133 - val_accuracy: 0.5788\n",
      "Epoch 558/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0539 - accuracy: 0.9807 - val_loss: 3.1118 - val_accuracy: 0.5892\n",
      "Epoch 559/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0402 - accuracy: 0.9871 - val_loss: 3.2896 - val_accuracy: 0.5742\n",
      "Epoch 560/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0257 - accuracy: 0.9918 - val_loss: 3.3252 - val_accuracy: 0.5721\n",
      "Epoch 561/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0289 - accuracy: 0.9898 - val_loss: 3.3380 - val_accuracy: 0.5796\n",
      "Epoch 562/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0289 - accuracy: 0.9896 - val_loss: 3.3458 - val_accuracy: 0.5788\n",
      "Epoch 563/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0206 - accuracy: 0.9918 - val_loss: 3.3655 - val_accuracy: 0.5817\n",
      "Epoch 564/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0164 - accuracy: 0.9925 - val_loss: 3.3763 - val_accuracy: 0.5850\n",
      "Epoch 565/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0164 - accuracy: 0.9923 - val_loss: 3.3792 - val_accuracy: 0.5854\n",
      "Epoch 566/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0161 - accuracy: 0.9927 - val_loss: 3.3842 - val_accuracy: 0.5962\n",
      "Epoch 567/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0181 - accuracy: 0.9923 - val_loss: 3.4598 - val_accuracy: 0.5779\n",
      "Epoch 568/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0210 - accuracy: 0.9918 - val_loss: 3.4365 - val_accuracy: 0.5863\n",
      "Epoch 569/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0172 - accuracy: 0.9921 - val_loss: 3.4470 - val_accuracy: 0.5842\n",
      "Epoch 570/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0177 - accuracy: 0.9916 - val_loss: 3.4173 - val_accuracy: 0.5842\n",
      "Epoch 571/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0170 - accuracy: 0.9916 - val_loss: 3.4332 - val_accuracy: 0.5871\n",
      "Epoch 572/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0177 - accuracy: 0.9918 - val_loss: 3.4360 - val_accuracy: 0.5867\n",
      "Epoch 573/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0205 - accuracy: 0.9907 - val_loss: 3.5444 - val_accuracy: 0.5771\n",
      "Epoch 574/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0242 - accuracy: 0.9891 - val_loss: 3.4587 - val_accuracy: 0.5725\n",
      "Epoch 575/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.0243 - accuracy: 0.9891 - val_loss: 3.4810 - val_accuracy: 0.5713\n",
      "Epoch 576/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0272 - accuracy: 0.9905 - val_loss: 3.4417 - val_accuracy: 0.5825\n",
      "Epoch 577/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0318 - accuracy: 0.9884 - val_loss: 3.3830 - val_accuracy: 0.5842\n",
      "Epoch 578/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0535 - accuracy: 0.9798 - val_loss: 3.4436 - val_accuracy: 0.5763\n",
      "Epoch 579/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0628 - accuracy: 0.9759 - val_loss: 3.3380 - val_accuracy: 0.5888\n",
      "Epoch 580/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0580 - accuracy: 0.9782 - val_loss: 3.3209 - val_accuracy: 0.5879\n",
      "Epoch 581/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0480 - accuracy: 0.9809 - val_loss: 3.3279 - val_accuracy: 0.5779\n",
      "Epoch 582/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0375 - accuracy: 0.9854 - val_loss: 3.3496 - val_accuracy: 0.5933\n",
      "Epoch 583/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0369 - accuracy: 0.9855 - val_loss: 3.3801 - val_accuracy: 0.5904\n",
      "Epoch 584/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0373 - accuracy: 0.9861 - val_loss: 3.4347 - val_accuracy: 0.5721\n",
      "Epoch 585/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0312 - accuracy: 0.9880 - val_loss: 3.4140 - val_accuracy: 0.5829\n",
      "Epoch 586/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0228 - accuracy: 0.9898 - val_loss: 3.4079 - val_accuracy: 0.5783\n",
      "Epoch 587/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0331 - accuracy: 0.9871 - val_loss: 3.4017 - val_accuracy: 0.5896\n",
      "Epoch 588/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0296 - accuracy: 0.9879 - val_loss: 3.3792 - val_accuracy: 0.5775\n",
      "Epoch 589/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0319 - accuracy: 0.9871 - val_loss: 3.4357 - val_accuracy: 0.5704\n",
      "Epoch 590/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0345 - accuracy: 0.9866 - val_loss: 3.4095 - val_accuracy: 0.5771\n",
      "Epoch 591/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0242 - accuracy: 0.9891 - val_loss: 3.3752 - val_accuracy: 0.5888\n",
      "Epoch 592/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0249 - accuracy: 0.9893 - val_loss: 3.5765 - val_accuracy: 0.5688\n",
      "Epoch 593/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0193 - accuracy: 0.9909 - val_loss: 3.4923 - val_accuracy: 0.5842\n",
      "Epoch 594/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0208 - accuracy: 0.9918 - val_loss: 3.5182 - val_accuracy: 0.5817\n",
      "Epoch 595/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0170 - accuracy: 0.9925 - val_loss: 3.4475 - val_accuracy: 0.5867\n",
      "Epoch 596/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0168 - accuracy: 0.9920 - val_loss: 3.5220 - val_accuracy: 0.5858\n",
      "Epoch 597/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0193 - accuracy: 0.9914 - val_loss: 3.5140 - val_accuracy: 0.5850\n",
      "Epoch 598/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0207 - accuracy: 0.9891 - val_loss: 3.4513 - val_accuracy: 0.5858\n",
      "Epoch 599/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0227 - accuracy: 0.9905 - val_loss: 3.4739 - val_accuracy: 0.5925\n",
      "Epoch 600/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0248 - accuracy: 0.9893 - val_loss: 3.5025 - val_accuracy: 0.5779\n",
      "Epoch 601/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0250 - accuracy: 0.9900 - val_loss: 3.5028 - val_accuracy: 0.5896\n",
      "Epoch 602/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0271 - accuracy: 0.9893 - val_loss: 3.4428 - val_accuracy: 0.5858\n",
      "Epoch 603/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0298 - accuracy: 0.9882 - val_loss: 3.4857 - val_accuracy: 0.5692\n",
      "Epoch 604/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0375 - accuracy: 0.9861 - val_loss: 3.5341 - val_accuracy: 0.5721\n",
      "Epoch 605/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0917 - accuracy: 0.9659 - val_loss: 3.4191 - val_accuracy: 0.5646\n",
      "Epoch 606/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.1019 - accuracy: 0.9638 - val_loss: 3.2769 - val_accuracy: 0.5904\n",
      "Epoch 607/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0833 - accuracy: 0.9696 - val_loss: 3.2660 - val_accuracy: 0.5808\n",
      "Epoch 608/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0529 - accuracy: 0.9814 - val_loss: 3.2286 - val_accuracy: 0.5771\n",
      "Epoch 609/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0612 - accuracy: 0.9780 - val_loss: 3.2365 - val_accuracy: 0.5717\n",
      "Epoch 610/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0443 - accuracy: 0.9834 - val_loss: 3.3578 - val_accuracy: 0.5679\n",
      "Epoch 611/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0308 - accuracy: 0.9887 - val_loss: 3.3364 - val_accuracy: 0.5717\n",
      "Epoch 612/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0224 - accuracy: 0.9904 - val_loss: 3.3393 - val_accuracy: 0.5871\n",
      "Epoch 613/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0219 - accuracy: 0.9912 - val_loss: 3.4347 - val_accuracy: 0.5775\n",
      "Epoch 614/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0159 - accuracy: 0.9921 - val_loss: 3.4015 - val_accuracy: 0.5842\n",
      "Epoch 615/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0164 - accuracy: 0.9921 - val_loss: 3.4133 - val_accuracy: 0.5896\n",
      "Epoch 616/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0166 - accuracy: 0.9923 - val_loss: 3.4274 - val_accuracy: 0.5813\n",
      "Epoch 617/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0176 - accuracy: 0.9916 - val_loss: 3.4556 - val_accuracy: 0.5788\n",
      "Epoch 618/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0138 - accuracy: 0.9932 - val_loss: 3.4773 - val_accuracy: 0.5858\n",
      "Epoch 619/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0152 - accuracy: 0.9927 - val_loss: 3.4725 - val_accuracy: 0.5788\n",
      "Epoch 620/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0171 - accuracy: 0.9921 - val_loss: 3.4701 - val_accuracy: 0.5817\n",
      "Epoch 621/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0148 - accuracy: 0.9923 - val_loss: 3.4430 - val_accuracy: 0.5813\n",
      "Epoch 622/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0167 - accuracy: 0.9920 - val_loss: 3.4974 - val_accuracy: 0.5817\n",
      "Epoch 623/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0148 - accuracy: 0.9923 - val_loss: 3.4407 - val_accuracy: 0.5846\n",
      "Epoch 624/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0161 - accuracy: 0.9923 - val_loss: 3.5465 - val_accuracy: 0.5804\n",
      "Epoch 625/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0171 - accuracy: 0.9920 - val_loss: 3.4595 - val_accuracy: 0.5829\n",
      "Epoch 626/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0193 - accuracy: 0.9905 - val_loss: 3.4417 - val_accuracy: 0.5867\n",
      "Epoch 627/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0229 - accuracy: 0.9900 - val_loss: 3.4711 - val_accuracy: 0.5908\n",
      "Epoch 628/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0241 - accuracy: 0.9905 - val_loss: 3.4644 - val_accuracy: 0.5729\n",
      "Epoch 629/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0218 - accuracy: 0.9904 - val_loss: 3.3967 - val_accuracy: 0.5733\n",
      "Epoch 630/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0240 - accuracy: 0.9895 - val_loss: 3.6356 - val_accuracy: 0.5592\n",
      "Epoch 631/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0315 - accuracy: 0.9880 - val_loss: 3.4107 - val_accuracy: 0.5863\n",
      "Epoch 632/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0336 - accuracy: 0.9862 - val_loss: 3.4930 - val_accuracy: 0.5808\n",
      "Epoch 633/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0457 - accuracy: 0.9841 - val_loss: 3.4413 - val_accuracy: 0.5796\n",
      "Epoch 634/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0515 - accuracy: 0.9807 - val_loss: 3.4588 - val_accuracy: 0.5846\n",
      "Epoch 635/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.1186 - accuracy: 0.9605 - val_loss: 3.2607 - val_accuracy: 0.5775\n",
      "Epoch 636/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0972 - accuracy: 0.9666 - val_loss: 3.1484 - val_accuracy: 0.5850\n",
      "Epoch 637/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0628 - accuracy: 0.9762 - val_loss: 3.1313 - val_accuracy: 0.5838\n",
      "Epoch 638/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0416 - accuracy: 0.9829 - val_loss: 3.1992 - val_accuracy: 0.5679\n",
      "Epoch 639/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0266 - accuracy: 0.9896 - val_loss: 3.2371 - val_accuracy: 0.5792\n",
      "Epoch 640/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0185 - accuracy: 0.9923 - val_loss: 3.3189 - val_accuracy: 0.5879\n",
      "Epoch 641/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0151 - accuracy: 0.9921 - val_loss: 3.3211 - val_accuracy: 0.5713\n",
      "Epoch 642/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0160 - accuracy: 0.9929 - val_loss: 3.3505 - val_accuracy: 0.5746\n",
      "Epoch 643/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0150 - accuracy: 0.9929 - val_loss: 3.3554 - val_accuracy: 0.5821\n",
      "Epoch 644/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0136 - accuracy: 0.9932 - val_loss: 3.3622 - val_accuracy: 0.5904\n",
      "Epoch 645/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0129 - accuracy: 0.9927 - val_loss: 3.3469 - val_accuracy: 0.5892\n",
      "Epoch 646/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0158 - accuracy: 0.9921 - val_loss: 3.3760 - val_accuracy: 0.5842\n",
      "Epoch 647/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0170 - accuracy: 0.9918 - val_loss: 3.3936 - val_accuracy: 0.5771\n",
      "Epoch 648/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0173 - accuracy: 0.9927 - val_loss: 3.3683 - val_accuracy: 0.5813\n",
      "Epoch 649/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0177 - accuracy: 0.9921 - val_loss: 3.3730 - val_accuracy: 0.5858\n",
      "Epoch 650/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0154 - accuracy: 0.9927 - val_loss: 3.3886 - val_accuracy: 0.5808\n",
      "Epoch 651/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0162 - accuracy: 0.9916 - val_loss: 3.4245 - val_accuracy: 0.5733\n",
      "Epoch 652/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0141 - accuracy: 0.9923 - val_loss: 3.4465 - val_accuracy: 0.5783\n",
      "Epoch 653/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0160 - accuracy: 0.9921 - val_loss: 3.3897 - val_accuracy: 0.5925\n",
      "Epoch 654/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0214 - accuracy: 0.9907 - val_loss: 3.4141 - val_accuracy: 0.5750\n",
      "Epoch 655/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0187 - accuracy: 0.9902 - val_loss: 3.3903 - val_accuracy: 0.5883\n",
      "Epoch 656/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0194 - accuracy: 0.9921 - val_loss: 3.4408 - val_accuracy: 0.5771\n",
      "Epoch 657/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0178 - accuracy: 0.9925 - val_loss: 3.4518 - val_accuracy: 0.5883\n",
      "Epoch 658/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0154 - accuracy: 0.9927 - val_loss: 3.3951 - val_accuracy: 0.5854\n",
      "Epoch 659/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0169 - accuracy: 0.9925 - val_loss: 3.4094 - val_accuracy: 0.5929\n",
      "Epoch 660/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0188 - accuracy: 0.9914 - val_loss: 3.3873 - val_accuracy: 0.5983\n",
      "Epoch 661/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0395 - accuracy: 0.9843 - val_loss: 3.3601 - val_accuracy: 0.5858\n",
      "Epoch 662/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0477 - accuracy: 0.9811 - val_loss: 3.2692 - val_accuracy: 0.5983\n",
      "Epoch 663/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0534 - accuracy: 0.9796 - val_loss: 3.3024 - val_accuracy: 0.5888\n",
      "Epoch 664/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0913 - accuracy: 0.9659 - val_loss: 3.2722 - val_accuracy: 0.5738\n",
      "Epoch 665/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.1098 - accuracy: 0.9636 - val_loss: 3.0698 - val_accuracy: 0.5888\n",
      "Epoch 666/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0711 - accuracy: 0.9739 - val_loss: 3.1609 - val_accuracy: 0.5758\n",
      "Epoch 667/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0404 - accuracy: 0.9845 - val_loss: 3.1390 - val_accuracy: 0.5829\n",
      "Epoch 668/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0292 - accuracy: 0.9882 - val_loss: 3.1288 - val_accuracy: 0.5938\n",
      "Epoch 669/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0178 - accuracy: 0.9920 - val_loss: 3.2417 - val_accuracy: 0.5804\n",
      "Epoch 670/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0143 - accuracy: 0.9925 - val_loss: 3.2473 - val_accuracy: 0.5929\n",
      "Epoch 671/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0134 - accuracy: 0.9929 - val_loss: 3.2606 - val_accuracy: 0.5921\n",
      "Epoch 672/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0136 - accuracy: 0.9912 - val_loss: 3.3602 - val_accuracy: 0.5883\n",
      "Epoch 673/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0160 - accuracy: 0.9921 - val_loss: 3.3229 - val_accuracy: 0.5888\n",
      "Epoch 674/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0150 - accuracy: 0.9939 - val_loss: 3.3181 - val_accuracy: 0.5925\n",
      "Epoch 675/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0162 - accuracy: 0.9918 - val_loss: 3.3232 - val_accuracy: 0.5925\n",
      "Epoch 676/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0152 - accuracy: 0.9921 - val_loss: 3.3212 - val_accuracy: 0.5913\n",
      "Epoch 677/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0158 - accuracy: 0.9916 - val_loss: 3.3858 - val_accuracy: 0.5746\n",
      "Epoch 678/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0196 - accuracy: 0.9923 - val_loss: 3.4184 - val_accuracy: 0.5958\n",
      "Epoch 679/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0175 - accuracy: 0.9914 - val_loss: 3.3720 - val_accuracy: 0.5942\n",
      "Epoch 680/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0177 - accuracy: 0.9909 - val_loss: 3.3889 - val_accuracy: 0.5858\n",
      "Epoch 681/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0174 - accuracy: 0.9905 - val_loss: 3.4104 - val_accuracy: 0.5813\n",
      "Epoch 682/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0150 - accuracy: 0.9927 - val_loss: 3.4367 - val_accuracy: 0.5917\n",
      "Epoch 683/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0165 - accuracy: 0.9912 - val_loss: 3.4691 - val_accuracy: 0.6000\n",
      "Epoch 684/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0180 - accuracy: 0.9918 - val_loss: 3.3994 - val_accuracy: 0.5888\n",
      "Epoch 685/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0188 - accuracy: 0.9923 - val_loss: 3.3606 - val_accuracy: 0.5908\n",
      "Epoch 686/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0170 - accuracy: 0.9923 - val_loss: 3.3998 - val_accuracy: 0.5804\n",
      "Epoch 687/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0171 - accuracy: 0.9921 - val_loss: 3.4168 - val_accuracy: 0.5842\n",
      "Epoch 688/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0199 - accuracy: 0.9907 - val_loss: 3.4853 - val_accuracy: 0.5996\n",
      "Epoch 689/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0337 - accuracy: 0.9859 - val_loss: 3.4196 - val_accuracy: 0.5758\n",
      "Epoch 690/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0486 - accuracy: 0.9802 - val_loss: 3.3523 - val_accuracy: 0.5788\n",
      "Epoch 691/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0872 - accuracy: 0.9668 - val_loss: 3.1601 - val_accuracy: 0.5867\n",
      "Epoch 692/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0803 - accuracy: 0.9730 - val_loss: 3.2114 - val_accuracy: 0.5750\n",
      "Epoch 693/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0695 - accuracy: 0.9750 - val_loss: 3.0979 - val_accuracy: 0.5875\n",
      "Epoch 694/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0483 - accuracy: 0.9812 - val_loss: 3.2229 - val_accuracy: 0.5817\n",
      "Epoch 695/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0319 - accuracy: 0.9871 - val_loss: 3.2491 - val_accuracy: 0.5838\n",
      "Epoch 696/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0272 - accuracy: 0.9896 - val_loss: 3.2600 - val_accuracy: 0.5888\n",
      "Epoch 697/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0199 - accuracy: 0.9904 - val_loss: 3.3071 - val_accuracy: 0.5917\n",
      "Epoch 698/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0168 - accuracy: 0.9918 - val_loss: 3.3059 - val_accuracy: 0.5842\n",
      "Epoch 699/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0163 - accuracy: 0.9930 - val_loss: 3.3378 - val_accuracy: 0.5821\n",
      "Epoch 700/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0141 - accuracy: 0.9927 - val_loss: 3.3320 - val_accuracy: 0.5838\n",
      "Epoch 701/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0157 - accuracy: 0.9923 - val_loss: 3.3470 - val_accuracy: 0.5850\n",
      "Epoch 702/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0142 - accuracy: 0.9921 - val_loss: 3.3729 - val_accuracy: 0.5904\n",
      "Epoch 703/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0137 - accuracy: 0.9921 - val_loss: 3.3642 - val_accuracy: 0.5904\n",
      "Epoch 704/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0157 - accuracy: 0.9914 - val_loss: 3.3662 - val_accuracy: 0.5883\n",
      "Epoch 705/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0164 - accuracy: 0.9923 - val_loss: 3.3569 - val_accuracy: 0.5896\n",
      "Epoch 706/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0165 - accuracy: 0.9920 - val_loss: 3.4109 - val_accuracy: 0.5933\n",
      "Epoch 707/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0145 - accuracy: 0.9920 - val_loss: 3.4171 - val_accuracy: 0.5979\n",
      "Epoch 708/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0161 - accuracy: 0.9918 - val_loss: 3.3633 - val_accuracy: 0.5987\n",
      "Epoch 709/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0158 - accuracy: 0.9916 - val_loss: 3.3798 - val_accuracy: 0.5875\n",
      "Epoch 710/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0180 - accuracy: 0.9916 - val_loss: 3.4516 - val_accuracy: 0.5992\n",
      "Epoch 711/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0189 - accuracy: 0.9920 - val_loss: 3.4559 - val_accuracy: 0.5729\n",
      "Epoch 712/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0234 - accuracy: 0.9909 - val_loss: 3.4411 - val_accuracy: 0.5729\n",
      "Epoch 713/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0379 - accuracy: 0.9866 - val_loss: 3.3940 - val_accuracy: 0.5871\n",
      "Epoch 714/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0647 - accuracy: 0.9770 - val_loss: 3.2949 - val_accuracy: 0.5929\n",
      "Epoch 715/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0684 - accuracy: 0.9746 - val_loss: 3.2823 - val_accuracy: 0.5575\n",
      "Epoch 716/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0738 - accuracy: 0.9723 - val_loss: 3.2222 - val_accuracy: 0.5642\n",
      "Epoch 717/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0583 - accuracy: 0.9786 - val_loss: 3.2640 - val_accuracy: 0.5658\n",
      "Epoch 718/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0377 - accuracy: 0.9859 - val_loss: 3.1374 - val_accuracy: 0.5863\n",
      "Epoch 719/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0243 - accuracy: 0.9902 - val_loss: 3.2432 - val_accuracy: 0.5779\n",
      "Epoch 720/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0178 - accuracy: 0.9925 - val_loss: 3.3673 - val_accuracy: 0.5842\n",
      "Epoch 721/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0168 - accuracy: 0.9920 - val_loss: 3.3564 - val_accuracy: 0.5904\n",
      "Epoch 722/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0169 - accuracy: 0.9914 - val_loss: 3.3519 - val_accuracy: 0.5800\n",
      "Epoch 723/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0135 - accuracy: 0.9937 - val_loss: 3.3622 - val_accuracy: 0.5838\n",
      "Epoch 724/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0152 - accuracy: 0.9921 - val_loss: 3.3981 - val_accuracy: 0.5858\n",
      "Epoch 725/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0173 - accuracy: 0.9912 - val_loss: 3.4042 - val_accuracy: 0.5867\n",
      "Epoch 726/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0147 - accuracy: 0.9916 - val_loss: 3.4346 - val_accuracy: 0.5796\n",
      "Epoch 727/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0173 - accuracy: 0.9918 - val_loss: 3.4215 - val_accuracy: 0.5829\n",
      "Epoch 728/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0155 - accuracy: 0.9925 - val_loss: 3.4677 - val_accuracy: 0.5779\n",
      "Epoch 729/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0140 - accuracy: 0.9927 - val_loss: 3.4598 - val_accuracy: 0.5871\n",
      "Epoch 730/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0172 - accuracy: 0.9912 - val_loss: 3.4197 - val_accuracy: 0.5821\n",
      "Epoch 731/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0155 - accuracy: 0.9916 - val_loss: 3.4096 - val_accuracy: 0.5763\n",
      "Epoch 732/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0165 - accuracy: 0.9914 - val_loss: 3.4080 - val_accuracy: 0.5858\n",
      "Epoch 733/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0164 - accuracy: 0.9920 - val_loss: 3.4049 - val_accuracy: 0.5871\n",
      "Epoch 734/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0161 - accuracy: 0.9929 - val_loss: 3.3558 - val_accuracy: 0.5875\n",
      "Epoch 735/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0164 - accuracy: 0.9925 - val_loss: 3.3976 - val_accuracy: 0.5850\n",
      "Epoch 736/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0155 - accuracy: 0.9918 - val_loss: 3.4057 - val_accuracy: 0.5721\n",
      "Epoch 737/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0171 - accuracy: 0.9925 - val_loss: 3.3671 - val_accuracy: 0.5929\n",
      "Epoch 738/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0162 - accuracy: 0.9918 - val_loss: 3.4399 - val_accuracy: 0.5833\n",
      "Epoch 739/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0184 - accuracy: 0.9914 - val_loss: 3.4192 - val_accuracy: 0.5846\n",
      "Epoch 740/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0306 - accuracy: 0.9868 - val_loss: 3.4930 - val_accuracy: 0.5692\n",
      "Epoch 741/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0511 - accuracy: 0.9820 - val_loss: 3.4834 - val_accuracy: 0.5704\n",
      "Epoch 742/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0838 - accuracy: 0.9663 - val_loss: 3.1357 - val_accuracy: 0.5829\n",
      "Epoch 743/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.1284 - accuracy: 0.9548 - val_loss: 3.1155 - val_accuracy: 0.5704\n",
      "Epoch 744/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0931 - accuracy: 0.9630 - val_loss: 3.1536 - val_accuracy: 0.5696\n",
      "Epoch 745/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0402 - accuracy: 0.9836 - val_loss: 3.1521 - val_accuracy: 0.5842\n",
      "Epoch 746/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0227 - accuracy: 0.9905 - val_loss: 3.2162 - val_accuracy: 0.5833\n",
      "Epoch 747/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0188 - accuracy: 0.9916 - val_loss: 3.2601 - val_accuracy: 0.5950\n",
      "Epoch 748/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0170 - accuracy: 0.9912 - val_loss: 3.3344 - val_accuracy: 0.5771\n",
      "Epoch 749/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0141 - accuracy: 0.9929 - val_loss: 3.3558 - val_accuracy: 0.5808\n",
      "Epoch 750/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0120 - accuracy: 0.9937 - val_loss: 3.4112 - val_accuracy: 0.5788\n",
      "Epoch 751/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0146 - accuracy: 0.9916 - val_loss: 3.4230 - val_accuracy: 0.5721\n",
      "Epoch 752/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0172 - accuracy: 0.9918 - val_loss: 3.4009 - val_accuracy: 0.5938\n",
      "Epoch 753/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0197 - accuracy: 0.9905 - val_loss: 3.3979 - val_accuracy: 0.5688\n",
      "Epoch 754/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0155 - accuracy: 0.9911 - val_loss: 3.4413 - val_accuracy: 0.5775\n",
      "Epoch 755/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0139 - accuracy: 0.9932 - val_loss: 3.3980 - val_accuracy: 0.5846\n",
      "Epoch 756/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0135 - accuracy: 0.9934 - val_loss: 3.4310 - val_accuracy: 0.5817\n",
      "Epoch 757/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0159 - accuracy: 0.9921 - val_loss: 3.3654 - val_accuracy: 0.5850\n",
      "Epoch 758/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0154 - accuracy: 0.9916 - val_loss: 3.4180 - val_accuracy: 0.5792\n",
      "Epoch 759/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0161 - accuracy: 0.9920 - val_loss: 3.4067 - val_accuracy: 0.5913\n",
      "Epoch 760/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0135 - accuracy: 0.9918 - val_loss: 3.4170 - val_accuracy: 0.5904\n",
      "Epoch 761/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0137 - accuracy: 0.9920 - val_loss: 3.4082 - val_accuracy: 0.5863\n",
      "Epoch 762/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0161 - accuracy: 0.9923 - val_loss: 3.4489 - val_accuracy: 0.5821\n",
      "Epoch 763/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0150 - accuracy: 0.9918 - val_loss: 3.4242 - val_accuracy: 0.5879\n",
      "Epoch 764/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0165 - accuracy: 0.9920 - val_loss: 3.4138 - val_accuracy: 0.5758\n",
      "Epoch 765/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0162 - accuracy: 0.9916 - val_loss: 3.3989 - val_accuracy: 0.5779\n",
      "Epoch 766/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0150 - accuracy: 0.9920 - val_loss: 3.4134 - val_accuracy: 0.5854\n",
      "Epoch 767/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0134 - accuracy: 0.9920 - val_loss: 3.4609 - val_accuracy: 0.5817\n",
      "Epoch 768/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0161 - accuracy: 0.9914 - val_loss: 3.4765 - val_accuracy: 0.5804\n",
      "Epoch 769/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0163 - accuracy: 0.9923 - val_loss: 3.4315 - val_accuracy: 0.5879\n",
      "Epoch 770/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0152 - accuracy: 0.9927 - val_loss: 3.4449 - val_accuracy: 0.5788\n",
      "Epoch 771/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0148 - accuracy: 0.9920 - val_loss: 3.4630 - val_accuracy: 0.5725\n",
      "Epoch 772/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0226 - accuracy: 0.9896 - val_loss: 3.3431 - val_accuracy: 0.5904\n",
      "Epoch 773/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0357 - accuracy: 0.9841 - val_loss: 3.4795 - val_accuracy: 0.5679\n",
      "Epoch 774/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0685 - accuracy: 0.9714 - val_loss: 3.2167 - val_accuracy: 0.5908\n",
      "Epoch 775/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.1298 - accuracy: 0.9525 - val_loss: 2.9760 - val_accuracy: 0.5696\n",
      "Epoch 776/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.1304 - accuracy: 0.9520 - val_loss: 2.8853 - val_accuracy: 0.5913\n",
      "Epoch 777/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0636 - accuracy: 0.9737 - val_loss: 2.9958 - val_accuracy: 0.5767\n",
      "Epoch 778/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0403 - accuracy: 0.9857 - val_loss: 3.0254 - val_accuracy: 0.5833\n",
      "Epoch 779/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0243 - accuracy: 0.9889 - val_loss: 3.1289 - val_accuracy: 0.5908\n",
      "Epoch 780/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0156 - accuracy: 0.9921 - val_loss: 3.1910 - val_accuracy: 0.5813\n",
      "Epoch 781/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0141 - accuracy: 0.9925 - val_loss: 3.2175 - val_accuracy: 0.5983\n",
      "Epoch 782/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0137 - accuracy: 0.9927 - val_loss: 3.2445 - val_accuracy: 0.5888\n",
      "Epoch 783/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0136 - accuracy: 0.9930 - val_loss: 3.3021 - val_accuracy: 0.5888\n",
      "Epoch 784/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0125 - accuracy: 0.9929 - val_loss: 3.2996 - val_accuracy: 0.5883\n",
      "Epoch 785/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0118 - accuracy: 0.9936 - val_loss: 3.2962 - val_accuracy: 0.5858\n",
      "Epoch 786/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0122 - accuracy: 0.9929 - val_loss: 3.3139 - val_accuracy: 0.5808\n",
      "Epoch 787/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0131 - accuracy: 0.9927 - val_loss: 3.3225 - val_accuracy: 0.5904\n",
      "Epoch 788/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0121 - accuracy: 0.9927 - val_loss: 3.3509 - val_accuracy: 0.5758\n",
      "Epoch 789/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0119 - accuracy: 0.9930 - val_loss: 3.3385 - val_accuracy: 0.5838\n",
      "Epoch 790/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0134 - accuracy: 0.9923 - val_loss: 3.3406 - val_accuracy: 0.5833\n",
      "Epoch 791/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0130 - accuracy: 0.9920 - val_loss: 3.3693 - val_accuracy: 0.5892\n",
      "Epoch 792/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0153 - accuracy: 0.9925 - val_loss: 3.3187 - val_accuracy: 0.5883\n",
      "Epoch 793/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0129 - accuracy: 0.9936 - val_loss: 3.3855 - val_accuracy: 0.5821\n",
      "Epoch 794/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0129 - accuracy: 0.9929 - val_loss: 3.3828 - val_accuracy: 0.5867\n",
      "Epoch 795/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0143 - accuracy: 0.9934 - val_loss: 3.4187 - val_accuracy: 0.5854\n",
      "Epoch 796/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0141 - accuracy: 0.9927 - val_loss: 3.4025 - val_accuracy: 0.5833\n",
      "Epoch 797/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0138 - accuracy: 0.9929 - val_loss: 3.3996 - val_accuracy: 0.5833\n",
      "Epoch 798/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0131 - accuracy: 0.9923 - val_loss: 3.3901 - val_accuracy: 0.5908\n",
      "Epoch 799/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0143 - accuracy: 0.9923 - val_loss: 3.3856 - val_accuracy: 0.5883\n",
      "Epoch 800/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0147 - accuracy: 0.9920 - val_loss: 3.4242 - val_accuracy: 0.5892\n",
      "Epoch 801/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0142 - accuracy: 0.9930 - val_loss: 3.3726 - val_accuracy: 0.5938\n",
      "Epoch 802/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0140 - accuracy: 0.9925 - val_loss: 3.4096 - val_accuracy: 0.5792\n",
      "Epoch 803/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0137 - accuracy: 0.9929 - val_loss: 3.4149 - val_accuracy: 0.5879\n",
      "Epoch 804/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0150 - accuracy: 0.9920 - val_loss: 3.3979 - val_accuracy: 0.5858\n",
      "Epoch 805/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0165 - accuracy: 0.9921 - val_loss: 3.4126 - val_accuracy: 0.5904\n",
      "Epoch 806/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0279 - accuracy: 0.9879 - val_loss: 3.5095 - val_accuracy: 0.5825\n",
      "Epoch 807/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0322 - accuracy: 0.9882 - val_loss: 3.4025 - val_accuracy: 0.5758\n",
      "Epoch 808/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0732 - accuracy: 0.9695 - val_loss: 3.3079 - val_accuracy: 0.5721\n",
      "Epoch 809/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.1547 - accuracy: 0.9436 - val_loss: 3.0927 - val_accuracy: 0.5704\n",
      "Epoch 810/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0901 - accuracy: 0.9661 - val_loss: 2.9675 - val_accuracy: 0.5813\n",
      "Epoch 811/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0534 - accuracy: 0.9786 - val_loss: 2.9386 - val_accuracy: 0.5817\n",
      "Epoch 812/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0306 - accuracy: 0.9870 - val_loss: 3.1217 - val_accuracy: 0.5754\n",
      "Epoch 813/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0263 - accuracy: 0.9891 - val_loss: 3.1794 - val_accuracy: 0.5813\n",
      "Epoch 814/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0171 - accuracy: 0.9920 - val_loss: 3.2075 - val_accuracy: 0.5804\n",
      "Epoch 815/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0138 - accuracy: 0.9925 - val_loss: 3.2900 - val_accuracy: 0.5725\n",
      "Epoch 816/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0122 - accuracy: 0.9927 - val_loss: 3.3052 - val_accuracy: 0.5850\n",
      "Epoch 817/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0123 - accuracy: 0.9923 - val_loss: 3.2935 - val_accuracy: 0.5804\n",
      "Epoch 818/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0117 - accuracy: 0.9930 - val_loss: 3.3284 - val_accuracy: 0.5879\n",
      "Epoch 819/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0128 - accuracy: 0.9921 - val_loss: 3.3413 - val_accuracy: 0.5871\n",
      "Epoch 820/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0128 - accuracy: 0.9923 - val_loss: 3.3416 - val_accuracy: 0.5904\n",
      "Epoch 821/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0125 - accuracy: 0.9921 - val_loss: 3.3560 - val_accuracy: 0.5804\n",
      "Epoch 822/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0121 - accuracy: 0.9932 - val_loss: 3.3968 - val_accuracy: 0.5796\n",
      "Epoch 823/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0110 - accuracy: 0.9934 - val_loss: 3.3873 - val_accuracy: 0.5821\n",
      "Epoch 824/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0128 - accuracy: 0.9929 - val_loss: 3.3774 - val_accuracy: 0.5896\n",
      "Epoch 825/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0162 - accuracy: 0.9920 - val_loss: 3.3849 - val_accuracy: 0.5854\n",
      "Epoch 826/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0148 - accuracy: 0.9918 - val_loss: 3.3749 - val_accuracy: 0.5738\n",
      "Epoch 827/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0133 - accuracy: 0.9936 - val_loss: 3.4112 - val_accuracy: 0.5917\n",
      "Epoch 828/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0143 - accuracy: 0.9920 - val_loss: 3.3945 - val_accuracy: 0.5900\n",
      "Epoch 829/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0146 - accuracy: 0.9921 - val_loss: 3.3888 - val_accuracy: 0.5850\n",
      "Epoch 830/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0149 - accuracy: 0.9929 - val_loss: 3.4082 - val_accuracy: 0.5858\n",
      "Epoch 831/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0131 - accuracy: 0.9930 - val_loss: 3.3887 - val_accuracy: 0.5800\n",
      "Epoch 832/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0178 - accuracy: 0.9916 - val_loss: 3.3687 - val_accuracy: 0.5938\n",
      "Epoch 833/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0196 - accuracy: 0.9907 - val_loss: 3.4117 - val_accuracy: 0.5875\n",
      "Epoch 834/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0309 - accuracy: 0.9864 - val_loss: 3.4483 - val_accuracy: 0.5783\n",
      "Epoch 835/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0428 - accuracy: 0.9834 - val_loss: 3.2942 - val_accuracy: 0.5883\n",
      "Epoch 836/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0528 - accuracy: 0.9793 - val_loss: 3.3511 - val_accuracy: 0.5858\n",
      "Epoch 837/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0888 - accuracy: 0.9689 - val_loss: 3.1949 - val_accuracy: 0.5733\n",
      "Epoch 838/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.1041 - accuracy: 0.9643 - val_loss: 2.8833 - val_accuracy: 0.5883\n",
      "Epoch 839/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0611 - accuracy: 0.9771 - val_loss: 3.0847 - val_accuracy: 0.5908\n",
      "Epoch 840/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0331 - accuracy: 0.9886 - val_loss: 3.1134 - val_accuracy: 0.5817\n",
      "Epoch 841/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0225 - accuracy: 0.9921 - val_loss: 3.2082 - val_accuracy: 0.5788\n",
      "Epoch 842/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0208 - accuracy: 0.9920 - val_loss: 3.1502 - val_accuracy: 0.5858\n",
      "Epoch 843/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0201 - accuracy: 0.9918 - val_loss: 3.2891 - val_accuracy: 0.5758\n",
      "Epoch 844/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0168 - accuracy: 0.9925 - val_loss: 3.2677 - val_accuracy: 0.5842\n",
      "Epoch 845/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0165 - accuracy: 0.9918 - val_loss: 3.2972 - val_accuracy: 0.5800\n",
      "Epoch 846/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0161 - accuracy: 0.9929 - val_loss: 3.2914 - val_accuracy: 0.5796\n",
      "Epoch 847/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0156 - accuracy: 0.9925 - val_loss: 3.3294 - val_accuracy: 0.5783\n",
      "Epoch 848/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0160 - accuracy: 0.9930 - val_loss: 3.3079 - val_accuracy: 0.5871\n",
      "Epoch 849/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0162 - accuracy: 0.9918 - val_loss: 3.3417 - val_accuracy: 0.5854\n",
      "Epoch 850/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0154 - accuracy: 0.9930 - val_loss: 3.3611 - val_accuracy: 0.5821\n",
      "Epoch 851/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0156 - accuracy: 0.9925 - val_loss: 3.3452 - val_accuracy: 0.5863\n",
      "Epoch 852/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0146 - accuracy: 0.9937 - val_loss: 3.3383 - val_accuracy: 0.5854\n",
      "Epoch 853/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0154 - accuracy: 0.9930 - val_loss: 3.3883 - val_accuracy: 0.5763\n",
      "Epoch 854/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0170 - accuracy: 0.9918 - val_loss: 3.3359 - val_accuracy: 0.5879\n",
      "Epoch 855/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.0162 - accuracy: 0.9927 - val_loss: 3.3494 - val_accuracy: 0.5896\n",
      "Epoch 856/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0163 - accuracy: 0.9921 - val_loss: 3.3201 - val_accuracy: 0.5838\n",
      "Epoch 857/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0184 - accuracy: 0.9920 - val_loss: 3.3338 - val_accuracy: 0.5867\n",
      "Epoch 858/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0164 - accuracy: 0.9929 - val_loss: 3.3726 - val_accuracy: 0.5921\n",
      "Epoch 859/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0164 - accuracy: 0.9923 - val_loss: 3.3497 - val_accuracy: 0.5833\n",
      "Epoch 860/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0170 - accuracy: 0.9916 - val_loss: 3.3557 - val_accuracy: 0.5950\n",
      "Epoch 861/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0188 - accuracy: 0.9912 - val_loss: 3.3870 - val_accuracy: 0.5854\n",
      "Epoch 862/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0332 - accuracy: 0.9879 - val_loss: 3.2885 - val_accuracy: 0.5958\n",
      "Epoch 863/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0560 - accuracy: 0.9786 - val_loss: 3.2404 - val_accuracy: 0.5729\n",
      "Epoch 864/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0852 - accuracy: 0.9677 - val_loss: 3.0978 - val_accuracy: 0.5833\n",
      "Epoch 865/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0820 - accuracy: 0.9702 - val_loss: 2.9624 - val_accuracy: 0.5929\n",
      "Epoch 866/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0463 - accuracy: 0.9827 - val_loss: 3.1571 - val_accuracy: 0.5896\n",
      "Epoch 867/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0485 - accuracy: 0.9825 - val_loss: 3.2092 - val_accuracy: 0.5729\n",
      "Epoch 868/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0322 - accuracy: 0.9866 - val_loss: 3.2218 - val_accuracy: 0.5846\n",
      "Epoch 869/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0209 - accuracy: 0.9920 - val_loss: 3.2867 - val_accuracy: 0.5921\n",
      "Epoch 870/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0200 - accuracy: 0.9907 - val_loss: 3.3027 - val_accuracy: 0.5817\n",
      "Epoch 871/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0231 - accuracy: 0.9911 - val_loss: 3.3849 - val_accuracy: 0.5829\n",
      "Epoch 872/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0179 - accuracy: 0.9918 - val_loss: 3.2922 - val_accuracy: 0.5858\n",
      "Epoch 873/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0170 - accuracy: 0.9927 - val_loss: 3.3839 - val_accuracy: 0.5804\n",
      "Epoch 874/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0171 - accuracy: 0.9918 - val_loss: 3.3976 - val_accuracy: 0.5792\n",
      "Epoch 875/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0164 - accuracy: 0.9920 - val_loss: 3.4016 - val_accuracy: 0.5758\n",
      "Epoch 876/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0163 - accuracy: 0.9921 - val_loss: 3.3798 - val_accuracy: 0.5842\n",
      "Epoch 877/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0145 - accuracy: 0.9937 - val_loss: 3.4425 - val_accuracy: 0.5771\n",
      "Epoch 878/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0148 - accuracy: 0.9927 - val_loss: 3.3997 - val_accuracy: 0.5863\n",
      "Epoch 879/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0167 - accuracy: 0.9921 - val_loss: 3.4309 - val_accuracy: 0.5838\n",
      "Epoch 880/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0155 - accuracy: 0.9929 - val_loss: 3.4607 - val_accuracy: 0.5817\n",
      "Epoch 881/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0160 - accuracy: 0.9927 - val_loss: 3.4039 - val_accuracy: 0.5892\n",
      "Epoch 882/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0209 - accuracy: 0.9914 - val_loss: 3.3948 - val_accuracy: 0.5767\n",
      "Epoch 883/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0172 - accuracy: 0.9914 - val_loss: 3.4089 - val_accuracy: 0.5883\n",
      "Epoch 884/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0155 - accuracy: 0.9934 - val_loss: 3.4647 - val_accuracy: 0.5800\n",
      "Epoch 885/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0140 - accuracy: 0.9927 - val_loss: 3.4823 - val_accuracy: 0.5775\n",
      "Epoch 886/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0158 - accuracy: 0.9918 - val_loss: 3.5254 - val_accuracy: 0.5779\n",
      "Epoch 887/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0169 - accuracy: 0.9916 - val_loss: 3.4732 - val_accuracy: 0.5817\n",
      "Epoch 888/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0167 - accuracy: 0.9916 - val_loss: 3.4764 - val_accuracy: 0.5892\n",
      "Epoch 889/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0172 - accuracy: 0.9925 - val_loss: 3.5117 - val_accuracy: 0.5821\n",
      "Epoch 890/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0166 - accuracy: 0.9925 - val_loss: 3.4187 - val_accuracy: 0.5896\n",
      "Epoch 891/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0163 - accuracy: 0.9918 - val_loss: 3.5671 - val_accuracy: 0.5750\n",
      "Epoch 892/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0216 - accuracy: 0.9909 - val_loss: 3.4654 - val_accuracy: 0.5796\n",
      "Epoch 893/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0297 - accuracy: 0.9891 - val_loss: 3.3986 - val_accuracy: 0.5971\n",
      "Epoch 894/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0533 - accuracy: 0.9832 - val_loss: 3.2870 - val_accuracy: 0.5954\n",
      "Epoch 895/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0903 - accuracy: 0.9663 - val_loss: 3.1971 - val_accuracy: 0.5821\n",
      "Epoch 896/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.1309 - accuracy: 0.9536 - val_loss: 2.9300 - val_accuracy: 0.5767\n",
      "Epoch 897/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.0869 - accuracy: 0.9652 - val_loss: 2.8888 - val_accuracy: 0.5875\n",
      "Epoch 898/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0310 - accuracy: 0.9895 - val_loss: 3.0830 - val_accuracy: 0.5838\n",
      "Epoch 899/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.0174 - accuracy: 0.9929 - val_loss: 3.1682 - val_accuracy: 0.5888\n",
      "Epoch 900/1000\n",
      "5600/5600 [==============================] - 0s 45us/sample - loss: 0.0163 - accuracy: 0.9918 - val_loss: 3.2161 - val_accuracy: 0.5829\n",
      "Epoch 901/1000\n",
      "5600/5600 [==============================] - 0s 53us/sample - loss: 0.0151 - accuracy: 0.9927 - val_loss: 3.2327 - val_accuracy: 0.5917\n",
      "Epoch 902/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.0142 - accuracy: 0.9923 - val_loss: 3.2852 - val_accuracy: 0.5913\n",
      "Epoch 903/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.0149 - accuracy: 0.9927 - val_loss: 3.3143 - val_accuracy: 0.5863\n",
      "Epoch 904/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.0138 - accuracy: 0.9921 - val_loss: 3.3329 - val_accuracy: 0.5933\n",
      "Epoch 905/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.0138 - accuracy: 0.9927 - val_loss: 3.3397 - val_accuracy: 0.5838\n",
      "Epoch 906/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0146 - accuracy: 0.9927 - val_loss: 3.3584 - val_accuracy: 0.5904\n",
      "Epoch 907/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0141 - accuracy: 0.9930 - val_loss: 3.3788 - val_accuracy: 0.5921\n",
      "Epoch 908/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0156 - accuracy: 0.9925 - val_loss: 3.3745 - val_accuracy: 0.5917\n",
      "Epoch 909/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0149 - accuracy: 0.9927 - val_loss: 3.3722 - val_accuracy: 0.5892\n",
      "Epoch 910/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 0.0153 - accuracy: 0.9920 - val_loss: 3.3957 - val_accuracy: 0.5913\n",
      "Epoch 911/1000\n",
      "5600/5600 [==============================] - 0s 47us/sample - loss: 0.0139 - accuracy: 0.9927 - val_loss: 3.3539 - val_accuracy: 0.5979\n",
      "Epoch 912/1000\n",
      "5600/5600 [==============================] - 0s 45us/sample - loss: 0.0139 - accuracy: 0.9927 - val_loss: 3.4354 - val_accuracy: 0.5921\n",
      "Epoch 913/1000\n",
      "5600/5600 [==============================] - 0s 45us/sample - loss: 0.0147 - accuracy: 0.9932 - val_loss: 3.4037 - val_accuracy: 0.5946\n",
      "Epoch 914/1000\n",
      "5600/5600 [==============================] - 0s 47us/sample - loss: 0.0152 - accuracy: 0.9923 - val_loss: 3.4260 - val_accuracy: 0.5796\n",
      "Epoch 915/1000\n",
      "5600/5600 [==============================] - 0s 44us/sample - loss: 0.0161 - accuracy: 0.9912 - val_loss: 3.4203 - val_accuracy: 0.5871\n",
      "Epoch 916/1000\n",
      "5600/5600 [==============================] - 0s 45us/sample - loss: 0.0200 - accuracy: 0.9904 - val_loss: 3.4515 - val_accuracy: 0.5883\n",
      "Epoch 917/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.0168 - accuracy: 0.9921 - val_loss: 3.3560 - val_accuracy: 0.5925\n",
      "Epoch 918/1000\n",
      "5600/5600 [==============================] - 0s 46us/sample - loss: 0.0164 - accuracy: 0.9927 - val_loss: 3.3937 - val_accuracy: 0.5875\n",
      "Epoch 919/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.0227 - accuracy: 0.9909 - val_loss: 3.4156 - val_accuracy: 0.5771\n",
      "Epoch 920/1000\n",
      "5600/5600 [==============================] - 0s 42us/sample - loss: 0.0704 - accuracy: 0.9745 - val_loss: 3.3788 - val_accuracy: 0.5654\n",
      "Epoch 921/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.0876 - accuracy: 0.9679 - val_loss: 3.1738 - val_accuracy: 0.5692\n",
      "Epoch 922/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0746 - accuracy: 0.9741 - val_loss: 3.0770 - val_accuracy: 0.5679\n",
      "Epoch 923/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.0367 - accuracy: 0.9875 - val_loss: 3.1463 - val_accuracy: 0.5879\n",
      "Epoch 924/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.0205 - accuracy: 0.9904 - val_loss: 3.2139 - val_accuracy: 0.5900\n",
      "Epoch 925/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.0238 - accuracy: 0.9887 - val_loss: 3.2461 - val_accuracy: 0.5892\n",
      "Epoch 926/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0172 - accuracy: 0.9905 - val_loss: 3.3432 - val_accuracy: 0.5783\n",
      "Epoch 927/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.0196 - accuracy: 0.9912 - val_loss: 3.3485 - val_accuracy: 0.5833\n",
      "Epoch 928/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0166 - accuracy: 0.9925 - val_loss: 3.3371 - val_accuracy: 0.5917\n",
      "Epoch 929/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0173 - accuracy: 0.9921 - val_loss: 3.3090 - val_accuracy: 0.5942\n",
      "Epoch 930/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0152 - accuracy: 0.9916 - val_loss: 3.3286 - val_accuracy: 0.5863\n",
      "Epoch 931/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.0149 - accuracy: 0.9929 - val_loss: 3.3268 - val_accuracy: 0.5867\n",
      "Epoch 932/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0143 - accuracy: 0.9923 - val_loss: 3.3543 - val_accuracy: 0.5821\n",
      "Epoch 933/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.0122 - accuracy: 0.9930 - val_loss: 3.3474 - val_accuracy: 0.5875\n",
      "Epoch 934/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.0132 - accuracy: 0.9925 - val_loss: 3.4086 - val_accuracy: 0.5829\n",
      "Epoch 935/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.0129 - accuracy: 0.9918 - val_loss: 3.3939 - val_accuracy: 0.5908\n",
      "Epoch 936/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.0127 - accuracy: 0.9923 - val_loss: 3.4435 - val_accuracy: 0.5850\n",
      "Epoch 937/1000\n",
      "5600/5600 [==============================] - 0s 43us/sample - loss: 0.0144 - accuracy: 0.9921 - val_loss: 3.4009 - val_accuracy: 0.5913\n",
      "Epoch 938/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.0127 - accuracy: 0.9930 - val_loss: 3.4232 - val_accuracy: 0.5858\n",
      "Epoch 939/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0121 - accuracy: 0.9920 - val_loss: 3.4699 - val_accuracy: 0.5888\n",
      "Epoch 940/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0120 - accuracy: 0.9927 - val_loss: 3.4825 - val_accuracy: 0.5758\n",
      "Epoch 941/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0136 - accuracy: 0.9929 - val_loss: 3.3915 - val_accuracy: 0.5946\n",
      "Epoch 942/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.0136 - accuracy: 0.9916 - val_loss: 3.4876 - val_accuracy: 0.5908\n",
      "Epoch 943/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.0155 - accuracy: 0.9921 - val_loss: 3.4033 - val_accuracy: 0.5896\n",
      "Epoch 944/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0137 - accuracy: 0.9925 - val_loss: 3.4657 - val_accuracy: 0.5729\n",
      "Epoch 945/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.0135 - accuracy: 0.9920 - val_loss: 3.4613 - val_accuracy: 0.5892\n",
      "Epoch 946/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.0181 - accuracy: 0.9909 - val_loss: 3.3434 - val_accuracy: 0.5975\n",
      "Epoch 947/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.0747 - accuracy: 0.9761 - val_loss: 3.2229 - val_accuracy: 0.5829\n",
      "Epoch 948/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.1053 - accuracy: 0.9652 - val_loss: 2.9999 - val_accuracy: 0.5917\n",
      "Epoch 949/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0851 - accuracy: 0.9718 - val_loss: 3.1081 - val_accuracy: 0.5688\n",
      "Epoch 950/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.0442 - accuracy: 0.9834 - val_loss: 3.0453 - val_accuracy: 0.5921\n",
      "Epoch 951/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.0298 - accuracy: 0.9880 - val_loss: 3.1710 - val_accuracy: 0.5888\n",
      "Epoch 952/1000\n",
      "5600/5600 [==============================] - 0s 42us/sample - loss: 0.0181 - accuracy: 0.9934 - val_loss: 3.1706 - val_accuracy: 0.5888\n",
      "Epoch 953/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.0147 - accuracy: 0.9932 - val_loss: 3.2098 - val_accuracy: 0.5942\n",
      "Epoch 954/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0139 - accuracy: 0.9934 - val_loss: 3.2339 - val_accuracy: 0.5929\n",
      "Epoch 955/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0145 - accuracy: 0.9930 - val_loss: 3.2737 - val_accuracy: 0.5904\n",
      "Epoch 956/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0136 - accuracy: 0.9930 - val_loss: 3.3099 - val_accuracy: 0.5896\n",
      "Epoch 957/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.0136 - accuracy: 0.9937 - val_loss: 3.3227 - val_accuracy: 0.5987\n",
      "Epoch 958/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0148 - accuracy: 0.9916 - val_loss: 3.3486 - val_accuracy: 0.5917\n",
      "Epoch 959/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.0145 - accuracy: 0.9927 - val_loss: 3.3435 - val_accuracy: 0.5871\n",
      "Epoch 960/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0151 - accuracy: 0.9925 - val_loss: 3.3197 - val_accuracy: 0.5913\n",
      "Epoch 961/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.0146 - accuracy: 0.9921 - val_loss: 3.3685 - val_accuracy: 0.5896\n",
      "Epoch 962/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.0151 - accuracy: 0.9914 - val_loss: 3.3434 - val_accuracy: 0.5842\n",
      "Epoch 963/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0129 - accuracy: 0.9932 - val_loss: 3.4099 - val_accuracy: 0.5896\n",
      "Epoch 964/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0136 - accuracy: 0.9932 - val_loss: 3.3881 - val_accuracy: 0.5838\n",
      "Epoch 965/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.0187 - accuracy: 0.9907 - val_loss: 3.3891 - val_accuracy: 0.5879\n",
      "Epoch 966/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.0170 - accuracy: 0.9921 - val_loss: 3.3857 - val_accuracy: 0.5846\n",
      "Epoch 967/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0212 - accuracy: 0.9905 - val_loss: 3.3570 - val_accuracy: 0.5750\n",
      "Epoch 968/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.0282 - accuracy: 0.9884 - val_loss: 3.2758 - val_accuracy: 0.5867\n",
      "Epoch 969/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.0310 - accuracy: 0.9871 - val_loss: 3.2878 - val_accuracy: 0.5946\n",
      "Epoch 970/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.0624 - accuracy: 0.9762 - val_loss: 3.1994 - val_accuracy: 0.5908\n",
      "Epoch 971/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.0831 - accuracy: 0.9686 - val_loss: 3.1499 - val_accuracy: 0.5725\n",
      "Epoch 972/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.0692 - accuracy: 0.9720 - val_loss: 3.0830 - val_accuracy: 0.5842\n",
      "Epoch 973/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.0286 - accuracy: 0.9879 - val_loss: 3.1467 - val_accuracy: 0.5925\n",
      "Epoch 974/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0167 - accuracy: 0.9918 - val_loss: 3.2350 - val_accuracy: 0.5796\n",
      "Epoch 975/1000\n",
      "5600/5600 [==============================] - 0s 42us/sample - loss: 0.0139 - accuracy: 0.9930 - val_loss: 3.2581 - val_accuracy: 0.5867\n",
      "Epoch 976/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.0119 - accuracy: 0.9930 - val_loss: 3.3109 - val_accuracy: 0.5863\n",
      "Epoch 977/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0111 - accuracy: 0.9936 - val_loss: 3.3331 - val_accuracy: 0.5950\n",
      "Epoch 978/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.0129 - accuracy: 0.9923 - val_loss: 3.3352 - val_accuracy: 0.5938\n",
      "Epoch 979/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.0124 - accuracy: 0.9929 - val_loss: 3.3121 - val_accuracy: 0.5908\n",
      "Epoch 980/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0125 - accuracy: 0.9930 - val_loss: 3.3541 - val_accuracy: 0.5775\n",
      "Epoch 981/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.0121 - accuracy: 0.9925 - val_loss: 3.3676 - val_accuracy: 0.5900\n",
      "Epoch 982/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.0118 - accuracy: 0.9932 - val_loss: 3.3500 - val_accuracy: 0.5858\n",
      "Epoch 983/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0115 - accuracy: 0.9937 - val_loss: 3.4144 - val_accuracy: 0.5854\n",
      "Epoch 984/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.0106 - accuracy: 0.9930 - val_loss: 3.4193 - val_accuracy: 0.5850\n",
      "Epoch 985/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.0119 - accuracy: 0.9930 - val_loss: 3.3661 - val_accuracy: 0.5900\n",
      "Epoch 986/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.0137 - accuracy: 0.9923 - val_loss: 3.3976 - val_accuracy: 0.5854\n",
      "Epoch 987/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.0130 - accuracy: 0.9914 - val_loss: 3.4191 - val_accuracy: 0.5946\n",
      "Epoch 988/1000\n",
      "5600/5600 [==============================] - 0s 54us/sample - loss: 0.0124 - accuracy: 0.9932 - val_loss: 3.3802 - val_accuracy: 0.5892\n",
      "Epoch 989/1000\n",
      "5600/5600 [==============================] - 0s 42us/sample - loss: 0.0113 - accuracy: 0.9930 - val_loss: 3.4510 - val_accuracy: 0.5808\n",
      "Epoch 990/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.0107 - accuracy: 0.9943 - val_loss: 3.4291 - val_accuracy: 0.5854\n",
      "Epoch 991/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.0105 - accuracy: 0.9941 - val_loss: 3.4480 - val_accuracy: 0.5846\n",
      "Epoch 992/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.0118 - accuracy: 0.9918 - val_loss: 3.4709 - val_accuracy: 0.5904\n",
      "Epoch 993/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0138 - accuracy: 0.9925 - val_loss: 3.4263 - val_accuracy: 0.5846\n",
      "Epoch 994/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.0120 - accuracy: 0.9929 - val_loss: 3.4163 - val_accuracy: 0.5913\n",
      "Epoch 995/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0130 - accuracy: 0.9927 - val_loss: 3.4603 - val_accuracy: 0.5921\n",
      "Epoch 996/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.0130 - accuracy: 0.9929 - val_loss: 3.4545 - val_accuracy: 0.5838\n",
      "Epoch 997/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.0137 - accuracy: 0.9923 - val_loss: 3.4112 - val_accuracy: 0.5850\n",
      "Epoch 998/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.0154 - accuracy: 0.9918 - val_loss: 3.4631 - val_accuracy: 0.5925\n",
      "Epoch 999/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.0123 - accuracy: 0.9934 - val_loss: 3.4410 - val_accuracy: 0.5842\n",
      "Epoch 1000/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.0167 - accuracy: 0.9918 - val_loss: 3.5184 - val_accuracy: 0.5921\n"
     ]
    }
   ],
   "source": [
    "# binary: ANN\n",
    "# specify network layers\n",
    "binary_ann = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28, )),\n",
    "    tf.keras.layers.Dense(100, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(100, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(100, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(100, activation = 'relu'),  \n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "# compile and fit network\n",
    "binary_ann.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy']) \n",
    "history = binary_ann.fit(X_train, y_train, epochs = 1000, batch_size = 128, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy vs. Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Training', 'Validation'], loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 5600 samples, validate on 2400 samples\n",
      "Epoch 1/1000\n",
      "5600/5600 [==============================] - 0s 63us/sample - loss: 0.6613 - accuracy: 0.6254 - val_loss: 0.6458 - val_accuracy: 0.6454\n",
      "Epoch 2/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.6473 - accuracy: 0.6416 - val_loss: 0.6412 - val_accuracy: 0.6454\n",
      "Epoch 3/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.6435 - accuracy: 0.6416 - val_loss: 0.6401 - val_accuracy: 0.6454\n",
      "Epoch 4/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.6410 - accuracy: 0.6416 - val_loss: 0.6382 - val_accuracy: 0.6454\n",
      "Epoch 5/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.6381 - accuracy: 0.6423 - val_loss: 0.6382 - val_accuracy: 0.6446\n",
      "Epoch 6/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.6359 - accuracy: 0.6425 - val_loss: 0.6375 - val_accuracy: 0.6454\n",
      "Epoch 7/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.6353 - accuracy: 0.6413 - val_loss: 0.6368 - val_accuracy: 0.6438\n",
      "Epoch 8/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.6322 - accuracy: 0.6421 - val_loss: 0.6365 - val_accuracy: 0.6438\n",
      "Epoch 9/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.6307 - accuracy: 0.6436 - val_loss: 0.6378 - val_accuracy: 0.6396\n",
      "Epoch 10/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.6279 - accuracy: 0.6441 - val_loss: 0.6355 - val_accuracy: 0.6396\n",
      "Epoch 11/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.6271 - accuracy: 0.6445 - val_loss: 0.6429 - val_accuracy: 0.6258\n",
      "Epoch 12/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.6265 - accuracy: 0.6470 - val_loss: 0.6386 - val_accuracy: 0.6371\n",
      "Epoch 13/1000\n",
      "5600/5600 [==============================] - 0s 48us/sample - loss: 0.6241 - accuracy: 0.6459 - val_loss: 0.6409 - val_accuracy: 0.6317\n",
      "Epoch 14/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.6206 - accuracy: 0.6502 - val_loss: 0.6371 - val_accuracy: 0.6392\n",
      "Epoch 15/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.6186 - accuracy: 0.6516 - val_loss: 0.6384 - val_accuracy: 0.6321\n",
      "Epoch 16/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.6185 - accuracy: 0.6546 - val_loss: 0.6401 - val_accuracy: 0.6317\n",
      "Epoch 17/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.6150 - accuracy: 0.6559 - val_loss: 0.6390 - val_accuracy: 0.6363\n",
      "Epoch 18/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.6134 - accuracy: 0.6546 - val_loss: 0.6401 - val_accuracy: 0.6308\n",
      "Epoch 19/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.6121 - accuracy: 0.6600 - val_loss: 0.6386 - val_accuracy: 0.6296\n",
      "Epoch 20/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.6106 - accuracy: 0.6580 - val_loss: 0.6401 - val_accuracy: 0.6333\n",
      "Epoch 21/1000\n",
      "5600/5600 [==============================] - 0s 42us/sample - loss: 0.6082 - accuracy: 0.6598 - val_loss: 0.6473 - val_accuracy: 0.6075\n",
      "Epoch 22/1000\n",
      "5600/5600 [==============================] - 0s 45us/sample - loss: 0.6069 - accuracy: 0.6607 - val_loss: 0.6439 - val_accuracy: 0.6204\n",
      "Epoch 23/1000\n",
      "5600/5600 [==============================] - 0s 44us/sample - loss: 0.6041 - accuracy: 0.6614 - val_loss: 0.6467 - val_accuracy: 0.6254\n",
      "Epoch 24/1000\n",
      "5600/5600 [==============================] - 0s 46us/sample - loss: 0.6038 - accuracy: 0.6634 - val_loss: 0.6481 - val_accuracy: 0.6108\n",
      "Epoch 25/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.6018 - accuracy: 0.6650 - val_loss: 0.6448 - val_accuracy: 0.6263\n",
      "Epoch 26/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.5985 - accuracy: 0.6650 - val_loss: 0.6471 - val_accuracy: 0.6271\n",
      "Epoch 27/1000\n",
      "5600/5600 [==============================] - 0s 47us/sample - loss: 0.6007 - accuracy: 0.6627 - val_loss: 0.6462 - val_accuracy: 0.6242\n",
      "Epoch 28/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.5977 - accuracy: 0.6679 - val_loss: 0.6511 - val_accuracy: 0.6342\n",
      "Epoch 29/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.5953 - accuracy: 0.6704 - val_loss: 0.6521 - val_accuracy: 0.6121\n",
      "Epoch 30/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.5926 - accuracy: 0.6716 - val_loss: 0.6585 - val_accuracy: 0.6375\n",
      "Epoch 31/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.5926 - accuracy: 0.6696 - val_loss: 0.6521 - val_accuracy: 0.6275\n",
      "Epoch 32/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.5901 - accuracy: 0.6766 - val_loss: 0.6508 - val_accuracy: 0.6217\n",
      "Epoch 33/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.5895 - accuracy: 0.6775 - val_loss: 0.6534 - val_accuracy: 0.6125\n",
      "Epoch 34/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.5859 - accuracy: 0.6809 - val_loss: 0.6667 - val_accuracy: 0.6304\n",
      "Epoch 35/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.5876 - accuracy: 0.6736 - val_loss: 0.6558 - val_accuracy: 0.6329\n",
      "Epoch 36/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.5857 - accuracy: 0.6754 - val_loss: 0.6565 - val_accuracy: 0.6263\n",
      "Epoch 37/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.5823 - accuracy: 0.6827 - val_loss: 0.6699 - val_accuracy: 0.5888\n",
      "Epoch 38/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.5808 - accuracy: 0.6841 - val_loss: 0.6584 - val_accuracy: 0.6242\n",
      "Epoch 39/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.5783 - accuracy: 0.6796 - val_loss: 0.6647 - val_accuracy: 0.6083\n",
      "Epoch 40/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.5793 - accuracy: 0.6804 - val_loss: 0.6650 - val_accuracy: 0.6075\n",
      "Epoch 41/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.5743 - accuracy: 0.6845 - val_loss: 0.6635 - val_accuracy: 0.6146\n",
      "Epoch 42/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.5715 - accuracy: 0.6904 - val_loss: 0.6674 - val_accuracy: 0.6208\n",
      "Epoch 43/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.5697 - accuracy: 0.6896 - val_loss: 0.6713 - val_accuracy: 0.6121\n",
      "Epoch 44/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.5708 - accuracy: 0.6879 - val_loss: 0.6710 - val_accuracy: 0.6187\n",
      "Epoch 45/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.5699 - accuracy: 0.6954 - val_loss: 0.6806 - val_accuracy: 0.6333\n",
      "Epoch 46/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.5689 - accuracy: 0.6891 - val_loss: 0.6859 - val_accuracy: 0.5917\n",
      "Epoch 47/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.5662 - accuracy: 0.6864 - val_loss: 0.6715 - val_accuracy: 0.6187\n",
      "Epoch 48/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.5664 - accuracy: 0.6916 - val_loss: 0.6707 - val_accuracy: 0.6246\n",
      "Epoch 49/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.5618 - accuracy: 0.6996 - val_loss: 0.6749 - val_accuracy: 0.6112\n",
      "Epoch 50/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.5612 - accuracy: 0.6941 - val_loss: 0.6797 - val_accuracy: 0.6171\n",
      "Epoch 51/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.5574 - accuracy: 0.7020 - val_loss: 0.6756 - val_accuracy: 0.6092\n",
      "Epoch 52/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.5573 - accuracy: 0.6975 - val_loss: 0.6790 - val_accuracy: 0.6167\n",
      "Epoch 53/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.5572 - accuracy: 0.6998 - val_loss: 0.6851 - val_accuracy: 0.6192\n",
      "Epoch 54/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.5564 - accuracy: 0.6979 - val_loss: 0.6821 - val_accuracy: 0.6075\n",
      "Epoch 55/1000\n",
      "5600/5600 [==============================] - 0s 44us/sample - loss: 0.5533 - accuracy: 0.7055 - val_loss: 0.6835 - val_accuracy: 0.6208\n",
      "Epoch 56/1000\n",
      "5600/5600 [==============================] - 0s 43us/sample - loss: 0.5514 - accuracy: 0.7046 - val_loss: 0.6869 - val_accuracy: 0.6075\n",
      "Epoch 57/1000\n",
      "5600/5600 [==============================] - 0s 60us/sample - loss: 0.5520 - accuracy: 0.7080 - val_loss: 0.6857 - val_accuracy: 0.6137\n",
      "Epoch 58/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.5535 - accuracy: 0.7011 - val_loss: 0.6897 - val_accuracy: 0.6104\n",
      "Epoch 59/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.5473 - accuracy: 0.7088 - val_loss: 0.6944 - val_accuracy: 0.6146\n",
      "Epoch 60/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.5471 - accuracy: 0.7104 - val_loss: 0.6951 - val_accuracy: 0.6058\n",
      "Epoch 61/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.5435 - accuracy: 0.7111 - val_loss: 0.6960 - val_accuracy: 0.5992\n",
      "Epoch 62/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.5443 - accuracy: 0.7105 - val_loss: 0.7007 - val_accuracy: 0.6229\n",
      "Epoch 63/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.5430 - accuracy: 0.7114 - val_loss: 0.7004 - val_accuracy: 0.6029\n",
      "Epoch 64/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.5425 - accuracy: 0.7100 - val_loss: 0.7084 - val_accuracy: 0.6296\n",
      "Epoch 65/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.5394 - accuracy: 0.7113 - val_loss: 0.7123 - val_accuracy: 0.5954\n",
      "Epoch 66/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.5378 - accuracy: 0.7164 - val_loss: 0.7069 - val_accuracy: 0.6033\n",
      "Epoch 67/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.5389 - accuracy: 0.7114 - val_loss: 0.6993 - val_accuracy: 0.6158\n",
      "Epoch 68/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.5367 - accuracy: 0.7146 - val_loss: 0.7116 - val_accuracy: 0.5950\n",
      "Epoch 69/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.5308 - accuracy: 0.7230 - val_loss: 0.7059 - val_accuracy: 0.6071\n",
      "Epoch 70/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.5320 - accuracy: 0.7163 - val_loss: 0.7074 - val_accuracy: 0.6083\n",
      "Epoch 71/1000\n",
      "5600/5600 [==============================] - 0s 43us/sample - loss: 0.5304 - accuracy: 0.7232 - val_loss: 0.7188 - val_accuracy: 0.6192\n",
      "Epoch 72/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.5296 - accuracy: 0.7191 - val_loss: 0.7227 - val_accuracy: 0.6112\n",
      "Epoch 73/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.5311 - accuracy: 0.7223 - val_loss: 0.7165 - val_accuracy: 0.6154\n",
      "Epoch 74/1000\n",
      "5600/5600 [==============================] - 0s 48us/sample - loss: 0.5327 - accuracy: 0.7216 - val_loss: 0.7209 - val_accuracy: 0.6229\n",
      "Epoch 75/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.5276 - accuracy: 0.7220 - val_loss: 0.7165 - val_accuracy: 0.6125\n",
      "Epoch 76/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.5248 - accuracy: 0.7254 - val_loss: 0.7408 - val_accuracy: 0.5879\n",
      "Epoch 77/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.5285 - accuracy: 0.7177 - val_loss: 0.7342 - val_accuracy: 0.5954\n",
      "Epoch 78/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.5243 - accuracy: 0.7202 - val_loss: 0.7219 - val_accuracy: 0.6033\n",
      "Epoch 79/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.5231 - accuracy: 0.7252 - val_loss: 0.7241 - val_accuracy: 0.5996\n",
      "Epoch 80/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.5203 - accuracy: 0.7262 - val_loss: 0.7337 - val_accuracy: 0.6133\n",
      "Epoch 81/1000\n",
      "5600/5600 [==============================] - 0s 54us/sample - loss: 0.5200 - accuracy: 0.7300 - val_loss: 0.7317 - val_accuracy: 0.6142\n",
      "Epoch 82/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.5171 - accuracy: 0.7325 - val_loss: 0.7280 - val_accuracy: 0.6104\n",
      "Epoch 83/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.5198 - accuracy: 0.7270 - val_loss: 0.7288 - val_accuracy: 0.6167\n",
      "Epoch 84/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.5126 - accuracy: 0.7321 - val_loss: 0.7301 - val_accuracy: 0.6192\n",
      "Epoch 85/1000\n",
      "5600/5600 [==============================] - 0s 45us/sample - loss: 0.5242 - accuracy: 0.7184 - val_loss: 0.7285 - val_accuracy: 0.6087\n",
      "Epoch 86/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.5160 - accuracy: 0.7348 - val_loss: 0.7468 - val_accuracy: 0.5888\n",
      "Epoch 87/1000\n",
      "5600/5600 [==============================] - 0s 69us/sample - loss: 0.5133 - accuracy: 0.7330 - val_loss: 0.7398 - val_accuracy: 0.6037\n",
      "Epoch 88/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.5112 - accuracy: 0.7398 - val_loss: 0.7443 - val_accuracy: 0.6087\n",
      "Epoch 89/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.5082 - accuracy: 0.7391 - val_loss: 0.7422 - val_accuracy: 0.6054\n",
      "Epoch 90/1000\n",
      "5600/5600 [==============================] - 0s 44us/sample - loss: 0.5069 - accuracy: 0.7416 - val_loss: 0.7445 - val_accuracy: 0.6012\n",
      "Epoch 91/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.5080 - accuracy: 0.7409 - val_loss: 0.7515 - val_accuracy: 0.5979\n",
      "Epoch 92/1000\n",
      "5600/5600 [==============================] - 0s 44us/sample - loss: 0.5085 - accuracy: 0.7357 - val_loss: 0.7582 - val_accuracy: 0.6192\n",
      "Epoch 93/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.5134 - accuracy: 0.7264 - val_loss: 0.7474 - val_accuracy: 0.6192\n",
      "Epoch 94/1000\n",
      "5600/5600 [==============================] - 0s 43us/sample - loss: 0.5049 - accuracy: 0.7437 - val_loss: 0.7487 - val_accuracy: 0.6137\n",
      "Epoch 95/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.5044 - accuracy: 0.7455 - val_loss: 0.7469 - val_accuracy: 0.6217\n",
      "Epoch 96/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.4995 - accuracy: 0.7427 - val_loss: 0.7430 - val_accuracy: 0.6121\n",
      "Epoch 97/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.5010 - accuracy: 0.7416 - val_loss: 0.7519 - val_accuracy: 0.6125\n",
      "Epoch 98/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.4981 - accuracy: 0.7409 - val_loss: 0.7583 - val_accuracy: 0.6133\n",
      "Epoch 99/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.4969 - accuracy: 0.7400 - val_loss: 0.7577 - val_accuracy: 0.6087\n",
      "Epoch 100/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.4993 - accuracy: 0.7425 - val_loss: 0.7627 - val_accuracy: 0.6037\n",
      "Epoch 101/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.4931 - accuracy: 0.7437 - val_loss: 0.7657 - val_accuracy: 0.6037\n",
      "Epoch 102/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.4934 - accuracy: 0.7502 - val_loss: 0.7650 - val_accuracy: 0.5962\n",
      "Epoch 103/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.4922 - accuracy: 0.7548 - val_loss: 0.7675 - val_accuracy: 0.6054\n",
      "Epoch 104/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.4932 - accuracy: 0.7484 - val_loss: 0.7691 - val_accuracy: 0.6062\n",
      "Epoch 105/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.4900 - accuracy: 0.7493 - val_loss: 0.7740 - val_accuracy: 0.6079\n",
      "Epoch 106/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.4882 - accuracy: 0.7482 - val_loss: 0.7815 - val_accuracy: 0.6187\n",
      "Epoch 107/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.4926 - accuracy: 0.7484 - val_loss: 0.7707 - val_accuracy: 0.6133\n",
      "Epoch 108/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.4882 - accuracy: 0.7500 - val_loss: 0.7775 - val_accuracy: 0.6171\n",
      "Epoch 109/1000\n",
      "5600/5600 [==============================] - 0s 68us/sample - loss: 0.4849 - accuracy: 0.7520 - val_loss: 0.7816 - val_accuracy: 0.5979\n",
      "Epoch 110/1000\n",
      "5600/5600 [==============================] - 0s 66us/sample - loss: 0.4874 - accuracy: 0.7482 - val_loss: 0.7740 - val_accuracy: 0.6071\n",
      "Epoch 111/1000\n",
      "5600/5600 [==============================] - 1s 102us/sample - loss: 0.4860 - accuracy: 0.7543 - val_loss: 0.7889 - val_accuracy: 0.6083\n",
      "Epoch 112/1000\n",
      "5600/5600 [==============================] - 0s 46us/sample - loss: 0.4825 - accuracy: 0.7500 - val_loss: 0.7857 - val_accuracy: 0.6112\n",
      "Epoch 113/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.4820 - accuracy: 0.7554 - val_loss: 0.7847 - val_accuracy: 0.5942\n",
      "Epoch 114/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.4865 - accuracy: 0.7505 - val_loss: 0.7988 - val_accuracy: 0.6004\n",
      "Epoch 115/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.4892 - accuracy: 0.7491 - val_loss: 0.7867 - val_accuracy: 0.6175\n",
      "Epoch 116/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.4846 - accuracy: 0.7491 - val_loss: 0.8045 - val_accuracy: 0.5846\n",
      "Epoch 117/1000\n",
      "5600/5600 [==============================] - 0s 47us/sample - loss: 0.4795 - accuracy: 0.7571 - val_loss: 0.7910 - val_accuracy: 0.6083\n",
      "Epoch 118/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.4764 - accuracy: 0.7523 - val_loss: 0.7946 - val_accuracy: 0.6167\n",
      "Epoch 119/1000\n",
      "5600/5600 [==============================] - 0s 45us/sample - loss: 0.4788 - accuracy: 0.7554 - val_loss: 0.7964 - val_accuracy: 0.6008\n",
      "Epoch 120/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.4765 - accuracy: 0.7541 - val_loss: 0.8044 - val_accuracy: 0.5875\n",
      "Epoch 121/1000\n",
      "5600/5600 [==============================] - 0s 46us/sample - loss: 0.4776 - accuracy: 0.7593 - val_loss: 0.8043 - val_accuracy: 0.5975\n",
      "Epoch 122/1000\n",
      "5600/5600 [==============================] - 0s 43us/sample - loss: 0.4719 - accuracy: 0.7632 - val_loss: 0.8059 - val_accuracy: 0.6054\n",
      "Epoch 123/1000\n",
      "5600/5600 [==============================] - 0s 45us/sample - loss: 0.4702 - accuracy: 0.7596 - val_loss: 0.8055 - val_accuracy: 0.5958\n",
      "Epoch 124/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 0.4710 - accuracy: 0.7620 - val_loss: 0.8118 - val_accuracy: 0.5900\n",
      "Epoch 125/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.4698 - accuracy: 0.7630 - val_loss: 0.8050 - val_accuracy: 0.6012\n",
      "Epoch 126/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.4708 - accuracy: 0.7577 - val_loss: 0.8242 - val_accuracy: 0.6150\n",
      "Epoch 127/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.4692 - accuracy: 0.7655 - val_loss: 0.8124 - val_accuracy: 0.5933\n",
      "Epoch 128/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.4690 - accuracy: 0.7639 - val_loss: 0.8102 - val_accuracy: 0.5917\n",
      "Epoch 129/1000\n",
      "5600/5600 [==============================] - 0s 63us/sample - loss: 0.4696 - accuracy: 0.7600 - val_loss: 0.8088 - val_accuracy: 0.5975\n",
      "Epoch 130/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.4665 - accuracy: 0.7613 - val_loss: 0.8169 - val_accuracy: 0.6046\n",
      "Epoch 131/1000\n",
      "5600/5600 [==============================] - 0s 45us/sample - loss: 0.4655 - accuracy: 0.7645 - val_loss: 0.8236 - val_accuracy: 0.5979\n",
      "Epoch 132/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 0.4639 - accuracy: 0.7693 - val_loss: 0.8302 - val_accuracy: 0.5892\n",
      "Epoch 133/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.4642 - accuracy: 0.7679 - val_loss: 0.8242 - val_accuracy: 0.6096\n",
      "Epoch 134/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 0.4592 - accuracy: 0.7700 - val_loss: 0.8218 - val_accuracy: 0.5950\n",
      "Epoch 135/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.4585 - accuracy: 0.7764 - val_loss: 0.8271 - val_accuracy: 0.5917\n",
      "Epoch 136/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.4586 - accuracy: 0.7702 - val_loss: 0.8518 - val_accuracy: 0.5842\n",
      "Epoch 137/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.4605 - accuracy: 0.7668 - val_loss: 0.8339 - val_accuracy: 0.5908\n",
      "Epoch 138/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.4611 - accuracy: 0.7645 - val_loss: 0.8343 - val_accuracy: 0.5850\n",
      "Epoch 139/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.4560 - accuracy: 0.7775 - val_loss: 0.8453 - val_accuracy: 0.5863\n",
      "Epoch 140/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 0.4556 - accuracy: 0.7729 - val_loss: 0.8396 - val_accuracy: 0.6021\n",
      "Epoch 141/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.4570 - accuracy: 0.7723 - val_loss: 0.8453 - val_accuracy: 0.5938\n",
      "Epoch 142/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.4537 - accuracy: 0.7713 - val_loss: 0.8410 - val_accuracy: 0.6146\n",
      "Epoch 143/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.4566 - accuracy: 0.7641 - val_loss: 0.8460 - val_accuracy: 0.6158\n",
      "Epoch 144/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.4570 - accuracy: 0.7714 - val_loss: 0.8390 - val_accuracy: 0.5946\n",
      "Epoch 145/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.4523 - accuracy: 0.7691 - val_loss: 0.8373 - val_accuracy: 0.5967\n",
      "Epoch 146/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.4494 - accuracy: 0.7727 - val_loss: 0.8443 - val_accuracy: 0.5950\n",
      "Epoch 147/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.4539 - accuracy: 0.7704 - val_loss: 0.8456 - val_accuracy: 0.5925\n",
      "Epoch 148/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.4493 - accuracy: 0.7750 - val_loss: 0.8785 - val_accuracy: 0.5792\n",
      "Epoch 149/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.4511 - accuracy: 0.7738 - val_loss: 0.8504 - val_accuracy: 0.5925\n",
      "Epoch 150/1000\n",
      "5600/5600 [==============================] - 0s 43us/sample - loss: 0.4443 - accuracy: 0.7764 - val_loss: 0.8880 - val_accuracy: 0.5717\n",
      "Epoch 151/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 0.4456 - accuracy: 0.7789 - val_loss: 0.8438 - val_accuracy: 0.6087\n",
      "Epoch 152/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.4462 - accuracy: 0.7723 - val_loss: 0.8625 - val_accuracy: 0.6058\n",
      "Epoch 153/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 0.4461 - accuracy: 0.7755 - val_loss: 0.8748 - val_accuracy: 0.5892\n",
      "Epoch 154/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.4442 - accuracy: 0.7812 - val_loss: 0.8576 - val_accuracy: 0.5992\n",
      "Epoch 155/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.4379 - accuracy: 0.7873 - val_loss: 0.8648 - val_accuracy: 0.5921\n",
      "Epoch 156/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.4393 - accuracy: 0.7854 - val_loss: 0.8637 - val_accuracy: 0.6046\n",
      "Epoch 157/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.4461 - accuracy: 0.7750 - val_loss: 0.8836 - val_accuracy: 0.5729\n",
      "Epoch 158/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.4406 - accuracy: 0.7814 - val_loss: 0.8713 - val_accuracy: 0.6000\n",
      "Epoch 159/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.4379 - accuracy: 0.7814 - val_loss: 0.8731 - val_accuracy: 0.5896\n",
      "Epoch 160/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.4365 - accuracy: 0.7829 - val_loss: 0.8689 - val_accuracy: 0.5979\n",
      "Epoch 161/1000\n",
      "5600/5600 [==============================] - 0s 44us/sample - loss: 0.4367 - accuracy: 0.7864 - val_loss: 0.8767 - val_accuracy: 0.6021\n",
      "Epoch 162/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.4385 - accuracy: 0.7791 - val_loss: 0.8854 - val_accuracy: 0.5825\n",
      "Epoch 163/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.4350 - accuracy: 0.7837 - val_loss: 0.8782 - val_accuracy: 0.5867\n",
      "Epoch 164/1000\n",
      "5600/5600 [==============================] - 0s 63us/sample - loss: 0.4381 - accuracy: 0.7793 - val_loss: 0.8843 - val_accuracy: 0.5921\n",
      "Epoch 165/1000\n",
      "5600/5600 [==============================] - 0s 45us/sample - loss: 0.4333 - accuracy: 0.7848 - val_loss: 0.8891 - val_accuracy: 0.6029\n",
      "Epoch 166/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.4322 - accuracy: 0.7902 - val_loss: 0.8810 - val_accuracy: 0.6046\n",
      "Epoch 167/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 0.4283 - accuracy: 0.7937 - val_loss: 0.8873 - val_accuracy: 0.5967\n",
      "Epoch 168/1000\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.4330 - accuracy: 0.7836 - val_loss: 0.8830 - val_accuracy: 0.5946\n",
      "Epoch 169/1000\n",
      "5600/5600 [==============================] - 0s 43us/sample - loss: 0.4292 - accuracy: 0.7877 - val_loss: 0.8930 - val_accuracy: 0.6042\n",
      "Epoch 170/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.4280 - accuracy: 0.7904 - val_loss: 0.8923 - val_accuracy: 0.5913\n",
      "Epoch 171/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.4358 - accuracy: 0.7814 - val_loss: 0.8939 - val_accuracy: 0.6054\n",
      "Epoch 172/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.4283 - accuracy: 0.7879 - val_loss: 0.8930 - val_accuracy: 0.5900\n",
      "Epoch 173/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.4250 - accuracy: 0.7880 - val_loss: 0.9049 - val_accuracy: 0.5896\n",
      "Epoch 174/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.4236 - accuracy: 0.7918 - val_loss: 0.8976 - val_accuracy: 0.6025\n",
      "Epoch 175/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.4248 - accuracy: 0.7929 - val_loss: 0.9007 - val_accuracy: 0.5942\n",
      "Epoch 176/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.4223 - accuracy: 0.7914 - val_loss: 0.9206 - val_accuracy: 0.5750\n",
      "Epoch 177/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.4282 - accuracy: 0.7886 - val_loss: 0.8983 - val_accuracy: 0.5921\n",
      "Epoch 178/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.4208 - accuracy: 0.7945 - val_loss: 0.9197 - val_accuracy: 0.6042\n",
      "Epoch 179/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.4277 - accuracy: 0.7877 - val_loss: 0.9118 - val_accuracy: 0.5858\n",
      "Epoch 180/1000\n",
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.4197 - accuracy: 0.7941 - val_loss: 0.9232 - val_accuracy: 0.5846\n",
      "Epoch 181/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.4205 - accuracy: 0.7905 - val_loss: 0.9060 - val_accuracy: 0.5954\n",
      "Epoch 182/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.4185 - accuracy: 0.7998 - val_loss: 0.9285 - val_accuracy: 0.5900\n",
      "Epoch 183/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.4164 - accuracy: 0.7982 - val_loss: 0.9218 - val_accuracy: 0.5942\n",
      "Epoch 184/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.4145 - accuracy: 0.8000 - val_loss: 0.9230 - val_accuracy: 0.6021\n",
      "Epoch 185/1000\n",
      "5600/5600 [==============================] - 0s 53us/sample - loss: 0.4190 - accuracy: 0.7921 - val_loss: 0.9248 - val_accuracy: 0.5904\n",
      "Epoch 186/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.4173 - accuracy: 0.7914 - val_loss: 0.9364 - val_accuracy: 0.5808\n",
      "Epoch 187/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.4162 - accuracy: 0.7934 - val_loss: 0.9290 - val_accuracy: 0.5821\n",
      "Epoch 188/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.4201 - accuracy: 0.7937 - val_loss: 0.9464 - val_accuracy: 0.5850\n",
      "Epoch 189/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.4151 - accuracy: 0.7966 - val_loss: 0.9362 - val_accuracy: 0.5813\n",
      "Epoch 190/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.4143 - accuracy: 0.7989 - val_loss: 0.9509 - val_accuracy: 0.5783\n",
      "Epoch 191/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.4124 - accuracy: 0.7964 - val_loss: 0.9439 - val_accuracy: 0.5896\n",
      "Epoch 192/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.4159 - accuracy: 0.7954 - val_loss: 0.9481 - val_accuracy: 0.6050\n",
      "Epoch 193/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.4111 - accuracy: 0.7991 - val_loss: 0.9357 - val_accuracy: 0.5796\n",
      "Epoch 194/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.4122 - accuracy: 0.7962 - val_loss: 0.9606 - val_accuracy: 0.5608\n",
      "Epoch 195/1000\n",
      "5600/5600 [==============================] - 0s 22us/sample - loss: 0.4130 - accuracy: 0.7995 - val_loss: 0.9463 - val_accuracy: 0.5829\n",
      "Epoch 196/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 0.4115 - accuracy: 0.8009 - val_loss: 0.9540 - val_accuracy: 0.6004\n",
      "Epoch 197/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.4075 - accuracy: 0.8021 - val_loss: 0.9658 - val_accuracy: 0.5679\n",
      "Epoch 198/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.4094 - accuracy: 0.8005 - val_loss: 0.9501 - val_accuracy: 0.5863\n",
      "Epoch 199/1000\n",
      "5600/5600 [==============================] - 0s 21us/sample - loss: 0.4072 - accuracy: 0.8002 - val_loss: 0.9582 - val_accuracy: 0.6046\n",
      "Epoch 200/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.4151 - accuracy: 0.7964 - val_loss: 0.9518 - val_accuracy: 0.5846\n",
      "Epoch 201/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.4029 - accuracy: 0.8043 - val_loss: 0.9636 - val_accuracy: 0.5825\n",
      "Epoch 202/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.4087 - accuracy: 0.7984 - val_loss: 0.9636 - val_accuracy: 0.5875\n",
      "Epoch 203/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.4040 - accuracy: 0.8052 - val_loss: 0.9714 - val_accuracy: 0.5804\n",
      "Epoch 204/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.4029 - accuracy: 0.8050 - val_loss: 0.9740 - val_accuracy: 0.5975\n",
      "Epoch 205/1000\n",
      "5600/5600 [==============================] - 0s 22us/sample - loss: 0.4003 - accuracy: 0.8030 - val_loss: 0.9718 - val_accuracy: 0.5783\n",
      "Epoch 206/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.4054 - accuracy: 0.8061 - val_loss: 0.9712 - val_accuracy: 0.5779\n",
      "Epoch 207/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.3999 - accuracy: 0.8064 - val_loss: 0.9677 - val_accuracy: 0.5958\n",
      "Epoch 208/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.3987 - accuracy: 0.8055 - val_loss: 0.9828 - val_accuracy: 0.6075\n",
      "Epoch 209/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.4078 - accuracy: 0.8005 - val_loss: 0.9779 - val_accuracy: 0.5775\n",
      "Epoch 210/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.4041 - accuracy: 0.7998 - val_loss: 0.9797 - val_accuracy: 0.5917\n",
      "Epoch 211/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.3940 - accuracy: 0.8150 - val_loss: 0.9892 - val_accuracy: 0.5771\n",
      "Epoch 212/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.3980 - accuracy: 0.8057 - val_loss: 0.9763 - val_accuracy: 0.5871\n",
      "Epoch 213/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.3970 - accuracy: 0.8120 - val_loss: 0.9719 - val_accuracy: 0.5917\n",
      "Epoch 214/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.3983 - accuracy: 0.8043 - val_loss: 1.0143 - val_accuracy: 0.5692\n",
      "Epoch 215/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.3958 - accuracy: 0.8062 - val_loss: 0.9740 - val_accuracy: 0.5788\n",
      "Epoch 216/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 39us/sample - loss: 0.3926 - accuracy: 0.8129 - val_loss: 0.9723 - val_accuracy: 0.5846\n",
      "Epoch 217/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.3955 - accuracy: 0.8086 - val_loss: 0.9746 - val_accuracy: 0.5800\n",
      "Epoch 218/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.3918 - accuracy: 0.8164 - val_loss: 0.9843 - val_accuracy: 0.5829\n",
      "Epoch 219/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.3927 - accuracy: 0.8104 - val_loss: 1.0023 - val_accuracy: 0.5842\n",
      "Epoch 220/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.3921 - accuracy: 0.8145 - val_loss: 1.0005 - val_accuracy: 0.5833\n",
      "Epoch 221/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.3912 - accuracy: 0.8150 - val_loss: 1.0054 - val_accuracy: 0.5813\n",
      "Epoch 222/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.3929 - accuracy: 0.8093 - val_loss: 0.9961 - val_accuracy: 0.6021\n",
      "Epoch 223/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.3926 - accuracy: 0.8121 - val_loss: 0.9991 - val_accuracy: 0.5950\n",
      "Epoch 224/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.3938 - accuracy: 0.8114 - val_loss: 1.0123 - val_accuracy: 0.5713\n",
      "Epoch 225/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.3911 - accuracy: 0.8139 - val_loss: 1.0031 - val_accuracy: 0.5992\n",
      "Epoch 226/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.3877 - accuracy: 0.8198 - val_loss: 1.0000 - val_accuracy: 0.5771\n",
      "Epoch 227/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.3893 - accuracy: 0.8163 - val_loss: 1.0187 - val_accuracy: 0.5733\n",
      "Epoch 228/1000\n",
      "5600/5600 [==============================] - 0s 22us/sample - loss: 0.3842 - accuracy: 0.8175 - val_loss: 1.0022 - val_accuracy: 0.5788\n",
      "Epoch 229/1000\n",
      "5600/5600 [==============================] - 0s 22us/sample - loss: 0.3848 - accuracy: 0.8155 - val_loss: 1.0093 - val_accuracy: 0.5746\n",
      "Epoch 230/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.3817 - accuracy: 0.8186 - val_loss: 1.0119 - val_accuracy: 0.5833\n",
      "Epoch 231/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.3869 - accuracy: 0.8112 - val_loss: 1.0153 - val_accuracy: 0.5800\n",
      "Epoch 232/1000\n",
      "5600/5600 [==============================] - 0s 22us/sample - loss: 0.3848 - accuracy: 0.8159 - val_loss: 1.0069 - val_accuracy: 0.5979\n",
      "Epoch 233/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.3859 - accuracy: 0.8141 - val_loss: 1.0336 - val_accuracy: 0.6087\n",
      "Epoch 234/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.3880 - accuracy: 0.8080 - val_loss: 1.0462 - val_accuracy: 0.5642\n",
      "Epoch 235/1000\n",
      "5600/5600 [==============================] - 0s 22us/sample - loss: 0.3854 - accuracy: 0.8180 - val_loss: 1.0191 - val_accuracy: 0.5996\n",
      "Epoch 236/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.3830 - accuracy: 0.8170 - val_loss: 1.0188 - val_accuracy: 0.5908\n",
      "Epoch 237/1000\n",
      "5600/5600 [==============================] - 0s 22us/sample - loss: 0.3764 - accuracy: 0.8205 - val_loss: 1.0138 - val_accuracy: 0.5896\n",
      "Epoch 238/1000\n",
      "5600/5600 [==============================] - 0s 22us/sample - loss: 0.3814 - accuracy: 0.8188 - val_loss: 1.0360 - val_accuracy: 0.5679\n",
      "Epoch 239/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.3780 - accuracy: 0.8204 - val_loss: 1.0523 - val_accuracy: 0.5892\n",
      "Epoch 240/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.3826 - accuracy: 0.8168 - val_loss: 1.0403 - val_accuracy: 0.5825\n",
      "Epoch 241/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.3780 - accuracy: 0.8159 - val_loss: 1.0527 - val_accuracy: 0.6012\n",
      "Epoch 242/1000\n",
      "5600/5600 [==============================] - 0s 22us/sample - loss: 0.3823 - accuracy: 0.8138 - val_loss: 1.0376 - val_accuracy: 0.5821\n",
      "Epoch 243/1000\n",
      "5600/5600 [==============================] - 0s 22us/sample - loss: 0.3732 - accuracy: 0.8213 - val_loss: 1.0499 - val_accuracy: 0.5663\n",
      "Epoch 244/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.3749 - accuracy: 0.8263 - val_loss: 1.0472 - val_accuracy: 0.5825\n",
      "Epoch 245/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.3808 - accuracy: 0.8146 - val_loss: 1.0346 - val_accuracy: 0.5979\n",
      "Epoch 246/1000\n",
      "5600/5600 [==============================] - 0s 22us/sample - loss: 0.3766 - accuracy: 0.8214 - val_loss: 1.0410 - val_accuracy: 0.5775\n",
      "Epoch 247/1000\n",
      "5600/5600 [==============================] - 0s 22us/sample - loss: 0.3706 - accuracy: 0.8246 - val_loss: 1.0539 - val_accuracy: 0.5896\n",
      "Epoch 248/1000\n",
      "5600/5600 [==============================] - 0s 22us/sample - loss: 0.3831 - accuracy: 0.8079 - val_loss: 1.0435 - val_accuracy: 0.5979\n",
      "Epoch 249/1000\n",
      "5600/5600 [==============================] - 0s 21us/sample - loss: 0.3709 - accuracy: 0.8213 - val_loss: 1.0541 - val_accuracy: 0.5746\n",
      "Epoch 250/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.3735 - accuracy: 0.8243 - val_loss: 1.0810 - val_accuracy: 0.5738\n",
      "Epoch 251/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.3833 - accuracy: 0.8120 - val_loss: 1.0435 - val_accuracy: 0.5825\n",
      "Epoch 252/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.3695 - accuracy: 0.8255 - val_loss: 1.0508 - val_accuracy: 0.5783\n",
      "Epoch 253/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.3772 - accuracy: 0.8161 - val_loss: 1.0503 - val_accuracy: 0.5838\n",
      "Epoch 254/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.3684 - accuracy: 0.8216 - val_loss: 1.0609 - val_accuracy: 0.5808\n",
      "Epoch 255/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.3636 - accuracy: 0.8323 - val_loss: 1.0618 - val_accuracy: 0.5725\n",
      "Epoch 256/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.3672 - accuracy: 0.8268 - val_loss: 1.0597 - val_accuracy: 0.5746\n",
      "Epoch 257/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.3643 - accuracy: 0.8296 - val_loss: 1.0795 - val_accuracy: 0.5938\n",
      "Epoch 258/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.3675 - accuracy: 0.8254 - val_loss: 1.0793 - val_accuracy: 0.5942\n",
      "Epoch 259/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.3633 - accuracy: 0.8289 - val_loss: 1.0537 - val_accuracy: 0.5858\n",
      "Epoch 260/1000\n",
      "5600/5600 [==============================] - 0s 22us/sample - loss: 0.3612 - accuracy: 0.8280 - val_loss: 1.0492 - val_accuracy: 0.5879\n",
      "Epoch 261/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.3620 - accuracy: 0.8314 - val_loss: 1.0614 - val_accuracy: 0.5783\n",
      "Epoch 262/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.3610 - accuracy: 0.8314 - val_loss: 1.0752 - val_accuracy: 0.5954\n",
      "Epoch 263/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.3609 - accuracy: 0.8275 - val_loss: 1.0873 - val_accuracy: 0.5700\n",
      "Epoch 264/1000\n",
      "5600/5600 [==============================] - 0s 22us/sample - loss: 0.3679 - accuracy: 0.8266 - val_loss: 1.0650 - val_accuracy: 0.5796\n",
      "Epoch 265/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.3628 - accuracy: 0.8327 - val_loss: 1.0846 - val_accuracy: 0.5792\n",
      "Epoch 266/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.3686 - accuracy: 0.8220 - val_loss: 1.0755 - val_accuracy: 0.5958\n",
      "Epoch 267/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.3691 - accuracy: 0.8264 - val_loss: 1.1049 - val_accuracy: 0.6154\n",
      "Epoch 268/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.3597 - accuracy: 0.8295 - val_loss: 1.0845 - val_accuracy: 0.5833\n",
      "Epoch 269/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.3604 - accuracy: 0.8332 - val_loss: 1.0833 - val_accuracy: 0.5983\n",
      "Epoch 270/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.3593 - accuracy: 0.8345 - val_loss: 1.0880 - val_accuracy: 0.5867\n",
      "Epoch 271/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.3642 - accuracy: 0.8261 - val_loss: 1.1071 - val_accuracy: 0.5758\n",
      "Epoch 272/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.3577 - accuracy: 0.8329 - val_loss: 1.0898 - val_accuracy: 0.5829\n",
      "Epoch 273/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.3614 - accuracy: 0.8298 - val_loss: 1.1005 - val_accuracy: 0.5792\n",
      "Epoch 274/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.3537 - accuracy: 0.8370 - val_loss: 1.1069 - val_accuracy: 0.5638\n",
      "Epoch 275/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.3558 - accuracy: 0.8334 - val_loss: 1.0896 - val_accuracy: 0.5775\n",
      "Epoch 276/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.3579 - accuracy: 0.8332 - val_loss: 1.0977 - val_accuracy: 0.5804\n",
      "Epoch 277/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.3593 - accuracy: 0.8307 - val_loss: 1.1019 - val_accuracy: 0.5783\n",
      "Epoch 278/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.3593 - accuracy: 0.8291 - val_loss: 1.1035 - val_accuracy: 0.5783\n",
      "Epoch 279/1000\n",
      "5600/5600 [==============================] - 0s 22us/sample - loss: 0.3569 - accuracy: 0.8318 - val_loss: 1.0947 - val_accuracy: 0.5879\n",
      "Epoch 280/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.3538 - accuracy: 0.8423 - val_loss: 1.0978 - val_accuracy: 0.5867\n",
      "Epoch 281/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.3549 - accuracy: 0.8329 - val_loss: 1.1267 - val_accuracy: 0.5742\n",
      "Epoch 282/1000\n",
      "5600/5600 [==============================] - 0s 22us/sample - loss: 0.3531 - accuracy: 0.8357 - val_loss: 1.0931 - val_accuracy: 0.5754\n",
      "Epoch 283/1000\n",
      "5600/5600 [==============================] - 0s 22us/sample - loss: 0.3506 - accuracy: 0.8368 - val_loss: 1.1267 - val_accuracy: 0.5704\n",
      "Epoch 284/1000\n",
      "5600/5600 [==============================] - 0s 22us/sample - loss: 0.3554 - accuracy: 0.8304 - val_loss: 1.1112 - val_accuracy: 0.5779\n",
      "Epoch 285/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.3465 - accuracy: 0.8438 - val_loss: 1.0959 - val_accuracy: 0.5913\n",
      "Epoch 286/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.3494 - accuracy: 0.8377 - val_loss: 1.1085 - val_accuracy: 0.5754\n",
      "Epoch 287/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.3501 - accuracy: 0.8373 - val_loss: 1.1070 - val_accuracy: 0.5863\n",
      "Epoch 288/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.3451 - accuracy: 0.8420 - val_loss: 1.1112 - val_accuracy: 0.5804\n",
      "Epoch 289/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.3510 - accuracy: 0.8386 - val_loss: 1.1375 - val_accuracy: 0.5663\n",
      "Epoch 290/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.3479 - accuracy: 0.8373 - val_loss: 1.1210 - val_accuracy: 0.5967\n",
      "Epoch 291/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.3526 - accuracy: 0.8350 - val_loss: 1.1065 - val_accuracy: 0.5775\n",
      "Epoch 292/1000\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.3568 - accuracy: 0.8288 - val_loss: 1.1403 - val_accuracy: 0.5946\n",
      "Epoch 293/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.3555 - accuracy: 0.8320 - val_loss: 1.1115 - val_accuracy: 0.5904\n",
      "Epoch 294/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.3472 - accuracy: 0.8389 - val_loss: 1.1215 - val_accuracy: 0.5746\n",
      "Epoch 295/1000\n",
      "5600/5600 [==============================] - 0s 22us/sample - loss: 0.3451 - accuracy: 0.8395 - val_loss: 1.1545 - val_accuracy: 0.5938\n",
      "Epoch 296/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.3436 - accuracy: 0.8438 - val_loss: 1.1295 - val_accuracy: 0.5813\n",
      "Epoch 297/1000\n",
      "5600/5600 [==============================] - 0s 43us/sample - loss: 0.3422 - accuracy: 0.8452 - val_loss: 1.1348 - val_accuracy: 0.5746\n",
      "Epoch 298/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 0.3446 - accuracy: 0.8407 - val_loss: 1.1215 - val_accuracy: 0.5717\n",
      "Epoch 299/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 0.3460 - accuracy: 0.8341 - val_loss: 1.1532 - val_accuracy: 0.5892\n",
      "Epoch 300/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.3449 - accuracy: 0.8416 - val_loss: 1.1238 - val_accuracy: 0.5983\n",
      "Epoch 301/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.3525 - accuracy: 0.8304 - val_loss: 1.1446 - val_accuracy: 0.5933\n",
      "Epoch 302/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.3405 - accuracy: 0.8436 - val_loss: 1.1659 - val_accuracy: 0.5754\n",
      "Epoch 303/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.3496 - accuracy: 0.8348 - val_loss: 1.1442 - val_accuracy: 0.5933\n",
      "Epoch 304/1000\n",
      "5600/5600 [==============================] - 0s 46us/sample - loss: 0.3388 - accuracy: 0.8475 - val_loss: 1.1399 - val_accuracy: 0.5788\n",
      "Epoch 305/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.3343 - accuracy: 0.8479 - val_loss: 1.1390 - val_accuracy: 0.5908\n",
      "Epoch 306/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.3372 - accuracy: 0.8432 - val_loss: 1.1399 - val_accuracy: 0.5858\n",
      "Epoch 307/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.3412 - accuracy: 0.8439 - val_loss: 1.1550 - val_accuracy: 0.5688\n",
      "Epoch 308/1000\n",
      "5600/5600 [==============================] - 0s 47us/sample - loss: 0.3434 - accuracy: 0.8389 - val_loss: 1.1566 - val_accuracy: 0.5788\n",
      "Epoch 309/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.3435 - accuracy: 0.8400 - val_loss: 1.1524 - val_accuracy: 0.5863\n",
      "Epoch 310/1000\n",
      "5600/5600 [==============================] - 0s 44us/sample - loss: 0.3353 - accuracy: 0.8495 - val_loss: 1.1710 - val_accuracy: 0.5733\n",
      "Epoch 311/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.3360 - accuracy: 0.8432 - val_loss: 1.1646 - val_accuracy: 0.5842\n",
      "Epoch 312/1000\n",
      "5600/5600 [==============================] - 0s 43us/sample - loss: 0.3370 - accuracy: 0.8454 - val_loss: 1.1577 - val_accuracy: 0.5771\n",
      "Epoch 313/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.3335 - accuracy: 0.8507 - val_loss: 1.1652 - val_accuracy: 0.5704\n",
      "Epoch 314/1000\n",
      "5600/5600 [==============================] - 0s 43us/sample - loss: 0.3299 - accuracy: 0.8482 - val_loss: 1.1533 - val_accuracy: 0.5913\n",
      "Epoch 315/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.3383 - accuracy: 0.8430 - val_loss: 1.1374 - val_accuracy: 0.5779\n",
      "Epoch 316/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.3354 - accuracy: 0.8434 - val_loss: 1.1775 - val_accuracy: 0.5708\n",
      "Epoch 317/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.3364 - accuracy: 0.8416 - val_loss: 1.1845 - val_accuracy: 0.5713\n",
      "Epoch 318/1000\n",
      "5600/5600 [==============================] - 0s 42us/sample - loss: 0.3343 - accuracy: 0.8462 - val_loss: 1.1717 - val_accuracy: 0.5863\n",
      "Epoch 319/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.3342 - accuracy: 0.8441 - val_loss: 1.1702 - val_accuracy: 0.5721\n",
      "Epoch 320/1000\n",
      "5600/5600 [==============================] - 0s 43us/sample - loss: 0.3275 - accuracy: 0.8495 - val_loss: 1.1802 - val_accuracy: 0.5900\n",
      "Epoch 321/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.3335 - accuracy: 0.8411 - val_loss: 1.1823 - val_accuracy: 0.5846\n",
      "Epoch 322/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.3317 - accuracy: 0.8502 - val_loss: 1.2058 - val_accuracy: 0.5642\n",
      "Epoch 323/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.3355 - accuracy: 0.8502 - val_loss: 1.1731 - val_accuracy: 0.5708\n",
      "Epoch 324/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.3286 - accuracy: 0.8489 - val_loss: 1.1864 - val_accuracy: 0.5792\n",
      "Epoch 325/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.3317 - accuracy: 0.8461 - val_loss: 1.2141 - val_accuracy: 0.5729\n",
      "Epoch 326/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.3338 - accuracy: 0.8414 - val_loss: 1.1800 - val_accuracy: 0.5754\n",
      "Epoch 327/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.3265 - accuracy: 0.8486 - val_loss: 1.1839 - val_accuracy: 0.5996\n",
      "Epoch 328/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.3269 - accuracy: 0.8448 - val_loss: 1.1930 - val_accuracy: 0.5938\n",
      "Epoch 329/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.3330 - accuracy: 0.8457 - val_loss: 1.1766 - val_accuracy: 0.5679\n",
      "Epoch 330/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.3247 - accuracy: 0.8520 - val_loss: 1.1815 - val_accuracy: 0.5833\n",
      "Epoch 331/1000\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.3364 - accuracy: 0.8413 - val_loss: 1.2192 - val_accuracy: 0.6042\n",
      "Epoch 332/1000\n",
      "5600/5600 [==============================] - 0s 40us/sample - loss: 0.3258 - accuracy: 0.8536 - val_loss: 1.1961 - val_accuracy: 0.6008\n",
      "Epoch 333/1000\n",
      "5600/5600 [==============================] - 0s 41us/sample - loss: 0.3254 - accuracy: 0.8577 - val_loss: 1.1820 - val_accuracy: 0.5725\n",
      "Epoch 334/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.3312 - accuracy: 0.8470 - val_loss: 1.2374 - val_accuracy: 0.5608\n",
      "Epoch 335/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.3243 - accuracy: 0.8518 - val_loss: 1.1924 - val_accuracy: 0.5713\n",
      "Epoch 336/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.3251 - accuracy: 0.8527 - val_loss: 1.1976 - val_accuracy: 0.5683\n",
      "Epoch 337/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.3239 - accuracy: 0.8509 - val_loss: 1.1979 - val_accuracy: 0.5792\n",
      "Epoch 338/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.3157 - accuracy: 0.8584 - val_loss: 1.2017 - val_accuracy: 0.5817\n",
      "Epoch 339/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.3171 - accuracy: 0.8566 - val_loss: 1.2264 - val_accuracy: 0.5958\n",
      "Epoch 340/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.3165 - accuracy: 0.8557 - val_loss: 1.2072 - val_accuracy: 0.5713\n",
      "Epoch 341/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.3151 - accuracy: 0.8596 - val_loss: 1.2288 - val_accuracy: 0.5679\n",
      "Epoch 342/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.3182 - accuracy: 0.8537 - val_loss: 1.2008 - val_accuracy: 0.5838\n",
      "Epoch 343/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.3209 - accuracy: 0.8562 - val_loss: 1.2126 - val_accuracy: 0.5838\n",
      "Epoch 344/1000\n",
      "5600/5600 [==============================] - 0s 52us/sample - loss: 0.3206 - accuracy: 0.8546 - val_loss: 1.2064 - val_accuracy: 0.5808\n",
      "Epoch 345/1000\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.3212 - accuracy: 0.8523 - val_loss: 1.2447 - val_accuracy: 0.5562\n",
      "Epoch 346/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.3195 - accuracy: 0.8529 - val_loss: 1.2500 - val_accuracy: 0.5558\n",
      "Epoch 347/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.3136 - accuracy: 0.8623 - val_loss: 1.2201 - val_accuracy: 0.5846\n",
      "Epoch 348/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.3207 - accuracy: 0.8539 - val_loss: 1.2434 - val_accuracy: 0.5671\n",
      "Epoch 349/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.3299 - accuracy: 0.8452 - val_loss: 1.2194 - val_accuracy: 0.5650\n",
      "Epoch 350/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.3183 - accuracy: 0.8543 - val_loss: 1.2090 - val_accuracy: 0.5888\n",
      "Epoch 351/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.3164 - accuracy: 0.8564 - val_loss: 1.2639 - val_accuracy: 0.5587\n",
      "Epoch 352/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.3222 - accuracy: 0.8461 - val_loss: 1.2342 - val_accuracy: 0.5583\n",
      "Epoch 353/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.3179 - accuracy: 0.8525 - val_loss: 1.2303 - val_accuracy: 0.5746\n",
      "Epoch 354/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.3103 - accuracy: 0.8587 - val_loss: 1.2243 - val_accuracy: 0.5704\n",
      "Epoch 355/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.3120 - accuracy: 0.8598 - val_loss: 1.2360 - val_accuracy: 0.5738\n",
      "Epoch 356/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.3076 - accuracy: 0.8652 - val_loss: 1.2256 - val_accuracy: 0.5846\n",
      "Epoch 357/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.3122 - accuracy: 0.8604 - val_loss: 1.2589 - val_accuracy: 0.5675\n",
      "Epoch 358/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.3135 - accuracy: 0.8614 - val_loss: 1.2541 - val_accuracy: 0.5633\n",
      "Epoch 359/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.3187 - accuracy: 0.8534 - val_loss: 1.2456 - val_accuracy: 0.5813\n",
      "Epoch 360/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.3114 - accuracy: 0.8552 - val_loss: 1.2263 - val_accuracy: 0.5763\n",
      "Epoch 361/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.3121 - accuracy: 0.8584 - val_loss: 1.2468 - val_accuracy: 0.5779\n",
      "Epoch 362/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.3129 - accuracy: 0.8568 - val_loss: 1.2493 - val_accuracy: 0.5738\n",
      "Epoch 363/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.3116 - accuracy: 0.8582 - val_loss: 1.2344 - val_accuracy: 0.5788\n",
      "Epoch 364/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.3050 - accuracy: 0.8630 - val_loss: 1.2454 - val_accuracy: 0.5804\n",
      "Epoch 365/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.3071 - accuracy: 0.8625 - val_loss: 1.2804 - val_accuracy: 0.5604\n",
      "Epoch 366/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.3093 - accuracy: 0.8604 - val_loss: 1.2681 - val_accuracy: 0.6037\n",
      "Epoch 367/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.3161 - accuracy: 0.8562 - val_loss: 1.2480 - val_accuracy: 0.5733\n",
      "Epoch 368/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.3073 - accuracy: 0.8596 - val_loss: 1.2531 - val_accuracy: 0.5871\n",
      "Epoch 369/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.3090 - accuracy: 0.8614 - val_loss: 1.2650 - val_accuracy: 0.6025\n",
      "Epoch 370/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.3053 - accuracy: 0.8602 - val_loss: 1.2711 - val_accuracy: 0.5713\n",
      "Epoch 371/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.3011 - accuracy: 0.8609 - val_loss: 1.2557 - val_accuracy: 0.5800\n",
      "Epoch 372/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.3004 - accuracy: 0.8684 - val_loss: 1.2647 - val_accuracy: 0.5846\n",
      "Epoch 373/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.3004 - accuracy: 0.8632 - val_loss: 1.2672 - val_accuracy: 0.5842\n",
      "Epoch 374/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.3054 - accuracy: 0.8580 - val_loss: 1.2671 - val_accuracy: 0.5604\n",
      "Epoch 375/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.2996 - accuracy: 0.8725 - val_loss: 1.2484 - val_accuracy: 0.5729\n",
      "Epoch 376/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.3020 - accuracy: 0.8646 - val_loss: 1.2650 - val_accuracy: 0.5863\n",
      "Epoch 377/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.3076 - accuracy: 0.8643 - val_loss: 1.2889 - val_accuracy: 0.5692\n",
      "Epoch 378/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.3077 - accuracy: 0.8593 - val_loss: 1.2814 - val_accuracy: 0.5650\n",
      "Epoch 379/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.3062 - accuracy: 0.8636 - val_loss: 1.2550 - val_accuracy: 0.5754\n",
      "Epoch 380/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2987 - accuracy: 0.8679 - val_loss: 1.2598 - val_accuracy: 0.5821\n",
      "Epoch 381/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.3026 - accuracy: 0.8650 - val_loss: 1.2953 - val_accuracy: 0.5783\n",
      "Epoch 382/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.3019 - accuracy: 0.8646 - val_loss: 1.2469 - val_accuracy: 0.5900\n",
      "Epoch 383/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.3032 - accuracy: 0.8643 - val_loss: 1.3221 - val_accuracy: 0.5904\n",
      "Epoch 384/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.3044 - accuracy: 0.8643 - val_loss: 1.3358 - val_accuracy: 0.5458\n",
      "Epoch 385/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.2990 - accuracy: 0.8637 - val_loss: 1.2875 - val_accuracy: 0.5604\n",
      "Epoch 386/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2998 - accuracy: 0.8686 - val_loss: 1.2783 - val_accuracy: 0.5675\n",
      "Epoch 387/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.3065 - accuracy: 0.8605 - val_loss: 1.2915 - val_accuracy: 0.5713\n",
      "Epoch 388/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2937 - accuracy: 0.8657 - val_loss: 1.2806 - val_accuracy: 0.5742\n",
      "Epoch 389/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2981 - accuracy: 0.8668 - val_loss: 1.2746 - val_accuracy: 0.5779\n",
      "Epoch 390/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.2947 - accuracy: 0.8725 - val_loss: 1.2834 - val_accuracy: 0.5842\n",
      "Epoch 391/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.3036 - accuracy: 0.8632 - val_loss: 1.2922 - val_accuracy: 0.5746\n",
      "Epoch 392/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2932 - accuracy: 0.8720 - val_loss: 1.2954 - val_accuracy: 0.5696\n",
      "Epoch 393/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.3003 - accuracy: 0.8627 - val_loss: 1.3053 - val_accuracy: 0.5642\n",
      "Epoch 394/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2943 - accuracy: 0.8704 - val_loss: 1.2974 - val_accuracy: 0.5771\n",
      "Epoch 395/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2940 - accuracy: 0.8698 - val_loss: 1.2686 - val_accuracy: 0.5842\n",
      "Epoch 396/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2977 - accuracy: 0.8646 - val_loss: 1.3576 - val_accuracy: 0.5654\n",
      "Epoch 397/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2935 - accuracy: 0.8741 - val_loss: 1.2815 - val_accuracy: 0.5829\n",
      "Epoch 398/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2962 - accuracy: 0.8695 - val_loss: 1.3297 - val_accuracy: 0.5871\n",
      "Epoch 399/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2928 - accuracy: 0.8702 - val_loss: 1.2946 - val_accuracy: 0.5821\n",
      "Epoch 400/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2872 - accuracy: 0.8761 - val_loss: 1.3015 - val_accuracy: 0.5863\n",
      "Epoch 401/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.2879 - accuracy: 0.8721 - val_loss: 1.3113 - val_accuracy: 0.5825\n",
      "Epoch 402/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.2883 - accuracy: 0.8680 - val_loss: 1.3125 - val_accuracy: 0.5758\n",
      "Epoch 403/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2893 - accuracy: 0.8702 - val_loss: 1.2981 - val_accuracy: 0.5938\n",
      "Epoch 404/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2905 - accuracy: 0.8736 - val_loss: 1.3112 - val_accuracy: 0.5717\n",
      "Epoch 405/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2871 - accuracy: 0.8761 - val_loss: 1.3212 - val_accuracy: 0.5592\n",
      "Epoch 406/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.2896 - accuracy: 0.8695 - val_loss: 1.3196 - val_accuracy: 0.5671\n",
      "Epoch 407/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.2851 - accuracy: 0.8752 - val_loss: 1.3345 - val_accuracy: 0.5800\n",
      "Epoch 408/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2840 - accuracy: 0.8759 - val_loss: 1.3164 - val_accuracy: 0.5767\n",
      "Epoch 409/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.2874 - accuracy: 0.8725 - val_loss: 1.3146 - val_accuracy: 0.5738\n",
      "Epoch 410/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2865 - accuracy: 0.8748 - val_loss: 1.3492 - val_accuracy: 0.5829\n",
      "Epoch 411/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2860 - accuracy: 0.8761 - val_loss: 1.3217 - val_accuracy: 0.5813\n",
      "Epoch 412/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2841 - accuracy: 0.8752 - val_loss: 1.3492 - val_accuracy: 0.5625\n",
      "Epoch 413/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2883 - accuracy: 0.8721 - val_loss: 1.3185 - val_accuracy: 0.5904\n",
      "Epoch 414/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2842 - accuracy: 0.8763 - val_loss: 1.3200 - val_accuracy: 0.5750\n",
      "Epoch 415/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2857 - accuracy: 0.8757 - val_loss: 1.3358 - val_accuracy: 0.5700\n",
      "Epoch 416/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2822 - accuracy: 0.8802 - val_loss: 1.3183 - val_accuracy: 0.5771\n",
      "Epoch 417/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2817 - accuracy: 0.8764 - val_loss: 1.3312 - val_accuracy: 0.5792\n",
      "Epoch 418/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2768 - accuracy: 0.8832 - val_loss: 1.3552 - val_accuracy: 0.5717\n",
      "Epoch 419/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.2800 - accuracy: 0.8802 - val_loss: 1.3312 - val_accuracy: 0.5746\n",
      "Epoch 420/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2779 - accuracy: 0.8807 - val_loss: 1.3282 - val_accuracy: 0.5758\n",
      "Epoch 421/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2807 - accuracy: 0.8766 - val_loss: 1.3568 - val_accuracy: 0.5842\n",
      "Epoch 422/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2799 - accuracy: 0.8782 - val_loss: 1.3314 - val_accuracy: 0.5875\n",
      "Epoch 423/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.2813 - accuracy: 0.8755 - val_loss: 1.3316 - val_accuracy: 0.5779\n",
      "Epoch 424/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.2775 - accuracy: 0.8771 - val_loss: 1.3339 - val_accuracy: 0.5883\n",
      "Epoch 425/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2787 - accuracy: 0.8752 - val_loss: 1.3643 - val_accuracy: 0.5942\n",
      "Epoch 426/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2777 - accuracy: 0.8804 - val_loss: 1.3683 - val_accuracy: 0.5717\n",
      "Epoch 427/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2780 - accuracy: 0.8802 - val_loss: 1.3717 - val_accuracy: 0.5667\n",
      "Epoch 428/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2815 - accuracy: 0.8736 - val_loss: 1.3336 - val_accuracy: 0.5775\n",
      "Epoch 429/1000\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.2766 - accuracy: 0.8795 - val_loss: 1.3861 - val_accuracy: 0.5783\n",
      "Epoch 430/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.2778 - accuracy: 0.8755 - val_loss: 1.3666 - val_accuracy: 0.5700\n",
      "Epoch 431/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2770 - accuracy: 0.8759 - val_loss: 1.3474 - val_accuracy: 0.5725\n",
      "Epoch 432/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.2747 - accuracy: 0.8786 - val_loss: 1.3634 - val_accuracy: 0.5871\n",
      "Epoch 433/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2775 - accuracy: 0.8802 - val_loss: 1.3562 - val_accuracy: 0.5675\n",
      "Epoch 434/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2766 - accuracy: 0.8779 - val_loss: 1.3780 - val_accuracy: 0.5758\n",
      "Epoch 435/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.2729 - accuracy: 0.8813 - val_loss: 1.3567 - val_accuracy: 0.5854\n",
      "Epoch 436/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2786 - accuracy: 0.8745 - val_loss: 1.3612 - val_accuracy: 0.5792\n",
      "Epoch 437/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2715 - accuracy: 0.8791 - val_loss: 1.3798 - val_accuracy: 0.5696\n",
      "Epoch 438/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.2775 - accuracy: 0.8789 - val_loss: 1.3949 - val_accuracy: 0.6008\n",
      "Epoch 439/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2879 - accuracy: 0.8727 - val_loss: 1.3772 - val_accuracy: 0.5808\n",
      "Epoch 440/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2839 - accuracy: 0.8732 - val_loss: 1.3990 - val_accuracy: 0.5996\n",
      "Epoch 441/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2735 - accuracy: 0.8813 - val_loss: 1.4093 - val_accuracy: 0.5575\n",
      "Epoch 442/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2740 - accuracy: 0.8805 - val_loss: 1.3844 - val_accuracy: 0.5713\n",
      "Epoch 443/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.2699 - accuracy: 0.8871 - val_loss: 1.3731 - val_accuracy: 0.5717\n",
      "Epoch 444/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.2790 - accuracy: 0.8764 - val_loss: 1.4077 - val_accuracy: 0.5742\n",
      "Epoch 445/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.2854 - accuracy: 0.8704 - val_loss: 1.3594 - val_accuracy: 0.5763\n",
      "Epoch 446/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.2709 - accuracy: 0.8852 - val_loss: 1.4014 - val_accuracy: 0.5596\n",
      "Epoch 447/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2715 - accuracy: 0.8825 - val_loss: 1.3920 - val_accuracy: 0.5671\n",
      "Epoch 448/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.2711 - accuracy: 0.8796 - val_loss: 1.3910 - val_accuracy: 0.5850\n",
      "Epoch 449/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2655 - accuracy: 0.8877 - val_loss: 1.3763 - val_accuracy: 0.5842\n",
      "Epoch 450/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2665 - accuracy: 0.8820 - val_loss: 1.4177 - val_accuracy: 0.5575\n",
      "Epoch 451/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2669 - accuracy: 0.8854 - val_loss: 1.4112 - val_accuracy: 0.5846\n",
      "Epoch 452/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2683 - accuracy: 0.8814 - val_loss: 1.3945 - val_accuracy: 0.5817\n",
      "Epoch 453/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2663 - accuracy: 0.8868 - val_loss: 1.3870 - val_accuracy: 0.5721\n",
      "Epoch 454/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2643 - accuracy: 0.8841 - val_loss: 1.4406 - val_accuracy: 0.5583\n",
      "Epoch 455/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2655 - accuracy: 0.8854 - val_loss: 1.3891 - val_accuracy: 0.5929\n",
      "Epoch 456/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2643 - accuracy: 0.8866 - val_loss: 1.4013 - val_accuracy: 0.5838\n",
      "Epoch 457/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2610 - accuracy: 0.8914 - val_loss: 1.4160 - val_accuracy: 0.5750\n",
      "Epoch 458/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.2631 - accuracy: 0.8896 - val_loss: 1.4040 - val_accuracy: 0.5679\n",
      "Epoch 459/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2766 - accuracy: 0.8741 - val_loss: 1.3938 - val_accuracy: 0.5704\n",
      "Epoch 460/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2749 - accuracy: 0.8754 - val_loss: 1.4080 - val_accuracy: 0.5725\n",
      "Epoch 461/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2611 - accuracy: 0.8889 - val_loss: 1.4272 - val_accuracy: 0.5604\n",
      "Epoch 462/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.2758 - accuracy: 0.8798 - val_loss: 1.4707 - val_accuracy: 0.5546\n",
      "Epoch 463/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.2689 - accuracy: 0.8818 - val_loss: 1.3964 - val_accuracy: 0.5688\n",
      "Epoch 464/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2688 - accuracy: 0.8838 - val_loss: 1.4161 - val_accuracy: 0.5850\n",
      "Epoch 465/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2629 - accuracy: 0.8846 - val_loss: 1.4197 - val_accuracy: 0.5738\n",
      "Epoch 466/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.2615 - accuracy: 0.8893 - val_loss: 1.3999 - val_accuracy: 0.5825\n",
      "Epoch 467/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2576 - accuracy: 0.8930 - val_loss: 1.4291 - val_accuracy: 0.5642\n",
      "Epoch 468/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2607 - accuracy: 0.8902 - val_loss: 1.4246 - val_accuracy: 0.5875\n",
      "Epoch 469/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2594 - accuracy: 0.8871 - val_loss: 1.4360 - val_accuracy: 0.5821\n",
      "Epoch 470/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2658 - accuracy: 0.8870 - val_loss: 1.4234 - val_accuracy: 0.5779\n",
      "Epoch 471/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2603 - accuracy: 0.8896 - val_loss: 1.4428 - val_accuracy: 0.5850\n",
      "Epoch 472/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2675 - accuracy: 0.8823 - val_loss: 1.4264 - val_accuracy: 0.5783\n",
      "Epoch 473/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.2577 - accuracy: 0.8889 - val_loss: 1.4352 - val_accuracy: 0.5717\n",
      "Epoch 474/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2574 - accuracy: 0.8948 - val_loss: 1.4383 - val_accuracy: 0.5813\n",
      "Epoch 475/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2549 - accuracy: 0.8934 - val_loss: 1.4545 - val_accuracy: 0.5646\n",
      "Epoch 476/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2543 - accuracy: 0.8905 - val_loss: 1.4109 - val_accuracy: 0.5775\n",
      "Epoch 477/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2633 - accuracy: 0.8861 - val_loss: 1.4761 - val_accuracy: 0.5625\n",
      "Epoch 478/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2665 - accuracy: 0.8809 - val_loss: 1.4783 - val_accuracy: 0.5654\n",
      "Epoch 479/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2568 - accuracy: 0.8891 - val_loss: 1.4446 - val_accuracy: 0.5708\n",
      "Epoch 480/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.2574 - accuracy: 0.8916 - val_loss: 1.4641 - val_accuracy: 0.5829\n",
      "Epoch 481/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2588 - accuracy: 0.8893 - val_loss: 1.4563 - val_accuracy: 0.5788\n",
      "Epoch 482/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2552 - accuracy: 0.8909 - val_loss: 1.4322 - val_accuracy: 0.5842\n",
      "Epoch 483/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2514 - accuracy: 0.8973 - val_loss: 1.4693 - val_accuracy: 0.5892\n",
      "Epoch 484/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2531 - accuracy: 0.8930 - val_loss: 1.4534 - val_accuracy: 0.5671\n",
      "Epoch 485/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2515 - accuracy: 0.8950 - val_loss: 1.4843 - val_accuracy: 0.5708\n",
      "Epoch 486/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2536 - accuracy: 0.8904 - val_loss: 1.4657 - val_accuracy: 0.5788\n",
      "Epoch 487/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.2511 - accuracy: 0.8938 - val_loss: 1.4549 - val_accuracy: 0.5729\n",
      "Epoch 488/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2667 - accuracy: 0.8857 - val_loss: 1.4358 - val_accuracy: 0.5854\n",
      "Epoch 489/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2532 - accuracy: 0.8880 - val_loss: 1.4825 - val_accuracy: 0.5758\n",
      "Epoch 490/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2483 - accuracy: 0.8934 - val_loss: 1.4880 - val_accuracy: 0.5817\n",
      "Epoch 491/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.2498 - accuracy: 0.8945 - val_loss: 1.4739 - val_accuracy: 0.5663\n",
      "Epoch 492/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.2506 - accuracy: 0.8932 - val_loss: 1.4768 - val_accuracy: 0.5817\n",
      "Epoch 493/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.2532 - accuracy: 0.8916 - val_loss: 1.4742 - val_accuracy: 0.5671\n",
      "Epoch 494/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2526 - accuracy: 0.8911 - val_loss: 1.4575 - val_accuracy: 0.5733\n",
      "Epoch 495/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2514 - accuracy: 0.8993 - val_loss: 1.4656 - val_accuracy: 0.5838\n",
      "Epoch 496/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2468 - accuracy: 0.8961 - val_loss: 1.4844 - val_accuracy: 0.5729\n",
      "Epoch 497/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2460 - accuracy: 0.8977 - val_loss: 1.4778 - val_accuracy: 0.5750\n",
      "Epoch 498/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2481 - accuracy: 0.9002 - val_loss: 1.4974 - val_accuracy: 0.5446\n",
      "Epoch 499/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2523 - accuracy: 0.8902 - val_loss: 1.4822 - val_accuracy: 0.5717\n",
      "Epoch 500/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2483 - accuracy: 0.8929 - val_loss: 1.4886 - val_accuracy: 0.5804\n",
      "Epoch 501/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2498 - accuracy: 0.8930 - val_loss: 1.4845 - val_accuracy: 0.5542\n",
      "Epoch 502/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.2520 - accuracy: 0.8911 - val_loss: 1.4747 - val_accuracy: 0.5692\n",
      "Epoch 503/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2429 - accuracy: 0.8977 - val_loss: 1.4684 - val_accuracy: 0.5775\n",
      "Epoch 504/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2473 - accuracy: 0.8966 - val_loss: 1.4697 - val_accuracy: 0.5750\n",
      "Epoch 505/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2455 - accuracy: 0.8954 - val_loss: 1.5041 - val_accuracy: 0.5633\n",
      "Epoch 506/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2460 - accuracy: 0.8966 - val_loss: 1.5051 - val_accuracy: 0.5829\n",
      "Epoch 507/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2455 - accuracy: 0.8963 - val_loss: 1.4779 - val_accuracy: 0.5783\n",
      "Epoch 508/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2450 - accuracy: 0.8988 - val_loss: 1.4797 - val_accuracy: 0.5875\n",
      "Epoch 509/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2424 - accuracy: 0.9007 - val_loss: 1.5208 - val_accuracy: 0.5625\n",
      "Epoch 510/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2466 - accuracy: 0.8998 - val_loss: 1.5019 - val_accuracy: 0.5725\n",
      "Epoch 511/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2437 - accuracy: 0.8939 - val_loss: 1.5062 - val_accuracy: 0.5625\n",
      "Epoch 512/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2440 - accuracy: 0.8984 - val_loss: 1.5076 - val_accuracy: 0.5721\n",
      "Epoch 513/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.2372 - accuracy: 0.9039 - val_loss: 1.5174 - val_accuracy: 0.5592\n",
      "Epoch 514/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2392 - accuracy: 0.8991 - val_loss: 1.4933 - val_accuracy: 0.5813\n",
      "Epoch 515/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2417 - accuracy: 0.9005 - val_loss: 1.5032 - val_accuracy: 0.5767\n",
      "Epoch 516/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2403 - accuracy: 0.9014 - val_loss: 1.5062 - val_accuracy: 0.5717\n",
      "Epoch 517/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.2452 - accuracy: 0.8936 - val_loss: 1.5533 - val_accuracy: 0.5621\n",
      "Epoch 518/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.2410 - accuracy: 0.8991 - val_loss: 1.5068 - val_accuracy: 0.5688\n",
      "Epoch 519/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2439 - accuracy: 0.8970 - val_loss: 1.5360 - val_accuracy: 0.5650\n",
      "Epoch 520/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2416 - accuracy: 0.8986 - val_loss: 1.5102 - val_accuracy: 0.5846\n",
      "Epoch 521/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2405 - accuracy: 0.9030 - val_loss: 1.5252 - val_accuracy: 0.5729\n",
      "Epoch 522/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2463 - accuracy: 0.8943 - val_loss: 1.5207 - val_accuracy: 0.5692\n",
      "Epoch 523/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2428 - accuracy: 0.8984 - val_loss: 1.4946 - val_accuracy: 0.5729\n",
      "Epoch 524/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2399 - accuracy: 0.9014 - val_loss: 1.5309 - val_accuracy: 0.5771\n",
      "Epoch 525/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2398 - accuracy: 0.8982 - val_loss: 1.5252 - val_accuracy: 0.5763\n",
      "Epoch 526/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2417 - accuracy: 0.8961 - val_loss: 1.5426 - val_accuracy: 0.5617\n",
      "Epoch 527/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2411 - accuracy: 0.9000 - val_loss: 1.5751 - val_accuracy: 0.5462\n",
      "Epoch 528/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2440 - accuracy: 0.8979 - val_loss: 1.5270 - val_accuracy: 0.5733\n",
      "Epoch 529/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2381 - accuracy: 0.9014 - val_loss: 1.5346 - val_accuracy: 0.5725\n",
      "Epoch 530/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2337 - accuracy: 0.9073 - val_loss: 1.5532 - val_accuracy: 0.5612\n",
      "Epoch 531/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.2462 - accuracy: 0.8880 - val_loss: 1.5429 - val_accuracy: 0.5600\n",
      "Epoch 532/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.2343 - accuracy: 0.9018 - val_loss: 1.5528 - val_accuracy: 0.5671\n",
      "Epoch 533/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.2373 - accuracy: 0.8973 - val_loss: 1.5767 - val_accuracy: 0.5496\n",
      "Epoch 534/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.2387 - accuracy: 0.8993 - val_loss: 1.5719 - val_accuracy: 0.5658\n",
      "Epoch 535/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.2388 - accuracy: 0.8939 - val_loss: 1.5307 - val_accuracy: 0.5746\n",
      "Epoch 536/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.2354 - accuracy: 0.9036 - val_loss: 1.5548 - val_accuracy: 0.5813\n",
      "Epoch 537/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2373 - accuracy: 0.8982 - val_loss: 1.5344 - val_accuracy: 0.5833\n",
      "Epoch 538/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2349 - accuracy: 0.9052 - val_loss: 1.5410 - val_accuracy: 0.5763\n",
      "Epoch 539/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2351 - accuracy: 0.9036 - val_loss: 1.5443 - val_accuracy: 0.5717\n",
      "Epoch 540/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2309 - accuracy: 0.9059 - val_loss: 1.5491 - val_accuracy: 0.5804\n",
      "Epoch 541/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2357 - accuracy: 0.9025 - val_loss: 1.5785 - val_accuracy: 0.5808\n",
      "Epoch 542/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2401 - accuracy: 0.8995 - val_loss: 1.5585 - val_accuracy: 0.5638\n",
      "Epoch 543/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2313 - accuracy: 0.9032 - val_loss: 1.5814 - val_accuracy: 0.5658\n",
      "Epoch 544/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2335 - accuracy: 0.9034 - val_loss: 1.5707 - val_accuracy: 0.5708\n",
      "Epoch 545/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2361 - accuracy: 0.8971 - val_loss: 1.5449 - val_accuracy: 0.5863\n",
      "Epoch 546/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.2312 - accuracy: 0.9023 - val_loss: 1.5950 - val_accuracy: 0.5638\n",
      "Epoch 547/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2287 - accuracy: 0.9039 - val_loss: 1.5472 - val_accuracy: 0.5725\n",
      "Epoch 548/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2294 - accuracy: 0.9052 - val_loss: 1.5535 - val_accuracy: 0.5700\n",
      "Epoch 549/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2295 - accuracy: 0.9013 - val_loss: 1.5643 - val_accuracy: 0.5713\n",
      "Epoch 550/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2236 - accuracy: 0.9104 - val_loss: 1.5643 - val_accuracy: 0.5713\n",
      "Epoch 551/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2281 - accuracy: 0.9052 - val_loss: 1.5880 - val_accuracy: 0.5567\n",
      "Epoch 552/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2332 - accuracy: 0.9048 - val_loss: 1.5725 - val_accuracy: 0.5583\n",
      "Epoch 553/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2277 - accuracy: 0.9039 - val_loss: 1.5874 - val_accuracy: 0.5738\n",
      "Epoch 554/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2234 - accuracy: 0.9104 - val_loss: 1.5992 - val_accuracy: 0.5646\n",
      "Epoch 555/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2268 - accuracy: 0.9029 - val_loss: 1.6238 - val_accuracy: 0.5579\n",
      "Epoch 556/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2311 - accuracy: 0.9007 - val_loss: 1.5777 - val_accuracy: 0.5654\n",
      "Epoch 557/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2324 - accuracy: 0.9045 - val_loss: 1.5660 - val_accuracy: 0.5742\n",
      "Epoch 558/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2309 - accuracy: 0.9013 - val_loss: 1.5908 - val_accuracy: 0.5783\n",
      "Epoch 559/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2276 - accuracy: 0.9057 - val_loss: 1.6049 - val_accuracy: 0.5525\n",
      "Epoch 560/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2260 - accuracy: 0.9059 - val_loss: 1.5863 - val_accuracy: 0.5688\n",
      "Epoch 561/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2251 - accuracy: 0.9054 - val_loss: 1.6156 - val_accuracy: 0.5629\n",
      "Epoch 562/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2236 - accuracy: 0.9118 - val_loss: 1.5904 - val_accuracy: 0.5592\n",
      "Epoch 563/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2230 - accuracy: 0.9086 - val_loss: 1.5859 - val_accuracy: 0.5733\n",
      "Epoch 564/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2281 - accuracy: 0.9016 - val_loss: 1.5983 - val_accuracy: 0.5658\n",
      "Epoch 565/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.2256 - accuracy: 0.9120 - val_loss: 1.5977 - val_accuracy: 0.5788\n",
      "Epoch 566/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.2213 - accuracy: 0.9071 - val_loss: 1.5911 - val_accuracy: 0.5713\n",
      "Epoch 567/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2214 - accuracy: 0.9052 - val_loss: 1.6026 - val_accuracy: 0.5692\n",
      "Epoch 568/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2231 - accuracy: 0.9098 - val_loss: 1.6024 - val_accuracy: 0.5742\n",
      "Epoch 569/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2229 - accuracy: 0.9075 - val_loss: 1.5927 - val_accuracy: 0.5575\n",
      "Epoch 570/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2222 - accuracy: 0.9120 - val_loss: 1.6161 - val_accuracy: 0.5642\n",
      "Epoch 571/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2218 - accuracy: 0.9132 - val_loss: 1.6241 - val_accuracy: 0.5654\n",
      "Epoch 572/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2232 - accuracy: 0.9086 - val_loss: 1.5950 - val_accuracy: 0.5754\n",
      "Epoch 573/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2214 - accuracy: 0.9068 - val_loss: 1.6151 - val_accuracy: 0.5888\n",
      "Epoch 574/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2284 - accuracy: 0.9029 - val_loss: 1.5868 - val_accuracy: 0.5688\n",
      "Epoch 575/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.2256 - accuracy: 0.9055 - val_loss: 1.6059 - val_accuracy: 0.5683\n",
      "Epoch 576/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2171 - accuracy: 0.9127 - val_loss: 1.6128 - val_accuracy: 0.5729\n",
      "Epoch 577/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2225 - accuracy: 0.9091 - val_loss: 1.6086 - val_accuracy: 0.5788\n",
      "Epoch 578/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2245 - accuracy: 0.9057 - val_loss: 1.6479 - val_accuracy: 0.5650\n",
      "Epoch 579/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2269 - accuracy: 0.9045 - val_loss: 1.6420 - val_accuracy: 0.5804\n",
      "Epoch 580/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2248 - accuracy: 0.9071 - val_loss: 1.6167 - val_accuracy: 0.5625\n",
      "Epoch 581/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.2168 - accuracy: 0.9127 - val_loss: 1.6597 - val_accuracy: 0.5562\n",
      "Epoch 582/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.2267 - accuracy: 0.9038 - val_loss: 1.6119 - val_accuracy: 0.5638\n",
      "Epoch 583/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2190 - accuracy: 0.9112 - val_loss: 1.6243 - val_accuracy: 0.5763\n",
      "Epoch 584/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2185 - accuracy: 0.9075 - val_loss: 1.6596 - val_accuracy: 0.5612\n",
      "Epoch 585/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2251 - accuracy: 0.9046 - val_loss: 1.6233 - val_accuracy: 0.5888\n",
      "Epoch 586/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2164 - accuracy: 0.9145 - val_loss: 1.6265 - val_accuracy: 0.5658\n",
      "Epoch 587/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.2159 - accuracy: 0.9146 - val_loss: 1.6097 - val_accuracy: 0.5813\n",
      "Epoch 588/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2214 - accuracy: 0.9098 - val_loss: 1.7004 - val_accuracy: 0.5492\n",
      "Epoch 589/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2423 - accuracy: 0.8925 - val_loss: 1.6270 - val_accuracy: 0.5738\n",
      "Epoch 590/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.2153 - accuracy: 0.9100 - val_loss: 1.5953 - val_accuracy: 0.5763\n",
      "Epoch 591/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2141 - accuracy: 0.9107 - val_loss: 1.6588 - val_accuracy: 0.5683\n",
      "Epoch 592/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2177 - accuracy: 0.9086 - val_loss: 1.6158 - val_accuracy: 0.5729\n",
      "Epoch 593/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2201 - accuracy: 0.9071 - val_loss: 1.6148 - val_accuracy: 0.5708\n",
      "Epoch 594/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2181 - accuracy: 0.9109 - val_loss: 1.6621 - val_accuracy: 0.5571\n",
      "Epoch 595/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2108 - accuracy: 0.9173 - val_loss: 1.6509 - val_accuracy: 0.5667\n",
      "Epoch 596/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2078 - accuracy: 0.9177 - val_loss: 1.6356 - val_accuracy: 0.5650\n",
      "Epoch 597/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2160 - accuracy: 0.9145 - val_loss: 1.6330 - val_accuracy: 0.5729\n",
      "Epoch 598/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2146 - accuracy: 0.9075 - val_loss: 1.6493 - val_accuracy: 0.5688\n",
      "Epoch 599/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2131 - accuracy: 0.9137 - val_loss: 1.6325 - val_accuracy: 0.5733\n",
      "Epoch 600/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2135 - accuracy: 0.9132 - val_loss: 1.6082 - val_accuracy: 0.5758\n",
      "Epoch 601/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2200 - accuracy: 0.9120 - val_loss: 1.6482 - val_accuracy: 0.5621\n",
      "Epoch 602/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2092 - accuracy: 0.9171 - val_loss: 1.6361 - val_accuracy: 0.5783\n",
      "Epoch 603/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2106 - accuracy: 0.9100 - val_loss: 1.6221 - val_accuracy: 0.5733\n",
      "Epoch 604/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2208 - accuracy: 0.9062 - val_loss: 1.6498 - val_accuracy: 0.5717\n",
      "Epoch 605/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.2140 - accuracy: 0.9146 - val_loss: 1.6852 - val_accuracy: 0.5612\n",
      "Epoch 606/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2220 - accuracy: 0.9039 - val_loss: 1.6408 - val_accuracy: 0.5775\n",
      "Epoch 607/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2113 - accuracy: 0.9155 - val_loss: 1.6399 - val_accuracy: 0.5721\n",
      "Epoch 608/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2138 - accuracy: 0.9132 - val_loss: 1.6752 - val_accuracy: 0.5721\n",
      "Epoch 609/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2203 - accuracy: 0.9062 - val_loss: 1.7105 - val_accuracy: 0.5617\n",
      "Epoch 610/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2233 - accuracy: 0.9054 - val_loss: 1.6685 - val_accuracy: 0.5750\n",
      "Epoch 611/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2159 - accuracy: 0.9130 - val_loss: 1.6832 - val_accuracy: 0.5725\n",
      "Epoch 612/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.2150 - accuracy: 0.9107 - val_loss: 1.6641 - val_accuracy: 0.5825\n",
      "Epoch 613/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.2114 - accuracy: 0.9145 - val_loss: 1.6446 - val_accuracy: 0.5758\n",
      "Epoch 614/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2144 - accuracy: 0.9120 - val_loss: 1.6844 - val_accuracy: 0.5675\n",
      "Epoch 615/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2080 - accuracy: 0.9179 - val_loss: 1.6764 - val_accuracy: 0.5796\n",
      "Epoch 616/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2100 - accuracy: 0.9130 - val_loss: 1.7502 - val_accuracy: 0.5496\n",
      "Epoch 617/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.2219 - accuracy: 0.9041 - val_loss: 1.6656 - val_accuracy: 0.5671\n",
      "Epoch 618/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2061 - accuracy: 0.9205 - val_loss: 1.6853 - val_accuracy: 0.5621\n",
      "Epoch 619/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2022 - accuracy: 0.9221 - val_loss: 1.6639 - val_accuracy: 0.5700\n",
      "Epoch 620/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2062 - accuracy: 0.9220 - val_loss: 1.6895 - val_accuracy: 0.5592\n",
      "Epoch 621/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2052 - accuracy: 0.9191 - val_loss: 1.6782 - val_accuracy: 0.5671\n",
      "Epoch 622/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2027 - accuracy: 0.9212 - val_loss: 1.6815 - val_accuracy: 0.5650\n",
      "Epoch 623/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2007 - accuracy: 0.9223 - val_loss: 1.6776 - val_accuracy: 0.5688\n",
      "Epoch 624/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.2024 - accuracy: 0.9204 - val_loss: 1.6716 - val_accuracy: 0.5621\n",
      "Epoch 625/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2057 - accuracy: 0.9187 - val_loss: 1.6728 - val_accuracy: 0.5729\n",
      "Epoch 626/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2037 - accuracy: 0.9173 - val_loss: 1.6904 - val_accuracy: 0.5600\n",
      "Epoch 627/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.2037 - accuracy: 0.9196 - val_loss: 1.6951 - val_accuracy: 0.5708\n",
      "Epoch 628/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2131 - accuracy: 0.9132 - val_loss: 1.6995 - val_accuracy: 0.5642\n",
      "Epoch 629/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2072 - accuracy: 0.9162 - val_loss: 1.7156 - val_accuracy: 0.5546\n",
      "Epoch 630/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2084 - accuracy: 0.9143 - val_loss: 1.7207 - val_accuracy: 0.5592\n",
      "Epoch 631/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2113 - accuracy: 0.9136 - val_loss: 1.6913 - val_accuracy: 0.5696\n",
      "Epoch 632/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2048 - accuracy: 0.9198 - val_loss: 1.6880 - val_accuracy: 0.5800\n",
      "Epoch 633/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1983 - accuracy: 0.9189 - val_loss: 1.7013 - val_accuracy: 0.5604\n",
      "Epoch 634/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2072 - accuracy: 0.9168 - val_loss: 1.7312 - val_accuracy: 0.5592\n",
      "Epoch 635/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2079 - accuracy: 0.9175 - val_loss: 1.7156 - val_accuracy: 0.5675\n",
      "Epoch 636/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1998 - accuracy: 0.9221 - val_loss: 1.7198 - val_accuracy: 0.5621\n",
      "Epoch 637/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2020 - accuracy: 0.9180 - val_loss: 1.6834 - val_accuracy: 0.5742\n",
      "Epoch 638/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2041 - accuracy: 0.9177 - val_loss: 1.7037 - val_accuracy: 0.5679\n",
      "Epoch 639/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.2067 - accuracy: 0.9155 - val_loss: 1.7194 - val_accuracy: 0.5683\n",
      "Epoch 640/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.2033 - accuracy: 0.9175 - val_loss: 1.7162 - val_accuracy: 0.5721\n",
      "Epoch 641/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2031 - accuracy: 0.9193 - val_loss: 1.7001 - val_accuracy: 0.5704\n",
      "Epoch 642/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1958 - accuracy: 0.9261 - val_loss: 1.7179 - val_accuracy: 0.5696\n",
      "Epoch 643/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.2009 - accuracy: 0.9173 - val_loss: 1.7182 - val_accuracy: 0.5692\n",
      "Epoch 644/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.1982 - accuracy: 0.9205 - val_loss: 1.7213 - val_accuracy: 0.5646\n",
      "Epoch 645/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1999 - accuracy: 0.9218 - val_loss: 1.7322 - val_accuracy: 0.5617\n",
      "Epoch 646/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.2011 - accuracy: 0.9218 - val_loss: 1.7011 - val_accuracy: 0.5871\n",
      "Epoch 647/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1978 - accuracy: 0.9236 - val_loss: 1.7461 - val_accuracy: 0.5579\n",
      "Epoch 648/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1957 - accuracy: 0.9218 - val_loss: 1.7003 - val_accuracy: 0.5708\n",
      "Epoch 649/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1996 - accuracy: 0.9221 - val_loss: 1.7181 - val_accuracy: 0.5696\n",
      "Epoch 650/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1927 - accuracy: 0.9211 - val_loss: 1.7149 - val_accuracy: 0.5721\n",
      "Epoch 651/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1950 - accuracy: 0.9236 - val_loss: 1.7257 - val_accuracy: 0.5642\n",
      "Epoch 652/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1970 - accuracy: 0.9216 - val_loss: 1.7294 - val_accuracy: 0.5621\n",
      "Epoch 653/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1987 - accuracy: 0.9230 - val_loss: 1.6851 - val_accuracy: 0.5758\n",
      "Epoch 654/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2035 - accuracy: 0.9191 - val_loss: 1.7639 - val_accuracy: 0.5525\n",
      "Epoch 655/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2066 - accuracy: 0.9123 - val_loss: 1.7253 - val_accuracy: 0.5650\n",
      "Epoch 656/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1956 - accuracy: 0.9246 - val_loss: 1.7116 - val_accuracy: 0.5779\n",
      "Epoch 657/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2040 - accuracy: 0.9136 - val_loss: 1.7179 - val_accuracy: 0.5679\n",
      "Epoch 658/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.1982 - accuracy: 0.9216 - val_loss: 1.7460 - val_accuracy: 0.5633\n",
      "Epoch 659/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2028 - accuracy: 0.9175 - val_loss: 1.7760 - val_accuracy: 0.5596\n",
      "Epoch 660/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.1988 - accuracy: 0.9205 - val_loss: 1.7176 - val_accuracy: 0.5838\n",
      "Epoch 661/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1995 - accuracy: 0.9204 - val_loss: 1.7265 - val_accuracy: 0.5750\n",
      "Epoch 662/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1945 - accuracy: 0.9221 - val_loss: 1.7370 - val_accuracy: 0.5671\n",
      "Epoch 663/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1963 - accuracy: 0.9252 - val_loss: 1.7398 - val_accuracy: 0.5704\n",
      "Epoch 664/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.1967 - accuracy: 0.9236 - val_loss: 1.7506 - val_accuracy: 0.5733\n",
      "Epoch 665/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.1946 - accuracy: 0.9239 - val_loss: 1.7510 - val_accuracy: 0.5587\n",
      "Epoch 666/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.1966 - accuracy: 0.9236 - val_loss: 1.7825 - val_accuracy: 0.5554\n",
      "Epoch 667/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2006 - accuracy: 0.9211 - val_loss: 1.7176 - val_accuracy: 0.5750\n",
      "Epoch 668/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1931 - accuracy: 0.9261 - val_loss: 1.7527 - val_accuracy: 0.5650\n",
      "Epoch 669/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.2029 - accuracy: 0.9162 - val_loss: 1.7447 - val_accuracy: 0.5654\n",
      "Epoch 670/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1985 - accuracy: 0.9218 - val_loss: 1.7492 - val_accuracy: 0.5792\n",
      "Epoch 671/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1885 - accuracy: 0.9280 - val_loss: 1.7615 - val_accuracy: 0.5733\n",
      "Epoch 672/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1923 - accuracy: 0.9230 - val_loss: 1.8114 - val_accuracy: 0.5542\n",
      "Epoch 673/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1950 - accuracy: 0.9257 - val_loss: 1.7505 - val_accuracy: 0.5750\n",
      "Epoch 674/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1911 - accuracy: 0.9255 - val_loss: 1.7549 - val_accuracy: 0.5688\n",
      "Epoch 675/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1982 - accuracy: 0.9195 - val_loss: 1.7501 - val_accuracy: 0.5646\n",
      "Epoch 676/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1896 - accuracy: 0.9286 - val_loss: 1.7676 - val_accuracy: 0.5738\n",
      "Epoch 677/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1859 - accuracy: 0.9271 - val_loss: 1.7569 - val_accuracy: 0.5683\n",
      "Epoch 678/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1912 - accuracy: 0.9236 - val_loss: 1.7782 - val_accuracy: 0.5700\n",
      "Epoch 679/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1962 - accuracy: 0.9207 - val_loss: 1.8499 - val_accuracy: 0.5533\n",
      "Epoch 680/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1985 - accuracy: 0.9180 - val_loss: 1.8079 - val_accuracy: 0.5675\n",
      "Epoch 681/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1964 - accuracy: 0.9214 - val_loss: 1.7563 - val_accuracy: 0.5779\n",
      "Epoch 682/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1997 - accuracy: 0.9168 - val_loss: 1.7746 - val_accuracy: 0.5833\n",
      "Epoch 683/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1938 - accuracy: 0.9207 - val_loss: 1.7690 - val_accuracy: 0.5683\n",
      "Epoch 684/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1986 - accuracy: 0.9182 - val_loss: 1.7780 - val_accuracy: 0.5729\n",
      "Epoch 685/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1926 - accuracy: 0.9254 - val_loss: 1.7723 - val_accuracy: 0.5704\n",
      "Epoch 686/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1867 - accuracy: 0.9286 - val_loss: 1.7571 - val_accuracy: 0.5721\n",
      "Epoch 687/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1832 - accuracy: 0.9323 - val_loss: 1.8014 - val_accuracy: 0.5550\n",
      "Epoch 688/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.1842 - accuracy: 0.9314 - val_loss: 1.8136 - val_accuracy: 0.5596\n",
      "Epoch 689/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1843 - accuracy: 0.9296 - val_loss: 1.7823 - val_accuracy: 0.5658\n",
      "Epoch 690/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.1811 - accuracy: 0.9318 - val_loss: 1.7533 - val_accuracy: 0.5746\n",
      "Epoch 691/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1803 - accuracy: 0.9350 - val_loss: 1.7728 - val_accuracy: 0.5742\n",
      "Epoch 692/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.1847 - accuracy: 0.9287 - val_loss: 1.8017 - val_accuracy: 0.5625\n",
      "Epoch 693/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1851 - accuracy: 0.9280 - val_loss: 1.7763 - val_accuracy: 0.5671\n",
      "Epoch 694/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.1832 - accuracy: 0.9302 - val_loss: 1.7782 - val_accuracy: 0.5646\n",
      "Epoch 695/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1821 - accuracy: 0.9312 - val_loss: 1.8006 - val_accuracy: 0.5683\n",
      "Epoch 696/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1836 - accuracy: 0.9298 - val_loss: 1.7786 - val_accuracy: 0.5746\n",
      "Epoch 697/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1853 - accuracy: 0.9277 - val_loss: 1.8502 - val_accuracy: 0.5596\n",
      "Epoch 698/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1929 - accuracy: 0.9243 - val_loss: 1.8135 - val_accuracy: 0.5667\n",
      "Epoch 699/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1821 - accuracy: 0.9304 - val_loss: 1.7862 - val_accuracy: 0.5658\n",
      "Epoch 700/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1874 - accuracy: 0.9275 - val_loss: 1.7961 - val_accuracy: 0.5750\n",
      "Epoch 701/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1894 - accuracy: 0.9218 - val_loss: 1.8108 - val_accuracy: 0.5808\n",
      "Epoch 702/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.1855 - accuracy: 0.9270 - val_loss: 1.8335 - val_accuracy: 0.5625\n",
      "Epoch 703/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1840 - accuracy: 0.9318 - val_loss: 1.8616 - val_accuracy: 0.5546\n",
      "Epoch 704/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1839 - accuracy: 0.9289 - val_loss: 1.7743 - val_accuracy: 0.5767\n",
      "Epoch 705/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.1807 - accuracy: 0.9332 - val_loss: 1.7864 - val_accuracy: 0.5700\n",
      "Epoch 706/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1944 - accuracy: 0.9236 - val_loss: 1.8197 - val_accuracy: 0.5704\n",
      "Epoch 707/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1833 - accuracy: 0.9255 - val_loss: 1.8128 - val_accuracy: 0.5754\n",
      "Epoch 708/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.1810 - accuracy: 0.9296 - val_loss: 1.8225 - val_accuracy: 0.5604\n",
      "Epoch 709/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1803 - accuracy: 0.9334 - val_loss: 1.8092 - val_accuracy: 0.5733\n",
      "Epoch 710/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1769 - accuracy: 0.9345 - val_loss: 1.8084 - val_accuracy: 0.5729\n",
      "Epoch 711/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1772 - accuracy: 0.9355 - val_loss: 1.8265 - val_accuracy: 0.5608\n",
      "Epoch 712/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.1793 - accuracy: 0.9309 - val_loss: 1.7993 - val_accuracy: 0.5650\n",
      "Epoch 713/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1871 - accuracy: 0.9254 - val_loss: 1.8631 - val_accuracy: 0.5829\n",
      "Epoch 714/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1850 - accuracy: 0.9307 - val_loss: 1.8072 - val_accuracy: 0.5671\n",
      "Epoch 715/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1781 - accuracy: 0.9325 - val_loss: 1.8287 - val_accuracy: 0.5629\n",
      "Epoch 716/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.1771 - accuracy: 0.9336 - val_loss: 1.8254 - val_accuracy: 0.5625\n",
      "Epoch 717/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1763 - accuracy: 0.9341 - val_loss: 1.8007 - val_accuracy: 0.5754\n",
      "Epoch 718/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1798 - accuracy: 0.9334 - val_loss: 1.8511 - val_accuracy: 0.5617\n",
      "Epoch 719/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1859 - accuracy: 0.9262 - val_loss: 1.8516 - val_accuracy: 0.5696\n",
      "Epoch 720/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1795 - accuracy: 0.9325 - val_loss: 1.8409 - val_accuracy: 0.5650\n",
      "Epoch 721/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.1785 - accuracy: 0.9318 - val_loss: 1.8649 - val_accuracy: 0.5562\n",
      "Epoch 722/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1809 - accuracy: 0.9321 - val_loss: 1.8164 - val_accuracy: 0.5733\n",
      "Epoch 723/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1795 - accuracy: 0.9350 - val_loss: 1.8257 - val_accuracy: 0.5704\n",
      "Epoch 724/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1825 - accuracy: 0.9262 - val_loss: 1.8432 - val_accuracy: 0.5604\n",
      "Epoch 725/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1838 - accuracy: 0.9261 - val_loss: 1.8312 - val_accuracy: 0.5721\n",
      "Epoch 726/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1948 - accuracy: 0.9196 - val_loss: 1.8655 - val_accuracy: 0.5642\n",
      "Epoch 727/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1995 - accuracy: 0.9168 - val_loss: 1.8256 - val_accuracy: 0.5871\n",
      "Epoch 728/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1983 - accuracy: 0.9204 - val_loss: 1.9420 - val_accuracy: 0.5492\n",
      "Epoch 729/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.1919 - accuracy: 0.9221 - val_loss: 1.8714 - val_accuracy: 0.5600\n",
      "Epoch 730/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1799 - accuracy: 0.9330 - val_loss: 1.8982 - val_accuracy: 0.5675\n",
      "Epoch 731/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1766 - accuracy: 0.9336 - val_loss: 1.8449 - val_accuracy: 0.5746\n",
      "Epoch 732/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1767 - accuracy: 0.9325 - val_loss: 1.8688 - val_accuracy: 0.5688\n",
      "Epoch 733/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1774 - accuracy: 0.9334 - val_loss: 1.8279 - val_accuracy: 0.5729\n",
      "Epoch 734/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1759 - accuracy: 0.9352 - val_loss: 1.8433 - val_accuracy: 0.5704\n",
      "Epoch 735/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.1750 - accuracy: 0.9355 - val_loss: 1.8557 - val_accuracy: 0.5683\n",
      "Epoch 736/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1767 - accuracy: 0.9348 - val_loss: 1.8638 - val_accuracy: 0.5612\n",
      "Epoch 737/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1768 - accuracy: 0.9343 - val_loss: 1.8362 - val_accuracy: 0.5721\n",
      "Epoch 738/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1816 - accuracy: 0.9314 - val_loss: 1.8851 - val_accuracy: 0.5554\n",
      "Epoch 739/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1752 - accuracy: 0.9332 - val_loss: 1.8690 - val_accuracy: 0.5633\n",
      "Epoch 740/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.1832 - accuracy: 0.9291 - val_loss: 1.8551 - val_accuracy: 0.5725\n",
      "Epoch 741/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1732 - accuracy: 0.9357 - val_loss: 1.8792 - val_accuracy: 0.5604\n",
      "Epoch 742/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1728 - accuracy: 0.9355 - val_loss: 1.8570 - val_accuracy: 0.5733\n",
      "Epoch 743/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1745 - accuracy: 0.9334 - val_loss: 1.9001 - val_accuracy: 0.5604\n",
      "Epoch 744/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1830 - accuracy: 0.9305 - val_loss: 1.8579 - val_accuracy: 0.5692\n",
      "Epoch 745/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1751 - accuracy: 0.9321 - val_loss: 1.8864 - val_accuracy: 0.5646\n",
      "Epoch 746/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.1691 - accuracy: 0.9391 - val_loss: 1.8719 - val_accuracy: 0.5713\n",
      "Epoch 747/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1775 - accuracy: 0.9332 - val_loss: 1.8716 - val_accuracy: 0.5713\n",
      "Epoch 748/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1751 - accuracy: 0.9368 - val_loss: 1.8844 - val_accuracy: 0.5658\n",
      "Epoch 749/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1747 - accuracy: 0.9334 - val_loss: 1.8668 - val_accuracy: 0.5821\n",
      "Epoch 750/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1706 - accuracy: 0.9350 - val_loss: 1.8900 - val_accuracy: 0.5629\n",
      "Epoch 751/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1718 - accuracy: 0.9364 - val_loss: 1.8951 - val_accuracy: 0.5596\n",
      "Epoch 752/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1757 - accuracy: 0.9334 - val_loss: 1.9177 - val_accuracy: 0.5771\n",
      "Epoch 753/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1738 - accuracy: 0.9334 - val_loss: 1.8743 - val_accuracy: 0.5792\n",
      "Epoch 754/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1798 - accuracy: 0.9279 - val_loss: 1.8758 - val_accuracy: 0.5675\n",
      "Epoch 755/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1769 - accuracy: 0.9320 - val_loss: 1.9062 - val_accuracy: 0.5767\n",
      "Epoch 756/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1757 - accuracy: 0.9357 - val_loss: 1.9044 - val_accuracy: 0.5642\n",
      "Epoch 757/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.1768 - accuracy: 0.9325 - val_loss: 1.8760 - val_accuracy: 0.5783\n",
      "Epoch 758/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1733 - accuracy: 0.9359 - val_loss: 1.9024 - val_accuracy: 0.5658\n",
      "Epoch 759/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1693 - accuracy: 0.9362 - val_loss: 1.8882 - val_accuracy: 0.5608\n",
      "Epoch 760/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1698 - accuracy: 0.9366 - val_loss: 1.9287 - val_accuracy: 0.5708\n",
      "Epoch 761/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1655 - accuracy: 0.9355 - val_loss: 1.8792 - val_accuracy: 0.5771\n",
      "Epoch 762/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1653 - accuracy: 0.9405 - val_loss: 1.8996 - val_accuracy: 0.5800\n",
      "Epoch 763/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1722 - accuracy: 0.9318 - val_loss: 1.9179 - val_accuracy: 0.5579\n",
      "Epoch 764/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1691 - accuracy: 0.9384 - val_loss: 1.9110 - val_accuracy: 0.5608\n",
      "Epoch 765/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1671 - accuracy: 0.9379 - val_loss: 1.8933 - val_accuracy: 0.5754\n",
      "Epoch 766/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1723 - accuracy: 0.9357 - val_loss: 1.8951 - val_accuracy: 0.5708\n",
      "Epoch 767/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1648 - accuracy: 0.9389 - val_loss: 1.9180 - val_accuracy: 0.5696\n",
      "Epoch 768/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1717 - accuracy: 0.9341 - val_loss: 1.8959 - val_accuracy: 0.5733\n",
      "Epoch 769/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1657 - accuracy: 0.9379 - val_loss: 1.9298 - val_accuracy: 0.5587\n",
      "Epoch 770/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.1750 - accuracy: 0.9307 - val_loss: 1.9080 - val_accuracy: 0.5767\n",
      "Epoch 771/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1779 - accuracy: 0.9266 - val_loss: 1.9510 - val_accuracy: 0.5504\n",
      "Epoch 772/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1865 - accuracy: 0.9227 - val_loss: 1.9351 - val_accuracy: 0.5650\n",
      "Epoch 773/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.1675 - accuracy: 0.9346 - val_loss: 1.9388 - val_accuracy: 0.5571\n",
      "Epoch 774/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1719 - accuracy: 0.9352 - val_loss: 1.9062 - val_accuracy: 0.5708\n",
      "Epoch 775/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1662 - accuracy: 0.9362 - val_loss: 1.9050 - val_accuracy: 0.5725\n",
      "Epoch 776/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.1609 - accuracy: 0.9407 - val_loss: 1.9378 - val_accuracy: 0.5679\n",
      "Epoch 777/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1628 - accuracy: 0.9395 - val_loss: 1.9159 - val_accuracy: 0.5642\n",
      "Epoch 778/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1677 - accuracy: 0.9348 - val_loss: 1.9331 - val_accuracy: 0.5663\n",
      "Epoch 779/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1665 - accuracy: 0.9359 - val_loss: 1.8982 - val_accuracy: 0.5646\n",
      "Epoch 780/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.1622 - accuracy: 0.9407 - val_loss: 1.9388 - val_accuracy: 0.5633\n",
      "Epoch 781/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1610 - accuracy: 0.9393 - val_loss: 1.9357 - val_accuracy: 0.5629\n",
      "Epoch 782/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.1601 - accuracy: 0.9402 - val_loss: 1.9343 - val_accuracy: 0.5646\n",
      "Epoch 783/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1655 - accuracy: 0.9368 - val_loss: 1.9128 - val_accuracy: 0.5692\n",
      "Epoch 784/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1641 - accuracy: 0.9382 - val_loss: 1.9081 - val_accuracy: 0.5717\n",
      "Epoch 785/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.1610 - accuracy: 0.9398 - val_loss: 1.9354 - val_accuracy: 0.5683\n",
      "Epoch 786/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1620 - accuracy: 0.9393 - val_loss: 1.9149 - val_accuracy: 0.5675\n",
      "Epoch 787/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1644 - accuracy: 0.9386 - val_loss: 1.9546 - val_accuracy: 0.5658\n",
      "Epoch 788/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.1621 - accuracy: 0.9411 - val_loss: 1.9328 - val_accuracy: 0.5633\n",
      "Epoch 789/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1623 - accuracy: 0.9402 - val_loss: 1.9408 - val_accuracy: 0.5771\n",
      "Epoch 790/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1651 - accuracy: 0.9396 - val_loss: 1.9430 - val_accuracy: 0.5562\n",
      "Epoch 791/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1667 - accuracy: 0.9337 - val_loss: 1.9458 - val_accuracy: 0.5725\n",
      "Epoch 792/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1641 - accuracy: 0.9395 - val_loss: 1.9750 - val_accuracy: 0.5713\n",
      "Epoch 793/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1693 - accuracy: 0.9329 - val_loss: 1.9218 - val_accuracy: 0.5704\n",
      "Epoch 794/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1670 - accuracy: 0.9348 - val_loss: 1.9242 - val_accuracy: 0.5713\n",
      "Epoch 795/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1547 - accuracy: 0.9479 - val_loss: 1.9352 - val_accuracy: 0.5696\n",
      "Epoch 796/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1593 - accuracy: 0.9436 - val_loss: 1.9167 - val_accuracy: 0.5725\n",
      "Epoch 797/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1655 - accuracy: 0.9388 - val_loss: 1.9229 - val_accuracy: 0.5700\n",
      "Epoch 798/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1625 - accuracy: 0.9386 - val_loss: 1.9409 - val_accuracy: 0.5646\n",
      "Epoch 799/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1556 - accuracy: 0.9455 - val_loss: 1.9412 - val_accuracy: 0.5708\n",
      "Epoch 800/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.1589 - accuracy: 0.9409 - val_loss: 1.9630 - val_accuracy: 0.5608\n",
      "Epoch 801/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1743 - accuracy: 0.9300 - val_loss: 1.9707 - val_accuracy: 0.5625\n",
      "Epoch 802/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1586 - accuracy: 0.9416 - val_loss: 1.9379 - val_accuracy: 0.5750\n",
      "Epoch 803/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1621 - accuracy: 0.9400 - val_loss: 1.9427 - val_accuracy: 0.5658\n",
      "Epoch 804/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1616 - accuracy: 0.9421 - val_loss: 1.9213 - val_accuracy: 0.5850\n",
      "Epoch 805/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1571 - accuracy: 0.9389 - val_loss: 1.9562 - val_accuracy: 0.5800\n",
      "Epoch 806/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1557 - accuracy: 0.9416 - val_loss: 1.9735 - val_accuracy: 0.5587\n",
      "Epoch 807/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1615 - accuracy: 0.9393 - val_loss: 1.9612 - val_accuracy: 0.5683\n",
      "Epoch 808/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.1548 - accuracy: 0.9459 - val_loss: 1.9625 - val_accuracy: 0.5729\n",
      "Epoch 809/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1533 - accuracy: 0.9454 - val_loss: 1.9458 - val_accuracy: 0.5633\n",
      "Epoch 810/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.1558 - accuracy: 0.9445 - val_loss: 1.9671 - val_accuracy: 0.5725\n",
      "Epoch 811/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.1589 - accuracy: 0.9402 - val_loss: 1.9537 - val_accuracy: 0.5688\n",
      "Epoch 812/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1550 - accuracy: 0.9432 - val_loss: 1.9640 - val_accuracy: 0.5713\n",
      "Epoch 813/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1541 - accuracy: 0.9420 - val_loss: 2.0036 - val_accuracy: 0.5604\n",
      "Epoch 814/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1586 - accuracy: 0.9375 - val_loss: 1.9801 - val_accuracy: 0.5738\n",
      "Epoch 815/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.1578 - accuracy: 0.9411 - val_loss: 1.9612 - val_accuracy: 0.5713\n",
      "Epoch 816/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1606 - accuracy: 0.9395 - val_loss: 1.9703 - val_accuracy: 0.5742\n",
      "Epoch 817/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1650 - accuracy: 0.9329 - val_loss: 2.0481 - val_accuracy: 0.5571\n",
      "Epoch 818/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1524 - accuracy: 0.9414 - val_loss: 2.0113 - val_accuracy: 0.5608\n",
      "Epoch 819/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1557 - accuracy: 0.9445 - val_loss: 1.9839 - val_accuracy: 0.5708\n",
      "Epoch 820/1000\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.1564 - accuracy: 0.9436 - val_loss: 1.9847 - val_accuracy: 0.5696\n",
      "Epoch 821/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1558 - accuracy: 0.9432 - val_loss: 1.9850 - val_accuracy: 0.5683\n",
      "Epoch 822/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1549 - accuracy: 0.9438 - val_loss: 1.9532 - val_accuracy: 0.5750\n",
      "Epoch 823/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1608 - accuracy: 0.9400 - val_loss: 1.9956 - val_accuracy: 0.5617\n",
      "Epoch 824/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1595 - accuracy: 0.9391 - val_loss: 1.9826 - val_accuracy: 0.5700\n",
      "Epoch 825/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1508 - accuracy: 0.9455 - val_loss: 1.9845 - val_accuracy: 0.5633\n",
      "Epoch 826/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1516 - accuracy: 0.9454 - val_loss: 1.9897 - val_accuracy: 0.5633\n",
      "Epoch 827/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1540 - accuracy: 0.9409 - val_loss: 1.9972 - val_accuracy: 0.5704\n",
      "Epoch 828/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1534 - accuracy: 0.9425 - val_loss: 1.9909 - val_accuracy: 0.5638\n",
      "Epoch 829/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1525 - accuracy: 0.9454 - val_loss: 2.0079 - val_accuracy: 0.5804\n",
      "Epoch 830/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1545 - accuracy: 0.9434 - val_loss: 1.9849 - val_accuracy: 0.5654\n",
      "Epoch 831/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1637 - accuracy: 0.9373 - val_loss: 1.9888 - val_accuracy: 0.5696\n",
      "Epoch 832/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1593 - accuracy: 0.9405 - val_loss: 2.0199 - val_accuracy: 0.5696\n",
      "Epoch 833/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1546 - accuracy: 0.9438 - val_loss: 1.9786 - val_accuracy: 0.5775\n",
      "Epoch 834/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1626 - accuracy: 0.9359 - val_loss: 2.0412 - val_accuracy: 0.5663\n",
      "Epoch 835/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.1587 - accuracy: 0.9375 - val_loss: 2.0046 - val_accuracy: 0.5671\n",
      "Epoch 836/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1555 - accuracy: 0.9398 - val_loss: 1.9961 - val_accuracy: 0.5725\n",
      "Epoch 837/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1596 - accuracy: 0.9396 - val_loss: 1.9817 - val_accuracy: 0.5771\n",
      "Epoch 838/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1555 - accuracy: 0.9429 - val_loss: 2.0072 - val_accuracy: 0.5663\n",
      "Epoch 839/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1516 - accuracy: 0.9441 - val_loss: 2.0729 - val_accuracy: 0.5579\n",
      "Epoch 840/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1565 - accuracy: 0.9407 - val_loss: 2.0052 - val_accuracy: 0.5758\n",
      "Epoch 841/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1543 - accuracy: 0.9427 - val_loss: 2.0373 - val_accuracy: 0.5596\n",
      "Epoch 842/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.1481 - accuracy: 0.9486 - val_loss: 2.0374 - val_accuracy: 0.5646\n",
      "Epoch 843/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1461 - accuracy: 0.9511 - val_loss: 2.0305 - val_accuracy: 0.5650\n",
      "Epoch 844/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1463 - accuracy: 0.9468 - val_loss: 2.0163 - val_accuracy: 0.5663\n",
      "Epoch 845/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.1482 - accuracy: 0.9473 - val_loss: 2.0334 - val_accuracy: 0.5646\n",
      "Epoch 846/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1514 - accuracy: 0.9434 - val_loss: 2.0220 - val_accuracy: 0.5729\n",
      "Epoch 847/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1455 - accuracy: 0.9468 - val_loss: 2.0161 - val_accuracy: 0.5754\n",
      "Epoch 848/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1455 - accuracy: 0.9466 - val_loss: 1.9986 - val_accuracy: 0.5667\n",
      "Epoch 849/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1494 - accuracy: 0.9441 - val_loss: 2.0002 - val_accuracy: 0.5750\n",
      "Epoch 850/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.1445 - accuracy: 0.9489 - val_loss: 2.0629 - val_accuracy: 0.5608\n",
      "Epoch 851/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1509 - accuracy: 0.9470 - val_loss: 2.0299 - val_accuracy: 0.5654\n",
      "Epoch 852/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.1473 - accuracy: 0.9459 - val_loss: 2.0758 - val_accuracy: 0.5596\n",
      "Epoch 853/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.1478 - accuracy: 0.9466 - val_loss: 2.0210 - val_accuracy: 0.5733\n",
      "Epoch 854/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1516 - accuracy: 0.9418 - val_loss: 2.0468 - val_accuracy: 0.5633\n",
      "Epoch 855/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1488 - accuracy: 0.9473 - val_loss: 2.0168 - val_accuracy: 0.5675\n",
      "Epoch 856/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1495 - accuracy: 0.9463 - val_loss: 2.0097 - val_accuracy: 0.5725\n",
      "Epoch 857/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.1471 - accuracy: 0.9448 - val_loss: 2.0519 - val_accuracy: 0.5663\n",
      "Epoch 858/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1534 - accuracy: 0.9409 - val_loss: 2.1212 - val_accuracy: 0.5583\n",
      "Epoch 859/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.1522 - accuracy: 0.9438 - val_loss: 2.0397 - val_accuracy: 0.5608\n",
      "Epoch 860/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1448 - accuracy: 0.9488 - val_loss: 2.0665 - val_accuracy: 0.5725\n",
      "Epoch 861/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1445 - accuracy: 0.9507 - val_loss: 2.0402 - val_accuracy: 0.5671\n",
      "Epoch 862/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1485 - accuracy: 0.9477 - val_loss: 2.0139 - val_accuracy: 0.5763\n",
      "Epoch 863/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1473 - accuracy: 0.9502 - val_loss: 2.0755 - val_accuracy: 0.5813\n",
      "Epoch 864/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.1433 - accuracy: 0.9493 - val_loss: 2.0583 - val_accuracy: 0.5754\n",
      "Epoch 865/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1473 - accuracy: 0.9448 - val_loss: 2.0387 - val_accuracy: 0.5746\n",
      "Epoch 866/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1465 - accuracy: 0.9464 - val_loss: 2.0359 - val_accuracy: 0.5667\n",
      "Epoch 867/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.1397 - accuracy: 0.9511 - val_loss: 2.0595 - val_accuracy: 0.5650\n",
      "Epoch 868/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1472 - accuracy: 0.9459 - val_loss: 2.0717 - val_accuracy: 0.5646\n",
      "Epoch 869/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1442 - accuracy: 0.9482 - val_loss: 2.0476 - val_accuracy: 0.5746\n",
      "Epoch 870/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1476 - accuracy: 0.9473 - val_loss: 2.0592 - val_accuracy: 0.5704\n",
      "Epoch 871/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1545 - accuracy: 0.9429 - val_loss: 2.0455 - val_accuracy: 0.5708\n",
      "Epoch 872/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1414 - accuracy: 0.9498 - val_loss: 2.0753 - val_accuracy: 0.5692\n",
      "Epoch 873/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1518 - accuracy: 0.9416 - val_loss: 2.0563 - val_accuracy: 0.5713\n",
      "Epoch 874/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.1514 - accuracy: 0.9434 - val_loss: 2.1138 - val_accuracy: 0.5562\n",
      "Epoch 875/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1474 - accuracy: 0.9443 - val_loss: 2.0373 - val_accuracy: 0.5713\n",
      "Epoch 876/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1486 - accuracy: 0.9436 - val_loss: 2.0793 - val_accuracy: 0.5725\n",
      "Epoch 877/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.1482 - accuracy: 0.9468 - val_loss: 2.0487 - val_accuracy: 0.5808\n",
      "Epoch 878/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1477 - accuracy: 0.9423 - val_loss: 2.0786 - val_accuracy: 0.5700\n",
      "Epoch 879/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1382 - accuracy: 0.9529 - val_loss: 2.0499 - val_accuracy: 0.5675\n",
      "Epoch 880/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.1394 - accuracy: 0.9518 - val_loss: 2.0548 - val_accuracy: 0.5767\n",
      "Epoch 881/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1398 - accuracy: 0.9484 - val_loss: 2.0669 - val_accuracy: 0.5708\n",
      "Epoch 882/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1385 - accuracy: 0.9538 - val_loss: 2.0587 - val_accuracy: 0.5679\n",
      "Epoch 883/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1379 - accuracy: 0.9527 - val_loss: 2.0703 - val_accuracy: 0.5717\n",
      "Epoch 884/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.1401 - accuracy: 0.9504 - val_loss: 2.0879 - val_accuracy: 0.5679\n",
      "Epoch 885/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1438 - accuracy: 0.9496 - val_loss: 2.0846 - val_accuracy: 0.5725\n",
      "Epoch 886/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1433 - accuracy: 0.9486 - val_loss: 2.0478 - val_accuracy: 0.5742\n",
      "Epoch 887/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1453 - accuracy: 0.9459 - val_loss: 2.0656 - val_accuracy: 0.5738\n",
      "Epoch 888/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.1384 - accuracy: 0.9529 - val_loss: 2.0973 - val_accuracy: 0.5663\n",
      "Epoch 889/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1436 - accuracy: 0.9448 - val_loss: 2.0742 - val_accuracy: 0.5800\n",
      "Epoch 890/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.1451 - accuracy: 0.9461 - val_loss: 2.1070 - val_accuracy: 0.5796\n",
      "Epoch 891/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1405 - accuracy: 0.9480 - val_loss: 2.0657 - val_accuracy: 0.5713\n",
      "Epoch 892/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1400 - accuracy: 0.9496 - val_loss: 2.1175 - val_accuracy: 0.5621\n",
      "Epoch 893/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1408 - accuracy: 0.9484 - val_loss: 2.0750 - val_accuracy: 0.5738\n",
      "Epoch 894/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1411 - accuracy: 0.9491 - val_loss: 2.0974 - val_accuracy: 0.5713\n",
      "Epoch 895/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.1375 - accuracy: 0.9514 - val_loss: 2.0994 - val_accuracy: 0.5708\n",
      "Epoch 896/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1470 - accuracy: 0.9432 - val_loss: 2.0888 - val_accuracy: 0.5654\n",
      "Epoch 897/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1397 - accuracy: 0.9488 - val_loss: 2.1056 - val_accuracy: 0.5667\n",
      "Epoch 898/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1381 - accuracy: 0.9496 - val_loss: 2.1606 - val_accuracy: 0.5587\n",
      "Epoch 899/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1387 - accuracy: 0.9520 - val_loss: 2.0624 - val_accuracy: 0.5721\n",
      "Epoch 900/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1375 - accuracy: 0.9525 - val_loss: 2.1252 - val_accuracy: 0.5621\n",
      "Epoch 901/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.1483 - accuracy: 0.9434 - val_loss: 2.1696 - val_accuracy: 0.5612\n",
      "Epoch 902/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1467 - accuracy: 0.9455 - val_loss: 2.0745 - val_accuracy: 0.5788\n",
      "Epoch 903/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.1444 - accuracy: 0.9470 - val_loss: 2.0848 - val_accuracy: 0.5733\n",
      "Epoch 904/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1383 - accuracy: 0.9507 - val_loss: 2.1553 - val_accuracy: 0.5587\n",
      "Epoch 905/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.1382 - accuracy: 0.9486 - val_loss: 2.0997 - val_accuracy: 0.5688\n",
      "Epoch 906/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.1350 - accuracy: 0.9493 - val_loss: 2.1043 - val_accuracy: 0.5763\n",
      "Epoch 907/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.1406 - accuracy: 0.9482 - val_loss: 2.1270 - val_accuracy: 0.5625\n",
      "Epoch 908/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1395 - accuracy: 0.9498 - val_loss: 2.1515 - val_accuracy: 0.5663\n",
      "Epoch 909/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1359 - accuracy: 0.9523 - val_loss: 2.1148 - val_accuracy: 0.5804\n",
      "Epoch 910/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1354 - accuracy: 0.9525 - val_loss: 2.1037 - val_accuracy: 0.5767\n",
      "Epoch 911/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1387 - accuracy: 0.9534 - val_loss: 2.0909 - val_accuracy: 0.5825\n",
      "Epoch 912/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1418 - accuracy: 0.9471 - val_loss: 2.1591 - val_accuracy: 0.5579\n",
      "Epoch 913/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.1384 - accuracy: 0.9518 - val_loss: 2.1349 - val_accuracy: 0.5746\n",
      "Epoch 914/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.1372 - accuracy: 0.9480 - val_loss: 2.1187 - val_accuracy: 0.5808\n",
      "Epoch 915/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.1376 - accuracy: 0.9523 - val_loss: 2.0755 - val_accuracy: 0.5863\n",
      "Epoch 916/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1351 - accuracy: 0.9532 - val_loss: 2.1059 - val_accuracy: 0.5646\n",
      "Epoch 917/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1350 - accuracy: 0.9518 - val_loss: 2.1333 - val_accuracy: 0.5646\n",
      "Epoch 918/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1451 - accuracy: 0.9461 - val_loss: 2.1358 - val_accuracy: 0.5683\n",
      "Epoch 919/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1368 - accuracy: 0.9489 - val_loss: 2.1222 - val_accuracy: 0.5692\n",
      "Epoch 920/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.1335 - accuracy: 0.9523 - val_loss: 2.1618 - val_accuracy: 0.5608\n",
      "Epoch 921/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1464 - accuracy: 0.9441 - val_loss: 2.1103 - val_accuracy: 0.5733\n",
      "Epoch 922/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1463 - accuracy: 0.9425 - val_loss: 2.1313 - val_accuracy: 0.5629\n",
      "Epoch 923/1000\n",
      "5600/5600 [==============================] - 0s 23us/sample - loss: 0.1403 - accuracy: 0.9488 - val_loss: 2.1503 - val_accuracy: 0.5638\n",
      "Epoch 924/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1361 - accuracy: 0.9538 - val_loss: 2.1080 - val_accuracy: 0.5700\n",
      "Epoch 925/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1311 - accuracy: 0.9536 - val_loss: 2.1395 - val_accuracy: 0.5596\n",
      "Epoch 926/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1308 - accuracy: 0.9554 - val_loss: 2.1339 - val_accuracy: 0.5838\n",
      "Epoch 927/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1398 - accuracy: 0.9450 - val_loss: 2.2187 - val_accuracy: 0.5550\n",
      "Epoch 928/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1432 - accuracy: 0.9450 - val_loss: 2.1065 - val_accuracy: 0.5771\n",
      "Epoch 929/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1333 - accuracy: 0.9543 - val_loss: 2.1152 - val_accuracy: 0.5775\n",
      "Epoch 930/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1327 - accuracy: 0.9516 - val_loss: 2.1371 - val_accuracy: 0.5708\n",
      "Epoch 931/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1333 - accuracy: 0.9521 - val_loss: 2.2120 - val_accuracy: 0.5525\n",
      "Epoch 932/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1392 - accuracy: 0.9493 - val_loss: 2.1810 - val_accuracy: 0.5683\n",
      "Epoch 933/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1308 - accuracy: 0.9541 - val_loss: 2.1692 - val_accuracy: 0.5738\n",
      "Epoch 934/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1284 - accuracy: 0.9554 - val_loss: 2.1570 - val_accuracy: 0.5775\n",
      "Epoch 935/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1254 - accuracy: 0.9570 - val_loss: 2.1553 - val_accuracy: 0.5629\n",
      "Epoch 936/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1303 - accuracy: 0.9543 - val_loss: 2.1331 - val_accuracy: 0.5771\n",
      "Epoch 937/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1277 - accuracy: 0.9552 - val_loss: 2.1714 - val_accuracy: 0.5612\n",
      "Epoch 938/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1372 - accuracy: 0.9498 - val_loss: 2.1774 - val_accuracy: 0.5696\n",
      "Epoch 939/1000\n",
      "5600/5600 [==============================] - 0s 24us/sample - loss: 0.1308 - accuracy: 0.9521 - val_loss: 2.1635 - val_accuracy: 0.5729\n",
      "Epoch 940/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1267 - accuracy: 0.9564 - val_loss: 2.1635 - val_accuracy: 0.5604\n",
      "Epoch 941/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.1296 - accuracy: 0.9550 - val_loss: 2.2652 - val_accuracy: 0.5512\n",
      "Epoch 942/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1351 - accuracy: 0.9514 - val_loss: 2.2029 - val_accuracy: 0.5600\n",
      "Epoch 943/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1375 - accuracy: 0.9489 - val_loss: 2.2088 - val_accuracy: 0.5638\n",
      "Epoch 944/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1439 - accuracy: 0.9446 - val_loss: 2.1715 - val_accuracy: 0.5867\n",
      "Epoch 945/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1362 - accuracy: 0.9491 - val_loss: 2.1666 - val_accuracy: 0.5683\n",
      "Epoch 946/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1257 - accuracy: 0.9588 - val_loss: 2.1485 - val_accuracy: 0.5717\n",
      "Epoch 947/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1376 - accuracy: 0.9461 - val_loss: 2.2039 - val_accuracy: 0.5838\n",
      "Epoch 948/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1433 - accuracy: 0.9429 - val_loss: 2.1751 - val_accuracy: 0.5721\n",
      "Epoch 949/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.1367 - accuracy: 0.9477 - val_loss: 2.2026 - val_accuracy: 0.5646\n",
      "Epoch 950/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1376 - accuracy: 0.9475 - val_loss: 2.1678 - val_accuracy: 0.5846\n",
      "Epoch 951/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1447 - accuracy: 0.9436 - val_loss: 2.1921 - val_accuracy: 0.5671\n",
      "Epoch 952/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1354 - accuracy: 0.9514 - val_loss: 2.1975 - val_accuracy: 0.5817\n",
      "Epoch 953/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1528 - accuracy: 0.9379 - val_loss: 2.1876 - val_accuracy: 0.5738\n",
      "Epoch 954/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1348 - accuracy: 0.9520 - val_loss: 2.1999 - val_accuracy: 0.5688\n",
      "Epoch 955/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1284 - accuracy: 0.9545 - val_loss: 2.1846 - val_accuracy: 0.5692\n",
      "Epoch 956/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1242 - accuracy: 0.9593 - val_loss: 2.1651 - val_accuracy: 0.5738\n",
      "Epoch 957/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1243 - accuracy: 0.9571 - val_loss: 2.1706 - val_accuracy: 0.5713\n",
      "Epoch 958/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1275 - accuracy: 0.9559 - val_loss: 2.1929 - val_accuracy: 0.5658\n",
      "Epoch 959/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1360 - accuracy: 0.9505 - val_loss: 2.1946 - val_accuracy: 0.5775\n",
      "Epoch 960/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1235 - accuracy: 0.9561 - val_loss: 2.2074 - val_accuracy: 0.5713\n",
      "Epoch 961/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1296 - accuracy: 0.9518 - val_loss: 2.1604 - val_accuracy: 0.5708\n",
      "Epoch 962/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1347 - accuracy: 0.9500 - val_loss: 2.1902 - val_accuracy: 0.5825\n",
      "Epoch 963/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1278 - accuracy: 0.9543 - val_loss: 2.1749 - val_accuracy: 0.5679\n",
      "Epoch 964/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1275 - accuracy: 0.9550 - val_loss: 2.2086 - val_accuracy: 0.5638\n",
      "Epoch 965/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1299 - accuracy: 0.9523 - val_loss: 2.2017 - val_accuracy: 0.5908\n",
      "Epoch 966/1000\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.1349 - accuracy: 0.9505 - val_loss: 2.1811 - val_accuracy: 0.5704\n",
      "Epoch 967/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1438 - accuracy: 0.9470 - val_loss: 2.2744 - val_accuracy: 0.5600\n",
      "Epoch 968/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1450 - accuracy: 0.9439 - val_loss: 2.2465 - val_accuracy: 0.5733\n",
      "Epoch 969/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1323 - accuracy: 0.9527 - val_loss: 2.2008 - val_accuracy: 0.5708\n",
      "Epoch 970/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1208 - accuracy: 0.9577 - val_loss: 2.2202 - val_accuracy: 0.5654\n",
      "Epoch 971/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1193 - accuracy: 0.9582 - val_loss: 2.1756 - val_accuracy: 0.5658\n",
      "Epoch 972/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1196 - accuracy: 0.9605 - val_loss: 2.2308 - val_accuracy: 0.5604\n",
      "Epoch 973/1000\n",
      "5600/5600 [==============================] - 0s 25us/sample - loss: 0.1246 - accuracy: 0.9552 - val_loss: 2.1970 - val_accuracy: 0.5638\n",
      "Epoch 974/1000\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.1266 - accuracy: 0.9570 - val_loss: 2.2244 - val_accuracy: 0.5696\n",
      "Epoch 975/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.1247 - accuracy: 0.9548 - val_loss: 2.2227 - val_accuracy: 0.5633\n",
      "Epoch 976/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.1232 - accuracy: 0.9598 - val_loss: 2.2201 - val_accuracy: 0.5704\n",
      "Epoch 977/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.1232 - accuracy: 0.9571 - val_loss: 2.2146 - val_accuracy: 0.5692\n",
      "Epoch 978/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.1245 - accuracy: 0.9579 - val_loss: 2.2172 - val_accuracy: 0.5654\n",
      "Epoch 979/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.1216 - accuracy: 0.9582 - val_loss: 2.2177 - val_accuracy: 0.5783\n",
      "Epoch 980/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.1216 - accuracy: 0.9575 - val_loss: 2.2189 - val_accuracy: 0.5746\n",
      "Epoch 981/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.1247 - accuracy: 0.9563 - val_loss: 2.2368 - val_accuracy: 0.5621\n",
      "Epoch 982/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.1232 - accuracy: 0.9580 - val_loss: 2.2181 - val_accuracy: 0.5671\n",
      "Epoch 983/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.1215 - accuracy: 0.9577 - val_loss: 2.1927 - val_accuracy: 0.5763\n",
      "Epoch 984/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.1214 - accuracy: 0.9586 - val_loss: 2.2356 - val_accuracy: 0.5625\n",
      "Epoch 985/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.1236 - accuracy: 0.9559 - val_loss: 2.2661 - val_accuracy: 0.5646\n",
      "Epoch 986/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.1221 - accuracy: 0.9563 - val_loss: 2.1959 - val_accuracy: 0.5692\n",
      "Epoch 987/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.1243 - accuracy: 0.9555 - val_loss: 2.2291 - val_accuracy: 0.5658\n",
      "Epoch 988/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.1263 - accuracy: 0.9532 - val_loss: 2.2461 - val_accuracy: 0.5658\n",
      "Epoch 989/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.1213 - accuracy: 0.9577 - val_loss: 2.2377 - val_accuracy: 0.5688\n",
      "Epoch 990/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.1231 - accuracy: 0.9566 - val_loss: 2.2527 - val_accuracy: 0.5646\n",
      "Epoch 991/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.1247 - accuracy: 0.9527 - val_loss: 2.2316 - val_accuracy: 0.5721\n",
      "Epoch 992/1000\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.1241 - accuracy: 0.9571 - val_loss: 2.2237 - val_accuracy: 0.5729\n",
      "Epoch 993/1000\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.1178 - accuracy: 0.9591 - val_loss: 2.2335 - val_accuracy: 0.5671\n",
      "Epoch 994/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.1262 - accuracy: 0.9538 - val_loss: 2.2344 - val_accuracy: 0.5758\n",
      "Epoch 995/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.1212 - accuracy: 0.9564 - val_loss: 2.2689 - val_accuracy: 0.5642\n",
      "Epoch 996/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.1246 - accuracy: 0.9554 - val_loss: 2.2382 - val_accuracy: 0.5775\n",
      "Epoch 997/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.1186 - accuracy: 0.9609 - val_loss: 2.2277 - val_accuracy: 0.5621\n",
      "Epoch 998/1000\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.1203 - accuracy: 0.9613 - val_loss: 2.2356 - val_accuracy: 0.5717\n",
      "Epoch 999/1000\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.1165 - accuracy: 0.9625 - val_loss: 2.2427 - val_accuracy: 0.5688\n",
      "Epoch 1000/1000\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.1215 - accuracy: 0.9566 - val_loss: 2.2663 - val_accuracy: 0.5696\n"
     ]
    }
   ],
   "source": [
    "# specify network layers\n",
    "binary_ann = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28, )),\n",
    "    tf.keras.layers.Dense(100, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(100, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "# compile and fit network\n",
    "binary_ann.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy']) \n",
    "history = binary_ann.fit(X_train, y_train, epochs = 1000, batch_size = 128, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnWd4VcXWgN9JD+kQeu+9hypSFbGiiAVBxcYnYkW9Yufa77Vh74AiV1SwICCIgoWmFOlFOoRQA4SeOt+POWWfmhPISV3v8+Q5u8zee+2TZNbMaqO01giCIAgCQEhxCyAIgiCUHEQpCIIgCA5EKQiCIAgORCkIgiAIDkQpCIIgCA5EKQiCIAgORCkIQUUpVU8ppZVSYQG0Ha6UWlAUcgnBRynVWymVWtxyCAVDlILgQCm1QymVpZRKdju+0tax1yseyVxkiVFKnVBKzSpuWUoTFuV8wu3nuuKWTShZiFIQ3NkODLHvKKVaA9HFJ44Hg4FMoL9SqnpRPjiQ2U4pIFFrHWv5+bK4BRJKFqIUBHcmATdZ9m8GPrM2UEolKKU+U0odVErtVEo9oZQKsZ0LVUq9opQ6pJTaBlzq5dpPlFJ7lVJ7lFLPKaVCCyDfzcD7wGpgqNu9ayulvrHJla6Uetty7g6l1Aal1HGl1HqlVAfbca2UamRpN1Ep9Zxtu7dSKlUp9YhSah8wQSmVpJSaYXvGEdt2Lcv1FZVSE5RSabbz39mOr1VKXW5pF277jtq5v6BNzsss+2G2th2UUlFKqc9t73dUKbVUKVW1AN+fV2zv/b5Saq7tO/pNKVXXcr677VkZts/u+b2z5fyDSqkDtt/5LZbjl9h+F8dtfwsPnet7COeOKAXBnSVAvFKqua2zvg743K3NW0AC0ADohVEi9n/2O4DLgPZACmZkb+VTIAdoZGvTH7g9EMGUUnWA3sBk289NlnOhwAxgJ1APqAlMsZ27Bhhrax8PXAGkB/JMoBpQEagLjMD8z0yw7dcBTgNvW9pPAioALYEqwOu2458BwyztLgH2aq1XennmF1hma8BFwCGt9QqMUkwAagOVgDttMhQGQ4FngWRgJeY7RilVEZgJvGl75mvATKVUJdt1vt4ZzPeXgPl93Aa8o5RKsp37BPg/rXUc0AqYV0jvIZwLWmv5kR+01gA7gAuAJ4AXgQHAXCAM0JjONhRjvmlhue7/gF9t2/OAOy3n+tuuDQOq2q6NtpwfAsy3bQ8HFviR7wlgpW27BpALtLftdwMOAmFerpsD3OfjnhpoZNmfCDxn2+4NZAFRfmRqBxyxbVcH8oAkL+1qAMeBeNv+VOBfPu7ZyNa2gm1/MvCUbftWYBHQpoC/23q2dz3q9tPc8t5TLO1jbd9vbeBG4C+3+y22/b78vXNvjMIKsxw7AHS1be+y/e3EF/ffvvw4f2SmIHhjEnAD5p/+M7dzyUAEZkRuZydmJAim89vtds5OXSAc2GszfRwFPsCMLgPhJmyjV611GvAbZuQMpvPaqbXO8XJdbWBrgM9w56DW+ox9RylVQSn1gc1sdgz4HUi0zVRqA4e11kfcb2KTdyFwtVIqEbjY/i5e2m4BNgCXK6UqYGY2/7OdnoRRclNs5pr/KqXCC/A+yVrrRMvPBss5x+9Na30COIz5fdbA9fcIzt+5z3e2ke72OzmFUTgAV2NmTDtt5qpuBXgPIUiIUhA80FrvxDicLwG+cTt9CMjGdPB26gB7bNt7MR2F9Zyd3ZiZgrVjitdat8xPJpsNuzHwqFJqn83G3wUYYnMA7wbq+HAG7wYa+rj1KYzpw041t/PuZYQfBJoCXbTW8UBPu4i251S0dfre+BRjQroGWKy13uOjHThNSAOB9TZFgdY6W2v9b611C6A7xlR3k+/bFAjH700pFYsxm6XZfuq6tbX/zvN7Z59orZdqrQdiBgXfAV+dpdxCISJKQfDFbUBfrfVJ60GtdS7mn/d5pVSczRk5Gqff4SvgXqVULZvteIzl2r3AT8CrSql4pVSIUqqhUqpXAPLcjDFltcCYbNph7NAVMKPuvzAK6SVlwlajlFLn2a79GHhIKdVRGRpZnKgrgRuUcZAPwPhI/BGHMYkctdnan3Z7vx+Bd20O6XClVE/Ltd8BHYD78JyBuTMFY3obiXOWgFKqj1KqtW1mcgyjoHPzuVegXKKU6qGUisD4Fv7UWu8GZgFNlFI32Jze12F+DzMCeGevKKUilFJDlVIJWuts27sU1nsI54AoBcErWuutWutlPk7fA5wEtgELMJ3WeNu5jzDmjVXACjxnGjdhzE/rgSMY27rf0FKlVBRwLfCW1nqf5Wc7xpxys01ZXY6xx+8CUjFOcrTWXwPP2+Q8jumcK9puf5/tuqMYR6tL5IwXxmFCdA9hnPKz3c7fiOmoN2Ls5/fbT2itTwPTgPpevhcXbJ3tYsxswBo2Wg3znR3DmJh+w6aQbdFD7+cj/1Hlmqcw2nLufxgldxjoiC26S2udjpmRPIhx0P8LuExrfSi/d86HG4EdNjPcnbg64oViQmkti+wIQlGhlHoKaKK1LlEdoFJqIpCqtX6iuGURipeykIwjCKUCm7npNswIWRBKJGI+EoQiQCl1B8Yp+6PW+vfilkcQfCHmI0EQBMGBzBQEQRAEB6XOp5CcnKzr1atX3GIIgiCUKpYvX35Ia105v3alTinUq1ePZct8RUoKgiAI3lBKuWele0XMR4IgCIIDUQqCIAiCA1EKgiAIgoNS51PwRnZ2NqmpqZw5cyb/xkJAREVFUatWLcLDC1KAUxCE0k6ZUAqpqanExcVRr149lFLFLU6pR2tNeno6qamp1K9fv7jFEQShCCkT5qMzZ85QqVIlUQiFhFKKSpUqycxLEMohZUIpAKIQChn5PgWhfFJmlIIgCEJZ5fDJLL5etjv/hoWAKIVCID09nXbt2tGuXTuqVatGzZo1HftZWVkB3eOWW25h06ZNftu88847TJ7sdQVHQRBKMatTjzJjdRp7jp72OKe1psd/5vHw1NXsPnwq6LKUCUdzcVOpUiVWrlwJwNixY4mNjeWhhx5yaeNYFDvEux6eMGFCvs8ZNWrUuQsrCEKRs2zHYRZuSee+CxrzzYpUXvpxIwvH9CU81PQHV7y90NF2ePd67M04zf/1akhunuaBL1dyKsssSpd29DS1K1bw+ozCQmYKQWTLli20atWKO++8kw4dOrB3715GjBhBSkoKLVu25JlnnnG07dGjBytXriQnJ4fExETGjBlD27Zt6datGwcOHADgiSeeYNy4cY72Y8aMoXPnzjRt2pRFixYBcPLkSa6++mratm3LkCFDSElJcSgsQRCCS05uHtm5eWituft/Kxj38z+89tMmBr+/mNd//getNc/OWM+B45k8Mm01eXmaNakZLveYuGgHc9btZ9C7i7jm/cWkHnHOHvYdC37wR5mbKfz7h3WsTztWqPdsUSOepy/Pd215r6xfv54JEybw/vtmlcSXXnqJihUrkpOTQ58+fRg8eDAtWrRwuSYjI4NevXrx0ksvMXr0aMaPH8+YMWM87q215q+//mL69Ok888wzzJ49m7feeotq1aoxbdo0Vq1aRYcOHc5KbkEo7yzbcZjm1eOJifTdTR44dobKcZHk5GnCQhSNHv8RMKP9Gav3erTPzMmjYeVYlu08wjcr9vDNij1c2tp1NdrGVWLZfOCE1+dFhAZ/HF/mlEJJo2HDhnTq1Mmx/8UXX/DJJ5+Qk5NDWloa69ev91AK0dHRXHzxxQB07NiRP/74w+u9Bw0a5GizY8cOABYsWMAjjzwCQNu2bWnZ8uyUmSCUNXJy8wgNUV4j6/LyzLoyISHm3MC3F7AqNYPYyDBy8zTfjTqPyLAQFm9LZ9O+44y9oiWv/rSJt+ZtASA2Mozm1eMc95u4aIdXGXYfPsWynUdcjs1cY5THwHY1uLhVNQa0qk5Obp5DwQAkRIez8qkLiyQqsMwphbMd0QeLmJgYx/bmzZt54403+Ouvv0hMTGTYsGFecwEiIiIc26GhoeTk5Hi9d2RkpEcbWTRJEDzRWtPo8R+5qVtd/n1FS7Q2CmDexv3cOtFZdfmN69vRs3FlVtlMOicyzf/VZW/9QXau839r5pq9HDye6dg/kZnD0h2unb03Lnzd+6J7FWMieOP69o79sNAQfn2oN9+vTKNt7QTOb1y5yMLExadQhBw7doy4uDji4+PZu3cvc+bMKfRn9OjRg6+++gqANWvWsH79+kJ/hiAUF1sOnOC7v/ec1XUAny3eyaVvLuDq9xexYtcRF4UAcN+UlYycvNzjeqtCAFwUgi9qJUVTr5J3p/Ad59enZmK0Yz8nN8+jTb3kGO67oDG9m1YhNKTo8obK3EyhJNOhQwdatGhBq1ataNCgAeedd16hP+Oee+7hpptuok2bNnTo0IFWrVqRkJBQ6M8RhOLg6vcWkXE6m5w8zdUdarJs5xEWb03nrt4NCbPZ24+eymLmmr0kRIczoGU1wkJD2HbopOMe6/can+Ogdxd5fcaSbYcBSI6N4NAJ3yHl7esk8veuo17P9WxSmXduaE9cVDifL9nJE9+tdTnfvVEyj1/aguU7j3D1e4s4dsa7NaA4KHVrNKekpGj3RXY2bNhA8+bNi0mikkVOTg45OTlERUWxefNm+vfvz+bNmwkLK7j+l+9VKGnUf3Qm9i5rwvBOfL5kJ79sPMCAltUYc3Ezrnx3IUdPZTvaJ0SH8+GNHbnuwyU+79mmVgKr3SKAAF4e3IakChHc/pnnol6d61Xkqzu7ceDYGaIjQrn2gyVs2OsMcLn/gsbcf0ETABZtOcQNH//pcv2XI7rSpUElMnNyafrEbAB2vHRp4F/EWaCUWq61TsmvncwUyhgnTpygX79+5OTkoLXmgw8+OCuFIAhFSV6eJk9rx2hfa82B45kooHJcJAeOZ3IqK5fKsWYb4JaJSx3Xz163jwVbDjl8AHYyTmd7KISwEEVOnnMwPKRzHR67JIZfNuznoz+2O44rpbigRVV+vO98qsZHMWDc7xw6kUmehkcubgpAlfgoAKbe2Y2WT88hOTaSD2/qSMsa8Y77dGtYifeHdeDOz1c4jtkjmiLDQnn4oqbUCXLuQUGQ3qKMkZiYyPLlnjZRQSgpHDmZxbq0Y/RonOw4NmLScn7esJ9v7+pO8+rxzN94gJGTV/i5iyfuCsGduKgw1oy9CID5Gw9wzxd/cyIzh451k2hSNY5O9SqSdvQM9ZNjqBIfyZXtagDQvLrp4Bc/2g/Aq30/JjKMqXd2Izk2knrJMS7nlFIMaFWdP/7Vh+s/XMKeo6cdSWsAo/o0KtB7BhtRCoIgFCn/9/ly/tp+mBn39KBptThCleLnDfsBuMpm5/+/Xg0Cvt+FLaoyd/1+x37LGvEkVghn4ZZ0x7HO9SvywbCOjv0+zaqwZmx/9h/LpFqCGe2HhijeGeo7ryc/Z29KvYp+z9euWIFqCVHsOXqaIkg3OGtEKQiCEDA5uXl8s2IPV3Wo6TLazTidzdjp67ivX2NqJUVz+GQWK3YdccTcPztjPXUqxfD3riP8td04ci97awFtayeyarens/bXjQdd9u/p28iRExCiwG79Wf/MRVSICOOd+Vt4eY6pHfbD3T1QCqat2MNDX68C4OObU4iPcl0wSinlUAhFxVtD2jNteSoNK8cW6XMLgigFQRACIjs3j//O3shHf2wnOy+PoV3qAvDJgu18syKVdWnH+O2fgxw9leXotBc/2pduL87zeU9vCgFg0/7jgAnrnHnv+SREhzuUQs2kaHYfNqUfKkSYLmxUn0YOpWBPQBvcsRb1k2M4eDzTQyEUFzUSo7mnX+PiFsMvohQEQQiI8Qu2Oxyxj3+7lsToCJZsS2fSkp2ONodPuoZwfrPC5BRYR/feqBQTQfrJLDrXr+iYScy4pwfNqsU5nM+vX9eWB75cxdjLW3Lbp54RQQ0rx9CxbpLLMfd9IX9KsGWr9NC7d2+PRLRx48Zx1113+bwmNtZMH9PS0hg8eLDP+7qH37ozbtw4Tp1yltO95JJLOHrU++hLEALFRP+cYeXuo2zaZ0bti7elu7QZ9b8VLgrBGzvTTX7AEpuT1s5Tl7Xgx/vOd+wvHNOXFwe15j9Xt3Eci4sKcygEgKva12LHS5fSr3lVr8/65cHe/Hdw2wDeTvCHzBQKgSFDhjBlyhQuuugix7EpU6bw8ssv53ttjRo1mDp16lk/e9y4cQwbNowKFUxI26xZs876XkL5YevBEzRIjvFZOuGl2Rv54Ldtjv3tL15C6pHTHuGc+bFmj4ndrxgTweJH+/LsjPU8O7AVlWIjyTht8gn6NatCVHgoQzrXccnsjfVTiG7hmL7k5pauHKvSgswUCoHBgwczY8YMMjNN/PSOHTtIS0ujXbt29OvXjw4dOtC6dWu+//57j2t37NhBq1atADh9+jTXX389bdq04brrruP0aWfJ3JEjRzpKbj/99NMAvPnmm6SlpdGnTx/69OkDQL169Th06BAAr732Gq1ataJVq1aOkts7duygefPm3HHHHbRs2ZL+/fu7PEco+6xOPUq/V39j/MIdjlLP01elsXZPBm/8vJlmT/7oohAAth06ybaDJ7ird0PWjO3Ps1e28nn/+paQzA17jxETEUpYaAjVE6J5d2hHKsWaml0J0eFMG9mdN4e41vyxExvlWynUTIymjo8SEsK5UfZmCj+OgX1rCvee1VrDxS/5PF2pUiU6d+7M7NmzGThwIFOmTOG6664jOjqab7/9lvj4eA4dOkTXrl254oorfI7O3nvvPSpUqMDq1atZvXq1S9nr559/nooVK5Kbm0u/fv1YvXo19957L6+99hrz588nOTnZ5V7Lly9nwoQJ/Pnnn2it6dKlC7169SIpKYnNmzfzxRdf8NFHH3Httdcybdo0hg0bVjjflVAi0Frz49p9HD2VTfeGlRyx839tP8yaPSZ799kZ63l2RmC1sX7ZsJ88bcIq46JM+Ygn3Uo3/Dy6F+vSMri0dXXyNFz+1gI27T9OnB8nrz+bf2RYaECyCYWLzBQKCbsJCYzpaMiQIWiteeyxx2jTpg0XXHABe/bsYf/+/T7v8fvvvzs65zZt2tCmjdO++tVXX9GhQwfat2/PunXr8i10t2DBAq666ipiYmKIjY1l0KBBjhLc9evXp127doBr2W2h7DB/0wHumryCx75dw9CP/yTjVDZLtqVz7QeLA1YEVl6YtRGA5Dgzyq8cF8k3d3UHTLjoj/edT6MqsQxsV5Ow0BAiwkKoaxvJV4mPLNCz3h/WkRu71i2wjELhUPZmCn5G9MHkyiuvZPTo0axYsYLTp0/ToUMHJk6cyMGDB1m+fDnh4eHUq1fPa6lsK95mEdu3b+eVV15h6dKlJCUlMXz48Hzv46+mlb3kNpiy22I+Kp3k5WnW7MmgTa0El7+bM9m5fPS7s1zDnqOnafvMT17vMfrCJrw29x+XYxOGd3IpIWElIdo56u9QJ4nfHu5NnYoVvP7d2tv2alI58JcCBrSqxoBW1Qp0jVB4yEyhkIiNjaV3797ceuutDBkyBDArqFWpUoXw8HDmz5/Pzp3+IzV69uzJ5MmTAVi7di2rV68GTMntmJgYEhIS2L9/Pz/+6Fx8Iy4ujuPHj3u913fffcepU6c4efIk3377Leeff75HO6H0Mn7hdga+s5AHv1pFvTEzWbn7KEdOZvH8zA2OSKGHL2rq83ql4N5+jbmrd0PHsU71kujd1NmJfz/qPIZ0ruPYb1I1zuUedSv5dlbbE8OqxhdtgphwbpS9mUIxMmTIEAYNGuQwIw0dOpTLL7+clJQU2rVrR7NmzfxeP3LkSG655RbatGlDu3bt6Ny5M2BWUGvfvj0tW7b0KLk9YsQILr74YqpXr878+fMdxzt06MDw4cMd97j99ttp3769mIpKGcfPZBMWEkJ0hLGvp5/I5M7PlzOsa122HjThnt/Y1he48p2FHtdbk7oAhnWtw+dLdnFJ62qMvcIsSFUhwmm7/+zWLiiluLRNdS5oXoW2tRNpWzuRFjXi6Vq/ot+IIHfu7NUQpRSDO9Yq+IsLxYaUzhZ8It9r8bD78Cm+XLqbxlVjuW/KSqrFR5GVm0fDyjGO1b3qVqpAs2pxzFnn20cFphzzMz+sZ/xCY07a/uIlHDieSeXYSEfm76eLdvD09HWO9kLZREpnC0IpIeN0NiM/X87p7Fzu7duYsT+sY2e6MyFx3zHjP7JmC+9MP+XSxh+PXNyU6zvXpmZiNEopD3POtSm1WZeWwYP9fZuahPKDKAVBKCLy8jS/bT5I7yau6+3+vH4/i7YaH8AtE5cSHlq4Sy9GhoV6+AKsREeESiaw4KDMOJpLmxmspCPfZ+Hzwe/buGXCUuZvOsDirekM/XgJR05msfuI64jffT1gfyRWCKdSTITLMfd9QSgIQVUKSqkBSqlNSqktSqkxXs7XVUr9opRarZT6VSl1Vh6pqKgo0tPTpSMrJLTWpKenExUlUSNny/KdR3jo61Xk5Wn+3nWE42eyWZ1qalJt2HucIR8tYeGWdLq/NI9xP2/2eZ97+/pegOXhi5qy4okLWf7khS7rD4y0RBMJQkEJmvlIKRUKvANcCKQCS5VS07XW1syZV4DPtNafKqX6Ai8CNxb0WbVq1SI1NZWDBw/m31gIiKioKGrVkqiRs+HwySyufs8sFhMZFsLkP3cB0MCWVWyNBjqdnev3Xg9c2IQ3522hWbU4LmhelW2HTrD1wEk27T9OlTins/jh/k3JydXccX4DqiVE0aByDFGSESycBcH0KXQGtmittwEopaYAAwGrUmgBPGDbng98dzYPCg8Pp379+ucgqiCcPRMXbmfsD+t5eXAbrkmp7ZL4ZVcIYOoH+aJafBQ3dqvLy3M20aNRMi1rxNO1YSWUUqx6qj+R4SFEhZtOfvSXK9m0/7iLXyIsNIQnL2vh2O/bzHslUUHIj2AqhZrAbst+KtDFrc0q4GrgDeAqIE4pVUlr7VKjVyk1AhgBUKdOHQShOPlzWzqb9h/npm710Foz9gczznl46mo+W7zTUVsoP+pUrMCuw8afsOSxfmituap9TWokRru0S6hQMhaIEcoHwVQK3kIo3I3+DwFvK6WGA78DewCP1be11h8CH4LJUyhcMQUhf05k5jB77T6ual+T6z5cAkCPRskcPJ7p0i5QhQDwy4O9eH3uPxw7Y0pIK6U8FII/xIcmBINgKoVUoLZlvxaQZm2gtU4DBgEopWKBq7XWgf9XCUKQ2XLgOD+t30+oUrz440aycpz1/vu++pvXa67pWIuvl6d6HH9/WAfu/HyFYz88NIR/DfCf5S4IRU0wlcJSoLFSqj5mBnA9cIO1gVIqGTistc4DHgXGB1EeQQiI2Wv38fWy3Xx0UwojJi1n28GTXJtinO6PfZt/WfaXr2nL5W1r0LpmAv/7axfXpNQiLMRUDrXz8+heZy3fxa2r883fe2hXO/Gs7yEIvgiaUtBa5yil7gbmAKHAeK31OqXUM8AyrfV0oDfwolJKY8xHo4IljyDkR3ZuHqFK8ci01WSczmbgOws5ZDMPfbXMc+Rv5+JW1fj9n4OczMrltWtNElhPW2XQUX2cIaXWVcUaVYk9azkvbFGVbS9c4og8EoTCJKgZzVrrWcAst2NPWbanAme/FqUgFALPz1xPpdhIXvpxI/FRYRw7Y9xa/vwDX9zRlSEfGd/Ce8M6ciorhzztfwlJ+6pil7Q+97LQohCEYCFlLoRyz0d/ONcesCsEfwzuWIum1UzZiKva1wSgQkRg/0ornrywQJVGBaGoKTNlLgTBFz+t20e9MTPJOJXtclxrHVAEz+TbXSOpT2bmUDEmgln3ns9/B7fxcZV3KsZEuPgWBKGkIUMWocwzYtJyAB79djVtayUSohSHTmTywe/bGN69nkf7fs2q8MvGA4798xolk1I3ieqJ0fywKo1oWxJZixrxRSK/IBQlohSEMo213PSsNfuYtWafy/mJi3a47D93ZSsub1uDtv82y1fe1sNkyk8d2Z28PE3rmvFc07E2glBWEaUglCmmLk8lITqcH9fuJTo8lBmr9wZ87f/1bMCwrnVdTEpPXOpcZCgkRDGipxSbE8o2ohSEMsPXy3bz8NTVXs9d3aEW01b4DisFiLE5gK01hXytPywIZRVRCkKp4qtlu3l73hZ+e7i3o8Pu9uIvpJ/IIsuSB+DOq9e25fmrWvH2vC28PX8LC8f0Zc7afTwzw1mf8dhppyP61vPq06GuJIcJ5Q9RCkKp4l+2mcDJrFxiI8M4k53L3owzPtvfcl49LmxuKoZGhYfy0EVNeegis+zkrT3q07BKLGtSj/LKT/848ggAnrq8hdf7CUJZR5SCUGqYsdpZOuvhr1fRv2VVHvhylc/2r1/Xlqva+18ToleTyvRolExkWCg3dJEKvIIgSkEokWTl5DFrzV4GtqvhMBO9YVmh7Me1+/hx7T6P69rUSqBj3SQe6t/U4SPIj9AQxR09G+TfUBDKAaIUhBJFVk4e4aGKD37byqtz/yE8NIQaiVHERIYRHZH/SmJ9mlbhgQubFIGkglA2EaUglBjOZOfS7MnZ3NuvsWOdgjd/2cym/ce9th/evZ5LnkH3hpW4t1/johBVEMosohSEYufQiUyem7GexlVNPaHPFu+gZ2NTZdSXQgB4/NLmTFy0g/rJMUwb2Z34qDBCpVCcIJwTohSEYmPtngxunbiUA26rlx09lc30VWk+rjLccX59wkNDWPVUfyLCQgIyLQmCkD+iFIRiY9zPmz0Ugj/Ob5zMk5e1IDo8lNoVKwCyfrEgFDaiFIRiY20+6xnb1zZ44/p2dG1QiYTocKLCZUYgCMFElIIQdPZmnObrZamM6tOIfcfOsG5PBjGRYew75kw661K/Iicyc1iXdsxxbOwVLTlwPJPL2tQQX4EgFBGiFISgkXrkFGv3ZDgWqw8NUbw8Z5PXtmOvaEmTqnH0+M88R4Zyq5oJNLE5nwVBKBpEKQhB4fDJLHr8Z77LMV8KISYilObVzdoEIZYCdFXjooInoCAIXpEloIRzZsuBE45VzZZsS6f5k7OZu94z29gX3999nmO7oWVB+/hoGbMIQlEj/3W8H5WTAAAgAElEQVTCWbP90Elmrk7jlZ/+AeCvx/vx8pxNnM7O5ZFpawK+T6MqThPRW9e3Z/G2QwxoVb3Q5RUEIX9kpiCcNbdNXOpQCAA3j19KVo738tWj+nhfnKaOLbTUTkKFcFEIglCMyExBOCvOZOdy7EyOy7ENe4/5aA0PX9SM23s0YMvBE9SpWIGsnDwyc/JIjo0ItqiCIBQAUQpCgVm45RBDP/4zoLavXduWLg0qAZAUE0GnmIrBFE0QhHNEzEdCwOTmaSYt3uFVIVza2rvJp1+zqtRMjA6yZIIgFBaiFASfnMnOpfuLvzBz9V7e+mUzDR+bxZPfr/Patlk1p7P4/guclUqlDIUglC7EfCT45MCxTNIyzjDqfyvybZto6fxv6FKHcT9vpnvDSsEUTxCEICBKQfDJqeycfNs8d2UrIsNCuKp9TZ78fh1R4SFUiYvi/WEd6FJflIIglDZEKQguTFqykye/W8v3o87juZnrfbYb1achoy9sSojCsVzmiicvdNQokrBSQSidiE9BcOHteWYd5IHvLGTpjiMAhIUo5j7Q09Hm31e05J6+jQkNUQ6FAFAxJoKEaPEhCEJpRmYKAgBHTmaxbOcR0k9keZz76YGeNKjsLD9xc/d6RSiZIAhFiSiFcsx5L82jWbU4RvdvwsjPV7Dr8Cmv7ZLjIgGYc39PsnO9ZywLglA2EKVQzsjKyWPR1kP0aJTMnqOn2XP0NL9sPOD3mvgoYxJqWk3KWAtCWUeUQjlh7Z4Mvl+5h/DQEN79dStVbKN/QRAEK6IUygk3fvInR2zlrQGvayO/P6yDY0EcO9ZENEEQyj4SfVTO6desimO7SdU4ZtzTgycube44dn7jysUhliAIxYQohXJCWKjnr7p6QhSvXdfOsR8fHU6rmglEhYcC0L9FVTrWTSoyGQVBKH5EKZRxcvM0ny7awUGLuah1zQTeHdqBeQ/2JiE6nDEXNwNw5Bi0q50IwDUptYteYEEQihWltQ7ezZUaALwBhAIfa61fcjtfB/gUSLS1GaO1nuXvnikpKXrZsmVBkrhssXZPBpe9tcDj+M+je9HIsuylN85k5zpmDIIglH6UUsu11in5tQvaTEEpFQq8A1wMtACGKKVauDV7AvhKa90euB54N1jylDemr0rzqhCGdK6dr0IARCEIQjklmOajzsAWrfU2rXUWMAUY6NZGA/G27QQgLYjylFlOZOYw9OMlfPt3Kmeyc9m47xj3fvG317YvDmpTxNIJglCaCGZIak1gt2U/Feji1mYs8JNS6h4gBrjA242UUiOAEQB16tQpdEFLO9+sSGXhlnQWbknngS9XeZy/t28j1uzJoFXNhGKQThCE0kQwlYLycszdgTEEmKi1flUp1Q2YpJRqpbV2qaWgtf4Q+BCMTyEo0pZirEXpvHFn74ZUiJCUFEEQ8iffnkIpdTcwWWt9pID3TgWs4Su18DQP3QYMANBaL1ZKRQHJgP+6C+WcTxftoHHVWDrVq8iDX61i+ipPq9u9/RrTqV4SidERohAEQQiYQHqLasBSpdQKYDwwRwcWsrQUaKyUqg/swTiSb3BrswvoB0xUSjUHooCDgQpfHsnJzePp6WZJzMEda3kohOoJUSx4pK9jXQNBEISCkK+jWWv9BNAY+AQYDmxWSr2glGqYz3U5wN3AHGADJsponVLqGaXUFbZmDwJ3KKVWAV8AwwNUOOWWnZZKplOXp7qc61g3iTeHtBeFIAjCWROQXUFrrZVS+4B9QA6QBExVSs3VWv/Lz3WzgFlux56ybK8HzjsbwcsTa/dksGRbOtd1qs26tGNe21zWpjpv39ChiCUTBKGsEYhP4V7gZuAQ8DHwsNY6WykVAmwGfCoFoXC4a7JZ6+C5mRs8zn10Uwpz1u3jqcvdU0AEQRAKTiAzhWRgkNZ6p/Wg1jpPKXVZcMQSrJzKyvF57oLmVbiwRdUilEYQhLJMIMlrs4DD9h2lVJxSqguA1tpz6CoUOqeycn2eyy8cVRAEoSAEMlN4D7Aaq096OSYEiemr0rwqhS/u6MrBE55rIgiCIJwLgSgFZY0IspmNJPA9CGw9eIJJi3cycdEOVj3dn/ioMI9yFUkVwnnlmrZ0a1ipmKQUBKEsE0jnvs3mbH7Ptn8XsC14IpVf+r36m2N7fdoxft/smbLx91P9i1IkQRDKGYH4FO4EumMS0Oz1i0YEUygBft6wn/d+3erYv6p9TaaN7F6MEgmCUB7Id6agtT6AyUYWgoh7zt4nC7Y7tmslRfPioNZSzloQhKATSJ5CFKZGUUtMGQoAtNa3BlGucsczM9Z7Pf7+sI4MaFWtiKURBKG8Eoj5aBKm/tFFwG+YwnbHgylUeWPl7qN8+/cej+O1kqJFIQiCUKQEohQaaa2fBE5qrT8FLgVaB1es8sGprBzWpWVw5TsLOXoqm15NKruc79ZAIowEQShaAok+yrZ9HlVKtcLUP6oXNInKETeP/4ulO5wVyZtUjWVY17ocOpHJrDV7ue+CxsUonSAI5ZFAlMKHSqkkzHrK04FY4MmgSlVOsCoEgLa1Ex0lK4Z0lhXmBEEoevwqBVvRu2O2BXZ+BxoUiVTlgKU7Drvs16tUgf4txH8gCELx4tenYFsW8+4ikqXMkpun2XbwBGD8CM/NWM817y8G4ILmVWlfJ5FZ951PRFggLh5BEITgEYj5aK5S6iHgS0zdIwC01od9XyJYeePnf3hz3hZ+e7g3vV7+1eVcn2aVGdqlbvEIJgiC4EYgSsGejzDKckwjpqSA+e0fU67iP7M3epy7sl3NohZHEATBJ4FkNNcvCkHKMjl5Jlt51pp9Lsc/v60LMZFSW1AQhJJDIBnNN3k7rrX+rPDFKT80qxZHp/pJxS2GIAiCC4EMUztZtqOAfsAKQJRCPoydvo5aSdGczMyhfnIMT1/egpjIMFLqJsniOIIglEgCMR/dY91XSiVgSl8IfjhyMouJi3YAEB6quLVHfXo3rVK8QgmCIOTD2cRAngIk1dYPv2zYT/tn5zr2s3O15CAIglAqCMSn8AMm2giMEmkBfBVMoUo7t326zGU/LETRvnZiMUkjCIIQOIH4FF6xbOcAO7XWqUGSp9RzMjPHZf/DGzvStnYiISHiQxAEoeQTiFLYBezVWp8BUEpFK6Xqaa13BFWyUsqXS3e77CfFRFA1PspHa0EQhJJFID6Fr4E8y36u7ZjgxpS/dnkslhMtq6UJglCKCEQphGmts+w7tu2I4IlUehnzzRrHtl0ZRIVLPSNBEEoPgfRYB5VSV9h3lFIDgUPBE6l0sv/YGZd9e6ZyZJjMFARBKD0E4lO4E5islHrbtp8KeM1yLq8cPpnF1OWuvvfk2AgOncgUB7MgCKWKQJLXtgJdlVKxgNJay/rMNjJOZ7NuTwYjJ68g43Q2YSHKUefoo5tS+H7lHmokiJNZEITSQ77mI6XUC0qpRK31Ca31caVUklLquaIQrqTT9t8/ccPHf5Jx2qxY2qeZM2O5dsUK3N23sZSzEAShVBGIT+FirfVR+45tFbZLgidS6SU+Kry4RRAEQTgnAlEKoUqpSPuOUioaiPTTvlyQm6c9jtVIFFORIAilm0AczZ8DvyilJtj2bwE+DZ5IpYObxv/p2P7mru58+Ns2bu/RgL7NqlApptzrTEEQSimBOJr/q5RaDVwAKGA2UO7Xj1y4JR2ALvUr0qFOEu/f2BGA9nVkjQRBEEovgWZW7cNkNV+NWU9hQ9AkKuGczMxh2MfOWcLQruVePwqCUIbwOVNQSjUBrgeGAOnAl5iQ1D5FJFuJQ2vNf2ZvZMEWZ+5e/xZVi1EiQRCEwsWf+Wgj8AdwudZ6C4BS6oEikaqE8vEf2/ls8U5qJkbzyMXNuKRVNcJCpYyFIAhlB3892tUYs9F8pdRHSql+GJ9CwCilBiilNimltiilxng5/7pSaqXt5x+l1FFv9ykJ5OVpnp9lrGYJ0eFc0baGKARBEMocPmcKWutvgW+VUjHAlcADQFWl1HvAt1rrn/zdWCkVCrwDXIgpjbFUKTVda+0oI6q1fsDS/h6g/bm8TDD5e/eR4hZBEAQh6OQ71NVan9RaT9ZaXwbUAlYCHqN+L3QGtmitt9kqq04BBvppPwT4IoD7Fjlz1+/n6vcWO/bjogKJ5BUEQSh9FMj+obU+rLX+QGvdN4DmNQHrijOptmMeKKXqAvWBeT7Oj1BKLVNKLTt48GBBRC4U7vjMubxmx7pJvH5duyKXQRAEoSgIplHcm//BMw3YcD0wVWud6+2k1vpDrXWK1jqlcuXKhSZgIJzKcl1e87+D21AjMbpIZRAEQSgqgqkUUoHalv1aQJqPttdTAk1HJzNzaPHUHMf+3Ad60rBybDFKJAiCEFyCqRSWAo2VUvWVUhGYjn+6eyOlVFMgCVjsfq64OXQi02W/cdW4YpJEEAShaAiaUtBa5wB3A3MwGdBfaa3XKaWesa7khnEwT9Fa+zItFRsjP1/h2H7jevEjCIJQ9glqGI3WehYwy+3YU277Y4Mpw9lyJjuX9XuPOfZrJYkfQRCEso9kX/lgX4brmss1EysUkySCIAhFhwTce+HQiUz6j/sdgFevacuprByqybKagiCUA0QpuJGTm8f9U1aSlZMHQJcGFamVJLMEQRDKB2I+cmPsD+tcqqDWSBBfgiAI5QdRCm5MW77Hsf3ioNaEhBSoBqAgCEKpRpSChaycPE5nO5Oqh3SuU4zSCIIgFD2iFCxYk9VqSikLQRDKIaIULDw/06yX0KxaHFNGdC1maQRBEIoeUQo2snLymLlmLwDPDGxF7YoScSQIQvlDlIINe/ZyzyaVSambVMzSCIIgFA+iFIDjZ7K58p2FADx1WXOJOBIEodwiSgGYuXqvY1vKWQiCUJ4p90ph/qYDvPLTJgCGdqlDdERoMUskCIJQfJTrMhfZuXncMmEpABOGd6JPsyrFLJEgCELxUq5nCou3pju2RSEIgiCUc6Vw0/i/ABg/PKWYJREEQSgZlFulcPxMtmO7e8PkYpREEASh5FBulcK8jQcA+N/tXYgKF+eyIAgClGOl8OXS3cRFhtG1QaXiFkUQBKHEUH6ij3YshC1z4dBm0ro8wSKbk1kS1QRBEJyUH6WQ9jcseB2AGhtnUIHx3NqnVTELJQiCULIoN+ajzM4juaPeTyzNawLAU+1P8dBFTYtZKkEQhJJFuVEK2w+dZO7GQ9yddS8A1x56G1b+r5ilEgRBKFmUG6VwOsusqPbSzf0BCDm4Eb4bCcf3OxttnAm/vlQc4gmCIJQIyo9SsC2zGRURBlUtvoRXmzi3p9wAv75YxJIJgiCUHMqNUjhjUwoVIkIhNML15C/PwNb5zv0/XoNjeyEvF768EXYvLUJJBUEQio9yE310OisPwFRB1bmuJ/94FUIsX8Uv/4YD66Hvk7BhOuxZAaPXFaG0giAIxUO5mSnYzUfR4aGgjYKgSgtng+zTrhdoDblZZjss0vVc6nIYmwB7VwdJWkEQhOKh3CmFqPBQyLMphaveh7jqZnvRm64XZJ+GnEyz7a4UNkw3n1vmBklaQRCE4qHcKIUztuij6IhQaHKRORhbFZpd6v2CTTMh06zbzIH1cHyf85x9pqHKzdcnCEI5odz0ap3qV+SRAc2M+ajvE/DAeoir5ul0tvLTE87tOY87t+2zChViHNJvpcDhbZ7XH9sLpw4XzgsIgiAUAeVGKbSrncjI3g0JDVEQEgoJNc0Jf6P9Pcud2zoP3jsP1k6zNFCw6n+QvhmWfmIO5dpKcufmwGvN4DWL30IQBKGEU26Ugk+yTgbWbt03sH8tTL3Neez4PhPOChAaDvvWwrPJ8M9P8PXN5niOzYG9cRa82R5yssx1x9IK7x0EQRAKCVEKudn5t/HFknec26ERsHaq2d79J2yc4dr2h/uMiemDnvBqU3ituTFPae0Z+ZSTBX99FLjCKipyMiXiShDKOKIU7GGnAaO9H8487qjCSnSi67kTB50RTAc3OI8veguWfQLPV4OMPc7j85+HWQ/BBjfFUtzMHA0fnC+zHEEow4hSKLBS8MGyCc7tM8cgvqZzf8b9ztBXd1Z/ZT4zdjuPpW8xnyElbEW4nYvNZ0mbwQiCUGiIUrAqhfPugwufObv75FhMQBm7TYeeVM/sH9kBMZV9PN9uvlKw8A1nbgSY7ezTkHXq7GQKlKxTniYsb9gzwSUUVxDKLOWmzIVP7J3wBWOhxwNme95zBZtBhEW7KoVVX5jPdkOhdlfYsQCiErxfa1cKyyeY6+w5EAC5mfBGOzh1CJ5KD1wed06mw+ovoetIUF5WmnuhOkQnwSM7/N8nz6YUtA8TmiAIpR4Z8vV+FOJqQMdbPM8lWyqojvjN9z0SapnPsCioYFnzOSwSKtaHY6mwc6H3a/evMZ8H1pvP00ednW5OJpzYB3k5rj6HY2mw60/vPoe8PBP9pLUpC641fHM7zHnURE/54vQR3+cc986xfZ6Dc14QhBJNUJWCUmqAUmqTUmqLUmqMjzbXKqXWK6XWKaWKftWb2p3gwQ2uzmF7p3z9F85jNdrB2Azo+S/Pe9idyDln4JRlRB8a6TQh5cfeVebT3vHa72fn9Raw6UfY/LOJXBrfH74cCrMfM3WY7Cz7BP53Dfz2X1MWfPHbcOKA63udLY4cjEJSCq+3hh8fyb/d8f0w4RJIW1k4zxUEwSdBUwpKqVDgHeBioAUwRCnVwq1NY+BR4DytdUvg/mDJc1aEerGuRca57qsQV5OPlczj0LBfwZ55Kt2U2ABX/wLAF9fD5Ktdj9nDYj8fDO/1gMPbzb49yW7zXKcpLDTcfJ5MN4pk3beu9zp9BOa/4DQTuVPYM4WMXfDn+/m3W/qRmWl92Av2ry+cZ4NRbhtnijlMECwEc6bQGdiitd6mtc4CpgAD3drcAbyjtT4CoLU+EER5Ck6IF6UQFe+6Hxphoo28cXgrxPpwMPvC3qmDp1Lwx5a5xhRldwYf2mQ+lXIqBXtnf2SH+fx6uDFX2Zk0CH77D/wzx/sz7NfnV7ojL8972Q872afNyD9QrI5ta5TWufL7y2ZhpffOK7x7CkIpJ5hKoSZg/Q9OtR2z0gRoopRaqJRaopQa4O1GSqkRSqllSqllBw8eDJK4XggJ9zzWYiDU6uzaJvO42W59jWtbq38BIKF2AA+1jFp9dc7+cB/lb/vVqQTcZwwAP1lqOqWtMJ9ThpiZxPY/3O5tmylMHuz53DPHzKgbzOzlzfa+R/V7V/v2sXjDqhS8Keqz5ajtz/OArJUhCHaCqRS8hLl4ZH6FAY2B3sAQ4GOlVKLHRVp/qLVO0VqnVK5cwJH3uRDqRSlEJ8Htc13bZGaY7c4jnMcHfQRXvGW27eGot//s6rz2hl3BwNl1Vu4LCFmxd+rWyKqTfqKa7KaV/evNLCLHT9jq9LvNqHv9dJPRDa6JelYiYlz3f33JKKHcHO/trX9K/goY5ofWcGCj5bYSZyEI7gTzvyIVsA6NawHuqbCpwPda62yt9XZgE0ZJlAz8JY9dNg6Sm8IQizPaOjNoeglUqGi2711pwj3jqkH3e/0/8+iusxYX8J/TkH3adIxWB3a2n/bhUcZx/V432PqL/+fazV5f3QgbfjDbU2/17pTOdTOL/f6y9+N2rJ13IB352ASY/ajn8b8nwbtdzOwJvP9+83KN8/7Y3vyfIwhlkGAqhaVAY6VUfaVUBHA9MN2tzXdAHwClVDLGnOTHGF1U2CY03sxHdlJugbv/gjpdncesCWrhFZzbkbFmhgHQfhhUSPZ936wT5vOaib7bNLnY9zl/oaWfXQFThgauFMKi4eAm3+ftTLgE9vmoifT350ZRvd7adMZpK01tJyveZjBWrHPOPEsE1IpJnv4N+2xjybvmc/Ncp8LaZgsrtq+N4U0p7P7TmL++G+ldFkEoTNZMhbXfFLcULgRNKWitc4C7gTnABuArrfU6pdQzSqkrbM3mAOlKqfXAfOBhrfU5ZGkVMiFhcO/fcM+KwNpbI5NCfHy1SkFsFddjtbt6tqvS0vdzkupC88u9nzudjxN400zXTtnfzCI8yuRe+OLobpM/4c8/MON+43DP2AWfDTQRRGu+8t42J8t06jMfgoxU53Hr7MDe6f/9uTFZrfjM7R5uJq7Jg+HtFLN9zJbrYVfQyotSCI82n6cOOY9ln3Ft88erJtrLFzmZztX9zpXsM/DD/XDSJk/qMhNuLJQNpt0GU73kSBUjQTWqaq1naa2baK0baq2ftx17Sms93battdajtdYttNattdZTgilPwNwy2/gHQsOhYgOo1NB/+/q9zKdScNP30GO0//bWENZej8DwmXD3Mtc2ERXwSUItuHaS94S7kwE44l1mCn7qGIVGuOZNWNEa3u9h8ifyY+t81/0dC7y3y800CmbpRzD9Hudxq1LIOWMqyNqd59aZzqop8GItz/vm5cCeFbDLVrvpxAF4vgZsm+/Z1q4o7BFlh7bA81Vh9dfONr88Y6K9sk56hrNqDc9VgdkB5F+A6eR3+FGqa7422e7znjX7H/czBRMLg7c7w+J3C+de3ji4CZ6p5BpRVxZZ+41/s29OFky/t9QUkhRPmzdqd4JLXvZeEsIbw6bBY7ZfeIPecMHTgV132evQa4zJh0huDC2vcp6LrujcTm7qel1cdSNbows872nvLP1hHZlYQ1I97rUT9vtwdmefhjN+rrUy90nXfV//HOu+hVkPm+0TB+DbO03Ha1UKXw41FWQXjjP7YVGw7jvYtQS+/T/fMlhLmW//3ShDe+FBgPStpgP74HyzfybDmJ7e7mj2v7ndtLHyQg1TGXf/OqfZzh4osGy8812/u8tztmHPXP+4H0z0E55rV+DuvhRfuSQF4dAmk+lu59hez3e0k3mi4M/8e5JRyO5l5AuLL4eZkvTFSfYZ8/80aZDZP3HADCSsbJkLKz41Safe/hZKGKIUCoPQcM+IGn9c97mZiXQY7mpm6m4bHV/5nutMwb1DiK9hPq2mnf7PFUhkB/469j/fg+0+ynsEOhL2ht1v4s7cp5z5FfvXmlpQy8bjPZDNhs4zCxqNv8jz3Fc3O7etvgdvfpQDG1xnRZnHTCKflWXjXavhAvzyb3ivO0ywrfVtD/GNiDHP/OlJWDkZNs1yXrN3FfynLqz/zvd72bHL5B515atS7fF9MO0O04n7w1vC3mvN4K0OXmTIgxdrwowH/N9z0dvwiiW6Ls/PWuYH//FMniwoG36A5RPP7R5gvsuC5ATZOXMMJtp+7/ZBwWvNnQMJB5a/35WTYbEtKrGE+RLsiFIoDpIbm5mIu9+hZkdTSqPdDa7HrTOWziOceRL2kNm6PaDloODJ6w13W36w+OkJz5mGFX/mMmuneybDue1NKbg7uXWeZ07E4reNj8QbB9bB96Oc38uZDPhvfefCS9b7b/rRfH493Lfs7nIdS4NptzuPT7rKe/tfXzQ+m5luJszcHFgwzlkNN79Rf/YZpwnN/h2vdKtCc2SnifRKtZk+f3ocTux3KhxHVV0vvpt3Opn3P2G7995VhdtJZp009w8kiuyFGvCRpfLAr/+Bca2d++u+9czZAXizHeyxvXuMLXjEm7nVXSnOsw3gSpgvwY4ohdLGJS87y2/Y/+lCQsya05eN82xfq5PnMV8VWwOhYj7+laLG6pD2xzpLh7N1nuf5HC9T+oImyv39ue9zR3Y6O0tfMyWAJe+b9b5nPwpvdnAqhQ3TjX/Bzh6LD+rwdjMr2jjL2Smt/tLVFLTyc/j5afjjNbPvHv67ZqpzW2tj0nrJFlFuzyKvUNH1mn9m2+7tpizs36Vd8fgL7X6lkemQP+jpv5PU2qlA3PHm1F87zXTmk640372vmZP9d2IvTAnw6wvGR2A/9/Vw+PQy5/mXG5vcGmudM/dE1UObTZ7PqcPeZ0rH93uXZ+di40+zzuTycmFLPiHhhYgohZLMcJvJwdeoTrtNz1NugQH/cW0z5Euo3Nz12M0/nL1Mrf1E3RQHh/4pnPt4C0E9l0WO4t2S9399AWY+aLb9JQzOfsSM8pe8a6K23MN3rdgd9m+2M7OiKUNcFZN1RmQ3n9k7bOvMZeNMEwVj5+Qh2LPcbJ8+6iyo6F73y+E/+cSsImhn/ffmM9D1N6wKbvNcM/twD05Y8LpRIHaHrvV/wqrgtHb1WR3cCG+0MeavXX8aRbl1nlOR+JtpvtHWdd/eUZ88YGZkVtwV5tspJpnzv/W93/vDXt6Pf32zmW2+d57zd/Z2J/h8UJEpBlEKJRl76KqvCCB7x1O3h/NY1ztd28RUglFL4HHLyCTKI2k8cDoOd263utpnsyLDXSn4mwVZZQ8Ea3Z5QfGWtLfsEzNq9dYRZZ2EeV6iin73E3762UDjC/FFaITpyI7udiqBVVOMr8SqbKa4mStfaeTc/k9dZ/mSY3tNh/XfhibyzB4RBcbMZ+fb/zNK4qDtdzNztNNkkr4V9vkp4W4vofL3JNfjdp+M3RxkjcDKSDUrGI5NMHK81tx7gMT4/sZnMukq885HdzsVHpjr7UvqAhzdCXMsZWD+/tx3hWAVCptmez93wsus4LibWcseoRVj+58/sM741HKyzODA132CgNKlrEJkSkqKXrZsWf4NywLpW80fcVI9E1VUowOMcBtBHdpsTDpW/4S1lPbYDM/jY3bBS3X8P/uiF03I5uafjAkqdanzfnMeN/b1vk+6dgwA/Z4yIZsRcXDRc0UfHVIzxdh3//HyDzp0mmeV2eKgRntI+zv4zxm5yERazR5jcmF2L3Ge63Q7LP04+DKcC7U6m5Iyy8bn7+R2p9llwYl6ajXY6SeyEpngLHdztozNgI8vcP6vXfKKqSJsj5JrMgBu+PKsb6+UWq61TsmvncwUSjKJdaBON7jibRi9EYZ7+SNPbuw7Uc4XEXFwvs2UMTbD+8yh210w9Gu4brIJubViH0iERniaSXqMNol1g4Ck5ToAAA8wSURBVMefXURHYWBPQHOn3jlUQ212Wf5tAuVkumvGe7D4oCfMtYVHWxUClHyFAJD6l4nqKahCgOCFwXpTCHDuCgFg/MVOhQDGDGcNm/5ntjGBBRlRCiWZ0HC4dTbUPx/iqxcs7NUb3e42nyEhZkTvmEX4mS02v8yYZG6ZDVd9aGtu92UouGOeSb6zo5QJuW3SHyo3M8cGvmuOPXCO1Uif9hE+W6eb6/Pt5UmstuwnD/lWFoHQ8yHPY0k+7MX5kbELUm4NsGruOZCX47ueVGnB7p8oD+xa5Lq/w0vEkzXTPkiIUijL3PC16/5Fz7uak+zYR/5d7vQ8Z6duN2h7nf0C26cyRf7q9fB+TYNecP9aaD/UzB4SLNnGd/0JXe9y7tsVjj98JRO6LGSknErLPgPqNcYZvmuf2Zz/IFz+BjS/goCw+irs4b/d7w7sWoB2w1z3Y5I97cq+CIbycI+WCYTiiDxzNz/GVS+a5yY3MTP1iLj82xaUbgX4u3Gn2aWFJ4cPRCmUZZr0D6xdjXbms99Tps7TqL/8t7dHoVhnLvesMB29O4k+OrQqzVwrxjoUToBYlzmtaUm4uvwN5+jY7qi3lhO/e6mpWNvvKeN49haKCtDDzWRhr5cE0GqQUa6dboehUwOL5nIvWxIZ772dFftMpPnl0KBP/u3t1HRPnvJCDS9JavlRu0vBrylsVCiEF2DG3Psx6HCT/zbd7oa2bs72qz+B+9fAo7th4DsFl9MbduV+0fMw6GMzgy6BiFIQjGnn1p9MJ1+pIVRu6r99j9HGydzeMvqt1NB09Plx/1oYaatB5L6KnTsDXoILn/V+7r5Vlmc3MuatMbugagunL6NBb/NpXRQpIsa1g/elFOxtKjaE2+aa/a6jPO/X+EJTTdYfA9/xzEiOiDHf+UUv+M5Gr9jAfNbuAtdP9v8Mb7L7olZnqN7Wfxtv+Furo6D0tpXX8KccG/c3I/auo5yjaxViFHsgdLoDej8CdS2+pFt+9GwXGQ9XvgsPbXZWCbAPeJSCNgUcsPji7qXmbxSgzTUmSbXe+a5tej7s3G7cHx78xygn8F44MwiIUiiLdBxesH/6qASoU4BRYEQFY2P3tghRfiTWNh03GGdreIyJsvBGp9vhvHuhsVsJi0S3yKmYZGPespt47DHsjfvDw9v8z5h8OcPt9wqPhto2JdD/WfjXdoir6trW+j1Ua+Ma/nvtZ9BuqGciXHg01OoI3UY5y5v4ki0qwb8/6YH1ZmTbbij0e9q1Y/HG0K/yb2PHqvDsyVqXvgYN+3pvP2SKiZJx5ya3qvmtbKGnUYlGMXqjfi/TkQ54wfhgwHTScdXMQMA+23EvJX/5m3DfarjU9ncVFuk8V9NL8E14tGf1YmsgQGg43D7PDFKsXPqqc/uKtzwrCifWcWZzR8Sa51jNkErBhf92vabvE3DnQjPrvv4L87eWWMc8f6iP6sKFTCGubSiUGC5/o7glCAyl4HEvxfHCY4zisXe21092dpCP7fVMKnOP5Ln0VbNwT73zISyfldrso+o+j7vGvtvt59aCgSGhnklK4KoUQsJMyfERv5lM3+ZXmPd0V6D5RR81tdiO7SUUfJFQ0yQV2hMLrTH61//PhDbbS4X0fNj5zqGRxtQWFm1Kjvd+zERoTbQ82/pd28t3V21l3mvD986EvDG7jP09JMTc/5/ZkFDHONXB+Jfs/Gu7+R4HfWxMl8mNTWf5/SjjH7Iv6GRNsLP7vVSIkeme5SY/4fWW0OthuOp9k1MB0NFS8wqcg4ikeubv4anDsOQ9o2hn3O+9sKS7ua9WR1NzbPYYuODfJju82eXm/WMqGxNVh5tcw8FjqhgFNelK37/vmh3N7KV6O+dMrForz3a1AjAJFhKiFISSQ4M+JjfirkWuCxaFhjs7VW8lxd0d0BXrG3NAIAx8Fzb+YGZXjfubjq9OV2c2cCCVYK2mIbucNdo5fTXguWCTu5JofoXx1ay0mYkufskoxw0Xmk4YTCejQuCEbZGgy1737gi1PyuhjnFM7rb5iKq1NiNROw+sNfWN3rHNhDrd7l3p2bHXTYqtArGVTXu7UrCOgO1mr063mc7THfsz2ljWNG97g7mubndnx2qfHYBJwgTXumAJtVwDJ/o/792HVbOjMQHaZxYhoSZIQGtTmTjaEpLd8RZTCNJbJx5f3fm8HrYaWKP+cl00q+UgZ0kVFeI0kfrLjq/b3fe5YkCUglByuH6yqcFvdSIHm5hKzkxnayceXgES67p2or6wmobaXOu9Taj7v5qbIrvOlsG75WeTuRoSZmRLsdQDsof0PmdTmNZO0+XWNquwvSOq3Axiq3maaWKrmB/7CDUy1ijYodOgQhJ81Nc8317C4poJJqs3sa7zHheMhQ0zPO/7WJqZgViVwpApxuzjjZAQz87R2llHJ5lZor+wYn/RYLU7ex5TyvUZYL6jfk8Fbhp1978NeBEOrDflNZQySW3gvShgCUWUglByiIhxjSQqTkJC4H4fS4y6Y58phEVBym3e27j7FHyF117yCsx5zHWmZCc/U5gde1kU+zOj4uEhP8uqXvmeWU3ObntvbDOnPHHAvFuD3mbWUbmJ6fSs9HjAM1ILvPtAmvpZRjYQ/C08VViEhJzbc+Kqwe0/w5vtzYDCrsQqNSgc+YoAUQqCcK7YR5Vhkb47e3fzka94+xZXmJ9zwW7Kqd8zsPbtbvAs1w5OJeHN5l4geQpYa6vpJaYUSGklMg4etmQiX/2Jb8d8CUSUgiCcK45ZgJ/FgOyKI+VWsyZGcuOzf949K/wv7Rhf3di6K5aA0enQqVClef7trAz5IjiyFBclrbJwPohSEEovSfXPrXRFYRMR6/tciytNxEvXUZDsw64eKJUa5r9ueH65JkVF4wuLWwKhgIhSEEov960sbgkMFSqa/IAWA323ia0M964oOpkE4SwRpSAIhcH5o/NvIwilAMloFgRBEByIUhAEQRAciFIQBEEQHIhSEARBEByIUhAEQRAciFIQBEEQHIhSEARBEByIUhAEQRAcKG1fvKKUoJQ6COw8y8uTgUOFKE5pQN65fCDvXD44l3euq7X2Un7XlVKnFM4FpdQyrbWX9fjKLvLO5QN55/JBUbyzmI8EQRAEB6IUBEEQBAflTSl8WNwCFAPyzuUDeefyQdDfuVz5FARBEAT/lLeZgiAIguAHUQqCIAiCg3KjFJRSA5RSm/6/vXsLsaqO4jj+/TWjoymmYySm1ihKZZGXxNR6CCsri3pIsEFIbCCSQIuolB4k6EWINEnELhaVaGRmMg+aTBJEoSWZjbccU3RKU8kLRoja6mGvObObZnLOcJzT2bM+sDl7r/3n8F97neF/9mX+R1KDpHnF7k+hSBoiabOk3ZJ2Sprr8UpJmyTt89d+HpekJX4cdkgaW9wMOkZSmaTvJdX69lBJWzzfjyR193iFbzf4/qpi9rujJPWVtEbSHq/1xC5Q42f9M10vaZWkHlmss6QVko5Jqk/F8q6tpJnefp+kmR3tT5cYFCSVAUuBB4CRQLWkkcXtVcFcAJ4zs5uACcDTnts8oM7MRgB1vg3JMRjhy5PAss7vckHMBXanthcCizzfk0CNx2uAk2Y2HFjk7UrR68AGM7sRGEWSe2ZrLGkQMAcYZ2a3AGXAY2Szzu8B97eI5VVbSZXAAuB2YDywoGkgyZuZZX4BJgIbU9vzgfnF7tdlyvUz4F5gLzDQYwOBvb6+HKhOtc+1K5UFGOx/KJOBWkAk/+VZ3rLewEZgoq+XezsVO4c88+0DHGjZ74zXeBBwGKj0utUC92W1zkAVUN/R2gLVwPJU/B/t8lm6xJkCzR+wJo0eyxQ/ZR4DbAEGmNkRAH+9xptl4VgsBl4A/vLt/sApM7vg2+mccvn6/tPevpQMA44D7/ols7cl9SLDNTazX4BXgUPAEZK6bSPbdU7Lt7YFq3lXGRTUSixTz+JK6g18AjxjZmf+q2krsZI5FpIeAo6Z2bZ0uJWm1o59paIcGAssM7MxwB80X05oTcnn7Jc+HgGGAtcCvUgunbSUpTq3R1t5Fiz/rjIoNAJDUtuDgV+L1JeCk9SNZEBYaWZrPfybpIG+fyBwzOOlfizuAB6WdBBYTXIJaTHQV1K5t0nnlMvX918F/N6ZHS6ARqDRzLb49hqSQSKrNQa4BzhgZsfN7DywFphEtuuclm9tC1bzrjIofAuM8CcXupPcsFpf5D4VhCQB7wC7zey11K71QNMTCDNJ7jU0xR/3pxgmAKebTlNLgZnNN7PBZlZFUscvzGwGsBmY5s1a5tt0HKZ5+5L6BmlmR4HDkm7w0N3ALjJaY3cImCDpSv+MN+Wc2Tq3kG9tNwJTJPXzs6wpHstfsW+wdOKNnKnAT8B+4KVi96eAed1Jcpq4A9juy1SS66l1wD5/rfT2InkSaz/wI8nTHUXPo4O53wXU+vowYCvQAHwMVHi8h283+P5hxe53B3MdDXzndV4H9Mt6jYGXgT1APfABUJHFOgOrSO6bnCf5xl/TkdoCT3j+DcCsjvYnprkIIYSQ01UuH4UQQmiHGBRCCCHkxKAQQgghJwaFEEIIOTEohBBCyIlBIQQn6aKk7amlYLPpSqpKz4IZwv9V+aWbhNBl/Glmo4vdiRCKKc4UQrgESQclLZS01ZfhHr9eUp3Pa18n6TqPD5D0qaQffJnkb1Um6S3/jYDPJfX09nMk7fL3WV2kNEMAYlAIIa1ni8tH01P7zpjZeOANkrmW8PX3zexWYCWwxONLgC/NbBTJHEU7PT4CWGpmNwOngEc9Pg8Y4+/z1OVKLoT2iP9oDsFJOmtmvVuJHwQmm9nPPvngUTPrL+kEyZz35z1+xMyulnQcGGxm51LvUQVssuRHU5D0ItDNzF6RtAE4SzJ9xTozO3uZUw2hTXGmEEL7WBvrbbVpzbnU+kWa7+k9SDKfzW3AttQsoCF0uhgUQmif6anXb3z9a5KZWgFmAF/5eh0wG3K/Jd2nrTeVdAUwxMw2k/xwUF/gX2crIXSW+EYSQrOekrantjeYWdNjqRWStpB8kar22BxghaTnSX4ZbZbH5wJvSqohOSOYTTILZmvKgA8lXUUyA+YiMztVsIxCyFPcUwjhEvyewjgzO1HsvoRwucXloxBCCDlxphBCCCEnzhRCCCHkxKAQQgghJwaFEEIIOTEohBBCyIlBIYQQQs7f5TkkKJQinDcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy vs. Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Training', 'Validation'], loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 5600 samples, validate on 2400 samples\n",
      "Epoch 1/100\n",
      "5600/5600 [==============================] - 0s 70us/sample - loss: 3.8890 - accuracy: 0.6266 - val_loss: 2.9066 - val_accuracy: 0.6454\n",
      "Epoch 2/100\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 2.2940 - accuracy: 0.6416 - val_loss: 1.7667 - val_accuracy: 0.6454\n",
      "Epoch 3/100\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 1.4486 - accuracy: 0.6416 - val_loss: 1.1760 - val_accuracy: 0.6454\n",
      "Epoch 4/100\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 1.0190 - accuracy: 0.6416 - val_loss: 0.8836 - val_accuracy: 0.6454\n",
      "Epoch 5/100\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.8125 - accuracy: 0.6416 - val_loss: 0.7500 - val_accuracy: 0.6454\n",
      "Epoch 6/100\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.7165 - accuracy: 0.6416 - val_loss: 0.6907 - val_accuracy: 0.6454\n",
      "Epoch 7/100\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.6768 - accuracy: 0.6416 - val_loss: 0.6607 - val_accuracy: 0.6454\n",
      "Epoch 8/100\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.6590 - accuracy: 0.6416 - val_loss: 0.6510 - val_accuracy: 0.6454\n",
      "Epoch 9/100\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.6526 - accuracy: 0.6416 - val_loss: 0.6462 - val_accuracy: 0.6454\n",
      "Epoch 10/100\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.6508 - accuracy: 0.6416 - val_loss: 0.6449 - val_accuracy: 0.6454\n",
      "Epoch 11/100\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.6516 - accuracy: 0.6416 - val_loss: 0.6449 - val_accuracy: 0.6454\n",
      "Epoch 12/100\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.6487 - accuracy: 0.6416 - val_loss: 0.6460 - val_accuracy: 0.6454\n",
      "Epoch 13/100\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.6511 - accuracy: 0.6416 - val_loss: 0.6458 - val_accuracy: 0.6454\n",
      "Epoch 14/100\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.6484 - accuracy: 0.6416 - val_loss: 0.6448 - val_accuracy: 0.6454\n",
      "Epoch 15/100\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.6486 - accuracy: 0.6416 - val_loss: 0.6438 - val_accuracy: 0.6454\n",
      "Epoch 16/100\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.6485 - accuracy: 0.6416 - val_loss: 0.6437 - val_accuracy: 0.6454\n",
      "Epoch 17/100\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.6483 - accuracy: 0.6416 - val_loss: 0.6447 - val_accuracy: 0.6454\n",
      "Epoch 18/100\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.6483 - accuracy: 0.6416 - val_loss: 0.6424 - val_accuracy: 0.6454\n",
      "Epoch 19/100\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.6481 - accuracy: 0.6416 - val_loss: 0.6483 - val_accuracy: 0.6454\n",
      "Epoch 20/100\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.6477 - accuracy: 0.6416 - val_loss: 0.6467 - val_accuracy: 0.6454\n",
      "Epoch 21/100\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.6481 - accuracy: 0.6416 - val_loss: 0.6418 - val_accuracy: 0.6454\n",
      "Epoch 22/100\n",
      "5600/5600 [==============================] - 0s 38us/sample - loss: 0.6492 - accuracy: 0.6416 - val_loss: 0.6421 - val_accuracy: 0.6454\n",
      "Epoch 23/100\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.6517 - accuracy: 0.6416 - val_loss: 0.6485 - val_accuracy: 0.6454\n",
      "Epoch 24/100\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.6480 - accuracy: 0.6416 - val_loss: 0.6425 - val_accuracy: 0.6454\n",
      "Epoch 25/100\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.6473 - accuracy: 0.6416 - val_loss: 0.6428 - val_accuracy: 0.6454\n",
      "Epoch 26/100\n",
      "5600/5600 [==============================] - 0s 42us/sample - loss: 0.6485 - accuracy: 0.6416 - val_loss: 0.6432 - val_accuracy: 0.6454\n",
      "Epoch 27/100\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.6476 - accuracy: 0.6416 - val_loss: 0.6430 - val_accuracy: 0.6454\n",
      "Epoch 28/100\n",
      "5600/5600 [==============================] - 0s 45us/sample - loss: 0.6472 - accuracy: 0.6416 - val_loss: 0.6428 - val_accuracy: 0.6454\n",
      "Epoch 29/100\n",
      "5600/5600 [==============================] - 0s 37us/sample - loss: 0.6475 - accuracy: 0.6416 - val_loss: 0.6433 - val_accuracy: 0.6454\n",
      "Epoch 30/100\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.6475 - accuracy: 0.6416 - val_loss: 0.6421 - val_accuracy: 0.6454\n",
      "Epoch 31/100\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.6458 - accuracy: 0.6416 - val_loss: 0.6441 - val_accuracy: 0.6454\n",
      "Epoch 32/100\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.6475 - accuracy: 0.6416 - val_loss: 0.6430 - val_accuracy: 0.6454\n",
      "Epoch 33/100\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.6480 - accuracy: 0.6416 - val_loss: 0.6411 - val_accuracy: 0.6454\n",
      "Epoch 34/100\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.6479 - accuracy: 0.6416 - val_loss: 0.6413 - val_accuracy: 0.6454\n",
      "Epoch 35/100\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.6487 - accuracy: 0.6416 - val_loss: 0.6419 - val_accuracy: 0.6454\n",
      "Epoch 36/100\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.6457 - accuracy: 0.6416 - val_loss: 0.6414 - val_accuracy: 0.6454\n",
      "Epoch 37/100\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.6468 - accuracy: 0.6416 - val_loss: 0.6449 - val_accuracy: 0.6454\n",
      "Epoch 38/100\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.6455 - accuracy: 0.6416 - val_loss: 0.6419 - val_accuracy: 0.6454\n",
      "Epoch 39/100\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.6459 - accuracy: 0.6416 - val_loss: 0.6407 - val_accuracy: 0.6454\n",
      "Epoch 40/100\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.6459 - accuracy: 0.6416 - val_loss: 0.6435 - val_accuracy: 0.6454\n",
      "Epoch 41/100\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.6462 - accuracy: 0.6416 - val_loss: 0.6407 - val_accuracy: 0.6454\n",
      "Epoch 42/100\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.6469 - accuracy: 0.6416 - val_loss: 0.6406 - val_accuracy: 0.6454\n",
      "Epoch 43/100\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.6479 - accuracy: 0.6416 - val_loss: 0.6410 - val_accuracy: 0.6454\n",
      "Epoch 44/100\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.6458 - accuracy: 0.6416 - val_loss: 0.6405 - val_accuracy: 0.6454\n",
      "Epoch 45/100\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.6467 - accuracy: 0.6416 - val_loss: 0.6429 - val_accuracy: 0.6454\n",
      "Epoch 46/100\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.6468 - accuracy: 0.6416 - val_loss: 0.6401 - val_accuracy: 0.6454\n",
      "Epoch 47/100\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.6458 - accuracy: 0.6416 - val_loss: 0.6400 - val_accuracy: 0.6454\n",
      "Epoch 48/100\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.6460 - accuracy: 0.6416 - val_loss: 0.6416 - val_accuracy: 0.6454\n",
      "Epoch 49/100\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.6451 - accuracy: 0.6416 - val_loss: 0.6410 - val_accuracy: 0.6454\n",
      "Epoch 50/100\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.6443 - accuracy: 0.6416 - val_loss: 0.6409 - val_accuracy: 0.6454\n",
      "Epoch 51/100\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.6453 - accuracy: 0.6416 - val_loss: 0.6416 - val_accuracy: 0.6454\n",
      "Epoch 52/100\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.6465 - accuracy: 0.6416 - val_loss: 0.6411 - val_accuracy: 0.6454\n",
      "Epoch 53/100\n",
      "5600/5600 [==============================] - 0s 36us/sample - loss: 0.6448 - accuracy: 0.6416 - val_loss: 0.6402 - val_accuracy: 0.6454\n",
      "Epoch 54/100\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.6449 - accuracy: 0.6416 - val_loss: 0.6399 - val_accuracy: 0.6454\n",
      "Epoch 55/100\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.6450 - accuracy: 0.6416 - val_loss: 0.6399 - val_accuracy: 0.6454\n",
      "Epoch 56/100\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.6466 - accuracy: 0.6423 - val_loss: 0.6399 - val_accuracy: 0.6454\n",
      "Epoch 57/100\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.6450 - accuracy: 0.6416 - val_loss: 0.6414 - val_accuracy: 0.6454\n",
      "Epoch 58/100\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.6455 - accuracy: 0.6416 - val_loss: 0.6401 - val_accuracy: 0.6454\n",
      "Epoch 59/100\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.6448 - accuracy: 0.6416 - val_loss: 0.6397 - val_accuracy: 0.6454\n",
      "Epoch 60/100\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.6453 - accuracy: 0.6420 - val_loss: 0.6418 - val_accuracy: 0.6450\n",
      "Epoch 61/100\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.6453 - accuracy: 0.6416 - val_loss: 0.6400 - val_accuracy: 0.6454\n",
      "Epoch 62/100\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.6452 - accuracy: 0.6416 - val_loss: 0.6398 - val_accuracy: 0.6454\n",
      "Epoch 63/100\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.6443 - accuracy: 0.6429 - val_loss: 0.6398 - val_accuracy: 0.6454\n",
      "Epoch 64/100\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.6463 - accuracy: 0.6416 - val_loss: 0.6407 - val_accuracy: 0.6454\n",
      "Epoch 65/100\n",
      "5600/5600 [==============================] - 0s 35us/sample - loss: 0.6455 - accuracy: 0.6420 - val_loss: 0.6397 - val_accuracy: 0.6454\n",
      "Epoch 66/100\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.6444 - accuracy: 0.6443 - val_loss: 0.6413 - val_accuracy: 0.6433\n",
      "Epoch 67/100\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.6450 - accuracy: 0.6425 - val_loss: 0.6393 - val_accuracy: 0.6454\n",
      "Epoch 68/100\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.6439 - accuracy: 0.6423 - val_loss: 0.6397 - val_accuracy: 0.6454\n",
      "Epoch 69/100\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.6440 - accuracy: 0.6420 - val_loss: 0.6396 - val_accuracy: 0.6454\n",
      "Epoch 70/100\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.6441 - accuracy: 0.6416 - val_loss: 0.6403 - val_accuracy: 0.6446\n",
      "Epoch 71/100\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.6443 - accuracy: 0.6413 - val_loss: 0.6393 - val_accuracy: 0.6454\n",
      "Epoch 72/100\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.6437 - accuracy: 0.6416 - val_loss: 0.6387 - val_accuracy: 0.6454\n",
      "Epoch 73/100\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.6474 - accuracy: 0.6413 - val_loss: 0.6414 - val_accuracy: 0.6454\n",
      "Epoch 74/100\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.6451 - accuracy: 0.6425 - val_loss: 0.6400 - val_accuracy: 0.6454\n",
      "Epoch 75/100\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.6439 - accuracy: 0.6421 - val_loss: 0.6392 - val_accuracy: 0.6454\n",
      "Epoch 76/100\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.6433 - accuracy: 0.6429 - val_loss: 0.6398 - val_accuracy: 0.6450\n",
      "Epoch 77/100\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.6437 - accuracy: 0.6425 - val_loss: 0.6391 - val_accuracy: 0.6454\n",
      "Epoch 78/100\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.6431 - accuracy: 0.6430 - val_loss: 0.6406 - val_accuracy: 0.6454\n",
      "Epoch 79/100\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.6446 - accuracy: 0.6414 - val_loss: 0.6407 - val_accuracy: 0.6433\n",
      "Epoch 80/100\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.6440 - accuracy: 0.6434 - val_loss: 0.6401 - val_accuracy: 0.6454\n",
      "Epoch 81/100\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.6435 - accuracy: 0.6411 - val_loss: 0.6408 - val_accuracy: 0.6454\n",
      "Epoch 82/100\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.6446 - accuracy: 0.6429 - val_loss: 0.6392 - val_accuracy: 0.6454\n",
      "Epoch 83/100\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.6446 - accuracy: 0.6429 - val_loss: 0.6395 - val_accuracy: 0.6454\n",
      "Epoch 84/100\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.6435 - accuracy: 0.6438 - val_loss: 0.6389 - val_accuracy: 0.6454\n",
      "Epoch 85/100\n",
      "5600/5600 [==============================] - 0s 29us/sample - loss: 0.6444 - accuracy: 0.6393 - val_loss: 0.6403 - val_accuracy: 0.6425\n",
      "Epoch 86/100\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.6456 - accuracy: 0.6432 - val_loss: 0.6448 - val_accuracy: 0.6354\n",
      "Epoch 87/100\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.6442 - accuracy: 0.6439 - val_loss: 0.6394 - val_accuracy: 0.6450\n",
      "Epoch 88/100\n",
      "5600/5600 [==============================] - 0s 30us/sample - loss: 0.6478 - accuracy: 0.6407 - val_loss: 0.6405 - val_accuracy: 0.6454\n",
      "Epoch 89/100\n",
      "5600/5600 [==============================] - 0s 26us/sample - loss: 0.6439 - accuracy: 0.6421 - val_loss: 0.6400 - val_accuracy: 0.6454\n",
      "Epoch 90/100\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.6433 - accuracy: 0.6434 - val_loss: 0.6387 - val_accuracy: 0.6429\n",
      "Epoch 91/100\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.6430 - accuracy: 0.6427 - val_loss: 0.6416 - val_accuracy: 0.6454\n",
      "Epoch 92/100\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.6429 - accuracy: 0.6427 - val_loss: 0.6377 - val_accuracy: 0.6454\n",
      "Epoch 93/100\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.6451 - accuracy: 0.6420 - val_loss: 0.6493 - val_accuracy: 0.6304\n",
      "Epoch 94/100\n",
      "5600/5600 [==============================] - 0s 27us/sample - loss: 0.6457 - accuracy: 0.6425 - val_loss: 0.6420 - val_accuracy: 0.6408\n",
      "Epoch 95/100\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.6443 - accuracy: 0.6427 - val_loss: 0.6411 - val_accuracy: 0.6454\n",
      "Epoch 96/100\n",
      "5600/5600 [==============================] - 0s 28us/sample - loss: 0.6433 - accuracy: 0.6438 - val_loss: 0.6390 - val_accuracy: 0.6450\n",
      "Epoch 97/100\n",
      "5600/5600 [==============================] - 0s 34us/sample - loss: 0.6448 - accuracy: 0.6443 - val_loss: 0.6394 - val_accuracy: 0.6454\n",
      "Epoch 98/100\n",
      "5600/5600 [==============================] - 0s 33us/sample - loss: 0.6437 - accuracy: 0.6409 - val_loss: 0.6421 - val_accuracy: 0.6421\n",
      "Epoch 99/100\n",
      "5600/5600 [==============================] - 0s 32us/sample - loss: 0.6432 - accuracy: 0.6423 - val_loss: 0.6396 - val_accuracy: 0.6438\n",
      "Epoch 100/100\n",
      "5600/5600 [==============================] - 0s 31us/sample - loss: 0.6448 - accuracy: 0.6436 - val_loss: 0.6396 - val_accuracy: 0.6438\n"
     ]
    }
   ],
   "source": [
    "# specify network layers\n",
    "binary_ann = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28, )),\n",
    "    tf.keras.layers.Dense(100, activation = 'relu', \n",
    "                       kernel_regularizer = tf.keras.regularizers.l2(l = 0.1)),\n",
    "    tf.keras.layers.Dense(100, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "# compile and fit network\n",
    "binary_ann.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy']) \n",
    "history = binary_ann.fit(X_train, y_train, epochs = 100, batch_size = 128, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy vs. Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Training', 'Validation'], loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df = pd.read_csv('data/songs_10000.csv')\n",
    "\n",
    "# drop additional index column\n",
    "songs_df = songs_df.drop(columns = 'Unnamed: 0')\n",
    "\n",
    "songs_df_clean = songs_df.drop(columns = ['Artist', 'Track Name', 'Track ID'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(songs_df_clean.loc[:, songs_df_clean.columns != 'Popularity'], \n",
    "                                                    songs_df_clean.Popularity, test_size = 0.2, \n",
    "                                                    random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "cat_cols = ['Key', 'Time Signature']\n",
    "X_train_num = X_train.drop(cat_cols, axis = 1)\n",
    "X_test_num = X_test.drop(cat_cols, axis = 1)\n",
    "num_features = X_train_num.columns.tolist()\n",
    "num_index_train = X_train.index.tolist()\n",
    "num_index_test = X_test.index.tolist()\n",
    "\n",
    "X_train_dum = pd.get_dummies(X_train[cat_cols], columns = cat_cols)\n",
    "X_test_dum = pd.get_dummies(X_test[cat_cols], columns = cat_cols)\n",
    "\n",
    "scaler = MinMaxScaler().fit(X_train_num)\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(X_train_num), index = num_index_train, columns = num_features)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test_num), index = num_index_test, columns = num_features)\n",
    "\n",
    "X_train = pd.concat([X_train_dum, X_train_scaled], axis = 1)\n",
    "X_test = pd.concat([X_test_dum, X_test_scaled], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5600 samples, validate on 2400 samples\n",
      "Epoch 1/1000\n",
      "5600/5600 [==============================] - 1s 91us/sample - loss: 58.6572 - accuracy: 0.0000e+00 - val_loss: 58.0132 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "5600/5600 [==============================] - 0s 67us/sample - loss: 57.6399 - accuracy: 0.0000e+00 - val_loss: 56.8782 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "5600/5600 [==============================] - 0s 72us/sample - loss: 56.4721 - accuracy: 0.0000e+00 - val_loss: 55.6473 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "5600/5600 [==============================] - 0s 69us/sample - loss: 55.1845 - accuracy: 0.0000e+00 - val_loss: 54.3559 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "5600/5600 [==============================] - 0s 70us/sample - loss: 53.9383 - accuracy: 0.0000e+00 - val_loss: 53.1504 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "5600/5600 [==============================] - 1s 97us/sample - loss: 52.7599 - accuracy: 0.0000e+00 - val_loss: 51.9943 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "5600/5600 [==============================] - 0s 62us/sample - loss: 51.6194 - accuracy: 0.0000e+00 - val_loss: 50.8672 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "5600/5600 [==============================] - 0s 72us/sample - loss: 50.5023 - accuracy: 0.0000e+00 - val_loss: 49.7588 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "5600/5600 [==============================] - 0s 69us/sample - loss: 49.4008 - accuracy: 0.0000e+00 - val_loss: 48.6634 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "5600/5600 [==============================] - 0s 69us/sample - loss: 48.3103 - accuracy: 0.0000e+00 - val_loss: 47.5775 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "5600/5600 [==============================] - 0s 71us/sample - loss: 47.2281 - accuracy: 0.0000e+00 - val_loss: 46.4987 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "5600/5600 [==============================] - 1s 97us/sample - loss: 46.1521 - accuracy: 0.0000e+00 - val_loss: 45.4253 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "5600/5600 [==============================] - 1s 103us/sample - loss: 45.0809 - accuracy: 0.0000e+00 - val_loss: 44.3562 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "5600/5600 [==============================] - 0s 70us/sample - loss: 44.0136 - accuracy: 0.0000e+00 - val_loss: 43.2905 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "5600/5600 [==============================] - 0s 72us/sample - loss: 42.9493 - accuracy: 0.0000e+00 - val_loss: 42.2275 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "5600/5600 [==============================] - 0s 71us/sample - loss: 41.8875 - accuracy: 0.0000e+00 - val_loss: 41.1667 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "5600/5600 [==============================] - 0s 71us/sample - loss: 40.8276 - accuracy: 0.0000e+00 - val_loss: 40.1077 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "5600/5600 [==============================] - 0s 71us/sample - loss: 39.7694 - accuracy: 0.0000e+00 - val_loss: 39.0502 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "5600/5600 [==============================] - 1s 91us/sample - loss: 38.7125 - accuracy: 0.0000e+00 - val_loss: 37.9939 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "5600/5600 [==============================] - 0s 81us/sample - loss: 37.6568 - accuracy: 0.0000e+00 - val_loss: 36.9387 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "5600/5600 [==============================] - 0s 70us/sample - loss: 36.6020 - accuracy: 0.0000e+00 - val_loss: 35.8843 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "5600/5600 [==============================] - 0s 74us/sample - loss: 35.5479 - accuracy: 0.0000e+00 - val_loss: 34.8305 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "5600/5600 [==============================] - 0s 70us/sample - loss: 34.4945 - accuracy: 0.0000e+00 - val_loss: 33.7774 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "5600/5600 [==============================] - 0s 71us/sample - loss: 33.4416 - accuracy: 0.0000e+00 - val_loss: 32.7248 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "5600/5600 [==============================] - 0s 71us/sample - loss: 32.3892 - accuracy: 0.0000e+00 - val_loss: 31.6725 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "5600/5600 [==============================] - 1s 100us/sample - loss: 31.3372 - accuracy: 0.0000e+00 - val_loss: 30.6207 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "5600/5600 [==============================] - 0s 85us/sample - loss: 30.2854 - accuracy: 0.0000e+00 - val_loss: 29.5691 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "5600/5600 [==============================] - 1s 106us/sample - loss: 29.2339 - accuracy: 0.0000e+00 - val_loss: 28.5177 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "5600/5600 [==============================] - 0s 74us/sample - loss: 28.1827 - accuracy: 0.0000e+00 - val_loss: 27.4666 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "5600/5600 [==============================] - 1s 97us/sample - loss: 27.1317 - accuracy: 0.0000e+00 - val_loss: 26.4156 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "5600/5600 [==============================] - 0s 69us/sample - loss: 26.0808 - accuracy: 0.0000e+00 - val_loss: 25.3648 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "5600/5600 [==============================] - 0s 71us/sample - loss: 25.0300 - accuracy: 0.0000e+00 - val_loss: 24.3141 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "5600/5600 [==============================] - 0s 71us/sample - loss: 23.9794 - accuracy: 0.0000e+00 - val_loss: 23.2635 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "5600/5600 [==============================] - 0s 69us/sample - loss: 22.9289 - accuracy: 0.0000e+00 - val_loss: 22.2130 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "5600/5600 [==============================] - 0s 60us/sample - loss: 21.8784 - accuracy: 0.0000e+00 - val_loss: 21.1625 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "5600/5600 [==============================] - 1s 96us/sample - loss: 20.8279 - accuracy: 0.0000e+00 - val_loss: 20.1120 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/1000\n",
      "5600/5600 [==============================] - 0s 62us/sample - loss: 19.7774 - accuracy: 0.0000e+00 - val_loss: 19.0617 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/1000\n",
      "5600/5600 [==============================] - 0s 72us/sample - loss: 18.7272 - accuracy: 0.0000e+00 - val_loss: 18.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "5600/5600 [==============================] - 0s 79us/sample - loss: 17.6769 - accuracy: 0.0000e+00 - val_loss: 16.9613 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/1000\n",
      "5600/5600 [==============================] - 0s 73us/sample - loss: 16.6268 - accuracy: 0.0000e+00 - val_loss: 15.9112 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "5600/5600 [==============================] - 0s 66us/sample - loss: 15.5767 - accuracy: 0.0000e+00 - val_loss: 14.8611 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "5600/5600 [==============================] - 0s 63us/sample - loss: 14.5268 - accuracy: 0.0000e+00 - val_loss: 13.8117 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "5600/5600 [==============================] - 0s 64us/sample - loss: 13.4790 - accuracy: 0.0000e+00 - val_loss: 12.7680 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "5600/5600 [==============================] - 0s 68us/sample - loss: 12.4426 - accuracy: 0.0000e+00 - val_loss: 11.7455 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "5600/5600 [==============================] - 0s 72us/sample - loss: 11.4383 - accuracy: 0.0000e+00 - val_loss: 10.7717 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/1000\n",
      "5600/5600 [==============================] - 0s 78us/sample - loss: 10.4941 - accuracy: 0.0000e+00 - val_loss: 9.8747 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/1000\n",
      "5600/5600 [==============================] - 0s 69us/sample - loss: 9.6456 - accuracy: 0.0000e+00 - val_loss: 9.0886 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/1000\n",
      "5600/5600 [==============================] - 1s 90us/sample - loss: 8.9159 - accuracy: 0.0000e+00 - val_loss: 8.4260 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/1000\n",
      "5600/5600 [==============================] - 1s 90us/sample - loss: 8.3097 - accuracy: 0.0000e+00 - val_loss: 7.8846 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/1000\n",
      "5600/5600 [==============================] - 0s 63us/sample - loss: 7.8221 - accuracy: 0.0000e+00 - val_loss: 7.4404 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/1000\n",
      "5600/5600 [==============================] - 1s 129us/sample - loss: 7.4434 - accuracy: 0.0000e+00 - val_loss: 7.0877 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 81us/sample - loss: 7.1413 - accuracy: 0.0000e+00 - val_loss: 6.8252 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/1000\n",
      "5600/5600 [==============================] - 0s 76us/sample - loss: 6.9046 - accuracy: 0.0000e+00 - val_loss: 6.6039 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/1000\n",
      "5600/5600 [==============================] - 0s 83us/sample - loss: 6.7222 - accuracy: 0.0000e+00 - val_loss: 6.4406 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/1000\n",
      "5600/5600 [==============================] - 0s 78us/sample - loss: 6.5785 - accuracy: 0.0000e+00 - val_loss: 6.3083 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 6.4739 - accuracy: 0.0000e+00 - val_loss: 6.2213 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.3945 - accuracy: 0.0000e+00 - val_loss: 6.1509 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.3330 - accuracy: 0.0000e+00 - val_loss: 6.0996 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 6.2944 - accuracy: 0.0000e+00 - val_loss: 6.0712 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.2685 - accuracy: 0.0000e+00 - val_loss: 6.0519 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.2481 - accuracy: 0.0000e+00 - val_loss: 6.0334 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.2285 - accuracy: 0.0000e+00 - val_loss: 6.0171 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.2139 - accuracy: 0.0286 - val_loss: 6.0098 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.2088 - accuracy: 0.0000e+00 - val_loss: 6.0071 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 6.2078 - accuracy: 0.0000e+00 - val_loss: 6.0069 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.2078 - accuracy: 0.0000e+00 - val_loss: 6.0069 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.2077 - accuracy: 0.0000e+00 - val_loss: 6.0067 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/1000\n",
      "5600/5600 [==============================] - 0s 61us/sample - loss: 6.2078 - accuracy: 0.0000e+00 - val_loss: 6.0067 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.2076 - accuracy: 0.0057 - val_loss: 6.0070 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.2079 - accuracy: 0.0000e+00 - val_loss: 6.0068 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.2078 - accuracy: 0.0000e+00 - val_loss: 6.0068 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.2080 - accuracy: 0.0000e+00 - val_loss: 6.0071 - val_accuracy: 4.1667e-04\n",
      "Epoch 73/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.2076 - accuracy: 0.0000e+00 - val_loss: 6.0070 - val_accuracy: 4.1667e-04\n",
      "Epoch 74/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 6.2079 - accuracy: 3.5714e-04 - val_loss: 6.0071 - val_accuracy: 8.3333e-04\n",
      "Epoch 75/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 6.2074 - accuracy: 0.0748 - val_loss: 6.0069 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.2072 - accuracy: 0.6946 - val_loss: 6.0065 - val_accuracy: 0.9950\n",
      "Epoch 77/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 6.2057 - accuracy: 0.8209 - val_loss: 6.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/1000\n",
      "5600/5600 [==============================] - 0s 60us/sample - loss: 6.1981 - accuracy: 1.7857e-04 - val_loss: 5.9911 - val_accuracy: 4.1667e-04\n",
      "Epoch 79/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.1786 - accuracy: 0.0234 - val_loss: 5.9688 - val_accuracy: 0.0392\n",
      "Epoch 80/1000\n",
      "5600/5600 [==============================] - 0s 60us/sample - loss: 6.1567 - accuracy: 0.0248 - val_loss: 5.9525 - val_accuracy: 0.0225\n",
      "Epoch 81/1000\n",
      "5600/5600 [==============================] - 0s 64us/sample - loss: 6.1465 - accuracy: 0.0220 - val_loss: 5.9472 - val_accuracy: 0.0063\n",
      "Epoch 82/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.1411 - accuracy: 0.0082 - val_loss: 5.9435 - val_accuracy: 0.0046\n",
      "Epoch 83/1000\n",
      "5600/5600 [==============================] - 0s 62us/sample - loss: 6.1366 - accuracy: 0.0075 - val_loss: 5.9403 - val_accuracy: 0.0042\n",
      "Epoch 84/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.1331 - accuracy: 0.0079 - val_loss: 5.9382 - val_accuracy: 0.0063\n",
      "Epoch 85/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.1288 - accuracy: 0.0079 - val_loss: 5.9347 - val_accuracy: 0.0092\n",
      "Epoch 86/1000\n",
      "5600/5600 [==============================] - 0s 71us/sample - loss: 6.1251 - accuracy: 0.0080 - val_loss: 5.9339 - val_accuracy: 0.0033\n",
      "Epoch 87/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 6.1218 - accuracy: 0.0070 - val_loss: 5.9312 - val_accuracy: 0.0058\n",
      "Epoch 88/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.1183 - accuracy: 0.0113 - val_loss: 5.9284 - val_accuracy: 0.0179\n",
      "Epoch 89/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.1159 - accuracy: 0.0314 - val_loss: 5.9253 - val_accuracy: 0.0246\n",
      "Epoch 90/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.1135 - accuracy: 0.0309 - val_loss: 5.9234 - val_accuracy: 0.0071\n",
      "Epoch 91/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.1106 - accuracy: 0.0264 - val_loss: 5.9219 - val_accuracy: 0.0571\n",
      "Epoch 92/1000\n",
      "5600/5600 [==============================] - 0s 61us/sample - loss: 6.1084 - accuracy: 0.0252 - val_loss: 5.9194 - val_accuracy: 0.0312\n",
      "Epoch 93/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.1076 - accuracy: 0.0546 - val_loss: 5.9183 - val_accuracy: 0.0354\n",
      "Epoch 94/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.1053 - accuracy: 0.0325 - val_loss: 5.9166 - val_accuracy: 0.0037\n",
      "Epoch 95/1000\n",
      "5600/5600 [==============================] - 0s 63us/sample - loss: 6.1043 - accuracy: 0.0105 - val_loss: 5.9164 - val_accuracy: 0.0142\n",
      "Epoch 96/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.1027 - accuracy: 0.0209 - val_loss: 5.9146 - val_accuracy: 0.0471\n",
      "Epoch 97/1000\n",
      "5600/5600 [==============================] - 0s 64us/sample - loss: 6.1016 - accuracy: 0.0205 - val_loss: 5.9131 - val_accuracy: 0.0321\n",
      "Epoch 98/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.1004 - accuracy: 0.0246 - val_loss: 5.9117 - val_accuracy: 0.0137\n",
      "Epoch 99/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0996 - accuracy: 0.0113 - val_loss: 5.9100 - val_accuracy: 0.0133\n",
      "Epoch 100/1000\n",
      "5600/5600 [==============================] - 0s 64us/sample - loss: 6.0980 - accuracy: 0.0393 - val_loss: 5.9101 - val_accuracy: 0.0408\n",
      "Epoch 101/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.0973 - accuracy: 0.0602 - val_loss: 5.9080 - val_accuracy: 0.0600\n",
      "Epoch 102/1000\n",
      "5600/5600 [==============================] - 0s 64us/sample - loss: 6.0962 - accuracy: 0.0184 - val_loss: 5.9072 - val_accuracy: 0.0246\n",
      "Epoch 103/1000\n",
      "5600/5600 [==============================] - 0s 63us/sample - loss: 6.0951 - accuracy: 0.0320 - val_loss: 5.9070 - val_accuracy: 0.0258\n",
      "Epoch 104/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.0944 - accuracy: 0.0352 - val_loss: 5.9061 - val_accuracy: 0.0354\n",
      "Epoch 105/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.0937 - accuracy: 0.0330 - val_loss: 5.9044 - val_accuracy: 0.0367\n",
      "Epoch 106/1000\n",
      "5600/5600 [==============================] - 0s 73us/sample - loss: 6.0931 - accuracy: 0.0398 - val_loss: 5.9040 - val_accuracy: 0.0575\n",
      "Epoch 107/1000\n",
      "5600/5600 [==============================] - 0s 89us/sample - loss: 6.0924 - accuracy: 0.0518 - val_loss: 5.9026 - val_accuracy: 0.0717\n",
      "Epoch 108/1000\n",
      "5600/5600 [==============================] - 0s 75us/sample - loss: 6.0910 - accuracy: 0.0645 - val_loss: 5.9017 - val_accuracy: 0.0917\n",
      "Epoch 109/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.0904 - accuracy: 0.0704 - val_loss: 5.9007 - val_accuracy: 0.0633\n",
      "Epoch 110/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0898 - accuracy: 0.0348 - val_loss: 5.9006 - val_accuracy: 0.0354\n",
      "Epoch 111/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.0890 - accuracy: 0.0368 - val_loss: 5.9000 - val_accuracy: 0.0521\n",
      "Epoch 112/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 6.0879 - accuracy: 0.0923 - val_loss: 5.9009 - val_accuracy: 0.0808\n",
      "Epoch 113/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0874 - accuracy: 0.0771 - val_loss: 5.8979 - val_accuracy: 0.0896\n",
      "Epoch 114/1000\n",
      "5600/5600 [==============================] - 0s 63us/sample - loss: 6.0863 - accuracy: 0.1016 - val_loss: 5.8983 - val_accuracy: 0.0871\n",
      "Epoch 115/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0860 - accuracy: 0.0564 - val_loss: 5.8953 - val_accuracy: 0.0487\n",
      "Epoch 116/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0848 - accuracy: 0.0413 - val_loss: 5.8943 - val_accuracy: 0.0454\n",
      "Epoch 117/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0842 - accuracy: 0.0375 - val_loss: 5.8932 - val_accuracy: 0.0350\n",
      "Epoch 118/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0833 - accuracy: 0.0400 - val_loss: 5.8920 - val_accuracy: 0.0533\n",
      "Epoch 119/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0826 - accuracy: 0.0434 - val_loss: 5.8914 - val_accuracy: 0.0275\n",
      "Epoch 120/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0815 - accuracy: 0.0248 - val_loss: 5.8915 - val_accuracy: 0.0367\n",
      "Epoch 121/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0806 - accuracy: 0.0355 - val_loss: 5.8897 - val_accuracy: 0.0358\n",
      "Epoch 122/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0804 - accuracy: 0.0320 - val_loss: 5.8887 - val_accuracy: 0.0404\n",
      "Epoch 123/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0789 - accuracy: 0.0330 - val_loss: 5.8905 - val_accuracy: 0.0300\n",
      "Epoch 124/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0782 - accuracy: 0.0407 - val_loss: 5.8878 - val_accuracy: 0.0458\n",
      "Epoch 125/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0777 - accuracy: 0.0380 - val_loss: 5.8872 - val_accuracy: 0.0442\n",
      "Epoch 126/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0776 - accuracy: 0.0364 - val_loss: 5.8883 - val_accuracy: 0.0342\n",
      "Epoch 127/1000\n",
      "5600/5600 [==============================] - 0s 60us/sample - loss: 6.0769 - accuracy: 0.0302 - val_loss: 5.8877 - val_accuracy: 0.0346\n",
      "Epoch 128/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.0759 - accuracy: 0.0282 - val_loss: 5.8884 - val_accuracy: 0.0383\n",
      "Epoch 129/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0750 - accuracy: 0.0307 - val_loss: 5.8874 - val_accuracy: 0.0258\n",
      "Epoch 130/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.0759 - accuracy: 0.0177 - val_loss: 5.8868 - val_accuracy: 0.0192\n",
      "Epoch 131/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0738 - accuracy: 0.0195 - val_loss: 5.8871 - val_accuracy: 0.0217\n",
      "Epoch 132/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0745 - accuracy: 0.0227 - val_loss: 5.8862 - val_accuracy: 0.0192\n",
      "Epoch 133/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.0727 - accuracy: 0.0305 - val_loss: 5.8863 - val_accuracy: 0.0442\n",
      "Epoch 134/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.0721 - accuracy: 0.0502 - val_loss: 5.8889 - val_accuracy: 0.0442\n",
      "Epoch 135/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0724 - accuracy: 0.0413 - val_loss: 5.8862 - val_accuracy: 0.0383\n",
      "Epoch 136/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0714 - accuracy: 0.0354 - val_loss: 5.8851 - val_accuracy: 0.0346\n",
      "Epoch 137/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 6.0704 - accuracy: 0.0334 - val_loss: 5.8849 - val_accuracy: 0.0312\n",
      "Epoch 138/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0699 - accuracy: 0.0375 - val_loss: 5.8846 - val_accuracy: 0.0421\n",
      "Epoch 139/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.0697 - accuracy: 0.0316 - val_loss: 5.8846 - val_accuracy: 0.0204\n",
      "Epoch 140/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0696 - accuracy: 0.0196 - val_loss: 5.8851 - val_accuracy: 0.0129\n",
      "Epoch 141/1000\n",
      "5600/5600 [==============================] - 0s 64us/sample - loss: 6.0683 - accuracy: 0.0139 - val_loss: 5.8845 - val_accuracy: 0.0150\n",
      "Epoch 142/1000\n",
      "5600/5600 [==============================] - 0s 60us/sample - loss: 6.0677 - accuracy: 0.0148 - val_loss: 5.8822 - val_accuracy: 0.0213\n",
      "Epoch 143/1000\n",
      "5600/5600 [==============================] - 0s 62us/sample - loss: 6.0666 - accuracy: 0.0239 - val_loss: 5.8851 - val_accuracy: 0.0242\n",
      "Epoch 144/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0659 - accuracy: 0.0246 - val_loss: 5.8822 - val_accuracy: 0.0375\n",
      "Epoch 145/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 6.0654 - accuracy: 0.0373 - val_loss: 5.8820 - val_accuracy: 0.0442\n",
      "Epoch 146/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0645 - accuracy: 0.0430 - val_loss: 5.8824 - val_accuracy: 0.0525\n",
      "Epoch 147/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0636 - accuracy: 0.0611 - val_loss: 5.8827 - val_accuracy: 0.0792\n",
      "Epoch 148/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0629 - accuracy: 0.0529 - val_loss: 5.8817 - val_accuracy: 0.0508\n",
      "Epoch 149/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 6.0617 - accuracy: 0.0477 - val_loss: 5.8821 - val_accuracy: 0.0529\n",
      "Epoch 150/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0616 - accuracy: 0.0445 - val_loss: 5.8806 - val_accuracy: 0.0533\n",
      "Epoch 151/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0610 - accuracy: 0.0416 - val_loss: 5.8819 - val_accuracy: 0.0362\n",
      "Epoch 152/1000\n",
      "5600/5600 [==============================] - 0s 60us/sample - loss: 6.0602 - accuracy: 0.0338 - val_loss: 5.8818 - val_accuracy: 0.0354\n",
      "Epoch 153/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.0594 - accuracy: 0.0312 - val_loss: 5.8832 - val_accuracy: 0.0346\n",
      "Epoch 154/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0586 - accuracy: 0.0270 - val_loss: 5.8819 - val_accuracy: 0.0325\n",
      "Epoch 155/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0573 - accuracy: 0.0357 - val_loss: 5.8814 - val_accuracy: 0.0354\n",
      "Epoch 156/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0571 - accuracy: 0.0300 - val_loss: 5.8818 - val_accuracy: 0.0375\n",
      "Epoch 157/1000\n",
      "5600/5600 [==============================] - 0s 64us/sample - loss: 6.0562 - accuracy: 0.0300 - val_loss: 5.8813 - val_accuracy: 0.0279\n",
      "Epoch 158/1000\n",
      "5600/5600 [==============================] - 0s 61us/sample - loss: 6.0549 - accuracy: 0.0393 - val_loss: 5.8800 - val_accuracy: 0.0379\n",
      "Epoch 159/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0543 - accuracy: 0.0411 - val_loss: 5.8799 - val_accuracy: 0.0475\n",
      "Epoch 160/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0537 - accuracy: 0.0341 - val_loss: 5.8825 - val_accuracy: 0.0208\n",
      "Epoch 161/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0521 - accuracy: 0.0271 - val_loss: 5.8790 - val_accuracy: 0.0396\n",
      "Epoch 162/1000\n",
      "5600/5600 [==============================] - 0s 68us/sample - loss: 6.0518 - accuracy: 0.0464 - val_loss: 5.8797 - val_accuracy: 0.0625\n",
      "Epoch 163/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0516 - accuracy: 0.0520 - val_loss: 5.8793 - val_accuracy: 0.0546\n",
      "Epoch 164/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0508 - accuracy: 0.0477 - val_loss: 5.8794 - val_accuracy: 0.0467\n",
      "Epoch 165/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0498 - accuracy: 0.0336 - val_loss: 5.8785 - val_accuracy: 0.0312\n",
      "Epoch 166/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0485 - accuracy: 0.0334 - val_loss: 5.8804 - val_accuracy: 0.0425\n",
      "Epoch 167/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0485 - accuracy: 0.0323 - val_loss: 5.8779 - val_accuracy: 0.0354\n",
      "Epoch 168/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0476 - accuracy: 0.0350 - val_loss: 5.8793 - val_accuracy: 0.0592\n",
      "Epoch 169/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0475 - accuracy: 0.0484 - val_loss: 5.8807 - val_accuracy: 0.0696\n",
      "Epoch 170/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0458 - accuracy: 0.0630 - val_loss: 5.8775 - val_accuracy: 0.0904\n",
      "Epoch 171/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0466 - accuracy: 0.0632 - val_loss: 5.8770 - val_accuracy: 0.0854\n",
      "Epoch 172/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0453 - accuracy: 0.0714 - val_loss: 5.8779 - val_accuracy: 0.0929\n",
      "Epoch 173/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0440 - accuracy: 0.0695 - val_loss: 5.8777 - val_accuracy: 0.0887\n",
      "Epoch 174/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0437 - accuracy: 0.0682 - val_loss: 5.8784 - val_accuracy: 0.0733\n",
      "Epoch 175/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0432 - accuracy: 0.0623 - val_loss: 5.8770 - val_accuracy: 0.0767\n",
      "Epoch 176/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 6.0423 - accuracy: 0.0646 - val_loss: 5.8761 - val_accuracy: 0.0750\n",
      "Epoch 177/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0421 - accuracy: 0.0577 - val_loss: 5.8779 - val_accuracy: 0.0567\n",
      "Epoch 178/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0412 - accuracy: 0.0486 - val_loss: 5.8765 - val_accuracy: 0.0733\n",
      "Epoch 179/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 6.0408 - accuracy: 0.0684 - val_loss: 5.8768 - val_accuracy: 0.0892\n",
      "Epoch 180/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0395 - accuracy: 0.0920 - val_loss: 5.8767 - val_accuracy: 0.0825\n",
      "Epoch 181/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0390 - accuracy: 0.0779 - val_loss: 5.8764 - val_accuracy: 0.0938\n",
      "Epoch 182/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0375 - accuracy: 0.0736 - val_loss: 5.8797 - val_accuracy: 0.0842\n",
      "Epoch 183/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0380 - accuracy: 0.0736 - val_loss: 5.8781 - val_accuracy: 0.0896\n",
      "Epoch 184/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0365 - accuracy: 0.0752 - val_loss: 5.8777 - val_accuracy: 0.0604\n",
      "Epoch 185/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 6.0368 - accuracy: 0.0591 - val_loss: 5.8786 - val_accuracy: 0.0750\n",
      "Epoch 186/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0351 - accuracy: 0.0646 - val_loss: 5.8778 - val_accuracy: 0.0883\n",
      "Epoch 187/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0348 - accuracy: 0.0805 - val_loss: 5.8770 - val_accuracy: 0.0904\n",
      "Epoch 188/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.0343 - accuracy: 0.0787 - val_loss: 5.8766 - val_accuracy: 0.0962\n",
      "Epoch 189/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0331 - accuracy: 0.0768 - val_loss: 5.8779 - val_accuracy: 0.0763\n",
      "Epoch 190/1000\n",
      "5600/5600 [==============================] - 0s 63us/sample - loss: 6.0328 - accuracy: 0.0654 - val_loss: 5.8760 - val_accuracy: 0.0875\n",
      "Epoch 191/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0323 - accuracy: 0.0782 - val_loss: 5.8762 - val_accuracy: 0.0942\n",
      "Epoch 192/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0329 - accuracy: 0.0696 - val_loss: 5.8766 - val_accuracy: 0.0887\n",
      "Epoch 193/1000\n",
      "5600/5600 [==============================] - 0s 62us/sample - loss: 6.0301 - accuracy: 0.0707 - val_loss: 5.8781 - val_accuracy: 0.1054\n",
      "Epoch 194/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0298 - accuracy: 0.1077 - val_loss: 5.8773 - val_accuracy: 0.1308\n",
      "Epoch 195/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0291 - accuracy: 0.0934 - val_loss: 5.8757 - val_accuracy: 0.0954\n",
      "Epoch 196/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0283 - accuracy: 0.0712 - val_loss: 5.8773 - val_accuracy: 0.0737\n",
      "Epoch 197/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 6.0279 - accuracy: 0.0711 - val_loss: 5.8765 - val_accuracy: 0.0871\n",
      "Epoch 198/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.0273 - accuracy: 0.0829 - val_loss: 5.8765 - val_accuracy: 0.1121\n",
      "Epoch 199/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0273 - accuracy: 0.0898 - val_loss: 5.8764 - val_accuracy: 0.1092\n",
      "Epoch 200/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 6.0254 - accuracy: 0.0870 - val_loss: 5.8760 - val_accuracy: 0.1275\n",
      "Epoch 201/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0263 - accuracy: 0.0907 - val_loss: 5.8769 - val_accuracy: 0.0829\n",
      "Epoch 202/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0251 - accuracy: 0.0739 - val_loss: 5.8779 - val_accuracy: 0.1075\n",
      "Epoch 203/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 6.0243 - accuracy: 0.1071 - val_loss: 5.8763 - val_accuracy: 0.1321\n",
      "Epoch 204/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.0248 - accuracy: 0.0946 - val_loss: 5.8770 - val_accuracy: 0.0913\n",
      "Epoch 205/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 6.0238 - accuracy: 0.0682 - val_loss: 5.8757 - val_accuracy: 0.1021\n",
      "Epoch 206/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.0227 - accuracy: 0.0763 - val_loss: 5.8788 - val_accuracy: 0.0871\n",
      "Epoch 207/1000\n",
      "5600/5600 [==============================] - 0s 60us/sample - loss: 6.0229 - accuracy: 0.0748 - val_loss: 5.8773 - val_accuracy: 0.0671\n",
      "Epoch 208/1000\n",
      "5600/5600 [==============================] - 0s 62us/sample - loss: 6.0212 - accuracy: 0.0598 - val_loss: 5.8764 - val_accuracy: 0.0846\n",
      "Epoch 209/1000\n",
      "5600/5600 [==============================] - 0s 65us/sample - loss: 6.0207 - accuracy: 0.0825 - val_loss: 5.8771 - val_accuracy: 0.1108\n",
      "Epoch 210/1000\n",
      "5600/5600 [==============================] - 0s 68us/sample - loss: 6.0203 - accuracy: 0.0795 - val_loss: 5.8766 - val_accuracy: 0.1150\n",
      "Epoch 211/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0198 - accuracy: 0.0914 - val_loss: 5.8774 - val_accuracy: 0.0742\n",
      "Epoch 212/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0202 - accuracy: 0.0673 - val_loss: 5.8767 - val_accuracy: 0.0704\n",
      "Epoch 213/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0194 - accuracy: 0.0764 - val_loss: 5.8774 - val_accuracy: 0.1133\n",
      "Epoch 214/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0181 - accuracy: 0.0834 - val_loss: 5.8776 - val_accuracy: 0.0737\n",
      "Epoch 215/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 6.0182 - accuracy: 0.0630 - val_loss: 5.8775 - val_accuracy: 0.0900\n",
      "Epoch 216/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 6.0181 - accuracy: 0.0750 - val_loss: 5.8770 - val_accuracy: 0.0754\n",
      "Epoch 217/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0169 - accuracy: 0.0598 - val_loss: 5.8768 - val_accuracy: 0.0708\n",
      "Epoch 218/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0164 - accuracy: 0.0627 - val_loss: 5.8766 - val_accuracy: 0.0812\n",
      "Epoch 219/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.0155 - accuracy: 0.0562 - val_loss: 5.8758 - val_accuracy: 0.0688\n",
      "Epoch 220/1000\n",
      "5600/5600 [==============================] - 0s 60us/sample - loss: 6.0155 - accuracy: 0.0641 - val_loss: 5.8766 - val_accuracy: 0.0708\n",
      "Epoch 221/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 6.0142 - accuracy: 0.0548 - val_loss: 5.8756 - val_accuracy: 0.0679\n",
      "Epoch 222/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0145 - accuracy: 0.0741 - val_loss: 5.8763 - val_accuracy: 0.0787\n",
      "Epoch 223/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0151 - accuracy: 0.0596 - val_loss: 5.8754 - val_accuracy: 0.0921\n",
      "Epoch 224/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0141 - accuracy: 0.0759 - val_loss: 5.8765 - val_accuracy: 0.0808\n",
      "Epoch 225/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 6.0127 - accuracy: 0.0611 - val_loss: 5.8769 - val_accuracy: 0.0792\n",
      "Epoch 226/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0127 - accuracy: 0.0496 - val_loss: 5.8754 - val_accuracy: 0.0642\n",
      "Epoch 227/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0130 - accuracy: 0.0557 - val_loss: 5.8758 - val_accuracy: 0.0650\n",
      "Epoch 228/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0112 - accuracy: 0.0593 - val_loss: 5.8768 - val_accuracy: 0.0796\n",
      "Epoch 229/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0113 - accuracy: 0.0761 - val_loss: 5.8768 - val_accuracy: 0.0625\n",
      "Epoch 230/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0103 - accuracy: 0.0520 - val_loss: 5.8764 - val_accuracy: 0.0554\n",
      "Epoch 231/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.0095 - accuracy: 0.0616 - val_loss: 5.8747 - val_accuracy: 0.0783\n",
      "Epoch 232/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.0101 - accuracy: 0.0825 - val_loss: 5.8760 - val_accuracy: 0.1142\n",
      "Epoch 233/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0099 - accuracy: 0.1102 - val_loss: 5.8746 - val_accuracy: 0.1400\n",
      "Epoch 234/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0093 - accuracy: 0.0991 - val_loss: 5.8733 - val_accuracy: 0.1004\n",
      "Epoch 235/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0090 - accuracy: 0.0973 - val_loss: 5.8759 - val_accuracy: 0.1033\n",
      "Epoch 236/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0076 - accuracy: 0.1327 - val_loss: 5.8768 - val_accuracy: 0.1771\n",
      "Epoch 237/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0083 - accuracy: 0.1557 - val_loss: 5.8768 - val_accuracy: 0.1321\n",
      "Epoch 238/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0069 - accuracy: 0.1107 - val_loss: 5.8738 - val_accuracy: 0.1275\n",
      "Epoch 239/1000\n",
      "5600/5600 [==============================] - 0s 60us/sample - loss: 6.0063 - accuracy: 0.1216 - val_loss: 5.8743 - val_accuracy: 0.1329\n",
      "Epoch 240/1000\n",
      "5600/5600 [==============================] - 0s 69us/sample - loss: 6.0059 - accuracy: 0.0971 - val_loss: 5.8746 - val_accuracy: 0.1183\n",
      "Epoch 241/1000\n",
      "5600/5600 [==============================] - 0s 79us/sample - loss: 6.0065 - accuracy: 0.0918 - val_loss: 5.8741 - val_accuracy: 0.0900\n",
      "Epoch 242/1000\n",
      "5600/5600 [==============================] - 0s 71us/sample - loss: 6.0053 - accuracy: 0.0655 - val_loss: 5.8737 - val_accuracy: 0.0696\n",
      "Epoch 243/1000\n",
      "5600/5600 [==============================] - 0s 66us/sample - loss: 6.0048 - accuracy: 0.0879 - val_loss: 5.8761 - val_accuracy: 0.1213\n",
      "Epoch 244/1000\n",
      "5600/5600 [==============================] - 0s 69us/sample - loss: 6.0052 - accuracy: 0.1154 - val_loss: 5.8735 - val_accuracy: 0.1171\n",
      "Epoch 245/1000\n",
      "5600/5600 [==============================] - 0s 62us/sample - loss: 6.0042 - accuracy: 0.0925 - val_loss: 5.8743 - val_accuracy: 0.0900\n",
      "Epoch 246/1000\n",
      "5600/5600 [==============================] - 0s 64us/sample - loss: 6.0045 - accuracy: 0.0730 - val_loss: 5.8738 - val_accuracy: 0.0725\n",
      "Epoch 247/1000\n",
      "5600/5600 [==============================] - 0s 65us/sample - loss: 6.0036 - accuracy: 0.0675 - val_loss: 5.8739 - val_accuracy: 0.0842\n",
      "Epoch 248/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0040 - accuracy: 0.0855 - val_loss: 5.8737 - val_accuracy: 0.0946\n",
      "Epoch 249/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0031 - accuracy: 0.0684 - val_loss: 5.8731 - val_accuracy: 0.0617\n",
      "Epoch 250/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0020 - accuracy: 0.0614 - val_loss: 5.8740 - val_accuracy: 0.1233\n",
      "Epoch 251/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 6.0026 - accuracy: 0.1048 - val_loss: 5.8724 - val_accuracy: 0.1262\n",
      "Epoch 252/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.0016 - accuracy: 0.1000 - val_loss: 5.8740 - val_accuracy: 0.1163\n",
      "Epoch 253/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 6.0011 - accuracy: 0.0961 - val_loss: 5.8747 - val_accuracy: 0.1075\n",
      "Epoch 254/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.0006 - accuracy: 0.1048 - val_loss: 5.8752 - val_accuracy: 0.1429\n",
      "Epoch 255/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.0012 - accuracy: 0.1266 - val_loss: 5.8757 - val_accuracy: 0.1196\n",
      "Epoch 256/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 6.0003 - accuracy: 0.1023 - val_loss: 5.8731 - val_accuracy: 0.1183\n",
      "Epoch 257/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9995 - accuracy: 0.0898 - val_loss: 5.8749 - val_accuracy: 0.0854\n",
      "Epoch 258/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 6.0001 - accuracy: 0.0689 - val_loss: 5.8728 - val_accuracy: 0.1175\n",
      "Epoch 259/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9991 - accuracy: 0.1327 - val_loss: 5.8735 - val_accuracy: 0.1112\n",
      "Epoch 260/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9987 - accuracy: 0.1109 - val_loss: 5.8717 - val_accuracy: 0.1625\n",
      "Epoch 261/1000\n",
      "5600/5600 [==============================] - 0s 61us/sample - loss: 5.9986 - accuracy: 0.1607 - val_loss: 5.8725 - val_accuracy: 0.1450\n",
      "Epoch 262/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9981 - accuracy: 0.0968 - val_loss: 5.8736 - val_accuracy: 0.1446\n",
      "Epoch 263/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9969 - accuracy: 0.1234 - val_loss: 5.8753 - val_accuracy: 0.1221\n",
      "Epoch 264/1000\n",
      "5600/5600 [==============================] - 0s 60us/sample - loss: 5.9988 - accuracy: 0.1186 - val_loss: 5.8730 - val_accuracy: 0.1604\n",
      "Epoch 265/1000\n",
      "5600/5600 [==============================] - 0s 64us/sample - loss: 5.9970 - accuracy: 0.1475 - val_loss: 5.8721 - val_accuracy: 0.1238\n",
      "Epoch 266/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9981 - accuracy: 0.1138 - val_loss: 5.8737 - val_accuracy: 0.1396\n",
      "Epoch 267/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 60us/sample - loss: 5.9974 - accuracy: 0.1416 - val_loss: 5.8731 - val_accuracy: 0.1371\n",
      "Epoch 268/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9963 - accuracy: 0.1202 - val_loss: 5.8722 - val_accuracy: 0.1279\n",
      "Epoch 269/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9965 - accuracy: 0.1164 - val_loss: 5.8718 - val_accuracy: 0.1412\n",
      "Epoch 270/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9959 - accuracy: 0.1489 - val_loss: 5.8730 - val_accuracy: 0.1733\n",
      "Epoch 271/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9970 - accuracy: 0.1502 - val_loss: 5.8717 - val_accuracy: 0.1688\n",
      "Epoch 272/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9958 - accuracy: 0.1527 - val_loss: 5.8722 - val_accuracy: 0.1771\n",
      "Epoch 273/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9947 - accuracy: 0.1557 - val_loss: 5.8722 - val_accuracy: 0.1325\n",
      "Epoch 274/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9940 - accuracy: 0.1164 - val_loss: 5.8763 - val_accuracy: 0.1179\n",
      "Epoch 275/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9952 - accuracy: 0.0975 - val_loss: 5.8738 - val_accuracy: 0.0971\n",
      "Epoch 276/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9945 - accuracy: 0.0948 - val_loss: 5.8759 - val_accuracy: 0.0962\n",
      "Epoch 277/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9947 - accuracy: 0.1063 - val_loss: 5.8735 - val_accuracy: 0.1338\n",
      "Epoch 278/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9940 - accuracy: 0.0962 - val_loss: 5.8744 - val_accuracy: 0.1042\n",
      "Epoch 279/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9936 - accuracy: 0.1293 - val_loss: 5.8750 - val_accuracy: 0.1317\n",
      "Epoch 280/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9937 - accuracy: 0.0932 - val_loss: 5.8740 - val_accuracy: 0.0958\n",
      "Epoch 281/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9940 - accuracy: 0.0998 - val_loss: 5.8722 - val_accuracy: 0.1279\n",
      "Epoch 282/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9936 - accuracy: 0.1159 - val_loss: 5.8735 - val_accuracy: 0.1208\n",
      "Epoch 283/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9933 - accuracy: 0.0907 - val_loss: 5.8729 - val_accuracy: 0.0962\n",
      "Epoch 284/1000\n",
      "5600/5600 [==============================] - 0s 63us/sample - loss: 5.9923 - accuracy: 0.0900 - val_loss: 5.8756 - val_accuracy: 0.1325\n",
      "Epoch 285/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9920 - accuracy: 0.1468 - val_loss: 5.8754 - val_accuracy: 0.1700\n",
      "Epoch 286/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9922 - accuracy: 0.1521 - val_loss: 5.8759 - val_accuracy: 0.1142\n",
      "Epoch 287/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9918 - accuracy: 0.0986 - val_loss: 5.8759 - val_accuracy: 0.1067\n",
      "Epoch 288/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9910 - accuracy: 0.1354 - val_loss: 5.8741 - val_accuracy: 0.1317\n",
      "Epoch 289/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9907 - accuracy: 0.0979 - val_loss: 5.8742 - val_accuracy: 0.1071\n",
      "Epoch 290/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9903 - accuracy: 0.0889 - val_loss: 5.8748 - val_accuracy: 0.1283\n",
      "Epoch 291/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9904 - accuracy: 0.1259 - val_loss: 5.8764 - val_accuracy: 0.1138\n",
      "Epoch 292/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9904 - accuracy: 0.0914 - val_loss: 5.8727 - val_accuracy: 0.1092\n",
      "Epoch 293/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9908 - accuracy: 0.0784 - val_loss: 5.8739 - val_accuracy: 0.0775\n",
      "Epoch 294/1000\n",
      "5600/5600 [==============================] - 0s 67us/sample - loss: 5.9898 - accuracy: 0.0846 - val_loss: 5.8740 - val_accuracy: 0.1375\n",
      "Epoch 295/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9901 - accuracy: 0.1118 - val_loss: 5.8731 - val_accuracy: 0.1367\n",
      "Epoch 296/1000\n",
      "5600/5600 [==============================] - 0s 62us/sample - loss: 5.9890 - accuracy: 0.1036 - val_loss: 5.8753 - val_accuracy: 0.1021\n",
      "Epoch 297/1000\n",
      "5600/5600 [==============================] - 0s 66us/sample - loss: 5.9889 - accuracy: 0.1084 - val_loss: 5.8778 - val_accuracy: 0.1163\n",
      "Epoch 298/1000\n",
      "5600/5600 [==============================] - 0s 60us/sample - loss: 5.9887 - accuracy: 0.0900 - val_loss: 5.8745 - val_accuracy: 0.1125\n",
      "Epoch 299/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9889 - accuracy: 0.1016 - val_loss: 5.8769 - val_accuracy: 0.1100\n",
      "Epoch 300/1000\n",
      "5600/5600 [==============================] - 0s 64us/sample - loss: 5.9886 - accuracy: 0.1002 - val_loss: 5.8745 - val_accuracy: 0.1246\n",
      "Epoch 301/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9884 - accuracy: 0.1498 - val_loss: 5.8754 - val_accuracy: 0.1483\n",
      "Epoch 302/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9879 - accuracy: 0.1184 - val_loss: 5.8758 - val_accuracy: 0.1279\n",
      "Epoch 303/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9881 - accuracy: 0.1193 - val_loss: 5.8755 - val_accuracy: 0.1258\n",
      "Epoch 304/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9872 - accuracy: 0.1207 - val_loss: 5.8750 - val_accuracy: 0.1533\n",
      "Epoch 305/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9869 - accuracy: 0.1179 - val_loss: 5.8760 - val_accuracy: 0.1154\n",
      "Epoch 306/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9868 - accuracy: 0.0920 - val_loss: 5.8763 - val_accuracy: 0.1071\n",
      "Epoch 307/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9867 - accuracy: 0.0914 - val_loss: 5.8746 - val_accuracy: 0.1171\n",
      "Epoch 308/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9859 - accuracy: 0.0923 - val_loss: 5.8766 - val_accuracy: 0.1283\n",
      "Epoch 309/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9865 - accuracy: 0.0843 - val_loss: 5.8768 - val_accuracy: 0.0950\n",
      "Epoch 310/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9858 - accuracy: 0.0782 - val_loss: 5.8744 - val_accuracy: 0.1171\n",
      "Epoch 311/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9860 - accuracy: 0.0955 - val_loss: 5.8767 - val_accuracy: 0.1042\n",
      "Epoch 312/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9862 - accuracy: 0.1061 - val_loss: 5.8753 - val_accuracy: 0.1437\n",
      "Epoch 313/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9849 - accuracy: 0.1457 - val_loss: 5.8753 - val_accuracy: 0.1437\n",
      "Epoch 314/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9852 - accuracy: 0.1509 - val_loss: 5.8784 - val_accuracy: 0.1513\n",
      "Epoch 315/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9854 - accuracy: 0.1282 - val_loss: 5.8762 - val_accuracy: 0.1379\n",
      "Epoch 316/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9851 - accuracy: 0.0816 - val_loss: 5.8767 - val_accuracy: 0.0662\n",
      "Epoch 317/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9848 - accuracy: 0.1027 - val_loss: 5.8762 - val_accuracy: 0.1338\n",
      "Epoch 318/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9841 - accuracy: 0.0945 - val_loss: 5.8762 - val_accuracy: 0.0933\n",
      "Epoch 319/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9842 - accuracy: 0.0902 - val_loss: 5.8777 - val_accuracy: 0.1371\n",
      "Epoch 320/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9836 - accuracy: 0.1161 - val_loss: 5.8762 - val_accuracy: 0.1271\n",
      "Epoch 321/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9831 - accuracy: 0.1182 - val_loss: 5.8761 - val_accuracy: 0.1363\n",
      "Epoch 322/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9829 - accuracy: 0.1338 - val_loss: 5.8770 - val_accuracy: 0.1412\n",
      "Epoch 323/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9833 - accuracy: 0.1220 - val_loss: 5.8776 - val_accuracy: 0.1142\n",
      "Epoch 324/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9824 - accuracy: 0.1405 - val_loss: 5.8770 - val_accuracy: 0.1479\n",
      "Epoch 325/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9830 - accuracy: 0.1396 - val_loss: 5.8769 - val_accuracy: 0.1296\n",
      "Epoch 326/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9818 - accuracy: 0.1164 - val_loss: 5.8767 - val_accuracy: 0.1304\n",
      "Epoch 327/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9825 - accuracy: 0.1229 - val_loss: 5.8770 - val_accuracy: 0.1250\n",
      "Epoch 328/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9815 - accuracy: 0.1130 - val_loss: 5.8769 - val_accuracy: 0.1300\n",
      "Epoch 329/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9823 - accuracy: 0.1282 - val_loss: 5.8785 - val_accuracy: 0.1254\n",
      "Epoch 330/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9816 - accuracy: 0.1227 - val_loss: 5.8768 - val_accuracy: 0.1579\n",
      "Epoch 331/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9811 - accuracy: 0.1582 - val_loss: 5.8791 - val_accuracy: 0.1437\n",
      "Epoch 332/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9808 - accuracy: 0.1523 - val_loss: 5.8771 - val_accuracy: 0.1437\n",
      "Epoch 333/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9811 - accuracy: 0.1488 - val_loss: 5.8785 - val_accuracy: 0.1500\n",
      "Epoch 334/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9802 - accuracy: 0.1227 - val_loss: 5.8774 - val_accuracy: 0.1292\n",
      "Epoch 335/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9804 - accuracy: 0.1029 - val_loss: 5.8775 - val_accuracy: 0.1350\n",
      "Epoch 336/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9796 - accuracy: 0.1296 - val_loss: 5.8773 - val_accuracy: 0.1300\n",
      "Epoch 337/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9796 - accuracy: 0.1095 - val_loss: 5.8775 - val_accuracy: 0.1229\n",
      "Epoch 338/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9795 - accuracy: 0.0816 - val_loss: 5.8779 - val_accuracy: 0.1063\n",
      "Epoch 339/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9785 - accuracy: 0.1123 - val_loss: 5.8776 - val_accuracy: 0.1163\n",
      "Epoch 340/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9792 - accuracy: 0.1395 - val_loss: 5.8798 - val_accuracy: 0.1500\n",
      "Epoch 341/1000\n",
      "5600/5600 [==============================] - 0s 60us/sample - loss: 5.9784 - accuracy: 0.1538 - val_loss: 5.8775 - val_accuracy: 0.1679\n",
      "Epoch 342/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9786 - accuracy: 0.1657 - val_loss: 5.8780 - val_accuracy: 0.1538\n",
      "Epoch 343/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9780 - accuracy: 0.1770 - val_loss: 5.8781 - val_accuracy: 0.1388\n",
      "Epoch 344/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9787 - accuracy: 0.0954 - val_loss: 5.8783 - val_accuracy: 0.1167\n",
      "Epoch 345/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9779 - accuracy: 0.1416 - val_loss: 5.8796 - val_accuracy: 0.1642\n",
      "Epoch 346/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9776 - accuracy: 0.1821 - val_loss: 5.8791 - val_accuracy: 0.1937\n",
      "Epoch 347/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9769 - accuracy: 0.1379 - val_loss: 5.8790 - val_accuracy: 0.1262\n",
      "Epoch 348/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9773 - accuracy: 0.1039 - val_loss: 5.8801 - val_accuracy: 0.0879\n",
      "Epoch 349/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9763 - accuracy: 0.0913 - val_loss: 5.8790 - val_accuracy: 0.1521\n",
      "Epoch 350/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9772 - accuracy: 0.1443 - val_loss: 5.8785 - val_accuracy: 0.1688\n",
      "Epoch 351/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9773 - accuracy: 0.1559 - val_loss: 5.8788 - val_accuracy: 0.1500\n",
      "Epoch 352/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9765 - accuracy: 0.1577 - val_loss: 5.8789 - val_accuracy: 0.2025\n",
      "Epoch 353/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9757 - accuracy: 0.1879 - val_loss: 5.8796 - val_accuracy: 0.1742\n",
      "Epoch 354/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9765 - accuracy: 0.1611 - val_loss: 5.8794 - val_accuracy: 0.1612\n",
      "Epoch 355/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9755 - accuracy: 0.1341 - val_loss: 5.8811 - val_accuracy: 0.1108\n",
      "Epoch 356/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9754 - accuracy: 0.1257 - val_loss: 5.8797 - val_accuracy: 0.1371\n",
      "Epoch 357/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9747 - accuracy: 0.1321 - val_loss: 5.8793 - val_accuracy: 0.1750\n",
      "Epoch 358/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9751 - accuracy: 0.1320 - val_loss: 5.8807 - val_accuracy: 0.1554\n",
      "Epoch 359/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9749 - accuracy: 0.1643 - val_loss: 5.8792 - val_accuracy: 0.2142\n",
      "Epoch 360/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9745 - accuracy: 0.1718 - val_loss: 5.8797 - val_accuracy: 0.1346\n",
      "Epoch 361/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9740 - accuracy: 0.1207 - val_loss: 5.8795 - val_accuracy: 0.1346\n",
      "Epoch 362/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9741 - accuracy: 0.1118 - val_loss: 5.8807 - val_accuracy: 0.1138\n",
      "Epoch 363/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9744 - accuracy: 0.1154 - val_loss: 5.8806 - val_accuracy: 0.1325\n",
      "Epoch 364/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9735 - accuracy: 0.1307 - val_loss: 5.8798 - val_accuracy: 0.1492\n",
      "Epoch 365/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9727 - accuracy: 0.1363 - val_loss: 5.8794 - val_accuracy: 0.1500\n",
      "Epoch 366/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9730 - accuracy: 0.1559 - val_loss: 5.8798 - val_accuracy: 0.1154\n",
      "Epoch 367/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9726 - accuracy: 0.1013 - val_loss: 5.8810 - val_accuracy: 0.1233\n",
      "Epoch 368/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9729 - accuracy: 0.1432 - val_loss: 5.8806 - val_accuracy: 0.1446\n",
      "Epoch 369/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9733 - accuracy: 0.1316 - val_loss: 5.8811 - val_accuracy: 0.1254\n",
      "Epoch 370/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9727 - accuracy: 0.1189 - val_loss: 5.8808 - val_accuracy: 0.1233\n",
      "Epoch 371/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9711 - accuracy: 0.1111 - val_loss: 5.8826 - val_accuracy: 0.1150\n",
      "Epoch 372/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9725 - accuracy: 0.1173 - val_loss: 5.8807 - val_accuracy: 0.1167\n",
      "Epoch 373/1000\n",
      "5600/5600 [==============================] - 0s 64us/sample - loss: 5.9722 - accuracy: 0.0893 - val_loss: 5.8807 - val_accuracy: 0.1138\n",
      "Epoch 374/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9721 - accuracy: 0.0959 - val_loss: 5.8813 - val_accuracy: 0.0679\n",
      "Epoch 375/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 70us/sample - loss: 5.9708 - accuracy: 0.1014 - val_loss: 5.8804 - val_accuracy: 0.1433\n",
      "Epoch 376/1000\n",
      "5600/5600 [==============================] - 0s 63us/sample - loss: 5.9716 - accuracy: 0.1357 - val_loss: 5.8809 - val_accuracy: 0.1625\n",
      "Epoch 377/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9706 - accuracy: 0.1596 - val_loss: 5.8805 - val_accuracy: 0.1633\n",
      "Epoch 378/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9714 - accuracy: 0.1520 - val_loss: 5.8805 - val_accuracy: 0.1596\n",
      "Epoch 379/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9709 - accuracy: 0.1525 - val_loss: 5.8807 - val_accuracy: 0.1529\n",
      "Epoch 380/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9702 - accuracy: 0.1068 - val_loss: 5.8812 - val_accuracy: 0.1067\n",
      "Epoch 381/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9707 - accuracy: 0.0977 - val_loss: 5.8808 - val_accuracy: 0.1279\n",
      "Epoch 382/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9697 - accuracy: 0.1275 - val_loss: 5.8817 - val_accuracy: 0.1383\n",
      "Epoch 383/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9695 - accuracy: 0.1325 - val_loss: 5.8814 - val_accuracy: 0.1433\n",
      "Epoch 384/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9688 - accuracy: 0.1171 - val_loss: 5.8812 - val_accuracy: 0.1229\n",
      "Epoch 385/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9691 - accuracy: 0.0946 - val_loss: 5.8813 - val_accuracy: 0.1125\n",
      "Epoch 386/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9697 - accuracy: 0.1034 - val_loss: 5.8809 - val_accuracy: 0.1179\n",
      "Epoch 387/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9690 - accuracy: 0.1304 - val_loss: 5.8812 - val_accuracy: 0.1379\n",
      "Epoch 388/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9687 - accuracy: 0.1389 - val_loss: 5.8812 - val_accuracy: 0.1404\n",
      "Epoch 389/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9679 - accuracy: 0.1405 - val_loss: 5.8816 - val_accuracy: 0.1496\n",
      "Epoch 390/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9686 - accuracy: 0.1484 - val_loss: 5.8821 - val_accuracy: 0.1592\n",
      "Epoch 391/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9665 - accuracy: 0.1686 - val_loss: 5.8838 - val_accuracy: 0.1787\n",
      "Epoch 392/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9684 - accuracy: 0.1298 - val_loss: 5.8818 - val_accuracy: 0.1363\n",
      "Epoch 393/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9661 - accuracy: 0.1393 - val_loss: 5.8835 - val_accuracy: 0.1179\n",
      "Epoch 394/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9674 - accuracy: 0.1109 - val_loss: 5.8834 - val_accuracy: 0.1379\n",
      "Epoch 395/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9677 - accuracy: 0.1323 - val_loss: 5.8832 - val_accuracy: 0.1417\n",
      "Epoch 396/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9670 - accuracy: 0.1186 - val_loss: 5.8825 - val_accuracy: 0.1254\n",
      "Epoch 397/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9669 - accuracy: 0.1393 - val_loss: 5.8824 - val_accuracy: 0.1600\n",
      "Epoch 398/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9664 - accuracy: 0.1262 - val_loss: 5.8839 - val_accuracy: 0.1163\n",
      "Epoch 399/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9662 - accuracy: 0.1145 - val_loss: 5.8846 - val_accuracy: 0.1333\n",
      "Epoch 400/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9654 - accuracy: 0.1513 - val_loss: 5.8826 - val_accuracy: 0.1908\n",
      "Epoch 401/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9658 - accuracy: 0.1880 - val_loss: 5.8836 - val_accuracy: 0.1912\n",
      "Epoch 402/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9662 - accuracy: 0.1771 - val_loss: 5.8878 - val_accuracy: 0.1621\n",
      "Epoch 403/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9662 - accuracy: 0.1621 - val_loss: 5.8833 - val_accuracy: 0.1688\n",
      "Epoch 404/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9656 - accuracy: 0.1477 - val_loss: 5.8832 - val_accuracy: 0.1550\n",
      "Epoch 405/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9647 - accuracy: 0.1457 - val_loss: 5.8835 - val_accuracy: 0.1437\n",
      "Epoch 406/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9652 - accuracy: 0.1382 - val_loss: 5.8832 - val_accuracy: 0.1525\n",
      "Epoch 407/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9651 - accuracy: 0.1623 - val_loss: 5.8834 - val_accuracy: 0.1421\n",
      "Epoch 408/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9649 - accuracy: 0.1439 - val_loss: 5.8840 - val_accuracy: 0.1558\n",
      "Epoch 409/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9648 - accuracy: 0.1238 - val_loss: 5.8839 - val_accuracy: 0.1321\n",
      "Epoch 410/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9643 - accuracy: 0.1277 - val_loss: 5.8834 - val_accuracy: 0.1575\n",
      "Epoch 411/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9637 - accuracy: 0.1461 - val_loss: 5.8832 - val_accuracy: 0.1242\n",
      "Epoch 412/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9651 - accuracy: 0.1195 - val_loss: 5.8845 - val_accuracy: 0.0954\n",
      "Epoch 413/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9642 - accuracy: 0.1070 - val_loss: 5.8836 - val_accuracy: 0.1708\n",
      "Epoch 414/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9654 - accuracy: 0.1564 - val_loss: 5.8843 - val_accuracy: 0.1292\n",
      "Epoch 415/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9630 - accuracy: 0.1116 - val_loss: 5.8852 - val_accuracy: 0.1229\n",
      "Epoch 416/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9653 - accuracy: 0.1637 - val_loss: 5.8845 - val_accuracy: 0.1650\n",
      "Epoch 417/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9632 - accuracy: 0.1536 - val_loss: 5.8850 - val_accuracy: 0.1629\n",
      "Epoch 418/1000\n",
      "5600/5600 [==============================] - 0s 62us/sample - loss: 5.9625 - accuracy: 0.1871 - val_loss: 5.8846 - val_accuracy: 0.1975\n",
      "Epoch 419/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9630 - accuracy: 0.1996 - val_loss: 5.8848 - val_accuracy: 0.1696\n",
      "Epoch 420/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9618 - accuracy: 0.1754 - val_loss: 5.8848 - val_accuracy: 0.1621\n",
      "Epoch 421/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9627 - accuracy: 0.1784 - val_loss: 5.8852 - val_accuracy: 0.1813\n",
      "Epoch 422/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9620 - accuracy: 0.1580 - val_loss: 5.8853 - val_accuracy: 0.1679\n",
      "Epoch 423/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9620 - accuracy: 0.1625 - val_loss: 5.8856 - val_accuracy: 0.1887\n",
      "Epoch 424/1000\n",
      "5600/5600 [==============================] - 0s 61us/sample - loss: 5.9605 - accuracy: 0.1446 - val_loss: 5.8899 - val_accuracy: 0.1354\n",
      "Epoch 425/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9622 - accuracy: 0.1845 - val_loss: 5.8855 - val_accuracy: 0.2104\n",
      "Epoch 426/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9616 - accuracy: 0.2023 - val_loss: 5.8853 - val_accuracy: 0.2467\n",
      "Epoch 427/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9609 - accuracy: 0.2529 - val_loss: 5.8854 - val_accuracy: 0.2338\n",
      "Epoch 428/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9612 - accuracy: 0.1955 - val_loss: 5.8854 - val_accuracy: 0.1558\n",
      "Epoch 429/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9607 - accuracy: 0.1598 - val_loss: 5.8863 - val_accuracy: 0.1754\n",
      "Epoch 430/1000\n",
      "5600/5600 [==============================] - 0s 60us/sample - loss: 5.9602 - accuracy: 0.1893 - val_loss: 5.8860 - val_accuracy: 0.1875\n",
      "Epoch 431/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9609 - accuracy: 0.1871 - val_loss: 5.8846 - val_accuracy: 0.1758\n",
      "Epoch 432/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9610 - accuracy: 0.1384 - val_loss: 5.8850 - val_accuracy: 0.1287\n",
      "Epoch 433/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9603 - accuracy: 0.1432 - val_loss: 5.8847 - val_accuracy: 0.1621\n",
      "Epoch 434/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9599 - accuracy: 0.2155 - val_loss: 5.8853 - val_accuracy: 0.2467\n",
      "Epoch 435/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9599 - accuracy: 0.2457 - val_loss: 5.8857 - val_accuracy: 0.2237\n",
      "Epoch 436/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9590 - accuracy: 0.2079 - val_loss: 5.8873 - val_accuracy: 0.1825\n",
      "Epoch 437/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9601 - accuracy: 0.1839 - val_loss: 5.8852 - val_accuracy: 0.1813\n",
      "Epoch 438/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9591 - accuracy: 0.1898 - val_loss: 5.8855 - val_accuracy: 0.2142\n",
      "Epoch 439/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9600 - accuracy: 0.2600 - val_loss: 5.8855 - val_accuracy: 0.2533\n",
      "Epoch 440/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9582 - accuracy: 0.2284 - val_loss: 5.8857 - val_accuracy: 0.2100\n",
      "Epoch 441/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9585 - accuracy: 0.2084 - val_loss: 5.8854 - val_accuracy: 0.1483\n",
      "Epoch 442/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9584 - accuracy: 0.1366 - val_loss: 5.8860 - val_accuracy: 0.1296\n",
      "Epoch 443/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9580 - accuracy: 0.1446 - val_loss: 5.8866 - val_accuracy: 0.1567\n",
      "Epoch 444/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9580 - accuracy: 0.1764 - val_loss: 5.8866 - val_accuracy: 0.2008\n",
      "Epoch 445/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9576 - accuracy: 0.2657 - val_loss: 5.8860 - val_accuracy: 0.3229\n",
      "Epoch 446/1000\n",
      "5600/5600 [==============================] - 0s 60us/sample - loss: 5.9579 - accuracy: 0.3139 - val_loss: 5.8871 - val_accuracy: 0.2333\n",
      "Epoch 447/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9583 - accuracy: 0.2339 - val_loss: 5.8871 - val_accuracy: 0.2117\n",
      "Epoch 448/1000\n",
      "5600/5600 [==============================] - 0s 60us/sample - loss: 5.9564 - accuracy: 0.2100 - val_loss: 5.8875 - val_accuracy: 0.1879\n",
      "Epoch 449/1000\n",
      "5600/5600 [==============================] - 0s 62us/sample - loss: 5.9568 - accuracy: 0.1661 - val_loss: 5.8867 - val_accuracy: 0.1604\n",
      "Epoch 450/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9569 - accuracy: 0.1609 - val_loss: 5.8867 - val_accuracy: 0.1617\n",
      "Epoch 451/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9565 - accuracy: 0.1946 - val_loss: 5.8879 - val_accuracy: 0.2017\n",
      "Epoch 452/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9580 - accuracy: 0.2257 - val_loss: 5.8870 - val_accuracy: 0.2054\n",
      "Epoch 453/1000\n",
      "5600/5600 [==============================] - 0s 60us/sample - loss: 5.9566 - accuracy: 0.2532 - val_loss: 5.8869 - val_accuracy: 0.2679\n",
      "Epoch 454/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9575 - accuracy: 0.2627 - val_loss: 5.8865 - val_accuracy: 0.2483\n",
      "Epoch 455/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9567 - accuracy: 0.3030 - val_loss: 5.8867 - val_accuracy: 0.2800\n",
      "Epoch 456/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9563 - accuracy: 0.2689 - val_loss: 5.8868 - val_accuracy: 0.1833\n",
      "Epoch 457/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9559 - accuracy: 0.1916 - val_loss: 5.8872 - val_accuracy: 0.1729\n",
      "Epoch 458/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9558 - accuracy: 0.1657 - val_loss: 5.8874 - val_accuracy: 0.1600\n",
      "Epoch 459/1000\n",
      "5600/5600 [==============================] - 0s 59us/sample - loss: 5.9555 - accuracy: 0.2125 - val_loss: 5.8883 - val_accuracy: 0.2054\n",
      "Epoch 460/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9554 - accuracy: 0.2279 - val_loss: 5.8880 - val_accuracy: 0.2113\n",
      "Epoch 461/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9546 - accuracy: 0.2241 - val_loss: 5.8886 - val_accuracy: 0.1975\n",
      "Epoch 462/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9551 - accuracy: 0.2218 - val_loss: 5.8876 - val_accuracy: 0.1908\n",
      "Epoch 463/1000\n",
      "5600/5600 [==============================] - 0s 61us/sample - loss: 5.9537 - accuracy: 0.2391 - val_loss: 5.8880 - val_accuracy: 0.2579\n",
      "Epoch 464/1000\n",
      "5600/5600 [==============================] - 0s 74us/sample - loss: 5.9550 - accuracy: 0.2484 - val_loss: 5.8875 - val_accuracy: 0.2679\n",
      "Epoch 465/1000\n",
      "5600/5600 [==============================] - 0s 67us/sample - loss: 5.9539 - accuracy: 0.2477 - val_loss: 5.8885 - val_accuracy: 0.2479\n",
      "Epoch 466/1000\n",
      "5600/5600 [==============================] - 0s 65us/sample - loss: 5.9535 - accuracy: 0.2514 - val_loss: 5.8874 - val_accuracy: 0.2742\n",
      "Epoch 467/1000\n",
      "5600/5600 [==============================] - 1s 138us/sample - loss: 5.9539 - accuracy: 0.2948 - val_loss: 5.8877 - val_accuracy: 0.2758\n",
      "Epoch 468/1000\n",
      "5600/5600 [==============================] - 0s 63us/sample - loss: 5.9542 - accuracy: 0.2668 - val_loss: 5.8880 - val_accuracy: 0.2308\n",
      "Epoch 469/1000\n",
      "5600/5600 [==============================] - 0s 60us/sample - loss: 5.9540 - accuracy: 0.2091 - val_loss: 5.8882 - val_accuracy: 0.2121\n",
      "Epoch 470/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9536 - accuracy: 0.2798 - val_loss: 5.8887 - val_accuracy: 0.2738\n",
      "Epoch 471/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9530 - accuracy: 0.2157 - val_loss: 5.8880 - val_accuracy: 0.1171\n",
      "Epoch 472/1000\n",
      "5600/5600 [==============================] - 0s 58us/sample - loss: 5.9524 - accuracy: 0.1937 - val_loss: 5.8876 - val_accuracy: 0.2096\n",
      "Epoch 473/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9528 - accuracy: 0.2257 - val_loss: 5.8881 - val_accuracy: 0.2242\n",
      "Epoch 474/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9523 - accuracy: 0.1779 - val_loss: 5.8883 - val_accuracy: 0.2046\n",
      "Epoch 475/1000\n",
      "5600/5600 [==============================] - 0s 57us/sample - loss: 5.9536 - accuracy: 0.2298 - val_loss: 5.8880 - val_accuracy: 0.2050\n",
      "Epoch 476/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9520 - accuracy: 0.1727 - val_loss: 5.8896 - val_accuracy: 0.2046\n",
      "Epoch 477/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9506 - accuracy: 0.1970 - val_loss: 5.8885 - val_accuracy: 0.1771\n",
      "Epoch 478/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9513 - accuracy: 0.2034 - val_loss: 5.8885 - val_accuracy: 0.1846\n",
      "Epoch 479/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9509 - accuracy: 0.2654 - val_loss: 5.8881 - val_accuracy: 0.2258\n",
      "Epoch 480/1000\n",
      "5600/5600 [==============================] - 0s 54us/sample - loss: 5.9519 - accuracy: 0.2632 - val_loss: 5.8879 - val_accuracy: 0.2396\n",
      "Epoch 481/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9512 - accuracy: 0.2627 - val_loss: 5.8889 - val_accuracy: 0.2442\n",
      "Epoch 482/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9517 - accuracy: 0.2536 - val_loss: 5.8884 - val_accuracy: 0.2829\n",
      "Epoch 483/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9511 - accuracy: 0.2354 - val_loss: 5.8892 - val_accuracy: 0.1787\n",
      "Epoch 484/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9513 - accuracy: 0.1655 - val_loss: 5.8884 - val_accuracy: 0.1579\n",
      "Epoch 485/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9502 - accuracy: 0.2043 - val_loss: 5.8888 - val_accuracy: 0.1621\n",
      "Epoch 486/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9503 - accuracy: 0.1680 - val_loss: 5.8893 - val_accuracy: 0.1821\n",
      "Epoch 487/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9507 - accuracy: 0.2075 - val_loss: 5.8886 - val_accuracy: 0.1917\n",
      "Epoch 488/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9506 - accuracy: 0.2387 - val_loss: 5.8892 - val_accuracy: 0.1729\n",
      "Epoch 489/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9486 - accuracy: 0.1805 - val_loss: 5.8891 - val_accuracy: 0.1538\n",
      "Epoch 490/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9504 - accuracy: 0.1877 - val_loss: 5.8888 - val_accuracy: 0.2746\n",
      "Epoch 491/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9497 - accuracy: 0.2746 - val_loss: 5.8898 - val_accuracy: 0.2275\n",
      "Epoch 492/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9498 - accuracy: 0.2750 - val_loss: 5.8884 - val_accuracy: 0.2604\n",
      "Epoch 493/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9498 - accuracy: 0.2486 - val_loss: 5.8896 - val_accuracy: 0.2317\n",
      "Epoch 494/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9494 - accuracy: 0.2880 - val_loss: 5.8884 - val_accuracy: 0.2808\n",
      "Epoch 495/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9487 - accuracy: 0.2466 - val_loss: 5.8894 - val_accuracy: 0.2517\n",
      "Epoch 496/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9494 - accuracy: 0.2879 - val_loss: 5.8883 - val_accuracy: 0.2733\n",
      "Epoch 497/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9486 - accuracy: 0.2796 - val_loss: 5.8891 - val_accuracy: 0.3125\n",
      "Epoch 498/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9483 - accuracy: 0.2829 - val_loss: 5.8882 - val_accuracy: 0.2208\n",
      "Epoch 499/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9489 - accuracy: 0.2484 - val_loss: 5.8892 - val_accuracy: 0.2283\n",
      "Epoch 500/1000\n",
      "5600/5600 [==============================] - 0s 54us/sample - loss: 5.9480 - accuracy: 0.2164 - val_loss: 5.8893 - val_accuracy: 0.1942\n",
      "Epoch 501/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9484 - accuracy: 0.2298 - val_loss: 5.8897 - val_accuracy: 0.1733\n",
      "Epoch 502/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9486 - accuracy: 0.2409 - val_loss: 5.8896 - val_accuracy: 0.2646\n",
      "Epoch 503/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9485 - accuracy: 0.2704 - val_loss: 5.8894 - val_accuracy: 0.3321\n",
      "Epoch 504/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9477 - accuracy: 0.3298 - val_loss: 5.8897 - val_accuracy: 0.2908\n",
      "Epoch 505/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9469 - accuracy: 0.2723 - val_loss: 5.8896 - val_accuracy: 0.2721\n",
      "Epoch 506/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9462 - accuracy: 0.2796 - val_loss: 5.8919 - val_accuracy: 0.2837\n",
      "Epoch 507/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9470 - accuracy: 0.3302 - val_loss: 5.8896 - val_accuracy: 0.3075\n",
      "Epoch 508/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9467 - accuracy: 0.2807 - val_loss: 5.8900 - val_accuracy: 0.2283\n",
      "Epoch 509/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9478 - accuracy: 0.2216 - val_loss: 5.8898 - val_accuracy: 0.2392\n",
      "Epoch 510/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9458 - accuracy: 0.1986 - val_loss: 5.8917 - val_accuracy: 0.1887\n",
      "Epoch 511/1000\n",
      "5600/5600 [==============================] - 0s 53us/sample - loss: 5.9469 - accuracy: 0.2359 - val_loss: 5.8905 - val_accuracy: 0.2717\n",
      "Epoch 512/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9467 - accuracy: 0.3139 - val_loss: 5.8902 - val_accuracy: 0.3187\n",
      "Epoch 513/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9462 - accuracy: 0.2707 - val_loss: 5.8897 - val_accuracy: 0.1750\n",
      "Epoch 514/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9465 - accuracy: 0.2334 - val_loss: 5.8904 - val_accuracy: 0.2450\n",
      "Epoch 515/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9466 - accuracy: 0.2659 - val_loss: 5.8897 - val_accuracy: 0.2550\n",
      "Epoch 516/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9465 - accuracy: 0.2595 - val_loss: 5.8904 - val_accuracy: 0.2488\n",
      "Epoch 517/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9460 - accuracy: 0.3082 - val_loss: 5.8906 - val_accuracy: 0.3467\n",
      "Epoch 518/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9446 - accuracy: 0.3152 - val_loss: 5.8919 - val_accuracy: 0.2871\n",
      "Epoch 519/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9466 - accuracy: 0.3289 - val_loss: 5.8904 - val_accuracy: 0.3004\n",
      "Epoch 520/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9451 - accuracy: 0.3011 - val_loss: 5.8907 - val_accuracy: 0.2179\n",
      "Epoch 521/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9455 - accuracy: 0.2409 - val_loss: 5.8900 - val_accuracy: 0.2062\n",
      "Epoch 522/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9452 - accuracy: 0.2055 - val_loss: 5.8904 - val_accuracy: 0.1437\n",
      "Epoch 523/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9452 - accuracy: 0.1677 - val_loss: 5.8911 - val_accuracy: 0.1483\n",
      "Epoch 524/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9469 - accuracy: 0.2041 - val_loss: 5.8910 - val_accuracy: 0.2550\n",
      "Epoch 525/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9450 - accuracy: 0.3030 - val_loss: 5.8910 - val_accuracy: 0.2958\n",
      "Epoch 526/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9447 - accuracy: 0.2934 - val_loss: 5.8910 - val_accuracy: 0.3283\n",
      "Epoch 527/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9461 - accuracy: 0.3018 - val_loss: 5.8920 - val_accuracy: 0.2542\n",
      "Epoch 528/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9454 - accuracy: 0.3284 - val_loss: 5.8907 - val_accuracy: 0.3271\n",
      "Epoch 529/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9445 - accuracy: 0.3182 - val_loss: 5.8925 - val_accuracy: 0.3092\n",
      "Epoch 530/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9452 - accuracy: 0.2516 - val_loss: 5.8918 - val_accuracy: 0.2300\n",
      "Epoch 531/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9445 - accuracy: 0.2364 - val_loss: 5.8908 - val_accuracy: 0.1963\n",
      "Epoch 532/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9439 - accuracy: 0.2307 - val_loss: 5.8896 - val_accuracy: 0.1900\n",
      "Epoch 533/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9430 - accuracy: 0.2314 - val_loss: 5.8931 - val_accuracy: 0.1958\n",
      "Epoch 534/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9442 - accuracy: 0.1789 - val_loss: 5.8925 - val_accuracy: 0.1421\n",
      "Epoch 535/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9440 - accuracy: 0.2977 - val_loss: 5.8903 - val_accuracy: 0.3125\n",
      "Epoch 536/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9430 - accuracy: 0.2879 - val_loss: 5.8907 - val_accuracy: 0.3063\n",
      "Epoch 537/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9442 - accuracy: 0.2834 - val_loss: 5.8894 - val_accuracy: 0.2779\n",
      "Epoch 538/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9427 - accuracy: 0.2705 - val_loss: 5.8897 - val_accuracy: 0.2237\n",
      "Epoch 539/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9422 - accuracy: 0.1879 - val_loss: 5.8902 - val_accuracy: 0.1496\n",
      "Epoch 540/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9428 - accuracy: 0.2195 - val_loss: 5.8902 - val_accuracy: 0.2558\n",
      "Epoch 541/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9427 - accuracy: 0.3339 - val_loss: 5.8909 - val_accuracy: 0.3146\n",
      "Epoch 542/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9430 - accuracy: 0.3125 - val_loss: 5.8903 - val_accuracy: 0.2862\n",
      "Epoch 543/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9436 - accuracy: 0.3091 - val_loss: 5.8899 - val_accuracy: 0.2983\n",
      "Epoch 544/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9422 - accuracy: 0.3120 - val_loss: 5.8903 - val_accuracy: 0.3158\n",
      "Epoch 545/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9414 - accuracy: 0.3587 - val_loss: 5.8895 - val_accuracy: 0.3171\n",
      "Epoch 546/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9421 - accuracy: 0.2857 - val_loss: 5.8898 - val_accuracy: 0.3388\n",
      "Epoch 547/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9419 - accuracy: 0.2975 - val_loss: 5.8893 - val_accuracy: 0.2842\n",
      "Epoch 548/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9425 - accuracy: 0.3032 - val_loss: 5.8900 - val_accuracy: 0.2163\n",
      "Epoch 549/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9428 - accuracy: 0.2604 - val_loss: 5.8899 - val_accuracy: 0.2733\n",
      "Epoch 550/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9417 - accuracy: 0.2738 - val_loss: 5.8899 - val_accuracy: 0.3279\n",
      "Epoch 551/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9416 - accuracy: 0.2741 - val_loss: 5.8899 - val_accuracy: 0.2483\n",
      "Epoch 552/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9426 - accuracy: 0.2670 - val_loss: 5.8902 - val_accuracy: 0.2083\n",
      "Epoch 553/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9418 - accuracy: 0.2221 - val_loss: 5.8901 - val_accuracy: 0.2442\n",
      "Epoch 554/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9410 - accuracy: 0.3093 - val_loss: 5.8904 - val_accuracy: 0.3225\n",
      "Epoch 555/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9408 - accuracy: 0.3289 - val_loss: 5.8908 - val_accuracy: 0.3242\n",
      "Epoch 556/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9413 - accuracy: 0.3323 - val_loss: 5.8895 - val_accuracy: 0.2767\n",
      "Epoch 557/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9413 - accuracy: 0.2566 - val_loss: 5.8894 - val_accuracy: 0.2742\n",
      "Epoch 558/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9411 - accuracy: 0.2500 - val_loss: 5.8895 - val_accuracy: 0.1858\n",
      "Epoch 559/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9402 - accuracy: 0.3245 - val_loss: 5.8896 - val_accuracy: 0.3717\n",
      "Epoch 560/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9396 - accuracy: 0.2730 - val_loss: 5.8919 - val_accuracy: 0.2371\n",
      "Epoch 561/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9401 - accuracy: 0.3380 - val_loss: 5.8897 - val_accuracy: 0.3583\n",
      "Epoch 562/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9400 - accuracy: 0.3970 - val_loss: 5.8896 - val_accuracy: 0.3558\n",
      "Epoch 563/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9402 - accuracy: 0.3820 - val_loss: 5.8897 - val_accuracy: 0.3438\n",
      "Epoch 564/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9398 - accuracy: 0.3489 - val_loss: 5.8895 - val_accuracy: 0.3442\n",
      "Epoch 565/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9395 - accuracy: 0.3457 - val_loss: 5.8899 - val_accuracy: 0.3575\n",
      "Epoch 566/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9409 - accuracy: 0.3639 - val_loss: 5.8887 - val_accuracy: 0.2875\n",
      "Epoch 567/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9399 - accuracy: 0.2475 - val_loss: 5.8906 - val_accuracy: 0.2733\n",
      "Epoch 568/1000\n",
      "5600/5600 [==============================] - 0s 53us/sample - loss: 5.9394 - accuracy: 0.2952 - val_loss: 5.8907 - val_accuracy: 0.4042\n",
      "Epoch 569/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9404 - accuracy: 0.4543 - val_loss: 5.8899 - val_accuracy: 0.3758\n",
      "Epoch 570/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9391 - accuracy: 0.4038 - val_loss: 5.8890 - val_accuracy: 0.3804\n",
      "Epoch 571/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9395 - accuracy: 0.3732 - val_loss: 5.8890 - val_accuracy: 0.3550\n",
      "Epoch 572/1000\n",
      "5600/5600 [==============================] - 0s 53us/sample - loss: 5.9385 - accuracy: 0.3779 - val_loss: 5.8903 - val_accuracy: 0.3758\n",
      "Epoch 573/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9397 - accuracy: 0.3827 - val_loss: 5.8895 - val_accuracy: 0.3175\n",
      "Epoch 574/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9390 - accuracy: 0.3113 - val_loss: 5.8900 - val_accuracy: 0.2046\n",
      "Epoch 575/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9384 - accuracy: 0.1748 - val_loss: 5.8890 - val_accuracy: 0.2221\n",
      "Epoch 576/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9390 - accuracy: 0.2771 - val_loss: 5.8893 - val_accuracy: 0.2612\n",
      "Epoch 577/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9382 - accuracy: 0.3459 - val_loss: 5.8887 - val_accuracy: 0.3442\n",
      "Epoch 578/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9380 - accuracy: 0.3239 - val_loss: 5.8879 - val_accuracy: 0.2596\n",
      "Epoch 579/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9375 - accuracy: 0.3116 - val_loss: 5.8888 - val_accuracy: 0.2788\n",
      "Epoch 580/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9378 - accuracy: 0.2357 - val_loss: 5.8914 - val_accuracy: 0.2167\n",
      "Epoch 581/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9381 - accuracy: 0.3084 - val_loss: 5.8889 - val_accuracy: 0.2742\n",
      "Epoch 582/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9368 - accuracy: 0.2668 - val_loss: 5.8894 - val_accuracy: 0.2521\n",
      "Epoch 583/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9377 - accuracy: 0.2357 - val_loss: 5.8891 - val_accuracy: 0.1792\n",
      "Epoch 584/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9370 - accuracy: 0.1770 - val_loss: 5.8890 - val_accuracy: 0.1538\n",
      "Epoch 585/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9374 - accuracy: 0.1621 - val_loss: 5.8885 - val_accuracy: 0.1637\n",
      "Epoch 586/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9374 - accuracy: 0.1929 - val_loss: 5.8904 - val_accuracy: 0.1646\n",
      "Epoch 587/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9376 - accuracy: 0.2568 - val_loss: 5.8881 - val_accuracy: 0.3063\n",
      "Epoch 588/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9379 - accuracy: 0.3227 - val_loss: 5.8898 - val_accuracy: 0.2883\n",
      "Epoch 589/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9377 - accuracy: 0.3357 - val_loss: 5.8891 - val_accuracy: 0.2604\n",
      "Epoch 590/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9347 - accuracy: 0.3861 - val_loss: 5.8897 - val_accuracy: 0.4371\n",
      "Epoch 591/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9379 - accuracy: 0.3614 - val_loss: 5.8890 - val_accuracy: 0.2854\n",
      "Epoch 592/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9371 - accuracy: 0.3250 - val_loss: 5.8891 - val_accuracy: 0.1950\n",
      "Epoch 593/1000\n",
      "5600/5600 [==============================] - 0s 54us/sample - loss: 5.9361 - accuracy: 0.2288 - val_loss: 5.8885 - val_accuracy: 0.1867\n",
      "Epoch 594/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9358 - accuracy: 0.2537 - val_loss: 5.8886 - val_accuracy: 0.2696\n",
      "Epoch 595/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9361 - accuracy: 0.3123 - val_loss: 5.8900 - val_accuracy: 0.3396\n",
      "Epoch 596/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9366 - accuracy: 0.3479 - val_loss: 5.8882 - val_accuracy: 0.2433\n",
      "Epoch 597/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9355 - accuracy: 0.3179 - val_loss: 5.8888 - val_accuracy: 0.3742\n",
      "Epoch 598/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9351 - accuracy: 0.3607 - val_loss: 5.8889 - val_accuracy: 0.3275\n",
      "Epoch 599/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9362 - accuracy: 0.2848 - val_loss: 5.8905 - val_accuracy: 0.2288\n",
      "Epoch 600/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9353 - accuracy: 0.2732 - val_loss: 5.8887 - val_accuracy: 0.2225\n",
      "Epoch 601/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9356 - accuracy: 0.2396 - val_loss: 5.8893 - val_accuracy: 0.2612\n",
      "Epoch 602/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9348 - accuracy: 0.2391 - val_loss: 5.8889 - val_accuracy: 0.2183\n",
      "Epoch 603/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9352 - accuracy: 0.2091 - val_loss: 5.8891 - val_accuracy: 0.2796\n",
      "Epoch 604/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9346 - accuracy: 0.2364 - val_loss: 5.8888 - val_accuracy: 0.1946\n",
      "Epoch 605/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9351 - accuracy: 0.2025 - val_loss: 5.8886 - val_accuracy: 0.2746\n",
      "Epoch 606/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9347 - accuracy: 0.2868 - val_loss: 5.8905 - val_accuracy: 0.1471\n",
      "Epoch 607/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9360 - accuracy: 0.2170 - val_loss: 5.8901 - val_accuracy: 0.2875\n",
      "Epoch 608/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9343 - accuracy: 0.3363 - val_loss: 5.8890 - val_accuracy: 0.3350\n",
      "Epoch 609/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9343 - accuracy: 0.3154 - val_loss: 5.8892 - val_accuracy: 0.3108\n",
      "Epoch 610/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9346 - accuracy: 0.3373 - val_loss: 5.8888 - val_accuracy: 0.3321\n",
      "Epoch 611/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9359 - accuracy: 0.3429 - val_loss: 5.8893 - val_accuracy: 0.3067\n",
      "Epoch 612/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9346 - accuracy: 0.2921 - val_loss: 5.8889 - val_accuracy: 0.2792\n",
      "Epoch 613/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9341 - accuracy: 0.3139 - val_loss: 5.8887 - val_accuracy: 0.2812\n",
      "Epoch 614/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9345 - accuracy: 0.2936 - val_loss: 5.8894 - val_accuracy: 0.2233\n",
      "Epoch 615/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9354 - accuracy: 0.2237 - val_loss: 5.8886 - val_accuracy: 0.2404\n",
      "Epoch 616/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9333 - accuracy: 0.2643 - val_loss: 5.8892 - val_accuracy: 0.2996\n",
      "Epoch 617/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9335 - accuracy: 0.2377 - val_loss: 5.8886 - val_accuracy: 0.2092\n",
      "Epoch 618/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9341 - accuracy: 0.2711 - val_loss: 5.8885 - val_accuracy: 0.2392\n",
      "Epoch 619/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9341 - accuracy: 0.2714 - val_loss: 5.8886 - val_accuracy: 0.3292\n",
      "Epoch 620/1000\n",
      "5600/5600 [==============================] - 0s 53us/sample - loss: 5.9332 - accuracy: 0.3996 - val_loss: 5.8899 - val_accuracy: 0.3275\n",
      "Epoch 621/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9331 - accuracy: 0.3761 - val_loss: 5.8886 - val_accuracy: 0.3125\n",
      "Epoch 622/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9343 - accuracy: 0.2989 - val_loss: 5.8890 - val_accuracy: 0.2713\n",
      "Epoch 623/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9329 - accuracy: 0.2311 - val_loss: 5.8891 - val_accuracy: 0.2625\n",
      "Epoch 624/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9329 - accuracy: 0.2175 - val_loss: 5.8897 - val_accuracy: 0.2346\n",
      "Epoch 625/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9328 - accuracy: 0.3498 - val_loss: 5.8896 - val_accuracy: 0.3025\n",
      "Epoch 626/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9326 - accuracy: 0.2843 - val_loss: 5.8905 - val_accuracy: 0.1771\n",
      "Epoch 627/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9335 - accuracy: 0.1995 - val_loss: 5.8923 - val_accuracy: 0.2138\n",
      "Epoch 628/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9330 - accuracy: 0.2193 - val_loss: 5.8891 - val_accuracy: 0.2308\n",
      "Epoch 629/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9330 - accuracy: 0.3162 - val_loss: 5.8896 - val_accuracy: 0.3425\n",
      "Epoch 630/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9327 - accuracy: 0.3059 - val_loss: 5.8905 - val_accuracy: 0.2158\n",
      "Epoch 631/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9324 - accuracy: 0.3289 - val_loss: 5.8885 - val_accuracy: 0.3650\n",
      "Epoch 632/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9319 - accuracy: 0.3893 - val_loss: 5.8884 - val_accuracy: 0.3162\n",
      "Epoch 633/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9320 - accuracy: 0.3482 - val_loss: 5.8879 - val_accuracy: 0.3321\n",
      "Epoch 634/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9316 - accuracy: 0.2823 - val_loss: 5.8910 - val_accuracy: 0.3221\n",
      "Epoch 635/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9327 - accuracy: 0.3291 - val_loss: 5.8905 - val_accuracy: 0.3250\n",
      "Epoch 636/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9312 - accuracy: 0.3991 - val_loss: 5.8885 - val_accuracy: 0.3900\n",
      "Epoch 637/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9322 - accuracy: 0.3489 - val_loss: 5.8887 - val_accuracy: 0.2900\n",
      "Epoch 638/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9312 - accuracy: 0.2718 - val_loss: 5.8878 - val_accuracy: 0.2587\n",
      "Epoch 639/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9319 - accuracy: 0.2832 - val_loss: 5.8881 - val_accuracy: 0.2412\n",
      "Epoch 640/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9308 - accuracy: 0.2275 - val_loss: 5.8883 - val_accuracy: 0.2408\n",
      "Epoch 641/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9317 - accuracy: 0.3320 - val_loss: 5.8879 - val_accuracy: 0.3621\n",
      "Epoch 642/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9296 - accuracy: 0.2761 - val_loss: 5.8892 - val_accuracy: 0.2442\n",
      "Epoch 643/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9308 - accuracy: 0.2414 - val_loss: 5.8874 - val_accuracy: 0.2262\n",
      "Epoch 644/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9315 - accuracy: 0.2309 - val_loss: 5.8876 - val_accuracy: 0.2075\n",
      "Epoch 645/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9301 - accuracy: 0.3168 - val_loss: 5.8878 - val_accuracy: 0.3267\n",
      "Epoch 646/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9310 - accuracy: 0.3589 - val_loss: 5.8880 - val_accuracy: 0.2779\n",
      "Epoch 647/1000\n",
      "5600/5600 [==============================] - 0s 66us/sample - loss: 5.9297 - accuracy: 0.2496 - val_loss: 5.8891 - val_accuracy: 0.1746\n",
      "Epoch 648/1000\n",
      "5600/5600 [==============================] - 0s 61us/sample - loss: 5.9318 - accuracy: 0.1664 - val_loss: 5.8882 - val_accuracy: 0.2212\n",
      "Epoch 649/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9306 - accuracy: 0.2663 - val_loss: 5.8882 - val_accuracy: 0.2896\n",
      "Epoch 650/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9288 - accuracy: 0.3284 - val_loss: 5.8911 - val_accuracy: 0.3008\n",
      "Epoch 651/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9302 - accuracy: 0.2743 - val_loss: 5.8904 - val_accuracy: 0.2338\n",
      "Epoch 652/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9307 - accuracy: 0.3891 - val_loss: 5.8896 - val_accuracy: 0.3979\n",
      "Epoch 653/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9301 - accuracy: 0.4129 - val_loss: 5.8885 - val_accuracy: 0.2921\n",
      "Epoch 654/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9292 - accuracy: 0.3218 - val_loss: 5.8888 - val_accuracy: 0.3525\n",
      "Epoch 655/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9291 - accuracy: 0.3525 - val_loss: 5.8902 - val_accuracy: 0.3313\n",
      "Epoch 656/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9293 - accuracy: 0.3554 - val_loss: 5.8888 - val_accuracy: 0.4046\n",
      "Epoch 657/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9297 - accuracy: 0.3489 - val_loss: 5.8902 - val_accuracy: 0.3246\n",
      "Epoch 658/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9285 - accuracy: 0.3850 - val_loss: 5.8880 - val_accuracy: 0.3617\n",
      "Epoch 659/1000\n",
      "5600/5600 [==============================] - 0s 52us/sample - loss: 5.9306 - accuracy: 0.2630 - val_loss: 5.8886 - val_accuracy: 0.2992\n",
      "Epoch 660/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9293 - accuracy: 0.3438 - val_loss: 5.8886 - val_accuracy: 0.2892\n",
      "Epoch 661/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9290 - accuracy: 0.3139 - val_loss: 5.8891 - val_accuracy: 0.2729\n",
      "Epoch 662/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9281 - accuracy: 0.3089 - val_loss: 5.8903 - val_accuracy: 0.2250\n",
      "Epoch 663/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9288 - accuracy: 0.3577 - val_loss: 5.8878 - val_accuracy: 0.4071\n",
      "Epoch 664/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9301 - accuracy: 0.2771 - val_loss: 5.8907 - val_accuracy: 0.2288\n",
      "Epoch 665/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9291 - accuracy: 0.3591 - val_loss: 5.8907 - val_accuracy: 0.3229\n",
      "Epoch 666/1000\n",
      "5600/5600 [==============================] - 0s 52us/sample - loss: 5.9283 - accuracy: 0.2661 - val_loss: 5.8890 - val_accuracy: 0.2542\n",
      "Epoch 667/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9274 - accuracy: 0.2491 - val_loss: 5.8882 - val_accuracy: 0.2329\n",
      "Epoch 668/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9282 - accuracy: 0.2175 - val_loss: 5.8917 - val_accuracy: 0.2900\n",
      "Epoch 669/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9284 - accuracy: 0.3209 - val_loss: 5.8899 - val_accuracy: 0.2746\n",
      "Epoch 670/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9280 - accuracy: 0.2837 - val_loss: 5.8886 - val_accuracy: 0.2079\n",
      "Epoch 671/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9280 - accuracy: 0.3652 - val_loss: 5.8887 - val_accuracy: 0.3862\n",
      "Epoch 672/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9278 - accuracy: 0.3884 - val_loss: 5.8880 - val_accuracy: 0.3025\n",
      "Epoch 673/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9267 - accuracy: 0.3191 - val_loss: 5.8870 - val_accuracy: 0.2483\n",
      "Epoch 674/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9278 - accuracy: 0.1898 - val_loss: 5.8880 - val_accuracy: 0.1929\n",
      "Epoch 675/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9287 - accuracy: 0.2523 - val_loss: 5.8883 - val_accuracy: 0.2379\n",
      "Epoch 676/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9276 - accuracy: 0.2616 - val_loss: 5.8891 - val_accuracy: 0.2704\n",
      "Epoch 677/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9280 - accuracy: 0.3738 - val_loss: 5.8887 - val_accuracy: 0.4329\n",
      "Epoch 678/1000\n",
      "5600/5600 [==============================] - 0s 55us/sample - loss: 5.9278 - accuracy: 0.3954 - val_loss: 5.8876 - val_accuracy: 0.3892\n",
      "Epoch 679/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9269 - accuracy: 0.4105 - val_loss: 5.8893 - val_accuracy: 0.3992\n",
      "Epoch 680/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9269 - accuracy: 0.3039 - val_loss: 5.8891 - val_accuracy: 0.2521\n",
      "Epoch 681/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9246 - accuracy: 0.2509 - val_loss: 5.8882 - val_accuracy: 0.2454\n",
      "Epoch 682/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9275 - accuracy: 0.2780 - val_loss: 5.8884 - val_accuracy: 0.2954\n",
      "Epoch 683/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9265 - accuracy: 0.2957 - val_loss: 5.8881 - val_accuracy: 0.2833\n",
      "Epoch 684/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9263 - accuracy: 0.2630 - val_loss: 5.8878 - val_accuracy: 0.2288\n",
      "Epoch 685/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9259 - accuracy: 0.3123 - val_loss: 5.8876 - val_accuracy: 0.2892\n",
      "Epoch 686/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9262 - accuracy: 0.2759 - val_loss: 5.8876 - val_accuracy: 0.2946\n",
      "Epoch 687/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9265 - accuracy: 0.3209 - val_loss: 5.8875 - val_accuracy: 0.3633\n",
      "Epoch 688/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9262 - accuracy: 0.3641 - val_loss: 5.8888 - val_accuracy: 0.3179\n",
      "Epoch 689/1000\n",
      "5600/5600 [==============================] - 0s 66us/sample - loss: 5.9263 - accuracy: 0.3498 - val_loss: 5.8909 - val_accuracy: 0.3250\n",
      "Epoch 690/1000\n",
      "5600/5600 [==============================] - 0s 60us/sample - loss: 5.9261 - accuracy: 0.3357 - val_loss: 5.8878 - val_accuracy: 0.3971\n",
      "Epoch 691/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9253 - accuracy: 0.3748 - val_loss: 5.8879 - val_accuracy: 0.3183\n",
      "Epoch 692/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9252 - accuracy: 0.2186 - val_loss: 5.8884 - val_accuracy: 0.2104\n",
      "Epoch 693/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9251 - accuracy: 0.2041 - val_loss: 5.8881 - val_accuracy: 0.2738\n",
      "Epoch 694/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9246 - accuracy: 0.3088 - val_loss: 5.8876 - val_accuracy: 0.2875\n",
      "Epoch 695/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9251 - accuracy: 0.2943 - val_loss: 5.8906 - val_accuracy: 0.2367\n",
      "Epoch 696/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9252 - accuracy: 0.2861 - val_loss: 5.8874 - val_accuracy: 0.3067\n",
      "Epoch 697/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9255 - accuracy: 0.3336 - val_loss: 5.8868 - val_accuracy: 0.3013\n",
      "Epoch 698/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9252 - accuracy: 0.3027 - val_loss: 5.8873 - val_accuracy: 0.2463\n",
      "Epoch 699/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9254 - accuracy: 0.2425 - val_loss: 5.8892 - val_accuracy: 0.2212\n",
      "Epoch 700/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9245 - accuracy: 0.2966 - val_loss: 5.8891 - val_accuracy: 0.3250\n",
      "Epoch 701/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9248 - accuracy: 0.3055 - val_loss: 5.8874 - val_accuracy: 0.3346\n",
      "Epoch 702/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9251 - accuracy: 0.3254 - val_loss: 5.8869 - val_accuracy: 0.3308\n",
      "Epoch 703/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9251 - accuracy: 0.2652 - val_loss: 5.8873 - val_accuracy: 0.2779\n",
      "Epoch 704/1000\n",
      "5600/5600 [==============================] - 0s 53us/sample - loss: 5.9242 - accuracy: 0.3020 - val_loss: 5.8877 - val_accuracy: 0.2454\n",
      "Epoch 705/1000\n",
      "5600/5600 [==============================] - 0s 54us/sample - loss: 5.9247 - accuracy: 0.2295 - val_loss: 5.8874 - val_accuracy: 0.2254\n",
      "Epoch 706/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9238 - accuracy: 0.1545 - val_loss: 5.8877 - val_accuracy: 0.1833\n",
      "Epoch 707/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9240 - accuracy: 0.3309 - val_loss: 5.8880 - val_accuracy: 0.4200\n",
      "Epoch 708/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9238 - accuracy: 0.3321 - val_loss: 5.8878 - val_accuracy: 0.2983\n",
      "Epoch 709/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9233 - accuracy: 0.2850 - val_loss: 5.8869 - val_accuracy: 0.2079\n",
      "Epoch 710/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9228 - accuracy: 0.2639 - val_loss: 5.8881 - val_accuracy: 0.2675\n",
      "Epoch 711/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9226 - accuracy: 0.2900 - val_loss: 5.8873 - val_accuracy: 0.2783\n",
      "Epoch 712/1000\n",
      "5600/5600 [==============================] - 0s 53us/sample - loss: 5.9245 - accuracy: 0.2898 - val_loss: 5.8870 - val_accuracy: 0.2713\n",
      "Epoch 713/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9233 - accuracy: 0.3505 - val_loss: 5.8875 - val_accuracy: 0.4238\n",
      "Epoch 714/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9228 - accuracy: 0.4266 - val_loss: 5.8872 - val_accuracy: 0.3604\n",
      "Epoch 715/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9237 - accuracy: 0.2979 - val_loss: 5.8876 - val_accuracy: 0.3079\n",
      "Epoch 716/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9230 - accuracy: 0.3209 - val_loss: 5.8871 - val_accuracy: 0.2779\n",
      "Epoch 717/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9222 - accuracy: 0.2411 - val_loss: 5.8889 - val_accuracy: 0.2383\n",
      "Epoch 718/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9222 - accuracy: 0.2288 - val_loss: 5.8878 - val_accuracy: 0.1958\n",
      "Epoch 719/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9235 - accuracy: 0.2148 - val_loss: 5.8896 - val_accuracy: 0.1688\n",
      "Epoch 720/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9226 - accuracy: 0.2693 - val_loss: 5.8872 - val_accuracy: 0.2321\n",
      "Epoch 721/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9227 - accuracy: 0.2280 - val_loss: 5.8885 - val_accuracy: 0.2721\n",
      "Epoch 722/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9217 - accuracy: 0.3963 - val_loss: 5.8874 - val_accuracy: 0.4004\n",
      "Epoch 723/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9224 - accuracy: 0.4175 - val_loss: 5.8878 - val_accuracy: 0.4446\n",
      "Epoch 724/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9223 - accuracy: 0.3664 - val_loss: 5.8885 - val_accuracy: 0.3108\n",
      "Epoch 725/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9219 - accuracy: 0.3741 - val_loss: 5.8878 - val_accuracy: 0.3338\n",
      "Epoch 726/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9222 - accuracy: 0.3493 - val_loss: 5.8872 - val_accuracy: 0.4367\n",
      "Epoch 727/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9210 - accuracy: 0.3293 - val_loss: 5.8893 - val_accuracy: 0.3071\n",
      "Epoch 728/1000\n",
      "5600/5600 [==============================] - 0s 52us/sample - loss: 5.9215 - accuracy: 0.3350 - val_loss: 5.8887 - val_accuracy: 0.3146\n",
      "Epoch 729/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9215 - accuracy: 0.2907 - val_loss: 5.8877 - val_accuracy: 0.2421\n",
      "Epoch 730/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9202 - accuracy: 0.2454 - val_loss: 5.8907 - val_accuracy: 0.2279\n",
      "Epoch 731/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9222 - accuracy: 0.2777 - val_loss: 5.8887 - val_accuracy: 0.2504\n",
      "Epoch 732/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9223 - accuracy: 0.2611 - val_loss: 5.8899 - val_accuracy: 0.1929\n",
      "Epoch 733/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9204 - accuracy: 0.3729 - val_loss: 5.8877 - val_accuracy: 0.4033\n",
      "Epoch 734/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9206 - accuracy: 0.3964 - val_loss: 5.8869 - val_accuracy: 0.3267\n",
      "Epoch 735/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9207 - accuracy: 0.2782 - val_loss: 5.8895 - val_accuracy: 0.3088\n",
      "Epoch 736/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9209 - accuracy: 0.2725 - val_loss: 5.8885 - val_accuracy: 0.1717\n",
      "Epoch 737/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9204 - accuracy: 0.2005 - val_loss: 5.8876 - val_accuracy: 0.1988\n",
      "Epoch 738/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9210 - accuracy: 0.2332 - val_loss: 5.8887 - val_accuracy: 0.3867\n",
      "Epoch 739/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9201 - accuracy: 0.3848 - val_loss: 5.8881 - val_accuracy: 0.2546\n",
      "Epoch 740/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9204 - accuracy: 0.2488 - val_loss: 5.8877 - val_accuracy: 0.2146\n",
      "Epoch 741/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9202 - accuracy: 0.3304 - val_loss: 5.8876 - val_accuracy: 0.2350\n",
      "Epoch 742/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9200 - accuracy: 0.2218 - val_loss: 5.8887 - val_accuracy: 0.2200\n",
      "Epoch 743/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9199 - accuracy: 0.2755 - val_loss: 5.8889 - val_accuracy: 0.1704\n",
      "Epoch 744/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9203 - accuracy: 0.1873 - val_loss: 5.8869 - val_accuracy: 0.2275\n",
      "Epoch 745/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9198 - accuracy: 0.2534 - val_loss: 5.8878 - val_accuracy: 0.2142\n",
      "Epoch 746/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9198 - accuracy: 0.3257 - val_loss: 5.8883 - val_accuracy: 0.3821\n",
      "Epoch 747/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9192 - accuracy: 0.2343 - val_loss: 5.8886 - val_accuracy: 0.2079\n",
      "Epoch 748/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9196 - accuracy: 0.2986 - val_loss: 5.8902 - val_accuracy: 0.3400\n",
      "Epoch 749/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9189 - accuracy: 0.3959 - val_loss: 5.8879 - val_accuracy: 0.3988\n",
      "Epoch 750/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9182 - accuracy: 0.3811 - val_loss: 5.8892 - val_accuracy: 0.3392\n",
      "Epoch 751/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9191 - accuracy: 0.3005 - val_loss: 5.8879 - val_accuracy: 0.2554\n",
      "Epoch 752/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9191 - accuracy: 0.2313 - val_loss: 5.8877 - val_accuracy: 0.2062\n",
      "Epoch 753/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9193 - accuracy: 0.2037 - val_loss: 5.8869 - val_accuracy: 0.1958\n",
      "Epoch 754/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9186 - accuracy: 0.2636 - val_loss: 5.8877 - val_accuracy: 0.3042\n",
      "Epoch 755/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9210 - accuracy: 0.2929 - val_loss: 5.8887 - val_accuracy: 0.2046\n",
      "Epoch 756/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9184 - accuracy: 0.2643 - val_loss: 5.8882 - val_accuracy: 0.2425\n",
      "Epoch 757/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9193 - accuracy: 0.2718 - val_loss: 5.8908 - val_accuracy: 0.3063\n",
      "Epoch 758/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9193 - accuracy: 0.3409 - val_loss: 5.8900 - val_accuracy: 0.2438\n",
      "Epoch 759/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9192 - accuracy: 0.3357 - val_loss: 5.8897 - val_accuracy: 0.3571\n",
      "Epoch 760/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9176 - accuracy: 0.3807 - val_loss: 5.8915 - val_accuracy: 0.3233\n",
      "Epoch 761/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9186 - accuracy: 0.2929 - val_loss: 5.8885 - val_accuracy: 0.3133\n",
      "Epoch 762/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9188 - accuracy: 0.4038 - val_loss: 5.8894 - val_accuracy: 0.4346\n",
      "Epoch 763/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9166 - accuracy: 0.3691 - val_loss: 5.8889 - val_accuracy: 0.3550\n",
      "Epoch 764/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9181 - accuracy: 0.3082 - val_loss: 5.8905 - val_accuracy: 0.2221\n",
      "Epoch 765/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9185 - accuracy: 0.2705 - val_loss: 5.8891 - val_accuracy: 0.3233\n",
      "Epoch 766/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9181 - accuracy: 0.3798 - val_loss: 5.8897 - val_accuracy: 0.2958\n",
      "Epoch 767/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9163 - accuracy: 0.2746 - val_loss: 5.8890 - val_accuracy: 0.1971\n",
      "Epoch 768/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9167 - accuracy: 0.1823 - val_loss: 5.8923 - val_accuracy: 0.2154\n",
      "Epoch 769/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9181 - accuracy: 0.2359 - val_loss: 5.8904 - val_accuracy: 0.2292\n",
      "Epoch 770/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9173 - accuracy: 0.2116 - val_loss: 5.8897 - val_accuracy: 0.1842\n",
      "Epoch 771/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9171 - accuracy: 0.2820 - val_loss: 5.8912 - val_accuracy: 0.3442\n",
      "Epoch 772/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9161 - accuracy: 0.3636 - val_loss: 5.8887 - val_accuracy: 0.2750\n",
      "Epoch 773/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9172 - accuracy: 0.1863 - val_loss: 5.8903 - val_accuracy: 0.1675\n",
      "Epoch 774/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9170 - accuracy: 0.2380 - val_loss: 5.8889 - val_accuracy: 0.2929\n",
      "Epoch 775/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9163 - accuracy: 0.2148 - val_loss: 5.8918 - val_accuracy: 0.1283\n",
      "Epoch 776/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9175 - accuracy: 0.3043 - val_loss: 5.8887 - val_accuracy: 0.3767\n",
      "Epoch 777/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9165 - accuracy: 0.2705 - val_loss: 5.8897 - val_accuracy: 0.3604\n",
      "Epoch 778/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9157 - accuracy: 0.3745 - val_loss: 5.8932 - val_accuracy: 0.3413\n",
      "Epoch 779/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9161 - accuracy: 0.2680 - val_loss: 5.8896 - val_accuracy: 0.1742\n",
      "Epoch 780/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9166 - accuracy: 0.2204 - val_loss: 5.8879 - val_accuracy: 0.2113\n",
      "Epoch 781/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9161 - accuracy: 0.2098 - val_loss: 5.8885 - val_accuracy: 0.1513\n",
      "Epoch 782/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9153 - accuracy: 0.1348 - val_loss: 5.8889 - val_accuracy: 0.1533\n",
      "Epoch 783/1000\n",
      "5600/5600 [==============================] - 0s 54us/sample - loss: 5.9161 - accuracy: 0.1291 - val_loss: 5.8888 - val_accuracy: 0.1287\n",
      "Epoch 784/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9165 - accuracy: 0.1579 - val_loss: 5.8891 - val_accuracy: 0.2862\n",
      "Epoch 785/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9162 - accuracy: 0.2855 - val_loss: 5.8887 - val_accuracy: 0.2525\n",
      "Epoch 786/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9162 - accuracy: 0.3887 - val_loss: 5.8894 - val_accuracy: 0.4013\n",
      "Epoch 787/1000\n",
      "5600/5600 [==============================] - 0s 52us/sample - loss: 5.9160 - accuracy: 0.3491 - val_loss: 5.8895 - val_accuracy: 0.2617\n",
      "Epoch 788/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9151 - accuracy: 0.2636 - val_loss: 5.8904 - val_accuracy: 0.2767\n",
      "Epoch 789/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9159 - accuracy: 0.3491 - val_loss: 5.8888 - val_accuracy: 0.3837\n",
      "Epoch 790/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9152 - accuracy: 0.3821 - val_loss: 5.8891 - val_accuracy: 0.3896\n",
      "Epoch 791/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9155 - accuracy: 0.3698 - val_loss: 5.8905 - val_accuracy: 0.2754\n",
      "Epoch 792/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9144 - accuracy: 0.2739 - val_loss: 5.8934 - val_accuracy: 0.1621\n",
      "Epoch 793/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9152 - accuracy: 0.1612 - val_loss: 5.8911 - val_accuracy: 0.2087\n",
      "Epoch 794/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9148 - accuracy: 0.2020 - val_loss: 5.8898 - val_accuracy: 0.2325\n",
      "Epoch 795/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9143 - accuracy: 0.3070 - val_loss: 5.8927 - val_accuracy: 0.2904\n",
      "Epoch 796/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9145 - accuracy: 0.3641 - val_loss: 5.8904 - val_accuracy: 0.2587\n",
      "Epoch 797/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9140 - accuracy: 0.2998 - val_loss: 5.8903 - val_accuracy: 0.3850\n",
      "Epoch 798/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9140 - accuracy: 0.3930 - val_loss: 5.8989 - val_accuracy: 0.3917\n",
      "Epoch 799/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9141 - accuracy: 0.3550 - val_loss: 5.8918 - val_accuracy: 0.2288\n",
      "Epoch 800/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9144 - accuracy: 0.2473 - val_loss: 5.8916 - val_accuracy: 0.2637\n",
      "Epoch 801/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9136 - accuracy: 0.3180 - val_loss: 5.8907 - val_accuracy: 0.2846\n",
      "Epoch 802/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9137 - accuracy: 0.3350 - val_loss: 5.8903 - val_accuracy: 0.3137\n",
      "Epoch 803/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9131 - accuracy: 0.4034 - val_loss: 5.8932 - val_accuracy: 0.4638\n",
      "Epoch 804/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9137 - accuracy: 0.4625 - val_loss: 5.8901 - val_accuracy: 0.3879\n",
      "Epoch 805/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9135 - accuracy: 0.3277 - val_loss: 5.8908 - val_accuracy: 0.3150\n",
      "Epoch 806/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9142 - accuracy: 0.3377 - val_loss: 5.8905 - val_accuracy: 0.3346\n",
      "Epoch 807/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9118 - accuracy: 0.3293 - val_loss: 5.8917 - val_accuracy: 0.3054\n",
      "Epoch 808/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9125 - accuracy: 0.3029 - val_loss: 5.8902 - val_accuracy: 0.2512\n",
      "Epoch 809/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9132 - accuracy: 0.3311 - val_loss: 5.8909 - val_accuracy: 0.3963\n",
      "Epoch 810/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9128 - accuracy: 0.3079 - val_loss: 5.8913 - val_accuracy: 0.3217\n",
      "Epoch 811/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9122 - accuracy: 0.3082 - val_loss: 5.8924 - val_accuracy: 0.2733\n",
      "Epoch 812/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9116 - accuracy: 0.2377 - val_loss: 5.8918 - val_accuracy: 0.2508\n",
      "Epoch 813/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9127 - accuracy: 0.2773 - val_loss: 5.8904 - val_accuracy: 0.3158\n",
      "Epoch 814/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9125 - accuracy: 0.3537 - val_loss: 5.8907 - val_accuracy: 0.2700\n",
      "Epoch 815/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9124 - accuracy: 0.2775 - val_loss: 5.8913 - val_accuracy: 0.2804\n",
      "Epoch 816/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9119 - accuracy: 0.2057 - val_loss: 5.8906 - val_accuracy: 0.2117\n",
      "Epoch 817/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9118 - accuracy: 0.2114 - val_loss: 5.8904 - val_accuracy: 0.1804\n",
      "Epoch 818/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9108 - accuracy: 0.1873 - val_loss: 5.8902 - val_accuracy: 0.2775\n",
      "Epoch 819/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9116 - accuracy: 0.2882 - val_loss: 5.8918 - val_accuracy: 0.2688\n",
      "Epoch 820/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9109 - accuracy: 0.2420 - val_loss: 5.8900 - val_accuracy: 0.1912\n",
      "Epoch 821/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9115 - accuracy: 0.1416 - val_loss: 5.8905 - val_accuracy: 0.0887\n",
      "Epoch 822/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9123 - accuracy: 0.0966 - val_loss: 5.8920 - val_accuracy: 0.1133\n",
      "Epoch 823/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9112 - accuracy: 0.1870 - val_loss: 5.8917 - val_accuracy: 0.2958\n",
      "Epoch 824/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9122 - accuracy: 0.2809 - val_loss: 5.8912 - val_accuracy: 0.2946\n",
      "Epoch 825/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9110 - accuracy: 0.2702 - val_loss: 5.8923 - val_accuracy: 0.2946\n",
      "Epoch 826/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9113 - accuracy: 0.3414 - val_loss: 5.8925 - val_accuracy: 0.3629\n",
      "Epoch 827/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9107 - accuracy: 0.2695 - val_loss: 5.8923 - val_accuracy: 0.1392\n",
      "Epoch 828/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9106 - accuracy: 0.1471 - val_loss: 5.8916 - val_accuracy: 0.1467\n",
      "Epoch 829/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9095 - accuracy: 0.2266 - val_loss: 5.8906 - val_accuracy: 0.2937\n",
      "Epoch 830/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9079 - accuracy: 0.2663 - val_loss: 5.8970 - val_accuracy: 0.1433\n",
      "Epoch 831/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9112 - accuracy: 0.1482 - val_loss: 5.8935 - val_accuracy: 0.1942\n",
      "Epoch 832/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9105 - accuracy: 0.2030 - val_loss: 5.8919 - val_accuracy: 0.1267\n",
      "Epoch 833/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9084 - accuracy: 0.2377 - val_loss: 5.8950 - val_accuracy: 0.2254\n",
      "Epoch 834/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9109 - accuracy: 0.2770 - val_loss: 5.8924 - val_accuracy: 0.3175\n",
      "Epoch 835/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9096 - accuracy: 0.3102 - val_loss: 5.8947 - val_accuracy: 0.2721\n",
      "Epoch 836/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9112 - accuracy: 0.3086 - val_loss: 5.8927 - val_accuracy: 0.2879\n",
      "Epoch 837/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9093 - accuracy: 0.2918 - val_loss: 5.8913 - val_accuracy: 0.2750\n",
      "Epoch 838/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9097 - accuracy: 0.3061 - val_loss: 5.8917 - val_accuracy: 0.3633\n",
      "Epoch 839/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9091 - accuracy: 0.3527 - val_loss: 5.8921 - val_accuracy: 0.3171\n",
      "Epoch 840/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9097 - accuracy: 0.2323 - val_loss: 5.8912 - val_accuracy: 0.0925\n",
      "Epoch 841/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9097 - accuracy: 0.1323 - val_loss: 5.8917 - val_accuracy: 0.2175\n",
      "Epoch 842/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9096 - accuracy: 0.2829 - val_loss: 5.8914 - val_accuracy: 0.3129\n",
      "Epoch 843/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9096 - accuracy: 0.2582 - val_loss: 5.8922 - val_accuracy: 0.2050\n",
      "Epoch 844/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9092 - accuracy: 0.1911 - val_loss: 5.8944 - val_accuracy: 0.1458\n",
      "Epoch 845/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9091 - accuracy: 0.2232 - val_loss: 5.8917 - val_accuracy: 0.3558\n",
      "Epoch 846/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9091 - accuracy: 0.2973 - val_loss: 5.8940 - val_accuracy: 0.2646\n",
      "Epoch 847/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9093 - accuracy: 0.1889 - val_loss: 5.8933 - val_accuracy: 0.1529\n",
      "Epoch 848/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9086 - accuracy: 0.2248 - val_loss: 5.8928 - val_accuracy: 0.3317\n",
      "Epoch 849/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9087 - accuracy: 0.2412 - val_loss: 5.8928 - val_accuracy: 0.2642\n",
      "Epoch 850/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9080 - accuracy: 0.2105 - val_loss: 5.8959 - val_accuracy: 0.0979\n",
      "Epoch 851/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9084 - accuracy: 0.1248 - val_loss: 5.8922 - val_accuracy: 0.1500\n",
      "Epoch 852/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9074 - accuracy: 0.1664 - val_loss: 5.8921 - val_accuracy: 0.1304\n",
      "Epoch 853/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9074 - accuracy: 0.2127 - val_loss: 5.8929 - val_accuracy: 0.2500\n",
      "Epoch 854/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9066 - accuracy: 0.2404 - val_loss: 5.8919 - val_accuracy: 0.1688\n",
      "Epoch 855/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9095 - accuracy: 0.2939 - val_loss: 5.8915 - val_accuracy: 0.3671\n",
      "Epoch 856/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9076 - accuracy: 0.3873 - val_loss: 5.8922 - val_accuracy: 0.3842\n",
      "Epoch 857/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9079 - accuracy: 0.2555 - val_loss: 5.8929 - val_accuracy: 0.1354\n",
      "Epoch 858/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9075 - accuracy: 0.1102 - val_loss: 5.8926 - val_accuracy: 0.1296\n",
      "Epoch 859/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9078 - accuracy: 0.1023 - val_loss: 5.8934 - val_accuracy: 0.0842\n",
      "Epoch 860/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9082 - accuracy: 0.1325 - val_loss: 5.8928 - val_accuracy: 0.1950\n",
      "Epoch 861/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9068 - accuracy: 0.2566 - val_loss: 5.8930 - val_accuracy: 0.3067\n",
      "Epoch 862/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9071 - accuracy: 0.2380 - val_loss: 5.8922 - val_accuracy: 0.1521\n",
      "Epoch 863/1000\n",
      "5600/5600 [==============================] - 0s 52us/sample - loss: 5.9069 - accuracy: 0.1568 - val_loss: 5.8923 - val_accuracy: 0.1637\n",
      "Epoch 864/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9077 - accuracy: 0.1262 - val_loss: 5.8918 - val_accuracy: 0.1121\n",
      "Epoch 865/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9080 - accuracy: 0.1352 - val_loss: 5.8925 - val_accuracy: 0.2171\n",
      "Epoch 866/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9066 - accuracy: 0.2262 - val_loss: 5.8932 - val_accuracy: 0.1833\n",
      "Epoch 867/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9062 - accuracy: 0.1896 - val_loss: 5.8929 - val_accuracy: 0.2242\n",
      "Epoch 868/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9060 - accuracy: 0.2191 - val_loss: 5.8937 - val_accuracy: 0.2571\n",
      "Epoch 869/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9059 - accuracy: 0.2998 - val_loss: 5.8926 - val_accuracy: 0.2804\n",
      "Epoch 870/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9056 - accuracy: 0.2195 - val_loss: 5.8938 - val_accuracy: 0.1700\n",
      "Epoch 871/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9071 - accuracy: 0.1764 - val_loss: 5.8918 - val_accuracy: 0.1575\n",
      "Epoch 872/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9074 - accuracy: 0.2579 - val_loss: 5.8937 - val_accuracy: 0.3596\n",
      "Epoch 873/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9062 - accuracy: 0.4159 - val_loss: 5.8923 - val_accuracy: 0.3667\n",
      "Epoch 874/1000\n",
      "5600/5600 [==============================] - 0s 52us/sample - loss: 5.9058 - accuracy: 0.4071 - val_loss: 5.8924 - val_accuracy: 0.3713\n",
      "Epoch 875/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9061 - accuracy: 0.4005 - val_loss: 5.8914 - val_accuracy: 0.3113\n",
      "Epoch 876/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9065 - accuracy: 0.2666 - val_loss: 5.8918 - val_accuracy: 0.2704\n",
      "Epoch 877/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9049 - accuracy: 0.3600 - val_loss: 5.8943 - val_accuracy: 0.3608\n",
      "Epoch 878/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9063 - accuracy: 0.2995 - val_loss: 5.8930 - val_accuracy: 0.2379\n",
      "Epoch 879/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9056 - accuracy: 0.3657 - val_loss: 5.8932 - val_accuracy: 0.4658\n",
      "Epoch 880/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9068 - accuracy: 0.5384 - val_loss: 5.8952 - val_accuracy: 0.3383\n",
      "Epoch 881/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9067 - accuracy: 0.2495 - val_loss: 5.8919 - val_accuracy: 0.1454\n",
      "Epoch 882/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9047 - accuracy: 0.2018 - val_loss: 5.8912 - val_accuracy: 0.3671\n",
      "Epoch 883/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9061 - accuracy: 0.3252 - val_loss: 5.8943 - val_accuracy: 0.2937\n",
      "Epoch 884/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9050 - accuracy: 0.3400 - val_loss: 5.8927 - val_accuracy: 0.3658\n",
      "Epoch 885/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9061 - accuracy: 0.3938 - val_loss: 5.8925 - val_accuracy: 0.4162\n",
      "Epoch 886/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9064 - accuracy: 0.3032 - val_loss: 5.8928 - val_accuracy: 0.2188\n",
      "Epoch 887/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9085 - accuracy: 0.2145 - val_loss: 5.8919 - val_accuracy: 0.1754\n",
      "Epoch 888/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9022 - accuracy: 0.1907 - val_loss: 5.8975 - val_accuracy: 0.2200\n",
      "Epoch 889/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9060 - accuracy: 0.2455 - val_loss: 5.8922 - val_accuracy: 0.2404\n",
      "Epoch 890/1000\n",
      "5600/5600 [==============================] - 0s 54us/sample - loss: 5.9043 - accuracy: 0.3316 - val_loss: 5.8925 - val_accuracy: 0.3883\n",
      "Epoch 891/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9038 - accuracy: 0.2518 - val_loss: 5.8922 - val_accuracy: 0.1742\n",
      "Epoch 892/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9048 - accuracy: 0.1445 - val_loss: 5.8923 - val_accuracy: 0.1567\n",
      "Epoch 893/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9042 - accuracy: 0.1871 - val_loss: 5.8947 - val_accuracy: 0.2675\n",
      "Epoch 894/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9051 - accuracy: 0.3111 - val_loss: 5.8942 - val_accuracy: 0.3338\n",
      "Epoch 895/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9040 - accuracy: 0.2521 - val_loss: 5.8921 - val_accuracy: 0.1471\n",
      "Epoch 896/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9039 - accuracy: 0.1827 - val_loss: 5.8932 - val_accuracy: 0.2138\n",
      "Epoch 897/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9038 - accuracy: 0.2475 - val_loss: 5.8926 - val_accuracy: 0.2113\n",
      "Epoch 898/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9037 - accuracy: 0.1793 - val_loss: 5.8942 - val_accuracy: 0.1125\n",
      "Epoch 899/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9045 - accuracy: 0.1088 - val_loss: 5.8924 - val_accuracy: 0.1154\n",
      "Epoch 900/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9040 - accuracy: 0.1257 - val_loss: 5.8919 - val_accuracy: 0.1367\n",
      "Epoch 901/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9046 - accuracy: 0.1248 - val_loss: 5.8927 - val_accuracy: 0.1621\n",
      "Epoch 902/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9037 - accuracy: 0.2468 - val_loss: 5.8933 - val_accuracy: 0.3862\n",
      "Epoch 903/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9037 - accuracy: 0.2655 - val_loss: 5.8925 - val_accuracy: 0.1692\n",
      "Epoch 904/1000\n",
      "5600/5600 [==============================] - 0s 56us/sample - loss: 5.9039 - accuracy: 0.2539 - val_loss: 5.8935 - val_accuracy: 0.2550\n",
      "Epoch 905/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9045 - accuracy: 0.1843 - val_loss: 5.8929 - val_accuracy: 0.1963\n",
      "Epoch 906/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9036 - accuracy: 0.1675 - val_loss: 5.8936 - val_accuracy: 0.1967\n",
      "Epoch 907/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9024 - accuracy: 0.2525 - val_loss: 5.8923 - val_accuracy: 0.3333\n",
      "Epoch 908/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9037 - accuracy: 0.2604 - val_loss: 5.8932 - val_accuracy: 0.1300\n",
      "Epoch 909/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9032 - accuracy: 0.1287 - val_loss: 5.8929 - val_accuracy: 0.1479\n",
      "Epoch 910/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9038 - accuracy: 0.1605 - val_loss: 5.8928 - val_accuracy: 0.1742\n",
      "Epoch 911/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9021 - accuracy: 0.2073 - val_loss: 5.8955 - val_accuracy: 0.1937\n",
      "Epoch 912/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9027 - accuracy: 0.2113 - val_loss: 5.8970 - val_accuracy: 0.2046\n",
      "Epoch 913/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9031 - accuracy: 0.2368 - val_loss: 5.8932 - val_accuracy: 0.3150\n",
      "Epoch 914/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9029 - accuracy: 0.2452 - val_loss: 5.8930 - val_accuracy: 0.3421\n",
      "Epoch 915/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9022 - accuracy: 0.3379 - val_loss: 5.8930 - val_accuracy: 0.2767\n",
      "Epoch 916/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.9019 - accuracy: 0.2905 - val_loss: 5.8944 - val_accuracy: 0.2508\n",
      "Epoch 917/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9021 - accuracy: 0.1852 - val_loss: 5.8950 - val_accuracy: 0.0846\n",
      "Epoch 918/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9022 - accuracy: 0.1180 - val_loss: 5.8933 - val_accuracy: 0.1804\n",
      "Epoch 919/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9031 - accuracy: 0.1918 - val_loss: 5.8952 - val_accuracy: 0.2175\n",
      "Epoch 920/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9010 - accuracy: 0.1887 - val_loss: 5.8939 - val_accuracy: 0.2096\n",
      "Epoch 921/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9031 - accuracy: 0.1905 - val_loss: 5.8941 - val_accuracy: 0.2100\n",
      "Epoch 922/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9017 - accuracy: 0.2873 - val_loss: 5.8927 - val_accuracy: 0.2738\n",
      "Epoch 923/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9022 - accuracy: 0.2968 - val_loss: 5.8921 - val_accuracy: 0.2042\n",
      "Epoch 924/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9022 - accuracy: 0.1396 - val_loss: 5.8928 - val_accuracy: 0.1258\n",
      "Epoch 925/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9012 - accuracy: 0.1884 - val_loss: 5.8939 - val_accuracy: 0.2271\n",
      "Epoch 926/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9018 - accuracy: 0.2195 - val_loss: 5.8921 - val_accuracy: 0.1996\n",
      "Epoch 927/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9020 - accuracy: 0.2204 - val_loss: 5.8945 - val_accuracy: 0.2600\n",
      "Epoch 928/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9017 - accuracy: 0.1764 - val_loss: 5.8937 - val_accuracy: 0.0867\n",
      "Epoch 929/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9008 - accuracy: 0.1732 - val_loss: 5.8942 - val_accuracy: 0.3608\n",
      "Epoch 930/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9018 - accuracy: 0.3329 - val_loss: 5.8946 - val_accuracy: 0.3083\n",
      "Epoch 931/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9010 - accuracy: 0.3380 - val_loss: 5.8923 - val_accuracy: 0.2783\n",
      "Epoch 932/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9010 - accuracy: 0.2471 - val_loss: 5.8958 - val_accuracy: 0.2292\n",
      "Epoch 933/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9013 - accuracy: 0.1809 - val_loss: 5.8936 - val_accuracy: 0.2042\n",
      "Epoch 934/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9011 - accuracy: 0.1591 - val_loss: 5.8936 - val_accuracy: 0.1375\n",
      "Epoch 935/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.8998 - accuracy: 0.1782 - val_loss: 5.8948 - val_accuracy: 0.2013\n",
      "Epoch 936/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9012 - accuracy: 0.1480 - val_loss: 5.8945 - val_accuracy: 0.1179\n",
      "Epoch 937/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9005 - accuracy: 0.2384 - val_loss: 5.8946 - val_accuracy: 0.2358\n",
      "Epoch 938/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9004 - accuracy: 0.1789 - val_loss: 5.8927 - val_accuracy: 0.0846\n",
      "Epoch 939/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9010 - accuracy: 0.0900 - val_loss: 5.8935 - val_accuracy: 0.0858\n",
      "Epoch 940/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9012 - accuracy: 0.1389 - val_loss: 5.8939 - val_accuracy: 0.1850\n",
      "Epoch 941/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.8998 - accuracy: 0.2013 - val_loss: 5.8942 - val_accuracy: 0.2067\n",
      "Epoch 942/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9004 - accuracy: 0.2313 - val_loss: 5.8953 - val_accuracy: 0.1904\n",
      "Epoch 943/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8999 - accuracy: 0.1959 - val_loss: 5.8935 - val_accuracy: 0.1925\n",
      "Epoch 944/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9006 - accuracy: 0.2486 - val_loss: 5.8933 - val_accuracy: 0.3029\n",
      "Epoch 945/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.8998 - accuracy: 0.2996 - val_loss: 5.8937 - val_accuracy: 0.3071\n",
      "Epoch 946/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.9002 - accuracy: 0.2275 - val_loss: 5.8967 - val_accuracy: 0.1587\n",
      "Epoch 947/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9012 - accuracy: 0.2055 - val_loss: 5.8941 - val_accuracy: 0.4233\n",
      "Epoch 948/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9003 - accuracy: 0.3439 - val_loss: 5.8930 - val_accuracy: 0.3092\n",
      "Epoch 949/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8996 - accuracy: 0.2188 - val_loss: 5.8935 - val_accuracy: 0.1804\n",
      "Epoch 950/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.8992 - accuracy: 0.1762 - val_loss: 5.8935 - val_accuracy: 0.1046\n",
      "Epoch 951/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8990 - accuracy: 0.1521 - val_loss: 5.8972 - val_accuracy: 0.1854\n",
      "Epoch 952/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9003 - accuracy: 0.2025 - val_loss: 5.8933 - val_accuracy: 0.1600\n",
      "Epoch 953/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9001 - accuracy: 0.2054 - val_loss: 5.8934 - val_accuracy: 0.2163\n",
      "Epoch 954/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9001 - accuracy: 0.1720 - val_loss: 5.8933 - val_accuracy: 0.1142\n",
      "Epoch 955/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.8982 - accuracy: 0.1180 - val_loss: 5.8976 - val_accuracy: 0.0967\n",
      "Epoch 956/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8988 - accuracy: 0.1239 - val_loss: 5.8930 - val_accuracy: 0.1017\n",
      "Epoch 957/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8994 - accuracy: 0.1587 - val_loss: 5.8949 - val_accuracy: 0.2188\n",
      "Epoch 958/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8999 - accuracy: 0.3177 - val_loss: 5.8938 - val_accuracy: 0.2892\n",
      "Epoch 959/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9003 - accuracy: 0.2268 - val_loss: 5.8929 - val_accuracy: 0.1996\n",
      "Epoch 960/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.8971 - accuracy: 0.2464 - val_loss: 5.8929 - val_accuracy: 0.3117\n",
      "Epoch 961/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.9001 - accuracy: 0.2691 - val_loss: 5.8942 - val_accuracy: 0.1838\n",
      "Epoch 962/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8984 - accuracy: 0.2134 - val_loss: 5.8932 - val_accuracy: 0.3050\n",
      "Epoch 963/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8991 - accuracy: 0.3207 - val_loss: 5.8954 - val_accuracy: 0.2833\n",
      "Epoch 964/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8981 - accuracy: 0.2923 - val_loss: 5.8935 - val_accuracy: 0.3054\n",
      "Epoch 965/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8994 - accuracy: 0.2264 - val_loss: 5.8947 - val_accuracy: 0.1875\n",
      "Epoch 966/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8983 - accuracy: 0.2416 - val_loss: 5.8949 - val_accuracy: 0.2321\n",
      "Epoch 967/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8980 - accuracy: 0.1454 - val_loss: 5.8941 - val_accuracy: 0.1317\n",
      "Epoch 968/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8984 - accuracy: 0.1357 - val_loss: 5.8939 - val_accuracy: 0.1754\n",
      "Epoch 969/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8979 - accuracy: 0.3100 - val_loss: 5.8941 - val_accuracy: 0.3167\n",
      "Epoch 970/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8999 - accuracy: 0.2539 - val_loss: 5.8936 - val_accuracy: 0.1867\n",
      "Epoch 971/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8985 - accuracy: 0.2537 - val_loss: 5.8936 - val_accuracy: 0.2625\n",
      "Epoch 972/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.8982 - accuracy: 0.3275 - val_loss: 5.8930 - val_accuracy: 0.3383\n",
      "Epoch 973/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8981 - accuracy: 0.4321 - val_loss: 5.8935 - val_accuracy: 0.4387\n",
      "Epoch 974/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8977 - accuracy: 0.3852 - val_loss: 5.8933 - val_accuracy: 0.2546\n",
      "Epoch 975/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.8982 - accuracy: 0.2209 - val_loss: 5.8938 - val_accuracy: 0.1467\n",
      "Epoch 976/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8970 - accuracy: 0.2196 - val_loss: 5.8938 - val_accuracy: 0.2146\n",
      "Epoch 977/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8973 - accuracy: 0.2861 - val_loss: 5.8937 - val_accuracy: 0.3000\n",
      "Epoch 978/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8971 - accuracy: 0.3243 - val_loss: 5.8939 - val_accuracy: 0.2475\n",
      "Epoch 979/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.8974 - accuracy: 0.2484 - val_loss: 5.8944 - val_accuracy: 0.1887\n",
      "Epoch 980/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8975 - accuracy: 0.2259 - val_loss: 5.8948 - val_accuracy: 0.2221\n",
      "Epoch 981/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8975 - accuracy: 0.1988 - val_loss: 5.8946 - val_accuracy: 0.1450\n",
      "Epoch 982/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8981 - accuracy: 0.1182 - val_loss: 5.8949 - val_accuracy: 0.1050\n",
      "Epoch 983/1000\n",
      "5600/5600 [==============================] - 0s 51us/sample - loss: 5.8985 - accuracy: 0.0841 - val_loss: 5.8971 - val_accuracy: 0.0908\n",
      "Epoch 984/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8977 - accuracy: 0.0923 - val_loss: 5.8993 - val_accuracy: 0.0763\n",
      "Epoch 985/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8978 - accuracy: 0.0930 - val_loss: 5.8954 - val_accuracy: 0.1187\n",
      "Epoch 986/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8973 - accuracy: 0.1155 - val_loss: 5.8949 - val_accuracy: 0.1021\n",
      "Epoch 987/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8972 - accuracy: 0.0793 - val_loss: 5.8953 - val_accuracy: 0.0871\n",
      "Epoch 988/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.8977 - accuracy: 0.1259 - val_loss: 5.8963 - val_accuracy: 0.2254\n",
      "Epoch 989/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8962 - accuracy: 0.2823 - val_loss: 5.8960 - val_accuracy: 0.1604\n",
      "Epoch 990/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8974 - accuracy: 0.1409 - val_loss: 5.8951 - val_accuracy: 0.2104\n",
      "Epoch 991/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8968 - accuracy: 0.2236 - val_loss: 5.8959 - val_accuracy: 0.1600\n",
      "Epoch 992/1000\n",
      "5600/5600 [==============================] - 0s 53us/sample - loss: 5.8974 - accuracy: 0.1043 - val_loss: 5.8942 - val_accuracy: 0.0879\n",
      "Epoch 993/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8969 - accuracy: 0.0939 - val_loss: 5.8945 - val_accuracy: 0.0608\n",
      "Epoch 994/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8964 - accuracy: 0.1289 - val_loss: 5.8983 - val_accuracy: 0.1850\n",
      "Epoch 995/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8966 - accuracy: 0.1863 - val_loss: 5.8938 - val_accuracy: 0.1421\n",
      "Epoch 996/1000\n",
      "5600/5600 [==============================] - 0s 54us/sample - loss: 5.8962 - accuracy: 0.1486 - val_loss: 5.8946 - val_accuracy: 0.1417\n",
      "Epoch 997/1000\n",
      "5600/5600 [==============================] - 0s 49us/sample - loss: 5.8972 - accuracy: 0.1700 - val_loss: 5.8956 - val_accuracy: 0.1679\n",
      "Epoch 998/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8970 - accuracy: 0.1420 - val_loss: 5.8953 - val_accuracy: 0.1596\n",
      "Epoch 999/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8961 - accuracy: 0.1663 - val_loss: 5.8973 - val_accuracy: 0.1467\n",
      "Epoch 1000/1000\n",
      "5600/5600 [==============================] - 0s 50us/sample - loss: 5.8962 - accuracy: 0.1468 - val_loss: 5.8959 - val_accuracy: 0.1138\n"
     ]
    }
   ],
   "source": [
    "# quantitative: ANN\n",
    "# specify network layers\n",
    "quant_ann = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(5, activation = 'sigmoid', input_shape = (28, )),\n",
    "    tf.keras.layers.Dense(10, activation = 'linear')\n",
    "])\n",
    "\n",
    "# compile and fit network\n",
    "quant_ann.compile(loss = 'mean_absolute_error', optimizer = 'adam', metrics = ['accuracy']) \n",
    "history = quant_ann.fit(X_train, y_train, epochs = 1000, batch_size = 32, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy vs. Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Training', 'Validation'], loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
